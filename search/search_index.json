{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"uorf4u Description uorf4u is a bioinformatics tool for annotation conserved upstream ORFs. Programming languages: Python3 OS: MacOS, Linux Python dependencies: biopython, configs, argparse, pandas, statistics, logomaker, matplotlib, reportlab. R dependencies: ggmsa, ggplot2, optparse OS-level dependencies: muscle License: WTFPL Version: 0.4.0 (August 2022) Data analysis pipeline: Installation The most stable release of uorf4u can be installed directly from pypi: python3 -m pip install uorf4u The development version is available at github : git clone https://github.com/art-egorov/uorf4u.git cd uorf4u python3 -m pip install --upgrade pip python3 -m pip install wheel python3 setup.py sdist bdist_wheel python3 -m pip install -e . Reference If you find uorf4u useful, please cite: Artyom A. Egorov, Gemma C. Atkinson uorf4u: ..., ---, doi Contact Please contact us by e-mail artem dot egorov AT med dot lu dot se or use Issues to report any technical problems. Authors uorf4u is developed by Artyom Egorov at the Atkinson Lab , Department of Experimental Medical Science, Lund University, Sweden. We are open for suggestions to extend and improve svist4get functionality. Please don't hesitate to share your ideas or feature requests.","title":"Home"},{"location":"#uorf4u","text":"","title":"uorf4u"},{"location":"#description","text":"uorf4u is a bioinformatics tool for annotation conserved upstream ORFs. Programming languages: Python3 OS: MacOS, Linux Python dependencies: biopython, configs, argparse, pandas, statistics, logomaker, matplotlib, reportlab. R dependencies: ggmsa, ggplot2, optparse OS-level dependencies: muscle License: WTFPL Version: 0.4.0 (August 2022)","title":"Description"},{"location":"#data-analysis-pipeline","text":"","title":"Data analysis pipeline:"},{"location":"#installation","text":"The most stable release of uorf4u can be installed directly from pypi: python3 -m pip install uorf4u The development version is available at github : git clone https://github.com/art-egorov/uorf4u.git cd uorf4u python3 -m pip install --upgrade pip python3 -m pip install wheel python3 setup.py sdist bdist_wheel python3 -m pip install -e .","title":"Installation"},{"location":"#reference","text":"If you find uorf4u useful, please cite: Artyom A. Egorov, Gemma C. Atkinson uorf4u: ..., ---, doi","title":"Reference"},{"location":"#contact","text":"Please contact us by e-mail artem dot egorov AT med dot lu dot se or use Issues to report any technical problems.","title":"Contact"},{"location":"#authors","text":"uorf4u is developed by Artyom Egorov at the Atkinson Lab , Department of Experimental Medical Science, Lund University, Sweden. We are open for suggestions to extend and improve svist4get functionality. Please don't hesitate to share your ideas or feature requests.","title":"Authors"},{"location":"API/package/","text":"data_processing submodule This module provides data processing including uORFs annotation and conserved subset searching. Homologues A Homologues object holds list of proteins homologues and information about them. Attributes: accession_numbers ( list ) \u2013 List of RefSeq accession numbers. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. records ( list ) \u2013 list of RefSeqProtein objects of the proteins. upstream_sequences ( list ) \u2013 List of dicts with SeqRecords objects and other information codon_table ( Bio . Data . CodonTable . CodonTable ) \u2013 Codon table (genetic code). conserved_paths ( list ) \u2013 list of Path's objects (Path class holds list of ORFs from different upstream sequences and information about them). Source code in uorf4u/data_processing.py 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 class Homologues : \"\"\"A Homologues object holds list of proteins homologues and information about them. Attributes: accession_numbers (list): List of RefSeq accession numbers. parameters (uorf4u.manager.Parameters): Parameters' class object. records (list): list of RefSeqProtein objects of the proteins. upstream_sequences (list): List of dicts with SeqRecords objects and other information (including annotated ORFs saved under the 'ORFs' key) about the upstream sequences. codon_table (Bio.Data.CodonTable.CodonTable): Codon table (genetic code). conserved_paths (list): list of Path's objects (Path class holds list of ORFs from different upstream sequences and information about them). \"\"\" def __init__ ( self , accession_numbers : list , parameters : uorf4u . manager . Parameters ): \"\"\"Create a Homologues object. Note: With initialisation it also creates a 'records' attribute - a list of RefSeqProtein objects of proteins based on accession numbers list. Arguments: accession_numbers (list): List of RefSeq accession numbers. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" try : self . accession_numbers = accession_numbers self . parameters = parameters self . records = [ RefSeqProtein ( i , parameters ) for i in accession_numbers ] self . upstream_sequences = None self . codon_table = Bio . Data . CodonTable . unambiguous_dna_by_name [ parameters . arguments [ \"ncbi_genetic_code_name\" ]] self . conserved_paths = None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to create a Homologues class' object.\" ) from error def get_upstream_sequences ( self ) -> list : \"\"\"Get upstream sequences of proteins' genes. Note: A protein may be found in several assemblies (for example in different strains). Returns: list: List of dicts with SeqRecords objects and other information about upstream sequences. \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udce1 Retrieving upstream sequences...\" , file = sys . stdout ) for record in self . records : record . get_assemblies () if self . parameters . arguments [ \"assemblies_list\" ] == 'NA' : assemblies_table = [ f \"accession_number \\t locus_id \\t assembly \\t organism \\t strain \\t tax_id\" ] list_of_protein_with_multiple_assemblies = [] numbers_of_assemblies = [] for record in self . records : if len ( record . assemblies_coordinates ) > 1 : list_of_protein_with_multiple_assemblies . append ( record . accession_number ) numbers_of_assemblies . append ( len ( record . assemblies_coordinates )) for assembly in record . assemblies_coordinates : assemblies_table . append ( f \" { record . accession_number } \\t { assembly [ 'locus_id' ] } \\t { assembly [ 'assembly' ] } \" f \" \\t { assembly [ 'org' ] } \\t { assembly [ 'strain' ] } \\t { assembly [ 'taxid' ] } \" ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) assemblies_table_path = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"assemblies_list.tsv\" ) assemblies_table_file = open ( assemblies_table_path , \"w\" ) assemblies_table_file . write ( \" \\n \" . join ( assemblies_table )) assemblies_table_file . close () if len ( list_of_protein_with_multiple_assemblies ) > 0 : print ( f \"\u2757\ufe0fWarning message: \\n\\t For { len ( list_of_protein_with_multiple_assemblies ) } proteins \" f \"several assemblies were found in identical protein database \\n \" f \" \\t with max number of assemblies per one protein as { max ( numbers_of_assemblies ) } \ud83d\ude31. \\n\\t \" f \"A table with information about the assemblies was saved as a tsv file: \" f \" { assemblies_table_path } . \\n\\t You can edit it and remove lines with assemblies \" f \"you do not want to include in your analysis. \\n \" f \" \\t After filtering, you can use -al cmd parameter with your table as an argument. \\n \" f \" \\t In addition, config file has 'max_number_of_assemblies' parameter \" f \"(set as { self . parameters . arguments [ 'max_number_of_assemblies' ] } ). \\n\\t By default \u2755, it's used \" f \"by uorf4u to limit max number of assemblies included in the analysis; \\n \" f \" \\t and it works only if '-al' option is not provided. In case number of assemblies is more than \" f \"the cutoff, \\n\\t random sampling \ud83c\udfb2 will be used to take only subset of them. \\n\\t \" f \"See documentation \ud83d\udcd6 for details.\" , file = sys . stderr ) else : assemblies_table = pandas . read_table ( self . parameters . arguments [ \"assemblies_list\" ], sep = \" \\t \" ) locus_ids = assemblies_table [ \"locus_id\" ] . to_list () upstream_sequences = [] an_with_no_annotated_useq = [] for record in self . records : assemblies = record . assemblies_coordinates if isinstance ( self . parameters . arguments [ \"max_number_of_assemblies\" ], int ) and \\ self . parameters . arguments [ \"assemblies_list\" ] == \"NA\" : if len ( assemblies ) >= self . parameters . arguments [ \"max_number_of_assemblies\" ]: assemblies = random . sample ( assemblies , self . parameters . arguments [ \"max_number_of_assemblies\" ]) if self . parameters . arguments [ \"assemblies_list\" ] != \"NA\" : assemblies_filtered = [ i for i in assemblies if i [ \"locus_id\" ] in locus_ids ] assemblies = assemblies_filtered record_upstream_sequences = [] for assembly in assemblies : handle = Bio . Entrez . efetch ( db = \"nucleotide\" , rettype = \"fasta\" , retmode = \"txt\" , id = assembly [ \"locus_id\" ]) locus_record = Bio . SeqIO . read ( handle , \"fasta\" ) useq_downstream_region_length = self . parameters . arguments [ \"downstream_region_length\" ] useq_upstream_region_length = self . parameters . arguments [ \"upstream_region_length\" ] if assembly [ \"strand\" ] == \"+\" : useq_start = max ( 0 , assembly [ \"start\" ] - self . parameters . arguments [ \"upstream_region_length\" ]) if useq_start == 0 : useq_upstream_region_length = assembly [ \"start\" ] useq_stop = min ( assembly [ \"start\" ] + self . parameters . arguments [ \"downstream_region_length\" ], len ( locus_record . seq )) if useq_stop == len ( locus_record . seq ): useq_downstream_region_length = len ( locus_record . seq ) - assembly [ \"start\" ] elif assembly [ \"strand\" ] == \"-\" : useq_start = max ( 0 , assembly [ \"stop\" ] - self . parameters . arguments [ \"downstream_region_length\" ]) if useq_start == 0 : useq_downstream_region_length = assembly [ \"stop\" ] useq_stop = min ( len ( locus_record . seq ), assembly [ \"stop\" ] + self . parameters . arguments [ \"upstream_region_length\" ]) if useq_stop == len ( locus_record . seq ): useq_upstream_region_length = len ( locus_record . seq ) - assembly [ \"stop\" ] useq_length = abs ( useq_stop - useq_start ) if useq_length >= self . parameters . arguments [ \"minimal_upstream_region_length\" ]: useq = locus_record . seq [ useq_start : useq_stop ] if assembly [ \"strand\" ] == \"-\" : useq = useq . reverse_complement () if assembly [ \"strain\" ] == \"NA\" : useq_name = assembly [ \"org\" ] elif assembly [ \"strain\" ] in assembly [ \"org\" ]: useq_name = f \" { assembly [ 'org' ] . replace ( assembly [ 'strain' ], '' ) } [ { assembly [ 'strain' ] } ]\" else : useq_name = f \" { assembly [ 'org' ] } [ { assembly [ 'strain' ] } ]\" useq_id = f \" { assembly [ 'locus_id' ] } | { useq_start } - { useq_stop } ( { assembly [ 'strand' ] } )\" # useq_id format: locus_id|start-stop|strand (coordinates in 0-based) useq_record = Bio . SeqRecord . SeqRecord ( useq , id = useq_id , name = useq_name , description = f \"ac: { record . accession_number } |\" f \"org: { assembly [ 'org' ] } |\" f \"strain: { assembly [ 'strain' ] } |\" f \"assembly: { assembly [ 'assembly' ] } |\" f \"length: { useq_length } \" ) useq_dict = dict ( record = useq_record , id = useq_id , locus_id = assembly [ 'locus_id' ], name = useq_name , length = useq_length , start = useq_start , stop = useq_stop , strand = assembly [ \"strand\" ], accession_number = record . accession_number , organism = { assembly [ 'org' ]}, useq_upstream_region_length = useq_upstream_region_length , useq_downstream_region_length = useq_downstream_region_length ) record_upstream_sequences . append ( useq_dict ) upstream_sequences += record_upstream_sequences if len ( record_upstream_sequences ) == 0 : an_with_no_annotated_useq . append ( record . accession_number ) if an_with_no_annotated_useq : print ( f \"\u2757Warning message: \\n\\t No upstream sequences for { len ( an_with_no_annotated_useq ) } protein(s)\" f \" were annotated. \\n\\t Corresponding loci in the nucleotide ncbi database can be too short \ud83d\udccf. \\n \" f \" \\t See 'minimal_upstream_region_length' config parameter description in the documentation.\" , file = sys . stderr ) self . upstream_sequences = upstream_sequences if self . parameters . arguments [ \"verbose\" ]: print ( f \"\u2705 { len ( self . upstream_sequences ) } upstream sequences were obtained.\" , file = sys . stdout ) return self . upstream_sequences except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to retrieve upstream sequences.\" ) from error def save_upstream_sequences ( self ) -> None : \"\"\"Save upstream sequences as a fasta file. Returns: None \"\"\" try : records = [] output_file = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"upstream_sequences.fa\" ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) for useq in self . upstream_sequences : records . append ( useq [ \"record\" ]) Bio . SeqIO . write ( records , output_file , \"fasta\" ) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc8c Fasta file with upstream sequences was saved to { output_file } .\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save a fasta file with upstream sequences.\" ) from error def annotate_orfs ( self ) -> None : \"\"\"Annotate ORFs of upstream sequences. Note: This function updates 'upstream_sequences' attribute. Returns: None \"\"\" if self . upstream_sequences is None : raise uorf4u . manager . uORF4uError ( f \"Error: 'annotate_orfs()' method can't be called.\" f \" Upstream sequences were not found.\" ) try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udd0e ORFs annotating in the upstream sequences...\" , file = sys . stdout ) if self . parameters . arguments [ \"alternative_start_codons\" ]: start_codons_list = self . codon_table . start_codons else : start_codons_list = [ self . parameters . arguments [ \"main_start_codon\" ]] for useq in self . upstream_sequences : useq_index = self . upstream_sequences . index ( useq ) if self . parameters . arguments [ \"check_assembly_annotation\" ]: useq [ \"locus_annotation\" ] = Locus ( useq [ \"locus_id\" ], start_b = useq [ \"start\" ], stop_b = useq [ \"stop\" ], target_strand = useq [ \"strand\" ]) useq [ \"ORFs\" ] = [] for first_position in range (( useq [ \"length\" ] - 3 ) + 1 ): first_codon = useq [ \"record\" ] . seq [ first_position : first_position + 3 ] if first_codon . upper () in start_codons_list : start_codon_position = first_position for second_position in range ( start_codon_position + 3 , ( useq [ \"length\" ] - 3 ) + 1 , 3 ): second_codon = useq [ \"record\" ] . seq [ second_position : second_position + 3 ] if second_codon . upper () in self . codon_table . stop_codons : stop_codon_position = second_position length = stop_codon_position - start_codon_position distance = ( len ( useq [ 'record' ] . seq ) - self . parameters . arguments [ \"downstream_region_length\" ]) - ( stop_codon_position ) id = f \" { useq [ 'locus_id' ] } | { useq [ 'accession_number' ] } |\" \\ f \" { distance } \" # id: locus_id|accession_number|distance_from_the_start_codon_to_the_main_orf name = f \" { useq [ 'name' ] } | { len ( useq [ 'record' ] . seq ) - ( start_codon_position + 1 ) } \" # name: useq_name|distance_from_the_start_codon_to_the_main_orf sd_window_start = max ( [ 0 , ( start_codon_position - self . parameters . arguments [ \"sd_window_length\" ])]) current_orf = ORF ( parameters = self . parameters , id = id , name = name , distance = distance , start = start_codon_position , stop = stop_codon_position , nt_sequence = useq [ \"record\" ] . seq [ start_codon_position : stop_codon_position ], sd_window_seq = useq [ \"record\" ] . seq [ sd_window_start : start_codon_position ], useq_index = useq_index ) if current_orf . length >= self . parameters . arguments [ \"min_orf_length\" ]: useq [ \"ORFs\" ] . append ( current_orf ) if self . parameters . arguments [ \"check_assembly_annotation\" ]: for cds in useq [ \"locus_annotation\" ] . CDSs : if current_orf . stop == cds [ \"relative_stop\" ] and ( ( current_orf . start - cds [ \"relative_start\" ]) % 3 == 0 ): the_same_stop = 1 current_orf . annotation = cds [ \"product_name\" ] if current_orf . start != cds [ \"relative_start\" ]: if current_orf . start < cds [ \"relative_start\" ]: current_orf . annotation += \" (extension)\" else : current_orf . annotation += \" (truncation)\" for annotated_orfs in useq [ \"ORFs\" ]: if current_orf . stop == annotated_orfs . stop and \\ current_orf . id != annotated_orfs . id : current_orf . extended_orfs . append ( annotated_orfs . id ) break number_of_orfs = sum ( len ( i [ \"ORFs\" ]) for i in self . upstream_sequences ) if number_of_orfs == 0 : print ( f \"\u26d4Termination: \\n\\t No ORF was annotated in upstream sequences.\" f \" \\n\\t This run will be terminated.\" , file = sys . stderr ) sys . exit () if self . parameters . arguments [ \"verbose\" ]: print ( f \"\u2705 { number_of_orfs } ORFs were annotated.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to annotate ORFs in upstream sequences.\" ) from error def filter_orfs_by_sd_annotation ( self ) -> None : \"\"\"Filter annotated ORFs by presence the Shine-Dalgarno sequence. Returns: None \"\"\" try : for useq in self . upstream_sequences : orf_list = useq [ \"ORFs\" ] filtered_orf_list = [] for orf in orf_list : orf . calculate_energies () if orf . min_energy < self . parameters . arguments [ \"sd_energy_cutoff\" ]: filtered_orf_list . append ( orf ) useq [ \"ORFs\" ] = filtered_orf_list number_of_orfs = sum ( len ( i [ \"ORFs\" ]) for i in self . upstream_sequences ) if number_of_orfs == 0 : print ( f \"\u26d4Termination: \\n\\t No ORF left after filtering by SD annotation.\" f \" \\n\\t This run will be terminated.\" , file = sys . stderr ) sys . exit () if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83e\uddf9 { number_of_orfs } ORFs remained in the analysis after filtering by presence of the SD sequence.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to filter uORFs by SD sequence presence.\" ) from error def save_annotated_orfs ( self ) -> None : \"\"\"Save information about annotated ORFs as a set of tsv files. Note: tsv files will be saved to the subdir called 'annotated_ORFs' located in 'output_dir'. Returns: None \"\"\" try : colnames = \" \\t \" . join ( [ \"id\" , \"name\" , \"length\" , \"nt_sequence\" , \"aa_sequence\" , \"sd_sequence_window\" , \"extended_orfs\" , \"annotation\" ]) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) output_dir_path = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"annotated_ORFs\" ) if not os . path . exists ( output_dir_path ): os . mkdir ( output_dir_path ) for useq in self . upstream_sequences : orf_list = useq [ \"ORFs\" ] file_name = f \" { useq [ 'locus_id' ] } | { useq [ 'accession_number' ] } \" \\ f \"_ { useq [ 'name' ] . replace ( ' ' , '_' ) . replace ( '/' , '_' ) } \" lines = [ colnames ] for orf in orf_list : if not orf . extended_orfs : extented_orfs_value = \"NA\" else : extented_orfs_value = ';' . join ( orf . extended_orfs ) lines . append ( \" \\t \" . join ( [ orf . id , orf . name , str ( orf . length ), str ( orf . nt_sequence ), str ( orf . aa_sequence ), str ( orf . sd_window_seq_str ), extented_orfs_value , orf . annotation ])) with open ( os . path . join ( output_dir_path , f \" { file_name } .tsv\" ), \"w\" ) as output : output . write ( \" \\n \" . join ( lines )) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc8c tsv files with information about annotated ORFs were saved to { output_dir_path } folder.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save annotated uORFs.\" ) from error def conserved_orf_searching ( self ) -> dict : \"\"\"Search for sets of conserved ORFs in upstream sequences. Note: It returns a dict with conserved ORFs and updates the self.conserved_paths attribute. Returns: dict: Dict with keys as lengths of ORFs' cluster and values as corresponding lists Path's objects. (Path class holds list of ORFs from different upstream sequences and information about them). \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udd0e Searching for conserved ORFs in upstream sequences...\" , file = sys . stdout ) lengths = [] for useq in self . upstream_sequences : for orf in useq [ \"ORFs\" ]: lengths . append ( orf . length ) lengths = sorted ( list ( set ( lengths ))) global_aligner = Bio . Align . PairwiseAligner () global_aligner . mode = \"global\" global_aligner . match_score = self . parameters . arguments [ \"global_match_score\" ] global_aligner . mismatch_score = self . parameters . arguments [ \"global_mismatch_score\" ] global_aligner . open_gap_score = self . parameters . arguments [ \"global_open_gap_score\" ] global_aligner . extend_gap_score = self . parameters . arguments [ \"global_extend_gap_score\" ] global_aligner . target_end_gap_score = self . parameters . arguments [ \"global_target_end_gap_score\" ] global_aligner . query_end_gap_score = self . parameters . arguments [ \"global_query_end_gap_score\" ] length_variance = self . parameters . arguments [ \"orf_length_group_range\" ] number_of_useqs = len ( self . upstream_sequences ) conserved_paths = [] for length in lengths : useq_indexes_with_filtered_orfs = [] filtered_orfs = dict () for useq_index in range ( number_of_useqs ): useq = self . upstream_sequences [ useq_index ] filtered_orfs [ useq_index ] = [] for orf in useq [ \"ORFs\" ]: if abs ( length - orf . length ) <= length_variance : filtered_orfs [ useq_index ] . append ( orf ) orfs_ids = [ i . id for i in filtered_orfs [ useq_index ]] for orf in filtered_orfs [ useq_index ]: if any ( i in orf . extended_orfs for i in orfs_ids ): filtered_orfs [ useq_index ] . remove ( orf ) if len ( filtered_orfs [ useq_index ]) > 0 : useq_indexes_with_filtered_orfs . append ( useq_index ) if len ( useq_indexes_with_filtered_orfs ) / number_of_useqs >= self . parameters . arguments [ \"orfs_presence_cutoff\" ]: if len ( filtered_orfs . keys ()) > self . parameters . arguments [ \"num_of_initial_genome_iteration\" ]: genome_iterator = random . sample ( filtered_orfs . keys (), self . parameters . arguments [ \"num_of_initial_genome_iteration\" ]) else : genome_iterator = filtered_orfs . keys () for initial_useq in genome_iterator : for initial_orf in filtered_orfs [ initial_useq ]: conserved_path = Path ( self . parameters ) conserved_path . update ( initial_orf ) for useq in random . sample ( filtered_orfs . keys (), len ( filtered_orfs . keys ())): if useq != initial_useq and filtered_orfs [ useq ] != []: score_sums = [] for orf in filtered_orfs [ useq ]: score_sum = 0 for path_orf in conserved_path . path : if self . parameters . arguments [ \"alignment_type\" ] == \"nt\" : current_alignment = global_aligner . align ( orf . nt_sequence , path_orf . nt_sequence ) elif self . parameters . arguments [ \"alignment_type\" ] == \"aa\" : current_alignment = global_aligner . align ( orf . aa_sequence , path_orf . aa_sequence ) score_sum += current_alignment . score score_sums . append ( score_sum ) max_score = max ( score_sums ) if max_score > self . parameters . arguments [ \"alignment_score_cutoff\" ]: if score_sums . count ( max_score ) == 1 : selected_orf = filtered_orfs [ useq ][ score_sums . index ( max_score )] else : num_of_candidates = len ( filtered_orfs [ useq ]) highest_score_orfs = [ filtered_orfs [ useq ][ k ] for k in range ( num_of_candidates ) if score_sums [ k ] == max_score ] highest_score_orfs_length_dists = [ orf_it . length - length for orf_it in highest_score_orfs ] min_length_dist = min ( highest_score_orfs_length_dists ) if highest_score_orfs_length_dists . count ( min_length_dist ) == 1 : selected_orf = highest_score_orfs [ highest_score_orfs_length_dists . index ( min_length_dist )] else : num_of_candidates = len ( highest_score_orfs ) the_closest_by_length_orfs = [ highest_score_orfs [ k ] for k in range ( num_of_candidates ) if highest_score_orfs_length_dists [ k ] == min_length_dist ] the_closest_by_length_orfs_lengths = [ orf_it . length for orf_it in the_closest_by_length_orfs ] max_length = max ( the_closest_by_length_orfs_lengths ) selected_orf = the_closest_by_length_orfs [ the_closest_by_length_orfs_lengths . index ( max_length )] conserved_path . update ( selected_orf , max_score ) if len ( conserved_path ) / number_of_useqs >= self . parameters . arguments [ \"orfs_presence_cutoff\" ]: to_save_this_path = 1 for old_path in conserved_paths : fraction_of_identity = conserved_path . calculate_similarity ( old_path ) if fraction_of_identity >= self . parameters . arguments [ \"paths_identity_cutoff\" ]: if conserved_path . score > old_path . score : conserved_paths . remove ( old_path ) elif conserved_path . score <= old_path . score : to_save_this_path = 0 if to_save_this_path == 1 : conserved_path . sort () conserved_paths . append ( conserved_path ) self . conserved_paths = conserved_paths number_of_paths = len ( conserved_paths ) if number_of_paths == 0 : print ( f \"\u26d4Termination: \\n\\t No conserved ORFs set was found.\" f \" \\n\\t This run will be terminated.\" , file = sys . stderr ) sys . exit () if self . parameters . arguments [ \"verbose\" ]: print ( f \"\u2705 { number_of_paths } sets of conserved ORFs were found.\" , file = sys . stdout ) return conserved_paths except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to perform searching for conserved uORFs.\" ) from error def filter_out_similar_paths ( self ) -> None : \"\"\"Filter out duplicates in sets of annotated conserved ORFs. Note: Two paths are considered as duplicates if they share more than half of ORFs (default value, see 'paths_identity_cutoff' config parameter). In case two paths are found as identical, only one with a higher score will be saved. Returns: None \"\"\" try : filtered_paths = [] for path in self . conserved_paths : to_add = 1 for path_filtered in filtered_paths : if path . calculate_similarity ( path_filtered ) > self . parameters . arguments [ \"paths_identity_cutoff\" ]: if path . score < path_filtered . score : to_add = 0 elif path . score == path_filtered . score and ( len ( path ) < len ( path_filtered )): to_add = 0 else : filtered_paths . remove ( path_filtered ) if to_add == 1 : filtered_paths . append ( path ) self . conserved_paths = filtered_paths if self . parameters . arguments [ \"verbose\" ]: num_of_paths = len ( self . conserved_paths ) print ( f \"\ud83e\uddf9 { num_of_paths } set(s) of conserved ORFs remained in the analysis after filtering \" f \"out duplicates.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to filter out duplicates in conserved uORFs sets.\" ) from error def run_msa ( self ) -> None : \"\"\"Run msa tool (muscle) for each path object (set of conserved ORFs). Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83e\uddee Running MSA tool for conserved ORFs.\" , file = sys . stdout ) for path in self . conserved_paths : path . muscle_msa () return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to get MSA of conserved uORFS.\" ) from error def save_msa ( self ) -> None : \"\"\"Save MSA of conserved ORFs as fasta files. Note: Fasta files will be saved to the subdirs: ['nucleotide_msa' - for MSA of nucleotide sequences of ORFs, 'amino_acid_msa' - MSA of amino acid sequences of ORFs, and 'sd_msa' - MSA of SD sequence regions of ORFS). All of them located in your 'output_dir'. Returns: None \"\"\" try : if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_fasta_files\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) for key in output_dirs : if not ( os . path . exists ( output_dirs [ key ])): os . mkdir ( output_dirs [ key ]) for path in self . conserved_paths : for seq_type in self . parameters . arguments [ \"sequences_to_write\" ]: msa = path . msa [ seq_type ] output = os . path . join ( output_dirs [ seq_type ], f \" { path . id } .fa\" ) Bio . AlignIO . write ( msa , output , \"fasta\" ) if self . parameters . arguments [ \"verbose\" ]: delimiter = \", \\n\\t \" print ( f \"\ud83d\udc8c MSA fasta files of conserved ORFs were saved to the folders: \\n \" f \" \\t { delimiter . join ( output_dirs . values ()) } folders.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save MSA of conserved uORFs.\" ) from error def save_orfs_sequences ( self ) -> None : \"\"\"Save sequences of conserved ORFs as fasta files. Note: Fasta files will be saved to the subdirs: ['nucleotide_orfs' - for MSA of nucleotide sequences of ORFs, 'amino_acid_msa' - MSA of amino acid sequences of ORFs, and 'sd_msa' - MSA of SD sequence regions of ORFS). All of them located in your 'output_dir'. Returns: None \"\"\" try : if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" ) sequence_to_write = [ i for i in self . parameters . arguments [ \"sequences_to_write\" ] if i != \"sd\" ] output_dirs = dict ( zip ( sequence_to_write , [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _orfs_fasta_files\" ) for i in sequence_to_write ])) for key in output_dirs : if not ( os . path . exists ( output_dirs [ key ])): os . mkdir ( output_dirs [ key ]) for seq_type in sequence_to_write : for path in self . conserved_paths : records = [] for orf in path . path : if seq_type == \"nt\" : record = Bio . SeqRecord . SeqRecord ( orf . nt_sequence , orf . id , \"\" , orf . name ) if seq_type == \"aa\" : record = Bio . SeqRecord . SeqRecord ( orf . aa_sequence , orf . id , \"\" , orf . name ) records . append ( record ) output = os . path . join ( output_dirs [ seq_type ], f \" { path . id } .fa\" ) Bio . SeqIO . write ( records , output , \"fasta\" ) if self . parameters . arguments [ \"verbose\" ]: delimiter = \", \\n\\t \" print ( f \"\ud83d\udc8c Sequences fasta files of conserved ORFs were saved to the folders: \\n \" f \" \\t { delimiter . join ( output_dirs . values ()) } .\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save sequences of conserved uORFs.\" ) from error def save_results_summary_table ( self ) -> None : \"\"\"Save results summary table. Note: A tsv table will be saved to your output_dir. Returns: None \"\"\" try : colnames = \" \\t \" . join ( [ \"id\" , \"length\" , \"average_distance_to_the_ORF\" , \"aa_alignment_length\" , \"nt_alignment_length\" , \"score\" , \"number_of_orfs\" , \"number_of_orfs/number_of_sequences\" , \"consensus(aa)\" , \"consensus(nt)\" , \"uORFs\" , \"uORFs_annotations\" ]) rows = [ colnames ] for path in self . conserved_paths : annotations = sorted ( set ([ i . annotation for i in path . path ])) if len ( annotations ) > 1 and \"NA\" in annotations : pass # annotations.remove(\"NA\") # To check then row = \" \\t \" . join ( [ path . id , str ( path . length ), str ( statistics . mean ([ i . distance for i in path . path ])), str ( path . msa [ \"aa\" ] . get_alignment_length ()), str ( path . msa [ \"nt\" ] . get_alignment_length ()), str ( path . score ), str ( len ( path )), str ( round ( len ( path ) / len ( self . upstream_sequences ), 3 )), str ( path . msa_consensus [ \"aa\" ]), str ( path . msa_consensus [ \"nt\" ]), ', ' . join ([ i . id for i in path . path ]), ', ' . join ( annotations )]) rows . append ( row ) output_file_path = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"results_summary.tsv\" ) f = open ( output_file_path , \"w\" ) f . write ( \" \\n \" . join ( rows )) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc8c Results summary tsv table saved to: { output_file_path } .\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save results summary table.\" ) from error def plot_ggmsa_figs ( self ) -> None : \"\"\"Plot MSA plots of conserved ORFs saved as fasta files. Note: R script based on ggmsa package [yulab-smu.top/ggmsa] used to produce MSA plots. R script (msa_plot.R) can be found in output_dir. This method uses subprocess to run this R script in the following way: `Rscript {output_dir}/msa_plot.R --msa_fasta path_to_fasta --output output_path --seq_type (nt/aa) --width N(mm) --height M(mm)`. Since during each run of uorf4u a local copy of this script is created in your output_dir, you can change it without any consequences for next uorf4u runs. This method based on _plot_ggmsa_ method of Path class and simply call it for each Path object. Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83c\udfa8 MSA figures plotting...\" , file = sys . stdout ) for path in self . conserved_paths : path . plot_ggmsa () if self . parameters . arguments [ \"verbose\" ]: rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_visualisation\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) delimiter = \", \\n\\t \" print ( f \"\ud83d\udc8c MSA figures were saved to the folders: \\n\\t { delimiter . join ( output_dirs . values ()) } .\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to visualise MSA of conserved uORFs.\" ) from error def plot_logo_figs ( self ) -> None : \"\"\"Plot sequence Logo figures of conserved ORFs saved as fasta files. Note: This method uses logomaker package to produce images. This method based on _plot_logo_ method of Path class and simply call it for each Path object. Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83c\udfa8 Sequence logo figures plotting...\" , file = sys . stdout ) for path in self . conserved_paths : path . plot_logo () if self . parameters . arguments [ \"verbose\" ]: rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _seqlogo_visualisation\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) delimiter = \", \\n\\t \" print ( f \"\ud83d\udc8c Sequence logo figures were saved to the folders: \\n\\t { delimiter . join ( output_dirs . values ()) } \" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to plot sequence logo of conserved uORFs.\" ) from error def plot_annotation ( self ) -> None : \"\"\"Plot loci' annotations figures with conserved ORFs highlighting. Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83c\udfa8 Loci annotations figures plotting...\" , file = sys . stdout ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) output_dir = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"annotation_visualisation\" ) if not os . path . exists ( output_dir ): os . mkdir ( output_dir ) for path in self . conserved_paths : output_file_name = f \" { os . path . join ( output_dir , path . id ) } .pdf\" annotation_plot_manager = uorf4u . drawing . AnnotationPlotManager ( path , self . upstream_sequences , self . parameters ) annotation_plot_manager . define_x_axis_coordinate_system () annotation_plot_manager . create_tracks () annotation_plot_manager . plot ( output_file_name ) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc8c Annotation figures were saved to the { output_dir } folder\" , file = sys . stdout ) except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to plot loci' annotations figures.\" ) from error __init__ ( accession_numbers , parameters ) Create a Homologues object. Note: With initialisation it also creates a 'records' attribute - a list of RefSeqProtein objects of proteins based on accession numbers list. Parameters: accession_numbers ( list ) \u2013 List of RefSeq accession numbers. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/data_processing.py 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 def __init__ ( self , accession_numbers : list , parameters : uorf4u . manager . Parameters ): \"\"\"Create a Homologues object. Note: With initialisation it also creates a 'records' attribute - a list of RefSeqProtein objects of proteins based on accession numbers list. Arguments: accession_numbers (list): List of RefSeq accession numbers. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" try : self . accession_numbers = accession_numbers self . parameters = parameters self . records = [ RefSeqProtein ( i , parameters ) for i in accession_numbers ] self . upstream_sequences = None self . codon_table = Bio . Data . CodonTable . unambiguous_dna_by_name [ parameters . arguments [ \"ncbi_genetic_code_name\" ]] self . conserved_paths = None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to create a Homologues class' object.\" ) from error annotate_orfs () Annotate ORFs of upstream sequences. Note: This function updates 'upstream_sequences' attribute. Returns: None \u2013 None Source code in uorf4u/data_processing.py 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 def annotate_orfs ( self ) -> None : \"\"\"Annotate ORFs of upstream sequences. Note: This function updates 'upstream_sequences' attribute. Returns: None \"\"\" if self . upstream_sequences is None : raise uorf4u . manager . uORF4uError ( f \"Error: 'annotate_orfs()' method can't be called.\" f \" Upstream sequences were not found.\" ) try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udd0e ORFs annotating in the upstream sequences...\" , file = sys . stdout ) if self . parameters . arguments [ \"alternative_start_codons\" ]: start_codons_list = self . codon_table . start_codons else : start_codons_list = [ self . parameters . arguments [ \"main_start_codon\" ]] for useq in self . upstream_sequences : useq_index = self . upstream_sequences . index ( useq ) if self . parameters . arguments [ \"check_assembly_annotation\" ]: useq [ \"locus_annotation\" ] = Locus ( useq [ \"locus_id\" ], start_b = useq [ \"start\" ], stop_b = useq [ \"stop\" ], target_strand = useq [ \"strand\" ]) useq [ \"ORFs\" ] = [] for first_position in range (( useq [ \"length\" ] - 3 ) + 1 ): first_codon = useq [ \"record\" ] . seq [ first_position : first_position + 3 ] if first_codon . upper () in start_codons_list : start_codon_position = first_position for second_position in range ( start_codon_position + 3 , ( useq [ \"length\" ] - 3 ) + 1 , 3 ): second_codon = useq [ \"record\" ] . seq [ second_position : second_position + 3 ] if second_codon . upper () in self . codon_table . stop_codons : stop_codon_position = second_position length = stop_codon_position - start_codon_position distance = ( len ( useq [ 'record' ] . seq ) - self . parameters . arguments [ \"downstream_region_length\" ]) - ( stop_codon_position ) id = f \" { useq [ 'locus_id' ] } | { useq [ 'accession_number' ] } |\" \\ f \" { distance } \" # id: locus_id|accession_number|distance_from_the_start_codon_to_the_main_orf name = f \" { useq [ 'name' ] } | { len ( useq [ 'record' ] . seq ) - ( start_codon_position + 1 ) } \" # name: useq_name|distance_from_the_start_codon_to_the_main_orf sd_window_start = max ( [ 0 , ( start_codon_position - self . parameters . arguments [ \"sd_window_length\" ])]) current_orf = ORF ( parameters = self . parameters , id = id , name = name , distance = distance , start = start_codon_position , stop = stop_codon_position , nt_sequence = useq [ \"record\" ] . seq [ start_codon_position : stop_codon_position ], sd_window_seq = useq [ \"record\" ] . seq [ sd_window_start : start_codon_position ], useq_index = useq_index ) if current_orf . length >= self . parameters . arguments [ \"min_orf_length\" ]: useq [ \"ORFs\" ] . append ( current_orf ) if self . parameters . arguments [ \"check_assembly_annotation\" ]: for cds in useq [ \"locus_annotation\" ] . CDSs : if current_orf . stop == cds [ \"relative_stop\" ] and ( ( current_orf . start - cds [ \"relative_start\" ]) % 3 == 0 ): the_same_stop = 1 current_orf . annotation = cds [ \"product_name\" ] if current_orf . start != cds [ \"relative_start\" ]: if current_orf . start < cds [ \"relative_start\" ]: current_orf . annotation += \" (extension)\" else : current_orf . annotation += \" (truncation)\" for annotated_orfs in useq [ \"ORFs\" ]: if current_orf . stop == annotated_orfs . stop and \\ current_orf . id != annotated_orfs . id : current_orf . extended_orfs . append ( annotated_orfs . id ) break number_of_orfs = sum ( len ( i [ \"ORFs\" ]) for i in self . upstream_sequences ) if number_of_orfs == 0 : print ( f \"\u26d4Termination: \\n\\t No ORF was annotated in upstream sequences.\" f \" \\n\\t This run will be terminated.\" , file = sys . stderr ) sys . exit () if self . parameters . arguments [ \"verbose\" ]: print ( f \"\u2705 { number_of_orfs } ORFs were annotated.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to annotate ORFs in upstream sequences.\" ) from error conserved_orf_searching () Search for sets of conserved ORFs in upstream sequences. Note: It returns a dict with conserved ORFs and updates the self.conserved_paths attribute. Returns: dict ( dict ) \u2013 Dict with keys as lengths of ORFs' cluster and values as corresponding lists Path's objects. (Path class holds list of ORFs from different upstream sequences and information about them). Source code in uorf4u/data_processing.py 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 def conserved_orf_searching ( self ) -> dict : \"\"\"Search for sets of conserved ORFs in upstream sequences. Note: It returns a dict with conserved ORFs and updates the self.conserved_paths attribute. Returns: dict: Dict with keys as lengths of ORFs' cluster and values as corresponding lists Path's objects. (Path class holds list of ORFs from different upstream sequences and information about them). \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udd0e Searching for conserved ORFs in upstream sequences...\" , file = sys . stdout ) lengths = [] for useq in self . upstream_sequences : for orf in useq [ \"ORFs\" ]: lengths . append ( orf . length ) lengths = sorted ( list ( set ( lengths ))) global_aligner = Bio . Align . PairwiseAligner () global_aligner . mode = \"global\" global_aligner . match_score = self . parameters . arguments [ \"global_match_score\" ] global_aligner . mismatch_score = self . parameters . arguments [ \"global_mismatch_score\" ] global_aligner . open_gap_score = self . parameters . arguments [ \"global_open_gap_score\" ] global_aligner . extend_gap_score = self . parameters . arguments [ \"global_extend_gap_score\" ] global_aligner . target_end_gap_score = self . parameters . arguments [ \"global_target_end_gap_score\" ] global_aligner . query_end_gap_score = self . parameters . arguments [ \"global_query_end_gap_score\" ] length_variance = self . parameters . arguments [ \"orf_length_group_range\" ] number_of_useqs = len ( self . upstream_sequences ) conserved_paths = [] for length in lengths : useq_indexes_with_filtered_orfs = [] filtered_orfs = dict () for useq_index in range ( number_of_useqs ): useq = self . upstream_sequences [ useq_index ] filtered_orfs [ useq_index ] = [] for orf in useq [ \"ORFs\" ]: if abs ( length - orf . length ) <= length_variance : filtered_orfs [ useq_index ] . append ( orf ) orfs_ids = [ i . id for i in filtered_orfs [ useq_index ]] for orf in filtered_orfs [ useq_index ]: if any ( i in orf . extended_orfs for i in orfs_ids ): filtered_orfs [ useq_index ] . remove ( orf ) if len ( filtered_orfs [ useq_index ]) > 0 : useq_indexes_with_filtered_orfs . append ( useq_index ) if len ( useq_indexes_with_filtered_orfs ) / number_of_useqs >= self . parameters . arguments [ \"orfs_presence_cutoff\" ]: if len ( filtered_orfs . keys ()) > self . parameters . arguments [ \"num_of_initial_genome_iteration\" ]: genome_iterator = random . sample ( filtered_orfs . keys (), self . parameters . arguments [ \"num_of_initial_genome_iteration\" ]) else : genome_iterator = filtered_orfs . keys () for initial_useq in genome_iterator : for initial_orf in filtered_orfs [ initial_useq ]: conserved_path = Path ( self . parameters ) conserved_path . update ( initial_orf ) for useq in random . sample ( filtered_orfs . keys (), len ( filtered_orfs . keys ())): if useq != initial_useq and filtered_orfs [ useq ] != []: score_sums = [] for orf in filtered_orfs [ useq ]: score_sum = 0 for path_orf in conserved_path . path : if self . parameters . arguments [ \"alignment_type\" ] == \"nt\" : current_alignment = global_aligner . align ( orf . nt_sequence , path_orf . nt_sequence ) elif self . parameters . arguments [ \"alignment_type\" ] == \"aa\" : current_alignment = global_aligner . align ( orf . aa_sequence , path_orf . aa_sequence ) score_sum += current_alignment . score score_sums . append ( score_sum ) max_score = max ( score_sums ) if max_score > self . parameters . arguments [ \"alignment_score_cutoff\" ]: if score_sums . count ( max_score ) == 1 : selected_orf = filtered_orfs [ useq ][ score_sums . index ( max_score )] else : num_of_candidates = len ( filtered_orfs [ useq ]) highest_score_orfs = [ filtered_orfs [ useq ][ k ] for k in range ( num_of_candidates ) if score_sums [ k ] == max_score ] highest_score_orfs_length_dists = [ orf_it . length - length for orf_it in highest_score_orfs ] min_length_dist = min ( highest_score_orfs_length_dists ) if highest_score_orfs_length_dists . count ( min_length_dist ) == 1 : selected_orf = highest_score_orfs [ highest_score_orfs_length_dists . index ( min_length_dist )] else : num_of_candidates = len ( highest_score_orfs ) the_closest_by_length_orfs = [ highest_score_orfs [ k ] for k in range ( num_of_candidates ) if highest_score_orfs_length_dists [ k ] == min_length_dist ] the_closest_by_length_orfs_lengths = [ orf_it . length for orf_it in the_closest_by_length_orfs ] max_length = max ( the_closest_by_length_orfs_lengths ) selected_orf = the_closest_by_length_orfs [ the_closest_by_length_orfs_lengths . index ( max_length )] conserved_path . update ( selected_orf , max_score ) if len ( conserved_path ) / number_of_useqs >= self . parameters . arguments [ \"orfs_presence_cutoff\" ]: to_save_this_path = 1 for old_path in conserved_paths : fraction_of_identity = conserved_path . calculate_similarity ( old_path ) if fraction_of_identity >= self . parameters . arguments [ \"paths_identity_cutoff\" ]: if conserved_path . score > old_path . score : conserved_paths . remove ( old_path ) elif conserved_path . score <= old_path . score : to_save_this_path = 0 if to_save_this_path == 1 : conserved_path . sort () conserved_paths . append ( conserved_path ) self . conserved_paths = conserved_paths number_of_paths = len ( conserved_paths ) if number_of_paths == 0 : print ( f \"\u26d4Termination: \\n\\t No conserved ORFs set was found.\" f \" \\n\\t This run will be terminated.\" , file = sys . stderr ) sys . exit () if self . parameters . arguments [ \"verbose\" ]: print ( f \"\u2705 { number_of_paths } sets of conserved ORFs were found.\" , file = sys . stdout ) return conserved_paths except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to perform searching for conserved uORFs.\" ) from error filter_orfs_by_sd_annotation () Filter annotated ORFs by presence the Shine-Dalgarno sequence. Returns: None \u2013 None Source code in uorf4u/data_processing.py 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 def filter_orfs_by_sd_annotation ( self ) -> None : \"\"\"Filter annotated ORFs by presence the Shine-Dalgarno sequence. Returns: None \"\"\" try : for useq in self . upstream_sequences : orf_list = useq [ \"ORFs\" ] filtered_orf_list = [] for orf in orf_list : orf . calculate_energies () if orf . min_energy < self . parameters . arguments [ \"sd_energy_cutoff\" ]: filtered_orf_list . append ( orf ) useq [ \"ORFs\" ] = filtered_orf_list number_of_orfs = sum ( len ( i [ \"ORFs\" ]) for i in self . upstream_sequences ) if number_of_orfs == 0 : print ( f \"\u26d4Termination: \\n\\t No ORF left after filtering by SD annotation.\" f \" \\n\\t This run will be terminated.\" , file = sys . stderr ) sys . exit () if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83e\uddf9 { number_of_orfs } ORFs remained in the analysis after filtering by presence of the SD sequence.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to filter uORFs by SD sequence presence.\" ) from error filter_out_similar_paths () Filter out duplicates in sets of annotated conserved ORFs. Note: Two paths are considered as duplicates if they share more than half of ORFs (default value, see 'paths_identity_cutoff' config parameter). In case two paths are found as identical, only one with a higher score will be saved. Returns: None \u2013 None Source code in uorf4u/data_processing.py 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 def filter_out_similar_paths ( self ) -> None : \"\"\"Filter out duplicates in sets of annotated conserved ORFs. Note: Two paths are considered as duplicates if they share more than half of ORFs (default value, see 'paths_identity_cutoff' config parameter). In case two paths are found as identical, only one with a higher score will be saved. Returns: None \"\"\" try : filtered_paths = [] for path in self . conserved_paths : to_add = 1 for path_filtered in filtered_paths : if path . calculate_similarity ( path_filtered ) > self . parameters . arguments [ \"paths_identity_cutoff\" ]: if path . score < path_filtered . score : to_add = 0 elif path . score == path_filtered . score and ( len ( path ) < len ( path_filtered )): to_add = 0 else : filtered_paths . remove ( path_filtered ) if to_add == 1 : filtered_paths . append ( path ) self . conserved_paths = filtered_paths if self . parameters . arguments [ \"verbose\" ]: num_of_paths = len ( self . conserved_paths ) print ( f \"\ud83e\uddf9 { num_of_paths } set(s) of conserved ORFs remained in the analysis after filtering \" f \"out duplicates.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to filter out duplicates in conserved uORFs sets.\" ) from error get_upstream_sequences () Get upstream sequences of proteins' genes. Note: A protein may be found in several assemblies (for example in different strains). Returns: list ( list ) \u2013 List of dicts with SeqRecords objects and other information about upstream sequences. Source code in uorf4u/data_processing.py 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 def get_upstream_sequences ( self ) -> list : \"\"\"Get upstream sequences of proteins' genes. Note: A protein may be found in several assemblies (for example in different strains). Returns: list: List of dicts with SeqRecords objects and other information about upstream sequences. \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udce1 Retrieving upstream sequences...\" , file = sys . stdout ) for record in self . records : record . get_assemblies () if self . parameters . arguments [ \"assemblies_list\" ] == 'NA' : assemblies_table = [ f \"accession_number \\t locus_id \\t assembly \\t organism \\t strain \\t tax_id\" ] list_of_protein_with_multiple_assemblies = [] numbers_of_assemblies = [] for record in self . records : if len ( record . assemblies_coordinates ) > 1 : list_of_protein_with_multiple_assemblies . append ( record . accession_number ) numbers_of_assemblies . append ( len ( record . assemblies_coordinates )) for assembly in record . assemblies_coordinates : assemblies_table . append ( f \" { record . accession_number } \\t { assembly [ 'locus_id' ] } \\t { assembly [ 'assembly' ] } \" f \" \\t { assembly [ 'org' ] } \\t { assembly [ 'strain' ] } \\t { assembly [ 'taxid' ] } \" ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) assemblies_table_path = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"assemblies_list.tsv\" ) assemblies_table_file = open ( assemblies_table_path , \"w\" ) assemblies_table_file . write ( \" \\n \" . join ( assemblies_table )) assemblies_table_file . close () if len ( list_of_protein_with_multiple_assemblies ) > 0 : print ( f \"\u2757\ufe0fWarning message: \\n\\t For { len ( list_of_protein_with_multiple_assemblies ) } proteins \" f \"several assemblies were found in identical protein database \\n \" f \" \\t with max number of assemblies per one protein as { max ( numbers_of_assemblies ) } \ud83d\ude31. \\n\\t \" f \"A table with information about the assemblies was saved as a tsv file: \" f \" { assemblies_table_path } . \\n\\t You can edit it and remove lines with assemblies \" f \"you do not want to include in your analysis. \\n \" f \" \\t After filtering, you can use -al cmd parameter with your table as an argument. \\n \" f \" \\t In addition, config file has 'max_number_of_assemblies' parameter \" f \"(set as { self . parameters . arguments [ 'max_number_of_assemblies' ] } ). \\n\\t By default \u2755, it's used \" f \"by uorf4u to limit max number of assemblies included in the analysis; \\n \" f \" \\t and it works only if '-al' option is not provided. In case number of assemblies is more than \" f \"the cutoff, \\n\\t random sampling \ud83c\udfb2 will be used to take only subset of them. \\n\\t \" f \"See documentation \ud83d\udcd6 for details.\" , file = sys . stderr ) else : assemblies_table = pandas . read_table ( self . parameters . arguments [ \"assemblies_list\" ], sep = \" \\t \" ) locus_ids = assemblies_table [ \"locus_id\" ] . to_list () upstream_sequences = [] an_with_no_annotated_useq = [] for record in self . records : assemblies = record . assemblies_coordinates if isinstance ( self . parameters . arguments [ \"max_number_of_assemblies\" ], int ) and \\ self . parameters . arguments [ \"assemblies_list\" ] == \"NA\" : if len ( assemblies ) >= self . parameters . arguments [ \"max_number_of_assemblies\" ]: assemblies = random . sample ( assemblies , self . parameters . arguments [ \"max_number_of_assemblies\" ]) if self . parameters . arguments [ \"assemblies_list\" ] != \"NA\" : assemblies_filtered = [ i for i in assemblies if i [ \"locus_id\" ] in locus_ids ] assemblies = assemblies_filtered record_upstream_sequences = [] for assembly in assemblies : handle = Bio . Entrez . efetch ( db = \"nucleotide\" , rettype = \"fasta\" , retmode = \"txt\" , id = assembly [ \"locus_id\" ]) locus_record = Bio . SeqIO . read ( handle , \"fasta\" ) useq_downstream_region_length = self . parameters . arguments [ \"downstream_region_length\" ] useq_upstream_region_length = self . parameters . arguments [ \"upstream_region_length\" ] if assembly [ \"strand\" ] == \"+\" : useq_start = max ( 0 , assembly [ \"start\" ] - self . parameters . arguments [ \"upstream_region_length\" ]) if useq_start == 0 : useq_upstream_region_length = assembly [ \"start\" ] useq_stop = min ( assembly [ \"start\" ] + self . parameters . arguments [ \"downstream_region_length\" ], len ( locus_record . seq )) if useq_stop == len ( locus_record . seq ): useq_downstream_region_length = len ( locus_record . seq ) - assembly [ \"start\" ] elif assembly [ \"strand\" ] == \"-\" : useq_start = max ( 0 , assembly [ \"stop\" ] - self . parameters . arguments [ \"downstream_region_length\" ]) if useq_start == 0 : useq_downstream_region_length = assembly [ \"stop\" ] useq_stop = min ( len ( locus_record . seq ), assembly [ \"stop\" ] + self . parameters . arguments [ \"upstream_region_length\" ]) if useq_stop == len ( locus_record . seq ): useq_upstream_region_length = len ( locus_record . seq ) - assembly [ \"stop\" ] useq_length = abs ( useq_stop - useq_start ) if useq_length >= self . parameters . arguments [ \"minimal_upstream_region_length\" ]: useq = locus_record . seq [ useq_start : useq_stop ] if assembly [ \"strand\" ] == \"-\" : useq = useq . reverse_complement () if assembly [ \"strain\" ] == \"NA\" : useq_name = assembly [ \"org\" ] elif assembly [ \"strain\" ] in assembly [ \"org\" ]: useq_name = f \" { assembly [ 'org' ] . replace ( assembly [ 'strain' ], '' ) } [ { assembly [ 'strain' ] } ]\" else : useq_name = f \" { assembly [ 'org' ] } [ { assembly [ 'strain' ] } ]\" useq_id = f \" { assembly [ 'locus_id' ] } | { useq_start } - { useq_stop } ( { assembly [ 'strand' ] } )\" # useq_id format: locus_id|start-stop|strand (coordinates in 0-based) useq_record = Bio . SeqRecord . SeqRecord ( useq , id = useq_id , name = useq_name , description = f \"ac: { record . accession_number } |\" f \"org: { assembly [ 'org' ] } |\" f \"strain: { assembly [ 'strain' ] } |\" f \"assembly: { assembly [ 'assembly' ] } |\" f \"length: { useq_length } \" ) useq_dict = dict ( record = useq_record , id = useq_id , locus_id = assembly [ 'locus_id' ], name = useq_name , length = useq_length , start = useq_start , stop = useq_stop , strand = assembly [ \"strand\" ], accession_number = record . accession_number , organism = { assembly [ 'org' ]}, useq_upstream_region_length = useq_upstream_region_length , useq_downstream_region_length = useq_downstream_region_length ) record_upstream_sequences . append ( useq_dict ) upstream_sequences += record_upstream_sequences if len ( record_upstream_sequences ) == 0 : an_with_no_annotated_useq . append ( record . accession_number ) if an_with_no_annotated_useq : print ( f \"\u2757Warning message: \\n\\t No upstream sequences for { len ( an_with_no_annotated_useq ) } protein(s)\" f \" were annotated. \\n\\t Corresponding loci in the nucleotide ncbi database can be too short \ud83d\udccf. \\n \" f \" \\t See 'minimal_upstream_region_length' config parameter description in the documentation.\" , file = sys . stderr ) self . upstream_sequences = upstream_sequences if self . parameters . arguments [ \"verbose\" ]: print ( f \"\u2705 { len ( self . upstream_sequences ) } upstream sequences were obtained.\" , file = sys . stdout ) return self . upstream_sequences except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to retrieve upstream sequences.\" ) from error plot_annotation () Plot loci' annotations figures with conserved ORFs highlighting. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 def plot_annotation ( self ) -> None : \"\"\"Plot loci' annotations figures with conserved ORFs highlighting. Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83c\udfa8 Loci annotations figures plotting...\" , file = sys . stdout ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) output_dir = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"annotation_visualisation\" ) if not os . path . exists ( output_dir ): os . mkdir ( output_dir ) for path in self . conserved_paths : output_file_name = f \" { os . path . join ( output_dir , path . id ) } .pdf\" annotation_plot_manager = uorf4u . drawing . AnnotationPlotManager ( path , self . upstream_sequences , self . parameters ) annotation_plot_manager . define_x_axis_coordinate_system () annotation_plot_manager . create_tracks () annotation_plot_manager . plot ( output_file_name ) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc8c Annotation figures were saved to the { output_dir } folder\" , file = sys . stdout ) except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to plot loci' annotations figures.\" ) from error plot_ggmsa_figs () Plot MSA plots of conserved ORFs saved as fasta files. Note: R script based on ggmsa package [yulab-smu.top/ggmsa] used to produce MSA plots. R script (msa_plot.R) can be found in output_dir. This method uses subprocess to run this R script in the following way: Rscript {output_dir}/msa_plot.R --msa_fasta path_to_fasta --output output_path --seq_type (nt/aa) --width N(mm) --height M(mm) . Since during each run of uorf4u a local copy of this script is created in your output_dir, you can change it without any consequences for next uorf4u runs. This method based on plot_ggmsa method of Path class and simply call it for each Path object. Returns: None \u2013 None Source code in uorf4u/data_processing.py 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 def plot_ggmsa_figs ( self ) -> None : \"\"\"Plot MSA plots of conserved ORFs saved as fasta files. Note: R script based on ggmsa package [yulab-smu.top/ggmsa] used to produce MSA plots. R script (msa_plot.R) can be found in output_dir. This method uses subprocess to run this R script in the following way: `Rscript {output_dir}/msa_plot.R --msa_fasta path_to_fasta --output output_path --seq_type (nt/aa) --width N(mm) --height M(mm)`. Since during each run of uorf4u a local copy of this script is created in your output_dir, you can change it without any consequences for next uorf4u runs. This method based on _plot_ggmsa_ method of Path class and simply call it for each Path object. Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83c\udfa8 MSA figures plotting...\" , file = sys . stdout ) for path in self . conserved_paths : path . plot_ggmsa () if self . parameters . arguments [ \"verbose\" ]: rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_visualisation\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) delimiter = \", \\n\\t \" print ( f \"\ud83d\udc8c MSA figures were saved to the folders: \\n\\t { delimiter . join ( output_dirs . values ()) } .\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to visualise MSA of conserved uORFs.\" ) from error plot_logo_figs () Plot sequence Logo figures of conserved ORFs saved as fasta files. Note: This method uses logomaker package to produce images. This method based on plot_logo method of Path class and simply call it for each Path object. Returns: None \u2013 None Source code in uorf4u/data_processing.py 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 def plot_logo_figs ( self ) -> None : \"\"\"Plot sequence Logo figures of conserved ORFs saved as fasta files. Note: This method uses logomaker package to produce images. This method based on _plot_logo_ method of Path class and simply call it for each Path object. Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83c\udfa8 Sequence logo figures plotting...\" , file = sys . stdout ) for path in self . conserved_paths : path . plot_logo () if self . parameters . arguments [ \"verbose\" ]: rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _seqlogo_visualisation\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) delimiter = \", \\n\\t \" print ( f \"\ud83d\udc8c Sequence logo figures were saved to the folders: \\n\\t { delimiter . join ( output_dirs . values ()) } \" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to plot sequence logo of conserved uORFs.\" ) from error run_msa () Run msa tool (muscle) for each path object (set of conserved ORFs). Returns: None \u2013 None Source code in uorf4u/data_processing.py 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 def run_msa ( self ) -> None : \"\"\"Run msa tool (muscle) for each path object (set of conserved ORFs). Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83e\uddee Running MSA tool for conserved ORFs.\" , file = sys . stdout ) for path in self . conserved_paths : path . muscle_msa () return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to get MSA of conserved uORFS.\" ) from error save_annotated_orfs () Save information about annotated ORFs as a set of tsv files. Note: tsv files will be saved to the subdir called 'annotated_ORFs' located in 'output_dir'. Returns: None \u2013 None Source code in uorf4u/data_processing.py 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 def save_annotated_orfs ( self ) -> None : \"\"\"Save information about annotated ORFs as a set of tsv files. Note: tsv files will be saved to the subdir called 'annotated_ORFs' located in 'output_dir'. Returns: None \"\"\" try : colnames = \" \\t \" . join ( [ \"id\" , \"name\" , \"length\" , \"nt_sequence\" , \"aa_sequence\" , \"sd_sequence_window\" , \"extended_orfs\" , \"annotation\" ]) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) output_dir_path = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"annotated_ORFs\" ) if not os . path . exists ( output_dir_path ): os . mkdir ( output_dir_path ) for useq in self . upstream_sequences : orf_list = useq [ \"ORFs\" ] file_name = f \" { useq [ 'locus_id' ] } | { useq [ 'accession_number' ] } \" \\ f \"_ { useq [ 'name' ] . replace ( ' ' , '_' ) . replace ( '/' , '_' ) } \" lines = [ colnames ] for orf in orf_list : if not orf . extended_orfs : extented_orfs_value = \"NA\" else : extented_orfs_value = ';' . join ( orf . extended_orfs ) lines . append ( \" \\t \" . join ( [ orf . id , orf . name , str ( orf . length ), str ( orf . nt_sequence ), str ( orf . aa_sequence ), str ( orf . sd_window_seq_str ), extented_orfs_value , orf . annotation ])) with open ( os . path . join ( output_dir_path , f \" { file_name } .tsv\" ), \"w\" ) as output : output . write ( \" \\n \" . join ( lines )) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc8c tsv files with information about annotated ORFs were saved to { output_dir_path } folder.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save annotated uORFs.\" ) from error save_msa () Save MSA of conserved ORFs as fasta files. Note: Fasta files will be saved to the subdirs: ['nucleotide_msa' - for MSA of nucleotide sequences of ORFs, 'amino_acid_msa' - MSA of amino acid sequences of ORFs, and 'sd_msa' - MSA of SD sequence regions of ORFS). All of them located in your 'output_dir'. Returns: None \u2013 None Source code in uorf4u/data_processing.py 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 def save_msa ( self ) -> None : \"\"\"Save MSA of conserved ORFs as fasta files. Note: Fasta files will be saved to the subdirs: ['nucleotide_msa' - for MSA of nucleotide sequences of ORFs, 'amino_acid_msa' - MSA of amino acid sequences of ORFs, and 'sd_msa' - MSA of SD sequence regions of ORFS). All of them located in your 'output_dir'. Returns: None \"\"\" try : if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_fasta_files\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) for key in output_dirs : if not ( os . path . exists ( output_dirs [ key ])): os . mkdir ( output_dirs [ key ]) for path in self . conserved_paths : for seq_type in self . parameters . arguments [ \"sequences_to_write\" ]: msa = path . msa [ seq_type ] output = os . path . join ( output_dirs [ seq_type ], f \" { path . id } .fa\" ) Bio . AlignIO . write ( msa , output , \"fasta\" ) if self . parameters . arguments [ \"verbose\" ]: delimiter = \", \\n\\t \" print ( f \"\ud83d\udc8c MSA fasta files of conserved ORFs were saved to the folders: \\n \" f \" \\t { delimiter . join ( output_dirs . values ()) } folders.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save MSA of conserved uORFs.\" ) from error save_orfs_sequences () Save sequences of conserved ORFs as fasta files. Note: Fasta files will be saved to the subdirs: ['nucleotide_orfs' - for MSA of nucleotide sequences of ORFs, 'amino_acid_msa' - MSA of amino acid sequences of ORFs, and 'sd_msa' - MSA of SD sequence regions of ORFS). All of them located in your 'output_dir'. Returns: None \u2013 None Source code in uorf4u/data_processing.py 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 def save_orfs_sequences ( self ) -> None : \"\"\"Save sequences of conserved ORFs as fasta files. Note: Fasta files will be saved to the subdirs: ['nucleotide_orfs' - for MSA of nucleotide sequences of ORFs, 'amino_acid_msa' - MSA of amino acid sequences of ORFs, and 'sd_msa' - MSA of SD sequence regions of ORFS). All of them located in your 'output_dir'. Returns: None \"\"\" try : if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" ) sequence_to_write = [ i for i in self . parameters . arguments [ \"sequences_to_write\" ] if i != \"sd\" ] output_dirs = dict ( zip ( sequence_to_write , [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _orfs_fasta_files\" ) for i in sequence_to_write ])) for key in output_dirs : if not ( os . path . exists ( output_dirs [ key ])): os . mkdir ( output_dirs [ key ]) for seq_type in sequence_to_write : for path in self . conserved_paths : records = [] for orf in path . path : if seq_type == \"nt\" : record = Bio . SeqRecord . SeqRecord ( orf . nt_sequence , orf . id , \"\" , orf . name ) if seq_type == \"aa\" : record = Bio . SeqRecord . SeqRecord ( orf . aa_sequence , orf . id , \"\" , orf . name ) records . append ( record ) output = os . path . join ( output_dirs [ seq_type ], f \" { path . id } .fa\" ) Bio . SeqIO . write ( records , output , \"fasta\" ) if self . parameters . arguments [ \"verbose\" ]: delimiter = \", \\n\\t \" print ( f \"\ud83d\udc8c Sequences fasta files of conserved ORFs were saved to the folders: \\n \" f \" \\t { delimiter . join ( output_dirs . values ()) } .\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save sequences of conserved uORFs.\" ) from error save_results_summary_table () Save results summary table. Note: A tsv table will be saved to your output_dir. Returns: None \u2013 None Source code in uorf4u/data_processing.py 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 def save_results_summary_table ( self ) -> None : \"\"\"Save results summary table. Note: A tsv table will be saved to your output_dir. Returns: None \"\"\" try : colnames = \" \\t \" . join ( [ \"id\" , \"length\" , \"average_distance_to_the_ORF\" , \"aa_alignment_length\" , \"nt_alignment_length\" , \"score\" , \"number_of_orfs\" , \"number_of_orfs/number_of_sequences\" , \"consensus(aa)\" , \"consensus(nt)\" , \"uORFs\" , \"uORFs_annotations\" ]) rows = [ colnames ] for path in self . conserved_paths : annotations = sorted ( set ([ i . annotation for i in path . path ])) if len ( annotations ) > 1 and \"NA\" in annotations : pass # annotations.remove(\"NA\") # To check then row = \" \\t \" . join ( [ path . id , str ( path . length ), str ( statistics . mean ([ i . distance for i in path . path ])), str ( path . msa [ \"aa\" ] . get_alignment_length ()), str ( path . msa [ \"nt\" ] . get_alignment_length ()), str ( path . score ), str ( len ( path )), str ( round ( len ( path ) / len ( self . upstream_sequences ), 3 )), str ( path . msa_consensus [ \"aa\" ]), str ( path . msa_consensus [ \"nt\" ]), ', ' . join ([ i . id for i in path . path ]), ', ' . join ( annotations )]) rows . append ( row ) output_file_path = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"results_summary.tsv\" ) f = open ( output_file_path , \"w\" ) f . write ( \" \\n \" . join ( rows )) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc8c Results summary tsv table saved to: { output_file_path } .\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save results summary table.\" ) from error save_upstream_sequences () Save upstream sequences as a fasta file. Returns: None \u2013 None Source code in uorf4u/data_processing.py 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 def save_upstream_sequences ( self ) -> None : \"\"\"Save upstream sequences as a fasta file. Returns: None \"\"\" try : records = [] output_file = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"upstream_sequences.fa\" ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) for useq in self . upstream_sequences : records . append ( useq [ \"record\" ]) Bio . SeqIO . write ( records , output_file , \"fasta\" ) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc8c Fasta file with upstream sequences was saved to { output_file } .\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save a fasta file with upstream sequences.\" ) from error Locus A Locus object holds sequence and annotation of the corresponding ncbi Reference Sequence. Attributes: locus_id ( str ) \u2013 a NCBI locus id from the Nucleotide database. locus_record ( Bio . SeqRecord . SeqRecord ) \u2013 a biopython record object of the sequence. CDSs ( list ) \u2013 list of dicts with information about annotated CDS in the locus' sequence. start_b ( int ) \u2013 start of region within annotation should be retrieved. stop_b ( int ) \u2013 stop of region within annotation should be retrieved. Source code in uorf4u/data_processing.py 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 class Locus : \"\"\" A Locus object holds sequence and annotation of the corresponding ncbi Reference Sequence. Attributes: locus_id (str): a NCBI locus id from the Nucleotide database. locus_record (Bio.SeqRecord.SeqRecord): a biopython record object of the sequence. CDSs (list): list of dicts with information about annotated CDS in the locus' sequence. start_b (int): start of region within annotation should be retrieved. stop_b (int): stop of region within annotation should be retrieved. \"\"\" def __init__ ( self , locus_id : str , start_b : int = 0 , stop_b : int = None , target_strand : str = \"NA\" ): \"\"\"Create a Locus object. Note: 0-based format is used for sequence indexing. Arguments: locus_id (str): locus id from the ncbi nucleotide database. start_b (int): start of region within annotation should be retrieved (optional). stop_b (int): stop of region within annotation should be retrieved (optional). target_strand (str): strand of the target object (optional). \"\"\" try : self . locus_id = locus_id handle = Bio . Entrez . efetch ( db = \"nucleotide\" , rettype = \"fasta\" , retmode = \"txt\" , id = locus_id ) self . locus_record = Bio . SeqIO . read ( handle , \"fasta\" ) if stop_b is None : stop_b = len ( self . locus_record . seq ) handle = Bio . Entrez . efetch ( db = \"nucleotide\" , rettype = \"gbwithparts\" , retmode = \"xml\" , id = locus_id ) xml_output = ( handle . read ()) . decode ( \"utf-8\" ) root = xml . etree . ElementTree . fromstring ( xml_output ) self . CDSs = [] for gbfeature in root . iter ( \"GBFeature\" ): if gbfeature . find ( \"GBFeature_key\" ) . text == \"CDS\" : try : starts , stops = [], [] for interval in gbfeature . iter ( \"GBInterval\" ): try : start , stop = int ( interval . find ( \"GBInterval_from\" ) . text ), int ( interval . find ( \"GBInterval_to\" ) . text ) if start > stop : start , stop , strand = stop - 1 , start , \"-\" else : start , stop , strand = start - 1 , stop , \"+\" starts . append ( start ) stops . append ( stop ) except : pass if starts : coordinates = list ( sorted ( zip ( starts , stops ), key = lambda pair : pair [ 0 ])) main_start , main_stop = coordinates [ 0 ][ 0 ], coordinates [ - 1 ][ - 1 ] if strand == \"+\" : main_stop = main_stop - 3 relative_start , relative_stop = main_start - start_b , main_stop - start_b elif strand == \"-\" : main_start = main_start + 3 relative_start_r , relative_stop_r = main_start - start_b , main_stop - start_b useq_length = stop_b - start_b relative_start , relative_stop = useq_length - relative_stop_r , useq_length - relative_start_r if strand == target_strand : relative_strand = \"+\" else : relative_strand = \"-\" if ( start_b <= main_start < stop_b ) or ( start_b <= main_stop < stop_b ): cds_seq = self . locus_record . seq [ main_start : main_stop ] if strand == '-' : cds_seq = cds_seq . reverse_complement () protein_id , product_name = 'NA' , 'NA' for gbqualifier in gbfeature . iter ( \"GBQualifier\" ): if gbqualifier . find ( \"GBQualifier_name\" ) . text == \"protein_id\" : protein_id = gbqualifier . find ( \"GBQualifier_value\" ) . text if gbqualifier . find ( \"GBQualifier_name\" ) . text == \"product\" : product_name = gbqualifier . find ( \"GBQualifier_value\" ) . text if protein_id != 'NA' : if product_name != 'NA' : product_name = f \" { protein_id } ( { product_name } )\" else : product_name = f \" { protein_id } \" self . CDSs . append ( dict ( protein_id = protein_id , product_name = product_name , coordinates = coordinates , nt_seq = cds_seq , main_start = main_start , main_stop = main_stop , strand = strand , relative_start = relative_start , relative_stop = relative_stop , relative_strand = relative_strand )) except : pass except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to create a Locus class' object.\" ) from error __init__ ( locus_id , start_b = 0 , stop_b = None , target_strand = 'NA' ) Create a Locus object. Note: 0-based format is used for sequence indexing. Parameters: locus_id ( str ) \u2013 locus id from the ncbi nucleotide database. start_b ( int ) \u2013 start of region within annotation should be retrieved (optional). stop_b ( int ) \u2013 stop of region within annotation should be retrieved (optional). target_strand ( str ) \u2013 strand of the target object (optional). Source code in uorf4u/data_processing.py 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 def __init__ ( self , locus_id : str , start_b : int = 0 , stop_b : int = None , target_strand : str = \"NA\" ): \"\"\"Create a Locus object. Note: 0-based format is used for sequence indexing. Arguments: locus_id (str): locus id from the ncbi nucleotide database. start_b (int): start of region within annotation should be retrieved (optional). stop_b (int): stop of region within annotation should be retrieved (optional). target_strand (str): strand of the target object (optional). \"\"\" try : self . locus_id = locus_id handle = Bio . Entrez . efetch ( db = \"nucleotide\" , rettype = \"fasta\" , retmode = \"txt\" , id = locus_id ) self . locus_record = Bio . SeqIO . read ( handle , \"fasta\" ) if stop_b is None : stop_b = len ( self . locus_record . seq ) handle = Bio . Entrez . efetch ( db = \"nucleotide\" , rettype = \"gbwithparts\" , retmode = \"xml\" , id = locus_id ) xml_output = ( handle . read ()) . decode ( \"utf-8\" ) root = xml . etree . ElementTree . fromstring ( xml_output ) self . CDSs = [] for gbfeature in root . iter ( \"GBFeature\" ): if gbfeature . find ( \"GBFeature_key\" ) . text == \"CDS\" : try : starts , stops = [], [] for interval in gbfeature . iter ( \"GBInterval\" ): try : start , stop = int ( interval . find ( \"GBInterval_from\" ) . text ), int ( interval . find ( \"GBInterval_to\" ) . text ) if start > stop : start , stop , strand = stop - 1 , start , \"-\" else : start , stop , strand = start - 1 , stop , \"+\" starts . append ( start ) stops . append ( stop ) except : pass if starts : coordinates = list ( sorted ( zip ( starts , stops ), key = lambda pair : pair [ 0 ])) main_start , main_stop = coordinates [ 0 ][ 0 ], coordinates [ - 1 ][ - 1 ] if strand == \"+\" : main_stop = main_stop - 3 relative_start , relative_stop = main_start - start_b , main_stop - start_b elif strand == \"-\" : main_start = main_start + 3 relative_start_r , relative_stop_r = main_start - start_b , main_stop - start_b useq_length = stop_b - start_b relative_start , relative_stop = useq_length - relative_stop_r , useq_length - relative_start_r if strand == target_strand : relative_strand = \"+\" else : relative_strand = \"-\" if ( start_b <= main_start < stop_b ) or ( start_b <= main_stop < stop_b ): cds_seq = self . locus_record . seq [ main_start : main_stop ] if strand == '-' : cds_seq = cds_seq . reverse_complement () protein_id , product_name = 'NA' , 'NA' for gbqualifier in gbfeature . iter ( \"GBQualifier\" ): if gbqualifier . find ( \"GBQualifier_name\" ) . text == \"protein_id\" : protein_id = gbqualifier . find ( \"GBQualifier_value\" ) . text if gbqualifier . find ( \"GBQualifier_name\" ) . text == \"product\" : product_name = gbqualifier . find ( \"GBQualifier_value\" ) . text if protein_id != 'NA' : if product_name != 'NA' : product_name = f \" { protein_id } ( { product_name } )\" else : product_name = f \" { protein_id } \" self . CDSs . append ( dict ( protein_id = protein_id , product_name = product_name , coordinates = coordinates , nt_seq = cds_seq , main_start = main_start , main_stop = main_stop , strand = strand , relative_start = relative_start , relative_stop = relative_stop , relative_strand = relative_strand )) except : pass except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to create a Locus class' object.\" ) from error ORF An ORF object holds information about an annotated ORF. Note: It's supposed that the ORFs class' objects will not be used directly by API users since it's only needed for other classes' methods. Attributes: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. id ( str ) \u2013 identifier of the ORF. Format: locus_id|accession_number|distance_from_the_start_codon_to_the_main_orf name ( str ) \u2013 name of the ORF. Format: useq_name|distance_from_the_start_codon_to_the_main_orf sequence_id ( str ) \u2013 identifier of the ORF's sequence (locus id from the ncbi database). start ( int ) \u2013 start position of the ORF on the locus (0-based). stop ( int ) \u2013 stop position of the ORF on the locus (0-based). length ( int ) \u2013 ORF's nucleotide sequence length. nt_sequence ( Bio . Seq . Seq ) \u2013 a Seq object of nucleotide sequence of the ORF. aa_sequence ( Bio . Seq . Seq ) \u2013 a Seq object of amino acid sequence of the ORF. sd_window_seq ( Bio . Seq . Seq ) \u2013 a Seq object of upstream sequence to the start codon of the ORF. min_energy ( float ) \u2013 minimal value of thermodynamic interaction between aSD and putative SD sequences within the upstream sequences to the start codon. putative_sd_sequence ( Bio . Seq . Seq ) \u2013 a Seq object of the putative SD sequence with the minimal energy value. extended_orfs ( list ) \u2013 a list of ORFs with that are in frame with the ORF, but have upstream start codon. Source code in uorf4u/data_processing.py 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 class ORF : \"\"\"An ORF object holds information about an annotated ORF. Note: It's supposed that the ORFs class' objects will not be used directly by API users since it's only needed for other classes' methods. Attributes: parameters (uorf4u.manager.Parameters): Parameters' class object. id (str): identifier of the ORF. Format: locus_id|accession_number|distance_from_the_start_codon_to_the_main_orf name (str): name of the ORF. Format: useq_name|distance_from_the_start_codon_to_the_main_orf sequence_id (str): identifier of the ORF's sequence (locus id from the ncbi database). start (int): start position of the ORF on the locus (0-based). stop (int): stop position of the ORF on the locus (0-based). length (int): ORF's nucleotide sequence length. nt_sequence (Bio.Seq.Seq): a Seq object of nucleotide sequence of the ORF. aa_sequence (Bio.Seq.Seq): a Seq object of amino acid sequence of the ORF. sd_window_seq (Bio.Seq.Seq): a Seq object of upstream sequence to the start codon of the ORF. min_energy (float): minimal value of thermodynamic interaction between aSD and putative SD sequences within the upstream sequences to the start codon. putative_sd_sequence (Bio.Seq.Seq): a Seq object of the putative SD sequence with the minimal energy value. extended_orfs (list): a list of ORFs with that are in frame with the ORF, but have upstream start codon. \"\"\" def __init__ ( self , parameters : uorf4u . manager . Parameters , id : str , name : str , nt_sequence : Bio . Seq . Seq , sd_window_seq : Bio . Seq . Seq , start : int , stop : int , distance : int , useq_index : int , annotation : str = \"NA\" ): \"\"\"Create an ORF object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. id (str): identifier of the ORF. Format: locus_id:distance_from_the_start_codon_to_the_proteins_orf:length. nt_sequence (Bio.Seq.Seq): a Seq object of nucleotide sequence of the ORF. sd_window_seq (Bio.Seq.Seq): a Seq object of upstream sequence to the start codon of the ORF. start (int): start position of the ORF on the locus (0-based). stop (int): stop position of the ORF on the locus (0-based). distance (int): distance to the main ORF. \"\"\" self . parameters = parameters codon_table = Bio . Data . CodonTable . unambiguous_dna_by_name [ # ambiguous can be needed! parameters . arguments [ \"ncbi_genetic_code_name\" ]] codon_table_ambiguous = Bio . Data . CodonTable . ambiguous_dna_by_name [ # ambiguous can be needed! parameters . arguments [ \"ncbi_genetic_code_name\" ]] self . name = name self . distance = distance self . id = id self . sequence_id = id . split ( \":\" )[ 0 ] self . start = start self . stop = stop self . length = len ( nt_sequence ) self . nt_sequence = nt_sequence self . annotation = annotation self . useq_index = useq_index try : self . aa_sequence = self . nt_sequence . translate ( table = codon_table ) except : self . aa_sequence = self . nt_sequence . translate ( table = codon_table_ambiguous ) self . sd_window_seq = sd_window_seq self . extended_orfs = [] self . min_energy = 0 self . putative_sd_sequence = \"NA\" self . sd_window_seq_str = \"NA\" def calculate_energies ( self ) -> None : \"\"\"Calculate energies of putative SD sequences of the upstream sequence. Returns: None \"\"\" # Loading reference energies json file with open ( self . parameters . arguments [ \"ref_energies\" ]) as ref_energy_file : ref_energy = json . load ( ref_energy_file ) sd_seq_length = min ([ len ( i ) for i in ref_energy . keys ()]) # Energies calculations if len ( self . sd_window_seq ) >= min ( ref_energy . values ()): energies = [] for position in range (( len ( self . sd_window_seq ) - sd_seq_length ) + 1 ): try : energies . append ( ref_energy [ self . sd_window_seq [ position : position + sd_seq_length ]]) except : energies . append ( 0 ) if energies : self . min_energy = min ( energies ) if self . min_energy < self . parameters . arguments [ \"sd_energy_cutoff\" ]: sd_start_position = energies . index ( self . min_energy ) # Be careful, it could be more than one! self . putative_sd_sequence = self . sd_window_seq [ sd_start_position : sd_start_position + sd_seq_length ] self . sd_window_seq_str = ( f \" { self . sd_window_seq [ 0 : sd_start_position ] . lower () } \" f \" { self . putative_sd_sequence . upper () } \" f \" { self . sd_window_seq [ sd_start_position : sd_start_position + sd_seq_length :] . lower () } \" ) return None __init__ ( parameters , id , name , nt_sequence , sd_window_seq , start , stop , distance , useq_index , annotation = 'NA' ) Create an ORF object. Parameters: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. id ( str ) \u2013 identifier of the ORF. Format: locus_id:distance_from_the_start_codon_to_the_proteins_orf:length. nt_sequence ( Bio . Seq . Seq ) \u2013 a Seq object of nucleotide sequence of the ORF. sd_window_seq ( Bio . Seq . Seq ) \u2013 a Seq object of upstream sequence to the start codon of the ORF. start ( int ) \u2013 start position of the ORF on the locus (0-based). stop ( int ) \u2013 stop position of the ORF on the locus (0-based). distance ( int ) \u2013 distance to the main ORF. Source code in uorf4u/data_processing.py 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 def __init__ ( self , parameters : uorf4u . manager . Parameters , id : str , name : str , nt_sequence : Bio . Seq . Seq , sd_window_seq : Bio . Seq . Seq , start : int , stop : int , distance : int , useq_index : int , annotation : str = \"NA\" ): \"\"\"Create an ORF object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. id (str): identifier of the ORF. Format: locus_id:distance_from_the_start_codon_to_the_proteins_orf:length. nt_sequence (Bio.Seq.Seq): a Seq object of nucleotide sequence of the ORF. sd_window_seq (Bio.Seq.Seq): a Seq object of upstream sequence to the start codon of the ORF. start (int): start position of the ORF on the locus (0-based). stop (int): stop position of the ORF on the locus (0-based). distance (int): distance to the main ORF. \"\"\" self . parameters = parameters codon_table = Bio . Data . CodonTable . unambiguous_dna_by_name [ # ambiguous can be needed! parameters . arguments [ \"ncbi_genetic_code_name\" ]] codon_table_ambiguous = Bio . Data . CodonTable . ambiguous_dna_by_name [ # ambiguous can be needed! parameters . arguments [ \"ncbi_genetic_code_name\" ]] self . name = name self . distance = distance self . id = id self . sequence_id = id . split ( \":\" )[ 0 ] self . start = start self . stop = stop self . length = len ( nt_sequence ) self . nt_sequence = nt_sequence self . annotation = annotation self . useq_index = useq_index try : self . aa_sequence = self . nt_sequence . translate ( table = codon_table ) except : self . aa_sequence = self . nt_sequence . translate ( table = codon_table_ambiguous ) self . sd_window_seq = sd_window_seq self . extended_orfs = [] self . min_energy = 0 self . putative_sd_sequence = \"NA\" self . sd_window_seq_str = \"NA\" calculate_energies () Calculate energies of putative SD sequences of the upstream sequence. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 def calculate_energies ( self ) -> None : \"\"\"Calculate energies of putative SD sequences of the upstream sequence. Returns: None \"\"\" # Loading reference energies json file with open ( self . parameters . arguments [ \"ref_energies\" ]) as ref_energy_file : ref_energy = json . load ( ref_energy_file ) sd_seq_length = min ([ len ( i ) for i in ref_energy . keys ()]) # Energies calculations if len ( self . sd_window_seq ) >= min ( ref_energy . values ()): energies = [] for position in range (( len ( self . sd_window_seq ) - sd_seq_length ) + 1 ): try : energies . append ( ref_energy [ self . sd_window_seq [ position : position + sd_seq_length ]]) except : energies . append ( 0 ) if energies : self . min_energy = min ( energies ) if self . min_energy < self . parameters . arguments [ \"sd_energy_cutoff\" ]: sd_start_position = energies . index ( self . min_energy ) # Be careful, it could be more than one! self . putative_sd_sequence = self . sd_window_seq [ sd_start_position : sd_start_position + sd_seq_length ] self . sd_window_seq_str = ( f \" { self . sd_window_seq [ 0 : sd_start_position ] . lower () } \" f \" { self . putative_sd_sequence . upper () } \" f \" { self . sd_window_seq [ sd_start_position : sd_start_position + sd_seq_length :] . lower () } \" ) return None Path A Path object holds information about a list of conserved ORFs. Note: It's supposed that the Path class' objects will not be used directly by API users since it's only needed for other classes' methods. Attributes: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. path ( list ) \u2013 List of the ORF class objects. score ( float ) \u2013 Score of the Path (calculated as sum of pairwise alignments scores of ORFs). msa ( dict ) \u2013 Dict with Multiple sequence alignment (MSA, Bio.Align.MultipleSeqAlignment object) as values for different sequences (nt, aa, sd) as keys. msa_consensus ( dict ) \u2013 Dict with consensus sequence (Bio.Seq.Seq object) as values for different sequences (nt, aa, sd) as keys. length \u2013 length of the nucleotide sequence alignment. id ( str ) \u2013 Path's id (format: length|score|num_of_orfs|average_distance_to_the_main_ORF Source code in uorf4u/data_processing.py 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 class Path : \"\"\"A Path object holds information about a list of conserved ORFs. Note: It's supposed that the Path class' objects will not be used directly by API users since it's only needed for other classes' methods. Attributes: parameters (uorf4u.manager.Parameters): Parameters' class object. path (list): List of the ORF class objects. score (float): Score of the Path (calculated as sum of pairwise alignments scores of ORFs). msa (dict): Dict with Multiple sequence alignment (MSA, Bio.Align.MultipleSeqAlignment object) as values for different sequences (nt, aa, sd) as keys. msa_consensus (dict): Dict with consensus sequence (Bio.Seq.Seq object) as values for different sequences (nt, aa, sd) as keys. length: length of the nucleotide sequence alignment. id (str): Path's id (format: length|score|num_of_orfs|average_distance_to_the_main_ORF \"\"\" def __init__ ( self , parameters : uorf4u . manager . Parameters ): \"\"\"Create a Path object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . parameters = parameters self . path = [] self . score = 0 self . msa = dict () self . msa_consensus = dict () self . id = None self . length = None def update ( self , orf : ORF , score = 0 ): \"\"\"Update a Path with a new ORF. Arguments: orf (ORF): an ORF class' object. score (float): a sum of pairwise alignment scores of the ORF against all ORFs in the Path. Returns: None \"\"\" self . path . append ( orf ) self . score += score def sort ( self ) -> None : \"\"\"Sort list of ORFs by their names. Returns: None \"\"\" sorted_path = [ x for _ , x in sorted ( zip ([ i . name for i in self . path ], self . path ), key = lambda pair : pair [ 0 ])] self . path = sorted_path return None def __len__ ( self ): \"\"\"__len__ magic method for a Path object. Returns: int: length of the path attribute - a number of ORFs in a Path. \"\"\" return len ( self . path ) def calculate_similarity ( self , other ) -> float : \"\"\"Calculate fraction of identical ORFs between two Path object. __Note:__ If two objects have different length, the fraction will be calculated as a number of identical ORFs divided by length of the shortest Path. Returns: float: fraction of identical ORFs. \"\"\" num_of_identical_elements = len ( set ( self . path ) & set ( other . path )) fraction_of_identical_orfs = num_of_identical_elements / min ( len ( self ), len ( other )) return fraction_of_identical_orfs def muscle_msa ( self ) -> None : \"\"\"Run a multiple sequence alignment tool (muscle) for the ORFs nucleotide and amino acid sequences. Note: This method updates nt_msa and aa_msa attributes. Returns: None \"\"\" self . msa = dict () for seq_type in self . parameters . arguments [ \"sequences_to_write\" ]: records = [] for orf in self . path : # record_id = f\"{orf.id}\" # record_description = f\"{(orf.name.split('|')[0])}\" record_id = f \" { ( orf . name . split ( '|' )[ 0 ]) . replace ( ' ' , '_' ) } \" record_description = f \" { orf . id } \" if seq_type == \"nt\" : record = Bio . SeqRecord . SeqRecord ( orf . nt_sequence , record_id , \"\" , record_description ) elif seq_type == \"aa\" : record = Bio . SeqRecord . SeqRecord ( orf . aa_sequence , record_id , \"\" , record_description ) elif seq_type == \"sd\" : record = Bio . SeqRecord . SeqRecord ( orf . sd_window_seq , record_id , \"\" , record_description ) records . append ( record ) temp_input = tempfile . NamedTemporaryFile () Bio . SeqIO . write ( records , temp_input . name , \"fasta\" ) temp_output = tempfile . NamedTemporaryFile () muscle = self . parameters . arguments [ \"muscle_binary\" ] subprocess . run ([ muscle , \"-align\" , temp_input . name , \"-output\" , temp_output . name ], stderr = subprocess . DEVNULL ) temp_input . close () msa = Bio . AlignIO . read ( temp_output . name , \"fasta\" ) msa . sort ( key = lambda r : r . description ) msa_info = Bio . Align . AlignInfo . SummaryInfo ( msa ) msa_consensus = msa_info . gap_consensus ( threshold = self . parameters . arguments [ \"consensus_threshold\" ]) temp_output . close () if seq_type == \"nt\" : self . length = msa . get_alignment_length () self . msa [ seq_type ], self . msa_consensus [ seq_type ] = msa , msa_consensus avr_distance = str ( round ( statistics . mean ([ i . distance for i in self . path ]))) self . id = f \"length- { self . msa [ 'nt' ] . get_alignment_length () } |score\u2013 { round ( self . score ) } |\" \\ f \"num_of_orfs- { len ( self . path ) } |avr_dist- { avr_distance } \" return None def plot_ggmsa ( self ) -> None : \"\"\"Plot MSA of conserved ORFs saved as fasta files. Note: R script based on ggmsa package [yulab-smu.top/ggmsa] used to produce MSA plots. R script (msa_plot.R) can be found in output_dir. This method uses subprocess to run this R script in the following way: `Rscript {output_dir}/msa_plot.R --msa_fasta path_to_fasta --output output_path --seq_type (nt/aa) --width N(mm) --height M(mm)`. Since during each run of uorf4u a local copy of this script is created in your output_dir, you can change it without any consequences for next uorf4u runs. Returns: None \"\"\" rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_visualisation\" ) for i in self . parameters . arguments [ \"sequences_to_write\" ]])) fasta_files_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_fasta_files\" ) for i in self . parameters . arguments [ \"sequences_to_write\" ]])) for o_dir in output_dirs . values (): if not ( os . path . exists ( o_dir )): os . mkdir ( o_dir ) r_script_path = self . parameters . arguments [ \"plot_msa_R_script\" ] r_script_local = os . path . join ( self . parameters . arguments [ \"output_dir\" ], os . path . basename ( r_script_path )) if not ( os . path . exists ( r_script_local )): shutil . copy ( r_script_path , r_script_local ) for s_type in self . parameters . arguments [ \"sequences_to_write\" ]: current_msa = self . msa [ s_type ] if s_type == \"nt\" or s_type == \"sd\" : seq_type = \"nt\" else : seq_type = \"aa\" output_file = os . path . abspath ( os . path . join ( output_dirs [ s_type ], f \" { self . id } .pdf\" )) input_file = os . path . abspath ( os . path . join ( fasta_files_dirs [ s_type ], f \" { self . id } .fa\" )) num_sequences = len ( current_msa ) length_of_alignment = current_msa . get_alignment_length () page_width = ( 50 + length_of_alignment ) * 5 page_height = max ( 17 , ( num_sequences + 5 ) * 3 ) subprocess . run ([ \"Rscript\" , r_script_local , \"--msa_fasta\" , input_file , \"--output\" , output_file , \"--seq_type\" , seq_type , \"--width\" , str ( page_width ), \"--height\" , str ( page_height )]) def plot_logo ( self ) -> None : \"\"\"Plot sequence Logo of conserved ORFs MSA saved as fasta files. Note: This method uses logomaker package to produce images. Returns: None \"\"\" rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _seqlogo_visualisation\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) for o_dir in output_dirs . values (): if not ( os . path . exists ( o_dir )): os . mkdir ( o_dir ) codons = Bio . Data . CodonTable . ambiguous_dna_by_name [ self . parameters . arguments [ \"ncbi_genetic_code_name\" ]] . protein_alphabet nucleotides = Bio . Data . CodonTable . ambiguous_dna_by_name [ self . parameters . arguments [ \"ncbi_genetic_code_name\" ]] . nucleotide_alphabet alphabet = dict ( nt = nucleotides , aa = codons ) for s_type in self . parameters . arguments [ \"sequences_to_write\" ]: current_msa = self . msa [ s_type ] if s_type == \"nt\" or s_type == \"sd\" : seq_type = \"nt\" elif s_type == \"aa\" : seq_type = \"aa\" output_file = os . path . abspath ( os . path . join ( output_dirs [ s_type ], f \" { os . path . basename ( self . id ) } .pdf\" )) msa_length = current_msa . get_alignment_length () num_of_sequences = len ( current_msa ) current_msa_info = Bio . Align . AlignInfo . SummaryInfo ( current_msa ) pos_specific_dict = dict () pos_specific_score_matrix = current_msa_info . pos_specific_score_matrix () for i in alphabet [ seq_type ]: pos_specific_dict [ i ] = [ 0 for j in range ( msa_length )] for i in range ( msa_length ): for element in pos_specific_score_matrix [ i ] . keys (): pos_specific_dict [ element ][ i ] = ( pos_specific_score_matrix [ i ][ element ] / num_of_sequences ) pos = [ i for i in range ( msa_length )] matrix_db = pandas . DataFrame ( pos_specific_dict , index = pos ) used_alphabet = [ k for k , v in pos_specific_dict . items () if sum ( v ) > 0 ] max_value = 1 if self . parameters . arguments [ \"logo_type\" ] == 'information' : info_mat = logomaker . transform_matrix ( matrix_db , from_type = \"probability\" , to_type = \"information\" ) matrix_db = info_mat # max_value = math.log2(len(used_alphabet)) # to update max_value = math . log2 ( len ( alphabet [ seq_type ])) colors = self . parameters . arguments [ f \"palette_ { seq_type } \" ] fig_size = ( max ( 10 , msa_length * 1.3 ), min ( 2.5 , 2.5 * 10 / ( msa_length ** ( 1 / 6 )))) logo = logomaker . Logo ( matrix_db , color_scheme = colors , figsize = fig_size ) logo . style_spines ( visible = False ) logo . style_spines ( spines = [ \"left\" ], visible = True , linewidth = 0.7 ) logo . ax . set_xticks ([]) logo . ax . set_yticks ([ 0 , max_value ]) plt . savefig ( output_file ) plt . close ( logo . fig ) return None __init__ ( parameters ) Create a Path object. Parameters: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/data_processing.py 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 def __init__ ( self , parameters : uorf4u . manager . Parameters ): \"\"\"Create a Path object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . parameters = parameters self . path = [] self . score = 0 self . msa = dict () self . msa_consensus = dict () self . id = None self . length = None __len__ () len magic method for a Path object. Returns: int \u2013 length of the path attribute - a number of ORFs in a Path. Source code in uorf4u/data_processing.py 1245 1246 1247 1248 1249 1250 1251 1252 def __len__ ( self ): \"\"\"__len__ magic method for a Path object. Returns: int: length of the path attribute - a number of ORFs in a Path. \"\"\" return len ( self . path ) calculate_similarity ( other ) Calculate fraction of identical ORFs between two Path object. Note: If two objects have different length, the fraction will be calculated as a number of identical ORFs divided by length of the shortest Path. Returns: float ( float ) \u2013 fraction of identical ORFs. Source code in uorf4u/data_processing.py 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 def calculate_similarity ( self , other ) -> float : \"\"\"Calculate fraction of identical ORFs between two Path object. __Note:__ If two objects have different length, the fraction will be calculated as a number of identical ORFs divided by length of the shortest Path. Returns: float: fraction of identical ORFs. \"\"\" num_of_identical_elements = len ( set ( self . path ) & set ( other . path )) fraction_of_identical_orfs = num_of_identical_elements / min ( len ( self ), len ( other )) return fraction_of_identical_orfs muscle_msa () Run a multiple sequence alignment tool (muscle) for the ORFs nucleotide and amino acid sequences. Note: This method updates nt_msa and aa_msa attributes. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 def muscle_msa ( self ) -> None : \"\"\"Run a multiple sequence alignment tool (muscle) for the ORFs nucleotide and amino acid sequences. Note: This method updates nt_msa and aa_msa attributes. Returns: None \"\"\" self . msa = dict () for seq_type in self . parameters . arguments [ \"sequences_to_write\" ]: records = [] for orf in self . path : # record_id = f\"{orf.id}\" # record_description = f\"{(orf.name.split('|')[0])}\" record_id = f \" { ( orf . name . split ( '|' )[ 0 ]) . replace ( ' ' , '_' ) } \" record_description = f \" { orf . id } \" if seq_type == \"nt\" : record = Bio . SeqRecord . SeqRecord ( orf . nt_sequence , record_id , \"\" , record_description ) elif seq_type == \"aa\" : record = Bio . SeqRecord . SeqRecord ( orf . aa_sequence , record_id , \"\" , record_description ) elif seq_type == \"sd\" : record = Bio . SeqRecord . SeqRecord ( orf . sd_window_seq , record_id , \"\" , record_description ) records . append ( record ) temp_input = tempfile . NamedTemporaryFile () Bio . SeqIO . write ( records , temp_input . name , \"fasta\" ) temp_output = tempfile . NamedTemporaryFile () muscle = self . parameters . arguments [ \"muscle_binary\" ] subprocess . run ([ muscle , \"-align\" , temp_input . name , \"-output\" , temp_output . name ], stderr = subprocess . DEVNULL ) temp_input . close () msa = Bio . AlignIO . read ( temp_output . name , \"fasta\" ) msa . sort ( key = lambda r : r . description ) msa_info = Bio . Align . AlignInfo . SummaryInfo ( msa ) msa_consensus = msa_info . gap_consensus ( threshold = self . parameters . arguments [ \"consensus_threshold\" ]) temp_output . close () if seq_type == \"nt\" : self . length = msa . get_alignment_length () self . msa [ seq_type ], self . msa_consensus [ seq_type ] = msa , msa_consensus avr_distance = str ( round ( statistics . mean ([ i . distance for i in self . path ]))) self . id = f \"length- { self . msa [ 'nt' ] . get_alignment_length () } |score\u2013 { round ( self . score ) } |\" \\ f \"num_of_orfs- { len ( self . path ) } |avr_dist- { avr_distance } \" return None plot_ggmsa () Plot MSA of conserved ORFs saved as fasta files. Note: R script based on ggmsa package [yulab-smu.top/ggmsa] used to produce MSA plots. R script (msa_plot.R) can be found in output_dir. This method uses subprocess to run this R script in the following way: Rscript {output_dir}/msa_plot.R --msa_fasta path_to_fasta --output output_path --seq_type (nt/aa) --width N(mm) --height M(mm) . Since during each run of uorf4u a local copy of this script is created in your output_dir, you can change it without any consequences for next uorf4u runs. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 def plot_ggmsa ( self ) -> None : \"\"\"Plot MSA of conserved ORFs saved as fasta files. Note: R script based on ggmsa package [yulab-smu.top/ggmsa] used to produce MSA plots. R script (msa_plot.R) can be found in output_dir. This method uses subprocess to run this R script in the following way: `Rscript {output_dir}/msa_plot.R --msa_fasta path_to_fasta --output output_path --seq_type (nt/aa) --width N(mm) --height M(mm)`. Since during each run of uorf4u a local copy of this script is created in your output_dir, you can change it without any consequences for next uorf4u runs. Returns: None \"\"\" rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_visualisation\" ) for i in self . parameters . arguments [ \"sequences_to_write\" ]])) fasta_files_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_fasta_files\" ) for i in self . parameters . arguments [ \"sequences_to_write\" ]])) for o_dir in output_dirs . values (): if not ( os . path . exists ( o_dir )): os . mkdir ( o_dir ) r_script_path = self . parameters . arguments [ \"plot_msa_R_script\" ] r_script_local = os . path . join ( self . parameters . arguments [ \"output_dir\" ], os . path . basename ( r_script_path )) if not ( os . path . exists ( r_script_local )): shutil . copy ( r_script_path , r_script_local ) for s_type in self . parameters . arguments [ \"sequences_to_write\" ]: current_msa = self . msa [ s_type ] if s_type == \"nt\" or s_type == \"sd\" : seq_type = \"nt\" else : seq_type = \"aa\" output_file = os . path . abspath ( os . path . join ( output_dirs [ s_type ], f \" { self . id } .pdf\" )) input_file = os . path . abspath ( os . path . join ( fasta_files_dirs [ s_type ], f \" { self . id } .fa\" )) num_sequences = len ( current_msa ) length_of_alignment = current_msa . get_alignment_length () page_width = ( 50 + length_of_alignment ) * 5 page_height = max ( 17 , ( num_sequences + 5 ) * 3 ) subprocess . run ([ \"Rscript\" , r_script_local , \"--msa_fasta\" , input_file , \"--output\" , output_file , \"--seq_type\" , seq_type , \"--width\" , str ( page_width ), \"--height\" , str ( page_height )]) plot_logo () Plot sequence Logo of conserved ORFs MSA saved as fasta files. Note: This method uses logomaker package to produce images. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 def plot_logo ( self ) -> None : \"\"\"Plot sequence Logo of conserved ORFs MSA saved as fasta files. Note: This method uses logomaker package to produce images. Returns: None \"\"\" rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _seqlogo_visualisation\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) for o_dir in output_dirs . values (): if not ( os . path . exists ( o_dir )): os . mkdir ( o_dir ) codons = Bio . Data . CodonTable . ambiguous_dna_by_name [ self . parameters . arguments [ \"ncbi_genetic_code_name\" ]] . protein_alphabet nucleotides = Bio . Data . CodonTable . ambiguous_dna_by_name [ self . parameters . arguments [ \"ncbi_genetic_code_name\" ]] . nucleotide_alphabet alphabet = dict ( nt = nucleotides , aa = codons ) for s_type in self . parameters . arguments [ \"sequences_to_write\" ]: current_msa = self . msa [ s_type ] if s_type == \"nt\" or s_type == \"sd\" : seq_type = \"nt\" elif s_type == \"aa\" : seq_type = \"aa\" output_file = os . path . abspath ( os . path . join ( output_dirs [ s_type ], f \" { os . path . basename ( self . id ) } .pdf\" )) msa_length = current_msa . get_alignment_length () num_of_sequences = len ( current_msa ) current_msa_info = Bio . Align . AlignInfo . SummaryInfo ( current_msa ) pos_specific_dict = dict () pos_specific_score_matrix = current_msa_info . pos_specific_score_matrix () for i in alphabet [ seq_type ]: pos_specific_dict [ i ] = [ 0 for j in range ( msa_length )] for i in range ( msa_length ): for element in pos_specific_score_matrix [ i ] . keys (): pos_specific_dict [ element ][ i ] = ( pos_specific_score_matrix [ i ][ element ] / num_of_sequences ) pos = [ i for i in range ( msa_length )] matrix_db = pandas . DataFrame ( pos_specific_dict , index = pos ) used_alphabet = [ k for k , v in pos_specific_dict . items () if sum ( v ) > 0 ] max_value = 1 if self . parameters . arguments [ \"logo_type\" ] == 'information' : info_mat = logomaker . transform_matrix ( matrix_db , from_type = \"probability\" , to_type = \"information\" ) matrix_db = info_mat # max_value = math.log2(len(used_alphabet)) # to update max_value = math . log2 ( len ( alphabet [ seq_type ])) colors = self . parameters . arguments [ f \"palette_ { seq_type } \" ] fig_size = ( max ( 10 , msa_length * 1.3 ), min ( 2.5 , 2.5 * 10 / ( msa_length ** ( 1 / 6 )))) logo = logomaker . Logo ( matrix_db , color_scheme = colors , figsize = fig_size ) logo . style_spines ( visible = False ) logo . style_spines ( spines = [ \"left\" ], visible = True , linewidth = 0.7 ) logo . ax . set_xticks ([]) logo . ax . set_yticks ([ 0 , max_value ]) plt . savefig ( output_file ) plt . close ( logo . fig ) return None sort () Sort list of ORFs by their names. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 def sort ( self ) -> None : \"\"\"Sort list of ORFs by their names. Returns: None \"\"\" sorted_path = [ x for _ , x in sorted ( zip ([ i . name for i in self . path ], self . path ), key = lambda pair : pair [ 0 ])] self . path = sorted_path return None update ( orf , score = 0 ) Update a Path with a new ORF. Parameters: orf ( ORF ) \u2013 an ORF class' object. score ( float ) \u2013 a sum of pairwise alignment scores of the ORF against all ORFs in the Path. Returns: \u2013 None Source code in uorf4u/data_processing.py 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 def update ( self , orf : ORF , score = 0 ): \"\"\"Update a Path with a new ORF. Arguments: orf (ORF): an ORF class' object. score (float): a sum of pairwise alignment scores of the ORF against all ORFs in the Path. Returns: None \"\"\" self . path . append ( orf ) self . score += score RefSeqProtein A RefSeqProtein object holds a RefSeq protein and information about it. Attributes: accession_number ( str ) \u2013 RefSeq accession number. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. record ( Bio . SeqRecord . SeqRecord ) \u2013 SeqRecord of the ncbi protein db. Can be obtained by the get_record() method. taxid ( str ) \u2013 Taxid of the protein. Can be obtained with get_assemblies() method. kingdom_taxid ( str ) \u2013 Kingdom taxid of a protein. Can be obtained with get_assemblies() method. organism ( str ) \u2013 Organism name of a protein. Can be obtained with get_assemblies() method. name ( str ) \u2013 Protein's product name from the ncbi (if available). assemblies_coordinates ( list ) \u2013 List of dictionaries with information about assemblies' coordinates of the protein obtained from ipg ncbi database. loci ( dict ) \u2013 Dict with keys as locus_ids and values as Locus class' objects. Source code in uorf4u/data_processing.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 class RefSeqProtein : \"\"\"A RefSeqProtein object holds a RefSeq protein and information about it. Attributes: accession_number (str): RefSeq accession number. parameters (uorf4u.manager.Parameters): Parameters' class object. record (Bio.SeqRecord.SeqRecord): SeqRecord of the ncbi protein db. Can be obtained by the get_record() method. taxid (str): Taxid of the protein. Can be obtained with get_assemblies() method. kingdom_taxid (str): Kingdom taxid of a protein. Can be obtained with get_assemblies() method. organism (str): Organism name of a protein. Can be obtained with get_assemblies() method. name (str): Protein's product name from the ncbi (if available). assemblies_coordinates (list): List of dictionaries with information about assemblies' coordinates of the protein obtained from ipg ncbi database. loci (dict): Dict with keys as locus_ids and values as Locus class' objects. \"\"\" def __init__ ( self , accession_number : str , parameters : uorf4u . manager . Parameters ): \"\"\"Create a RefSeqProtein object. Arguments: accession_number (str): RefSeq accession number. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . accession_number = accession_number self . name = \"NA\" self . parameters = parameters self . record = None self . taxid = None self . kingdom_taxid = None self . organism = None self . assemblies_coordinates = None self . loci = None def get_record ( self ) -> Bio . SeqRecord . SeqRecord : \"\"\"Get a SeqRecord object of a protein from the ncbi protein database. Note: This method returns a record and updates the record attribute. Returns: Bio.SeqRecord.SeqRecordRecord: Record of the protein. \"\"\" try : handle = Bio . Entrez . efetch ( db = \"protein\" , id = self . accession_number , rettype = \"gbwithparts\" , retmode = \"text\" ) self . record = Bio . SeqIO . read ( handle , \"gb\" ) return self . record except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to get a SeqRecord of the protein from the ncbi protein database.\" ) from error def get_assemblies ( self ) -> list : \"\"\"Get assemblies (loci) coordinates of a protein. Note: This method returns a list of assemblies coordinates and updates the self.assemblies_coordinates attribute. Returns: list: List of dictionaries with information about assemblies' coordinates of a protein obtained from the ipg ncbi database. \"\"\" try : handle = Bio . Entrez . efetch ( db = \"protein\" , rettype = \"ipg\" , retmode = \"xml\" , id = self . accession_number ) xml_output = ( handle . read ()) . decode ( 'utf-8' ) root = xml . etree . ElementTree . fromstring ( xml_output ) list_of_kingdom_taxid = [] assemblies_coordinates = [] for protein in root . iter ( \"Protein\" ): if protein . attrib [ \"source\" ] == \"RefSeq\" : if \"name\" in protein . attrib . keys (): self . name = protein . attrib [ \"name\" ] self . taxid = protein . attrib [ \"taxid\" ] self . kingdom_taxid = protein . attrib [ \"kingdom_taxid\" ] self . organism = protein . attrib [ \"org\" ] list_of_kingdom_taxid . append ( self . kingdom_taxid ) for cds in protein . iter ( \"CDS\" ): if \"assembly\" not in cds . attrib . keys (): cds . attrib [ \"assembly\" ] = \"NA\" if \"strain\" not in cds . attrib . keys (): cds . attrib [ \"strain\" ] = \"NA\" try : assemblies_coordinates . append ( dict ( locus_id = cds . attrib [ \"accver\" ], start = ( int ( cds . attrib [ \"start\" ]) - 1 ), stop = int ( cds . attrib [ \"stop\" ]), strand = cds . attrib [ 'strand' ], length = int ( cds . attrib [ \"stop\" ]) - ( int ( cds . attrib [ \"start\" ]) - 1 ), assembly = cds . attrib [ \"assembly\" ], strain = cds . attrib [ \"strain\" ], org = cds . attrib [ \"org\" ], taxid = cds . attrib [ \"taxid\" ])) except : print ( f \"\u2755Attention: { cds . attrib [ 'accver' ] } record is not completed and\" f \" cannot be processed\" , file = sys . stderr ) if len ( assemblies_coordinates ) == 0 : print ( f \"\u2757Warning message: \\n\\t No assembly was found for the protein \" f \"' { self . accession_number } '. \\n\\t This protein record can be suppressed by the ncbi.\" , file = sys . stderr ) self . assemblies_coordinates = assemblies_coordinates return assemblies_coordinates except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to get assemblies coordinates of a protein.\" ) from error ''' def get_loci(self, start=-float(\"inf\"), end=float(\"inf\"), strand=\"NA\") -> dict: \"\"\"Get Locus class objects for each sequence from the ncbi nt database on which the protein is annotated. Returns: dict: Dict with keys as locus_ids and values as Locus class' objects. \"\"\" self.loci = dict() for assembly in self.assemblies_coordinates: locus_id = assembly[\"locus_id\"] self.loci[locus_id] = Locus(locus_id, start_b=start, end_b=end, strand=strand) return self.loci ''' def blastp_searching_for_homologues ( self ) -> list : \"\"\"Search for a protein's homologues with blastp against the 'refseq_protein' database. Note: This function does not create a new object's attribute; It only returns a list of accession numbers. Returns: list: List of proteins' accession numbers obtained with blastp searching. This list also contains the query protein's accession number. \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc40 Searching for homologues of { self . accession_number } with blastp against the RefSeq database...\" , file = sys . stdout ) handle = Bio . Blast . NCBIWWW . qblast ( \"blastp\" , \"refseq_protein\" , self . accession_number , expect = self . parameters . arguments [ \"blastp_evalue_cutoff\" ], hitlist_size = self . parameters . arguments [ \"blastp_hit_list_size\" ], alignments = self . parameters . arguments [ \"blastp_max_number_of_alignments\" ]) xml_output = handle . read () hits_an_list = [ self . accession_number ] blastp_stat_dict = dict () blastp_stat_dict [ self . accession_number ] = dict ( pident_to_query_length = \"the query\" , pident_to_sequence_length = \"the query\" , pident_to_alignment_length = \"the query\" , evalue = \"the query\" ) root = xml . etree . ElementTree . fromstring ( xml_output ) query_length = int ( root . find ( \"BlastOutput_query-len\" ) . text ) for hit in root . iter ( \"Hit\" ): hit_id = hit . find ( \"Hit_id\" ) . text . strip ( \"ref\" ) . strip ( \"|\" ) if hit_id != self . accession_number : hit_description = hit . find ( \"Hit_def\" ) . text subject_length = int ( hit . find ( \"Hit_len\" ) . text ) hsp_identity_sum , hsp_positive_sum , hsp_align_length = 0 , 0 , 0 evalue = [] for hsp in hit . iter ( \"Hsp\" ): hsp_identity_sum += int ( hsp . find ( \"Hsp_identity\" ) . text ) hsp_positive_sum += int ( hsp . find ( \"Hsp_positive\" ) . text ) hsp_align_length += int ( hsp . find ( \"Hsp_align-len\" ) . text ) evalue . append ( hsp . find ( \"Hsp_evalue\" ) . text ) pident_to_query_length = hsp_identity_sum / query_length pident_to_seq_length = hsp_identity_sum / subject_length pident_to_alignment_length = hsp_identity_sum / hsp_align_length if pident_to_query_length >= self . parameters . arguments [ \"blastp_pident_to_query_length_cutoff\" ]: blastp_stat_dict [ hit_id ] = dict ( pident_to_query_length = str ( round ( pident_to_query_length , 2 )), pident_to_sequence_length = str ( round ( pident_to_seq_length , 2 )), pident_to_alignment_length = str ( round ( pident_to_alignment_length , 2 )), evalue = \",\" . join ( evalue )) if hit_id not in hits_an_list : hits_an_list . append ( hit_id ) columns = \" \\t \" . join ([ \"accession_number\" , \"name\" , \"pident_to_query_length\" , \"pident_to_sequence_length\" , \"pident_to_alignment_length\" , \"e-value\" ]) table = [ columns ] hits_records_list = [ RefSeqProtein ( i , self . parameters ) for i in hits_an_list ] for rec in hits_records_list : rec . get_assemblies () table . append ( \" \\t \" . join ([ rec . accession_number , rec . name , blastp_stat_dict [ rec . accession_number ][ \"pident_to_query_length\" ], blastp_stat_dict [ rec . accession_number ][ \"pident_to_sequence_length\" ], blastp_stat_dict [ rec . accession_number ][ \"pident_to_alignment_length\" ], blastp_stat_dict [ rec . accession_number ][ \"evalue\" ]])) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) output_filename = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"found_homologues.tsv\" ) f = open ( output_filename , \"w\" ) f . write ( \" \\n \" . join ( table )) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\u2705 { len ( hits_records_list ) - 1 } homologues were found. \" f \"\ud83d\udc8c Summary table saved to: { output_filename } \" , file = sys . stdout ) return hits_an_list except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to perform searching for homologues with blastp.\" ) from error __init__ ( accession_number , parameters ) Create a RefSeqProtein object. Parameters: accession_number ( str ) \u2013 RefSeq accession number. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/data_processing.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 def __init__ ( self , accession_number : str , parameters : uorf4u . manager . Parameters ): \"\"\"Create a RefSeqProtein object. Arguments: accession_number (str): RefSeq accession number. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . accession_number = accession_number self . name = \"NA\" self . parameters = parameters self . record = None self . taxid = None self . kingdom_taxid = None self . organism = None self . assemblies_coordinates = None self . loci = None blastp_searching_for_homologues () Search for a protein's homologues with blastp against the 'refseq_protein' database. Note: This function does not create a new object's attribute; It only returns a list of accession numbers. Returns: list ( list ) \u2013 List of proteins' accession numbers obtained with blastp searching. This list also contains the query protein's accession number. Source code in uorf4u/data_processing.py 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 def blastp_searching_for_homologues ( self ) -> list : \"\"\"Search for a protein's homologues with blastp against the 'refseq_protein' database. Note: This function does not create a new object's attribute; It only returns a list of accession numbers. Returns: list: List of proteins' accession numbers obtained with blastp searching. This list also contains the query protein's accession number. \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc40 Searching for homologues of { self . accession_number } with blastp against the RefSeq database...\" , file = sys . stdout ) handle = Bio . Blast . NCBIWWW . qblast ( \"blastp\" , \"refseq_protein\" , self . accession_number , expect = self . parameters . arguments [ \"blastp_evalue_cutoff\" ], hitlist_size = self . parameters . arguments [ \"blastp_hit_list_size\" ], alignments = self . parameters . arguments [ \"blastp_max_number_of_alignments\" ]) xml_output = handle . read () hits_an_list = [ self . accession_number ] blastp_stat_dict = dict () blastp_stat_dict [ self . accession_number ] = dict ( pident_to_query_length = \"the query\" , pident_to_sequence_length = \"the query\" , pident_to_alignment_length = \"the query\" , evalue = \"the query\" ) root = xml . etree . ElementTree . fromstring ( xml_output ) query_length = int ( root . find ( \"BlastOutput_query-len\" ) . text ) for hit in root . iter ( \"Hit\" ): hit_id = hit . find ( \"Hit_id\" ) . text . strip ( \"ref\" ) . strip ( \"|\" ) if hit_id != self . accession_number : hit_description = hit . find ( \"Hit_def\" ) . text subject_length = int ( hit . find ( \"Hit_len\" ) . text ) hsp_identity_sum , hsp_positive_sum , hsp_align_length = 0 , 0 , 0 evalue = [] for hsp in hit . iter ( \"Hsp\" ): hsp_identity_sum += int ( hsp . find ( \"Hsp_identity\" ) . text ) hsp_positive_sum += int ( hsp . find ( \"Hsp_positive\" ) . text ) hsp_align_length += int ( hsp . find ( \"Hsp_align-len\" ) . text ) evalue . append ( hsp . find ( \"Hsp_evalue\" ) . text ) pident_to_query_length = hsp_identity_sum / query_length pident_to_seq_length = hsp_identity_sum / subject_length pident_to_alignment_length = hsp_identity_sum / hsp_align_length if pident_to_query_length >= self . parameters . arguments [ \"blastp_pident_to_query_length_cutoff\" ]: blastp_stat_dict [ hit_id ] = dict ( pident_to_query_length = str ( round ( pident_to_query_length , 2 )), pident_to_sequence_length = str ( round ( pident_to_seq_length , 2 )), pident_to_alignment_length = str ( round ( pident_to_alignment_length , 2 )), evalue = \",\" . join ( evalue )) if hit_id not in hits_an_list : hits_an_list . append ( hit_id ) columns = \" \\t \" . join ([ \"accession_number\" , \"name\" , \"pident_to_query_length\" , \"pident_to_sequence_length\" , \"pident_to_alignment_length\" , \"e-value\" ]) table = [ columns ] hits_records_list = [ RefSeqProtein ( i , self . parameters ) for i in hits_an_list ] for rec in hits_records_list : rec . get_assemblies () table . append ( \" \\t \" . join ([ rec . accession_number , rec . name , blastp_stat_dict [ rec . accession_number ][ \"pident_to_query_length\" ], blastp_stat_dict [ rec . accession_number ][ \"pident_to_sequence_length\" ], blastp_stat_dict [ rec . accession_number ][ \"pident_to_alignment_length\" ], blastp_stat_dict [ rec . accession_number ][ \"evalue\" ]])) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) output_filename = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"found_homologues.tsv\" ) f = open ( output_filename , \"w\" ) f . write ( \" \\n \" . join ( table )) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\u2705 { len ( hits_records_list ) - 1 } homologues were found. \" f \"\ud83d\udc8c Summary table saved to: { output_filename } \" , file = sys . stdout ) return hits_an_list except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to perform searching for homologues with blastp.\" ) from error get_assemblies () Get assemblies (loci) coordinates of a protein. Note: This method returns a list of assemblies coordinates and updates the self.assemblies_coordinates attribute. Returns: list ( list ) \u2013 List of dictionaries with information about assemblies' coordinates of a protein obtained from the ipg ncbi database. Source code in uorf4u/data_processing.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 def get_assemblies ( self ) -> list : \"\"\"Get assemblies (loci) coordinates of a protein. Note: This method returns a list of assemblies coordinates and updates the self.assemblies_coordinates attribute. Returns: list: List of dictionaries with information about assemblies' coordinates of a protein obtained from the ipg ncbi database. \"\"\" try : handle = Bio . Entrez . efetch ( db = \"protein\" , rettype = \"ipg\" , retmode = \"xml\" , id = self . accession_number ) xml_output = ( handle . read ()) . decode ( 'utf-8' ) root = xml . etree . ElementTree . fromstring ( xml_output ) list_of_kingdom_taxid = [] assemblies_coordinates = [] for protein in root . iter ( \"Protein\" ): if protein . attrib [ \"source\" ] == \"RefSeq\" : if \"name\" in protein . attrib . keys (): self . name = protein . attrib [ \"name\" ] self . taxid = protein . attrib [ \"taxid\" ] self . kingdom_taxid = protein . attrib [ \"kingdom_taxid\" ] self . organism = protein . attrib [ \"org\" ] list_of_kingdom_taxid . append ( self . kingdom_taxid ) for cds in protein . iter ( \"CDS\" ): if \"assembly\" not in cds . attrib . keys (): cds . attrib [ \"assembly\" ] = \"NA\" if \"strain\" not in cds . attrib . keys (): cds . attrib [ \"strain\" ] = \"NA\" try : assemblies_coordinates . append ( dict ( locus_id = cds . attrib [ \"accver\" ], start = ( int ( cds . attrib [ \"start\" ]) - 1 ), stop = int ( cds . attrib [ \"stop\" ]), strand = cds . attrib [ 'strand' ], length = int ( cds . attrib [ \"stop\" ]) - ( int ( cds . attrib [ \"start\" ]) - 1 ), assembly = cds . attrib [ \"assembly\" ], strain = cds . attrib [ \"strain\" ], org = cds . attrib [ \"org\" ], taxid = cds . attrib [ \"taxid\" ])) except : print ( f \"\u2755Attention: { cds . attrib [ 'accver' ] } record is not completed and\" f \" cannot be processed\" , file = sys . stderr ) if len ( assemblies_coordinates ) == 0 : print ( f \"\u2757Warning message: \\n\\t No assembly was found for the protein \" f \"' { self . accession_number } '. \\n\\t This protein record can be suppressed by the ncbi.\" , file = sys . stderr ) self . assemblies_coordinates = assemblies_coordinates return assemblies_coordinates except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to get assemblies coordinates of a protein.\" ) from error get_record () Get a SeqRecord object of a protein from the ncbi protein database. Note: This method returns a record and updates the record attribute. Returns: Bio . SeqRecord . SeqRecord \u2013 Bio.SeqRecord.SeqRecordRecord: Record of the protein. Source code in uorf4u/data_processing.py 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 def get_record ( self ) -> Bio . SeqRecord . SeqRecord : \"\"\"Get a SeqRecord object of a protein from the ncbi protein database. Note: This method returns a record and updates the record attribute. Returns: Bio.SeqRecord.SeqRecordRecord: Record of the protein. \"\"\" try : handle = Bio . Entrez . efetch ( db = \"protein\" , id = self . accession_number , rettype = \"gbwithparts\" , retmode = \"text\" ) self . record = Bio . SeqIO . read ( handle , \"gb\" ) return self . record except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to get a SeqRecord of the protein from the ncbi protein database.\" ) from error manager submodule This module provides managing classes and methods for the tool. Parameters A Parameters object holds and parse cmd's and config's arguments for the tool. Note: A Parameters object have to be created in each script since it's used by each class of the tool as a mandatory argument. Source code in uorf4u/manager.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 class Parameters : \"\"\"A Parameters object holds and parse cmd's and config's arguments for the tool. Note: A Parameters object have to be created in each script since it's used by each class of the tool as a mandatory argument. \"\"\" def __init__ ( self ): self . arguments = dict ( assemblies_list = \"NA\" , debug = False , verbose = False ) def parse_cmd_arguments ( self ) -> None : parser = argparse . ArgumentParser ( prog = \"uorf4u\" , add_help = False , usage = \"uorf4u [-an accession_number| -hl [ac1, ac2..] | -hlf path ]\" \"[optional arguments]\" ) mutually_exclusive_group = parser . add_mutually_exclusive_group () mutually_exclusive_group . add_argument ( \"-an\" , dest = \"accession_number\" , type = str , default = None ) mutually_exclusive_group . add_argument ( \"-hl\" , dest = \"homologues_list\" , nargs = \"*\" , default = None ) mutually_exclusive_group . add_argument ( \"-hlf\" , dest = \"homologues_list_file\" , type = str , default = None ) # mutually_exclusive_group.add_argument('-useq', dest='upstream_sequences', type=str, default=None) parser . add_argument ( \"--data\" , dest = \"uorf4u_data\" , action = \"store_true\" ) parser . add_argument ( \"-al\" , dest = \"assemblies_list\" , type = str , default = \"NA\" ) parser . add_argument ( \"-at\" , dest = \"alignment_type\" , choices = [ 'nt' , 'aa' , None ], type = str , default = None ) parser . add_argument ( \"-ul\" , dest = \"upstream_region_length\" , type = int , default = None ) parser . add_argument ( \"-bh\" , dest = \"blastp_hit_list_size\" , type = int , default = None ) parser . add_argument ( \"-asc\" , dest = \"alternative_start_codons\" , action = \"store_true\" , default = None ) parser . add_argument ( \"-o\" , dest = \"output_dir\" , type = str , default = None ) parser . add_argument ( \"-c\" , dest = \"config_file\" , type = str , default = \"internal\" ) parser . add_argument ( \"-v\" , \"--version\" , action = 'version' , version = ' %(prog)s 0.4.0' ) parser . add_argument ( \"--verbose\" , \"-verbose\" , dest = \"verbose\" , action = \"store_true\" ) parser . add_argument ( \"--debug\" , \"-debug\" , dest = \"debug\" , action = \"store_true\" ) parser . add_argument ( \"-h\" , \"--help\" , dest = \"help\" , action = \"store_true\" ) args = parser . parse_args () args = vars ( args ) if len ( sys . argv [ 1 :]) == 0 : args [ \"help\" ] = True if args [ \"uorf4u_data\" ]: uorf4u . methods . copy_package_data () sys . exit () if args [ \"help\" ]: help_message_path = os . path . join ( os . path . dirname ( __file__ ), 'uorf4u_data' , \"help.txt\" ) with open ( help_message_path , \"r\" ) as help_message : print ( help_message . read (), file = sys . stdout ) sys . exit () filtered_args = { k : v for k , v in args . items () if v is not None } self . arguments . update ( filtered_args ) def load_config ( self , path = \"internal\" ): try : if path == \"internal\" : path = os . path . join ( os . path . dirname ( __file__ ), \"uorf4u_data\" , \"uorf4u.cfg\" ) config = configs . load ( path ) config = config . get_config () internal_dir = os . path . dirname ( __file__ ) config [ \"root\" ][ \"output_dir\" ] = config [ \"root\" ][ \"output_dir\" ] . replace ( \" {current_date} \" , time . strftime ( \"%Y_%m_ %d -%H_%M\" )) for key in config [ \"root\" ] . keys (): if type ( config [ \"root\" ][ key ]) is str and \" {internal} \" in config [ \"root\" ][ key ]: config [ \"root\" ][ key ] = config [ \"root\" ][ key ] . replace ( \" {internal} \" , os . path . join ( internal_dir , \"uorf4u_data\" )) self . arguments . update ( config [ 'root' ]) self . load_palette () except Exception as error : raise uORF4uError ( \"Unable to parse the specified config file. Please check your config file.\" ) from error def load_palette ( self ): for seq_type in [ \"nt\" , \"aa\" ]: palette_path = self . arguments [ f \"palette_ { seq_type } \" ] palette_pre_dict = configs . load ( palette_path ) . get_config ()[ \"root\" ] palette_dict = dict () for elements , color in palette_pre_dict . items (): for element in elements : palette_dict [ element ] = color self . arguments [ f \"palette_ { seq_type } \" ] = palette_dict def update ( self , parameters ): self . arguments . update ( parameters ) uORF4uError Bases: Exception A helper for exceptions parsing inherited from the Exception class. Source code in uorf4u/manager.py 12 13 14 15 16 class uORF4uError ( Exception ): \"\"\"A helper for exceptions parsing inherited from the Exception class. \"\"\" pass drawing submodule This module provides visualisation of loci annotation. AnnotationPlotManager AnnotationPlotManager object holds needed information for annotation visualisation and controls it. Note: It's supposed that the AnnotationPlotManager' objects will not be used directly by API users since visualisation can be controlled by 'plot_annotation' method. Attributes: path ( uorf4u . data_processing . Path ) \u2013 Path class' objects that holds list of conserved ORFs. upstream_sequences ( list ) \u2013 list of dicts with information about upstream sequences. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. coordinate_system ( dict ) \u2013 coordinate system of figure. additional_data ( dict ) \u2013 dict with data for visualisation tracks. Source code in uorf4u/drawing.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 class AnnotationPlotManager : \"\"\" AnnotationPlotManager object holds needed information for annotation visualisation and controls it. Note: It's supposed that the AnnotationPlotManager' objects will not be used directly by API users since visualisation can be controlled by 'plot_annotation' method. Attributes: path (uorf4u.data_processing.Path): Path class' objects that holds list of conserved ORFs. upstream_sequences (list): list of dicts with information about upstream sequences. parameters (uorf4u.manager.Parameters): Parameters' class object. coordinate_system (dict): coordinate system of figure. additional_data (dict): dict with data for visualisation tracks. \"\"\" def __init__ ( self , path , upstream_sequences : list , parameters : uorf4u . manager . Parameters ): \"\"\"Create a AnnotationPlotManager object. Arguments: path (uorf4u.data_processing.Path): Path class' objects that holds list of conserved ORFs. upstream_sequences (list): list of dicts with information about upstream sequences. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . path = path self . upstream_sequences = upstream_sequences self . parameters = parameters self . coordinate_system = dict () self . additional_data = dict () def define_x_axis_coordinate_system ( self ) -> None : \"\"\"Define coordinate system. Returns: None \"\"\" label_height = self . parameters . arguments [ \"label_height_to_orf_height\" ] * self . parameters . arguments [ \"orf_height\" ] * cm label_font_size = uorf4u . methods . string_height_to_font_size ( label_height , \"regular\" , self . parameters . arguments ) max_label_width = max ([ reportlab . pdfbase . pdfmetrics . stringWidth ( i [ \"id\" ], \"regular\" , label_font_size ) for i in self . upstream_sequences ]) self . additional_data [ \"label_font_size\" ] = label_font_size self . additional_data [ \"ordered_upstream_sequences\" ] = [ self . upstream_sequences [ i ] for i in [ orf . useq_index for orf in self . path . path ]] self . additional_data [ \"number_of_sequences\" ] = len ( self . path ) self . additional_data [ \"max_upstream_sequence_length\" ] = max ( i [ \"useq_upstream_region_length\" ] for i in self . additional_data [ \"ordered_upstream_sequences\" ]) self . additional_data [ \"max_downstream_sequence_length\" ] = max ( i [ \"useq_downstream_region_length\" ] for i in self . additional_data [ \"ordered_upstream_sequences\" ]) window_size_nt = self . additional_data [ \"max_upstream_sequence_length\" ] + self . additional_data [ \"max_downstream_sequence_length\" ] if self . parameters . arguments [ \"annotation_width\" ] == \"auto\" : annotation_width = window_size_nt * self . parameters . arguments [ \"mm_per_nt\" ] * mm else : annotation_width = self . parameters . arguments [ \"annotation_width\" ] * cm self . coordinate_system [ \"transformation_coef\" ] = annotation_width / window_size_nt self . coordinate_system [ \"x_labels_start\" ] = self . parameters . arguments [ \"margin\" ] * cm self . coordinate_system [ \"x_labels_stop\" ] = self . coordinate_system [ \"x_labels_start\" ] + max_label_width self . coordinate_system [ \"x_annotation_start\" ] = self . coordinate_system [ \"x_labels_stop\" ] + \\ self . parameters . arguments [ \"label_gap\" ] * cm self . coordinate_system [ \"x_annotation_stop\" ] = self . coordinate_system [ \"x_annotation_start\" ] + annotation_width self . coordinate_system [ \"figure_width\" ] = 2 * self . parameters . arguments [ \"margin\" ] * cm + annotation_width + \\ max_label_width + self . parameters . arguments [ \"label_gap\" ] * cm self . coordinate_system [ \"figure_height\" ] = self . parameters . arguments [ \"margin\" ] * cm return None def create_tracks ( self ) -> None : \"\"\"Create visualisation tracks. Returns: None \"\"\" self . tracks = [] \"\"\" title_loader = TitleLoader(self.parameters) title_loader.prepare_data(self.coordinate_system, self.additional_data) title_track = title_loader.create_track() self.tracks.append(title_track) self.coordinate_system[\"figure_height\"] += title_track.needed_y_space() \"\"\" for index in range ( self . additional_data [ \"number_of_sequences\" ]): upstream_sequence = self . additional_data [ \"ordered_upstream_sequences\" ][ index ] conserved_orf = self . path . path [ index ] sequence_loader = SequencesLoader ( self . parameters ) sequence_loader . prepare_data ( upstream_sequence , conserved_orf , self . coordinate_system , self . additional_data ) track = sequence_loader . create_track () self . tracks . append ( track ) self . coordinate_system [ \"figure_height\" ] += track . needed_y_space () self . coordinate_system [ \"figure_height\" ] += self . parameters . arguments [ \"gap\" ] * cm # if index < self.additional_data[\"number_of_sequences\"] - 1: axis_tics_loader = AxisLoader ( self . parameters ) axis_tics_loader . prepare_data ( self . coordinate_system , self . additional_data ) axis_tics_track = axis_tics_loader . create_track () self . tracks . append ( axis_tics_track ) self . coordinate_system [ \"figure_height\" ] += axis_tics_track . needed_y_space () self . coordinate_system [ \"figure_height\" ] += self . parameters . arguments [ \"margin\" ] * cm def plot ( self , filename ): image = Image ( filename , self . coordinate_system [ \"figure_width\" ], self . coordinate_system [ \"figure_height\" ]) current_y_top = self . coordinate_system [ \"figure_height\" ] - self . parameters . arguments [ \"margin\" ] * cm for track in self . tracks : track . visualisation_data [ \"y_top\" ] = current_y_top track . draw ( image . canvas ) current_y_top -= ( track . needed_space + self . parameters . arguments [ \"gap\" ] * cm ) image . save () return None __init__ ( path , upstream_sequences , parameters ) Create a AnnotationPlotManager object. Parameters: path ( uorf4u . data_processing . Path ) \u2013 Path class' objects that holds list of conserved ORFs. upstream_sequences ( list ) \u2013 list of dicts with information about upstream sequences. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 def __init__ ( self , path , upstream_sequences : list , parameters : uorf4u . manager . Parameters ): \"\"\"Create a AnnotationPlotManager object. Arguments: path (uorf4u.data_processing.Path): Path class' objects that holds list of conserved ORFs. upstream_sequences (list): list of dicts with information about upstream sequences. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . path = path self . upstream_sequences = upstream_sequences self . parameters = parameters self . coordinate_system = dict () self . additional_data = dict () create_tracks () Create visualisation tracks. Returns: None \u2013 None Source code in uorf4u/drawing.py 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 def create_tracks ( self ) -> None : \"\"\"Create visualisation tracks. Returns: None \"\"\" self . tracks = [] \"\"\" title_loader = TitleLoader(self.parameters) title_loader.prepare_data(self.coordinate_system, self.additional_data) title_track = title_loader.create_track() self.tracks.append(title_track) self.coordinate_system[\"figure_height\"] += title_track.needed_y_space() \"\"\" for index in range ( self . additional_data [ \"number_of_sequences\" ]): upstream_sequence = self . additional_data [ \"ordered_upstream_sequences\" ][ index ] conserved_orf = self . path . path [ index ] sequence_loader = SequencesLoader ( self . parameters ) sequence_loader . prepare_data ( upstream_sequence , conserved_orf , self . coordinate_system , self . additional_data ) track = sequence_loader . create_track () self . tracks . append ( track ) self . coordinate_system [ \"figure_height\" ] += track . needed_y_space () self . coordinate_system [ \"figure_height\" ] += self . parameters . arguments [ \"gap\" ] * cm # if index < self.additional_data[\"number_of_sequences\"] - 1: axis_tics_loader = AxisLoader ( self . parameters ) axis_tics_loader . prepare_data ( self . coordinate_system , self . additional_data ) axis_tics_track = axis_tics_loader . create_track () self . tracks . append ( axis_tics_track ) self . coordinate_system [ \"figure_height\" ] += axis_tics_track . needed_y_space () self . coordinate_system [ \"figure_height\" ] += self . parameters . arguments [ \"margin\" ] * cm define_x_axis_coordinate_system () Define coordinate system. Returns: None \u2013 None Source code in uorf4u/drawing.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 def define_x_axis_coordinate_system ( self ) -> None : \"\"\"Define coordinate system. Returns: None \"\"\" label_height = self . parameters . arguments [ \"label_height_to_orf_height\" ] * self . parameters . arguments [ \"orf_height\" ] * cm label_font_size = uorf4u . methods . string_height_to_font_size ( label_height , \"regular\" , self . parameters . arguments ) max_label_width = max ([ reportlab . pdfbase . pdfmetrics . stringWidth ( i [ \"id\" ], \"regular\" , label_font_size ) for i in self . upstream_sequences ]) self . additional_data [ \"label_font_size\" ] = label_font_size self . additional_data [ \"ordered_upstream_sequences\" ] = [ self . upstream_sequences [ i ] for i in [ orf . useq_index for orf in self . path . path ]] self . additional_data [ \"number_of_sequences\" ] = len ( self . path ) self . additional_data [ \"max_upstream_sequence_length\" ] = max ( i [ \"useq_upstream_region_length\" ] for i in self . additional_data [ \"ordered_upstream_sequences\" ]) self . additional_data [ \"max_downstream_sequence_length\" ] = max ( i [ \"useq_downstream_region_length\" ] for i in self . additional_data [ \"ordered_upstream_sequences\" ]) window_size_nt = self . additional_data [ \"max_upstream_sequence_length\" ] + self . additional_data [ \"max_downstream_sequence_length\" ] if self . parameters . arguments [ \"annotation_width\" ] == \"auto\" : annotation_width = window_size_nt * self . parameters . arguments [ \"mm_per_nt\" ] * mm else : annotation_width = self . parameters . arguments [ \"annotation_width\" ] * cm self . coordinate_system [ \"transformation_coef\" ] = annotation_width / window_size_nt self . coordinate_system [ \"x_labels_start\" ] = self . parameters . arguments [ \"margin\" ] * cm self . coordinate_system [ \"x_labels_stop\" ] = self . coordinate_system [ \"x_labels_start\" ] + max_label_width self . coordinate_system [ \"x_annotation_start\" ] = self . coordinate_system [ \"x_labels_stop\" ] + \\ self . parameters . arguments [ \"label_gap\" ] * cm self . coordinate_system [ \"x_annotation_stop\" ] = self . coordinate_system [ \"x_annotation_start\" ] + annotation_width self . coordinate_system [ \"figure_width\" ] = 2 * self . parameters . arguments [ \"margin\" ] * cm + annotation_width + \\ max_label_width + self . parameters . arguments [ \"label_gap\" ] * cm self . coordinate_system [ \"figure_height\" ] = self . parameters . arguments [ \"margin\" ] * cm return None AxisLoader Bases: Loader An AxisLoader object prepares data for an Axis track object. Attributes: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. prepared_data ( dict ) \u2013 dict with data needed for a visualisation track. Source code in uorf4u/drawing.py 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 class AxisLoader ( Loader ): \"\"\"An AxisLoader object prepares data for an Axis track object. Attributes: parameters (uorf4u.manager.Parameters): Parameters' class object. prepared_data (dict): dict with data needed for a visualisation track. \"\"\" def __init__ ( self , parameters ): \"\"\"Create an AxisLoader object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( parameters ) def prepare_data ( self , coordinate_system : dict , additional_data : dict ): \"\"\"Prepare data for an Axis visualisation track. Attributes: coordinate_system (dict): coordinate system of a figure page. additional_data (dict): data needed for a track initialisation. Returns: dict: dictionary with prepared data for visualisation. \"\"\" prepared_data = dict () prepared_data [ \"coordinate_system\" ] = coordinate_system prepared_data [ \"max_upstream_sequence_length\" ] = additional_data [ \"max_upstream_sequence_length\" ] prepared_data [ \"max_downstream_sequence_length\" ] = additional_data [ \"max_downstream_sequence_length\" ] step = int ( round ( additional_data [ \"max_upstream_sequence_length\" ] / 3 , - 2 )) tics = [ - additional_data [ \"max_upstream_sequence_length\" ], 0 , additional_data [ \"max_downstream_sequence_length\" ]] x_tic_centred = int ( round ( - additional_data [ \"max_upstream_sequence_length\" ] / 2 , - 2 )) tics . append ( x_tic_centred ) x_tic_left , x_tic_right = x_tic_centred - step , x_tic_centred + step while x_tic_right < 0 and x_tic_left > - additional_data [ \"max_upstream_sequence_length\" ]: tics . append ( x_tic_left ) tics . append ( x_tic_right ) x_tic_left -= step x_tic_right += step tics . sort () tics_coordinates = [ self . transform_relative_position_to_x_coordinate ( i , coordinate_system , additional_data [ \"max_upstream_sequence_length\" ]) for i in tics ] prepared_data [ \"tics\" ] = { k : v for k , v in zip ( tics , tics_coordinates )} self . prepared_data = prepared_data return prepared_data def transform_relative_position_to_x_coordinate ( self , relative_position : int , coordinate_system : dict , max_upstream_sequence_length : int ) -> float : \"\"\"Transform nucleotide x coordinate to pdf's. Arguments: relative_position (int): nucleotide position coordinate_system (dict): coordinate system of a figure. max_upstream_sequence_length (int): max length of upstream sequences for visualisation. Returns: float: transformed x coordinate. \"\"\" return coordinate_system [ \"x_annotation_start\" ] + ( relative_position + max_upstream_sequence_length ) * \\ coordinate_system [ \"transformation_coef\" ] def create_track ( self ) -> TicsVis : \"\"\"Initialise a Tics track object. Returns: TicsVis: visualisation track. \"\"\" return TicsVis ( self . prepared_data , self . parameters ) __init__ ( parameters ) Create an AxisLoader object. Parameters: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing.py 695 696 697 698 699 700 701 702 def __init__ ( self , parameters ): \"\"\"Create an AxisLoader object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( parameters ) create_track () Initialise a Tics track object. Returns: TicsVis ( TicsVis ) \u2013 visualisation track. Source code in uorf4u/drawing.py 751 752 753 754 755 756 757 758 def create_track ( self ) -> TicsVis : \"\"\"Initialise a Tics track object. Returns: TicsVis: visualisation track. \"\"\" return TicsVis ( self . prepared_data , self . parameters ) prepare_data ( coordinate_system , additional_data ) Prepare data for an Axis visualisation track. Attributes: coordinate_system ( dict ) \u2013 coordinate system of a figure page. additional_data ( dict ) \u2013 data needed for a track initialisation. Returns: dict \u2013 dictionary with prepared data for visualisation. Source code in uorf4u/drawing.py 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 def prepare_data ( self , coordinate_system : dict , additional_data : dict ): \"\"\"Prepare data for an Axis visualisation track. Attributes: coordinate_system (dict): coordinate system of a figure page. additional_data (dict): data needed for a track initialisation. Returns: dict: dictionary with prepared data for visualisation. \"\"\" prepared_data = dict () prepared_data [ \"coordinate_system\" ] = coordinate_system prepared_data [ \"max_upstream_sequence_length\" ] = additional_data [ \"max_upstream_sequence_length\" ] prepared_data [ \"max_downstream_sequence_length\" ] = additional_data [ \"max_downstream_sequence_length\" ] step = int ( round ( additional_data [ \"max_upstream_sequence_length\" ] / 3 , - 2 )) tics = [ - additional_data [ \"max_upstream_sequence_length\" ], 0 , additional_data [ \"max_downstream_sequence_length\" ]] x_tic_centred = int ( round ( - additional_data [ \"max_upstream_sequence_length\" ] / 2 , - 2 )) tics . append ( x_tic_centred ) x_tic_left , x_tic_right = x_tic_centred - step , x_tic_centred + step while x_tic_right < 0 and x_tic_left > - additional_data [ \"max_upstream_sequence_length\" ]: tics . append ( x_tic_left ) tics . append ( x_tic_right ) x_tic_left -= step x_tic_right += step tics . sort () tics_coordinates = [ self . transform_relative_position_to_x_coordinate ( i , coordinate_system , additional_data [ \"max_upstream_sequence_length\" ]) for i in tics ] prepared_data [ \"tics\" ] = { k : v for k , v in zip ( tics , tics_coordinates )} self . prepared_data = prepared_data return prepared_data transform_relative_position_to_x_coordinate ( relative_position , coordinate_system , max_upstream_sequence_length ) Transform nucleotide x coordinate to pdf's. Parameters: relative_position ( int ) \u2013 nucleotide position coordinate_system ( dict ) \u2013 coordinate system of a figure. max_upstream_sequence_length ( int ) \u2013 max length of upstream sequences for visualisation. Returns: float ( float ) \u2013 transformed x coordinate. Source code in uorf4u/drawing.py 736 737 738 739 740 741 742 743 744 745 746 747 748 749 def transform_relative_position_to_x_coordinate ( self , relative_position : int , coordinate_system : dict , max_upstream_sequence_length : int ) -> float : \"\"\"Transform nucleotide x coordinate to pdf's. Arguments: relative_position (int): nucleotide position coordinate_system (dict): coordinate system of a figure. max_upstream_sequence_length (int): max length of upstream sequences for visualisation. Returns: float: transformed x coordinate. \"\"\" return coordinate_system [ \"x_annotation_start\" ] + ( relative_position + max_upstream_sequence_length ) * \\ coordinate_system [ \"transformation_coef\" ] Image An Image object holds pdf. Attributes: canvas ( reportlab . pdfgen . canvas . Canvas ) \u2013 pdf object of the reportlab library. Source code in uorf4u/drawing.py 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 class Image : \"\"\"An Image object holds pdf. Attributes: canvas (reportlab.pdfgen.canvas.Canvas): pdf object of the reportlab library. \"\"\" def __init__ ( self , filename : str , width : float , height : float ): \"\"\"Create an Image object. Arguments: filename (str): path and name of a pdf. width (float): width of a pdf. height (float): height of a pdf. \"\"\" self . canvas = reportlab . pdfgen . canvas . Canvas ( filename , pagesize = ( width , height )) def save ( self ) -> None : \"\"\"Save a pdf file. Returns: None \"\"\" self . canvas . save () return None __init__ ( filename , width , height ) Create an Image object. Parameters: filename ( str ) \u2013 path and name of a pdf. width ( float ) \u2013 width of a pdf. height ( float ) \u2013 height of a pdf. Source code in uorf4u/drawing.py 769 770 771 772 773 774 775 776 777 778 def __init__ ( self , filename : str , width : float , height : float ): \"\"\"Create an Image object. Arguments: filename (str): path and name of a pdf. width (float): width of a pdf. height (float): height of a pdf. \"\"\" self . canvas = reportlab . pdfgen . canvas . Canvas ( filename , pagesize = ( width , height )) save () Save a pdf file. Returns: None \u2013 None Source code in uorf4u/drawing.py 780 781 782 783 784 785 786 787 788 def save ( self ) -> None : \"\"\"Save a pdf file. Returns: None \"\"\" self . canvas . save () return None Loader Parent class for tracks loaders. Attributes: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. prepared_data ( dict ) \u2013 dict with data needed for visualisation tracks. Source code in uorf4u/drawing.py 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 class Loader : \"\"\"Parent class for tracks loaders. Attributes: parameters (uorf4u.manager.Parameters): Parameters' class object. prepared_data (dict): dict with data needed for visualisation tracks. \"\"\" def __init__ ( self , parameters : uorf4u . manager . Parameters ): \"\"\"Parent's constructor for creating a Loader class object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . parameters = parameters self . prepared_data = None def prepare_data ( self ) -> None : \"\"\"Empty parent's method for data preparation. Returns: None \"\"\" pass def create_track ( self ) -> None : \"\"\"Empty parent's method for initialisation of a track. Returns: None \"\"\" pass __init__ ( parameters ) Parent's constructor for creating a Loader class object. Parameters: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing.py 488 489 490 491 492 493 494 495 def __init__ ( self , parameters : uorf4u . manager . Parameters ): \"\"\"Parent's constructor for creating a Loader class object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . parameters = parameters self . prepared_data = None create_track () Empty parent's method for initialisation of a track. Returns: None \u2013 None Source code in uorf4u/drawing.py 506 507 508 509 510 511 512 513 def create_track ( self ) -> None : \"\"\"Empty parent's method for initialisation of a track. Returns: None \"\"\" pass prepare_data () Empty parent's method for data preparation. Returns: None \u2013 None Source code in uorf4u/drawing.py 497 498 499 500 501 502 503 504 def prepare_data ( self ) -> None : \"\"\"Empty parent's method for data preparation. Returns: None \"\"\" pass SequenceVis Bases: Track SequenceVis track draws sequences and annotation. Attributes: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. needed_space ( float ) \u2013 needed vertical space for a track. Source code in uorf4u/drawing.py 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 class SequenceVis ( Track ): \"\"\"SequenceVis track draws sequences and annotation. Attributes: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. needed_space (float): needed vertical space for a track. \"\"\" def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Create a SequenceVis object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( visualisation_data , parameters ) self . needed_space = None def needed_y_space ( self ) -> float : \"\"\"Calculate needed vertical space for a SequenceVis track. Returns: float: needed vertical space. \"\"\" self . needed_space = self . parameters . arguments [ \"orf_height\" ] * cm return self . needed_space def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Draw a Sequence track. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" orf_height = self . parameters . arguments [ \"orf_height\" ] * cm y_c = self . visualisation_data [ \"y_top\" ] - 0.5 * orf_height canvas . setStrokeColorRGB ( * uorf4u . methods . get_color ( \"upstream_seq_line_color\" , self . parameters . arguments )) canvas . setLineCap ( 0 ) canvas . setLineWidth ( self . parameters . arguments [ \"upstream_seq_line_width\" ]) canvas . line ( self . visualisation_data [ \"upstream_sequence_line_start_x\" ], y_c , self . visualisation_data [ \"upstream_sequence_line_stop_x\" ], y_c ) # Cleaning the space: canvas . setFillColorRGB ( 1 , 1 , 1 , 1 ) for orf_dict in self . visualisation_data [ \"orfs_coordinates_dict\" ] . values (): # canvas.line(orf_dict[\"x_start\"], y_c, orf_dict[\"x_stop\"], y_c) canvas . rect ( orf_dict [ \"x_start\" ], y_c - orf_height / 2 , orf_dict [ \"x_stop\" ] - orf_dict [ \"x_start\" ], orf_height , stroke = 0 , fill = 1 ) # Labels canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFont ( \"regular\" , self . visualisation_data [ \"label_font_size\" ]) y_l = y_c - 0.5 * ( self . parameters . arguments [ \"label_height_to_orf_height\" ] * orf_height ) canvas . drawRightString ( self . visualisation_data [ \"coordinate_system\" ][ \"x_labels_stop\" ], y_l , self . visualisation_data [ \"useq_id\" ]) # main_CDS canvas . setLineWidth ( self . parameters . arguments [ \"orf_line_width\" ]) canvas . setStrokeColorRGB ( * uorf4u . methods . get_color ( \"cds_seq_stroke_color\" , self . parameters . arguments )) canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"cds_seq_fill_color\" , self . parameters . arguments )) p = canvas . beginPath () p . moveTo ( self . visualisation_data [ \"main_CDS_stop_x\" ], y_c - orf_height / 2 ) p . lineTo ( self . visualisation_data [ \"main_CDS_start_x\" ], y_c - orf_height / 2 ) p . lineTo ( self . visualisation_data [ \"main_CDS_start_x\" ], y_c + orf_height / 2 ) p . lineTo ( self . visualisation_data [ \"main_CDS_stop_x\" ], y_c + orf_height / 2 ) canvas . drawPath ( p , stroke = 1 , fill = 1 ) # Other ORFs: for orf in self . visualisation_data [ \"annotated_orfs\" ]: orf_dict = self . visualisation_data [ \"orfs_coordinates_dict\" ][ orf ] if orf != self . visualisation_data [ \"conserved_orf\" ]: fill_color = None stroke_color = uorf4u . methods . get_color ( \"other_uorfs_stroke_color\" , self . parameters . arguments ) else : fill_color = uorf4u . methods . get_color ( \"conserved_uorfs_fill_color\" , self . parameters . arguments ) stroke_color = uorf4u . methods . get_color ( \"conserved_uorfs_stroke_color\" , self . parameters . arguments ) self . orf_object ( canvas , orf_dict [ \"x_start\" ], orf_dict [ \"x_stop\" ], y_c , orf_dict [ \"strand\" ], orf_height , orf_dict [ \"left_out\" ], orf_dict [ \"right_out\" ], fill_color , stroke_color ) # Annotated in RefSeq CDSs if self . parameters . arguments [ \"check_assembly_annotation\" ]: fill_color = None stroke_color = uorf4u . methods . get_color ( \"annotated_orf_stroke_color\" , self . parameters . arguments ) for protein_id , cds_dict in self . visualisation_data [ \"CDSs_coordinates_dict\" ] . items (): self . orf_object ( canvas , cds_dict [ \"x_start\" ], cds_dict [ \"x_stop\" ], y_c , cds_dict [ \"strand\" ], orf_height , cds_dict [ \"left_out\" ], cds_dict [ \"right_out\" ], fill_color , stroke_color ) return None def orf_object ( self , canvas : reportlab . pdfgen . canvas . Canvas , x_start : float , x_stop : float , y_c : float , strand : str , height : float , left_out : bool , right_out : bool , fill_color : str , stroke_color : str ) -> None : \"\"\"Method for drawing an ORF's polygon. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. x_start (float): ORF's start coordinate (already transformed to pdf's) x_stop (float): ORF's stop coordinate (already transformed to pdf's) y_c: (float): centred y coordinate of a current track. strand (str): strand of an ORF. height (float): height of a polygon. left_out (bool): whether an ORF is out of range on the left. right_out (bool): whether an ORF is out of range on the right. fill_color (str): fill color of a polygon. stroke_color (str): stroke color of a polygon. Returns: None \"\"\" fill , stroke = 0 , 0 if stroke_color : canvas . setStrokeColorRGB ( * stroke_color ) stroke = 1 if fill_color : canvas . setFillColorRGB ( * fill_color ) fill = 1 arrow_length = min ( height , ( x_stop - x_start )) p = canvas . beginPath () if strand == \"+\" and not left_out and not right_out : p . moveTo ( x_start , y_c ) p . lineTo ( x_start , y_c + height / 2 ) p . lineTo ( x_stop - arrow_length , y_c + height / 2 ) p . lineTo ( x_stop , y_c ) p . lineTo ( x_stop - arrow_length , y_c - height / 2 ) p . lineTo ( x_start , y_c - height / 2 ) p . lineTo ( x_start , y_c ) elif strand == \"+\" and left_out and not right_out : p . moveTo ( x_start , y_c + height / 2 ) p . lineTo ( x_stop - arrow_length , y_c + height / 2 ) p . lineTo ( x_stop , y_c ) p . lineTo ( x_stop - arrow_length , y_c - height / 2 ) p . lineTo ( x_start , y_c - height / 2 ) elif strand == \"+\" and right_out and not left_out : p . moveTo ( x_stop , y_c + height / 2 ) p . lineTo ( x_start , y_c + height / 2 ) p . lineTo ( x_start , y_c - height / 2 ) p . lineTo ( x_stop , y_c - height / 2 ) elif strand == \"-\" and not left_out and not right_out : p . moveTo ( x_stop , y_c ) p . lineTo ( x_stop , y_c + height / 2 ) p . lineTo ( x_start + arrow_length , y_c + height / 2 ) p . lineTo ( x_start , y_c ) p . lineTo ( x_start + arrow_length , y_c - height / 2 ) p . lineTo ( x_stop , y_c - height / 2 ) p . lineTo ( x_stop , y_c ) elif strand == \"-\" and right_out and not left_out : p . moveTo ( x_stop , y_c + height / 2 ) p . lineTo ( x_start + arrow_length , y_c + height / 2 ) p . lineTo ( x_start , y_c ) p . lineTo ( x_start + arrow_length , y_c - height / 2 ) p . lineTo ( x_stop , y_c - height / 2 ) elif strand == \"-\" and left_out and not right_out : p . moveTo ( x_start , y_c + height / 2 ) p . lineTo ( x_stop , y_c + height / 2 ) p . lineTo ( x_stop , y_c - height / 2 ) p . lineTo ( x_start , y_c - height / 2 ) canvas . drawPath ( p , stroke = stroke , fill = fill ) __init__ ( visualisation_data , parameters ) Create a SequenceVis object. Parameters: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing.py 248 249 250 251 252 253 254 255 256 257 def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Create a SequenceVis object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( visualisation_data , parameters ) self . needed_space = None draw ( canvas ) Draw a Sequence track. Parameters: canvas ( reportlab . pdfgen . canvas . Canvas ) \u2013 a pdf object. Returns: None \u2013 None Source code in uorf4u/drawing.py 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Draw a Sequence track. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" orf_height = self . parameters . arguments [ \"orf_height\" ] * cm y_c = self . visualisation_data [ \"y_top\" ] - 0.5 * orf_height canvas . setStrokeColorRGB ( * uorf4u . methods . get_color ( \"upstream_seq_line_color\" , self . parameters . arguments )) canvas . setLineCap ( 0 ) canvas . setLineWidth ( self . parameters . arguments [ \"upstream_seq_line_width\" ]) canvas . line ( self . visualisation_data [ \"upstream_sequence_line_start_x\" ], y_c , self . visualisation_data [ \"upstream_sequence_line_stop_x\" ], y_c ) # Cleaning the space: canvas . setFillColorRGB ( 1 , 1 , 1 , 1 ) for orf_dict in self . visualisation_data [ \"orfs_coordinates_dict\" ] . values (): # canvas.line(orf_dict[\"x_start\"], y_c, orf_dict[\"x_stop\"], y_c) canvas . rect ( orf_dict [ \"x_start\" ], y_c - orf_height / 2 , orf_dict [ \"x_stop\" ] - orf_dict [ \"x_start\" ], orf_height , stroke = 0 , fill = 1 ) # Labels canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFont ( \"regular\" , self . visualisation_data [ \"label_font_size\" ]) y_l = y_c - 0.5 * ( self . parameters . arguments [ \"label_height_to_orf_height\" ] * orf_height ) canvas . drawRightString ( self . visualisation_data [ \"coordinate_system\" ][ \"x_labels_stop\" ], y_l , self . visualisation_data [ \"useq_id\" ]) # main_CDS canvas . setLineWidth ( self . parameters . arguments [ \"orf_line_width\" ]) canvas . setStrokeColorRGB ( * uorf4u . methods . get_color ( \"cds_seq_stroke_color\" , self . parameters . arguments )) canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"cds_seq_fill_color\" , self . parameters . arguments )) p = canvas . beginPath () p . moveTo ( self . visualisation_data [ \"main_CDS_stop_x\" ], y_c - orf_height / 2 ) p . lineTo ( self . visualisation_data [ \"main_CDS_start_x\" ], y_c - orf_height / 2 ) p . lineTo ( self . visualisation_data [ \"main_CDS_start_x\" ], y_c + orf_height / 2 ) p . lineTo ( self . visualisation_data [ \"main_CDS_stop_x\" ], y_c + orf_height / 2 ) canvas . drawPath ( p , stroke = 1 , fill = 1 ) # Other ORFs: for orf in self . visualisation_data [ \"annotated_orfs\" ]: orf_dict = self . visualisation_data [ \"orfs_coordinates_dict\" ][ orf ] if orf != self . visualisation_data [ \"conserved_orf\" ]: fill_color = None stroke_color = uorf4u . methods . get_color ( \"other_uorfs_stroke_color\" , self . parameters . arguments ) else : fill_color = uorf4u . methods . get_color ( \"conserved_uorfs_fill_color\" , self . parameters . arguments ) stroke_color = uorf4u . methods . get_color ( \"conserved_uorfs_stroke_color\" , self . parameters . arguments ) self . orf_object ( canvas , orf_dict [ \"x_start\" ], orf_dict [ \"x_stop\" ], y_c , orf_dict [ \"strand\" ], orf_height , orf_dict [ \"left_out\" ], orf_dict [ \"right_out\" ], fill_color , stroke_color ) # Annotated in RefSeq CDSs if self . parameters . arguments [ \"check_assembly_annotation\" ]: fill_color = None stroke_color = uorf4u . methods . get_color ( \"annotated_orf_stroke_color\" , self . parameters . arguments ) for protein_id , cds_dict in self . visualisation_data [ \"CDSs_coordinates_dict\" ] . items (): self . orf_object ( canvas , cds_dict [ \"x_start\" ], cds_dict [ \"x_stop\" ], y_c , cds_dict [ \"strand\" ], orf_height , cds_dict [ \"left_out\" ], cds_dict [ \"right_out\" ], fill_color , stroke_color ) return None needed_y_space () Calculate needed vertical space for a SequenceVis track. Returns: float ( float ) \u2013 needed vertical space. Source code in uorf4u/drawing.py 259 260 261 262 263 264 265 266 267 def needed_y_space ( self ) -> float : \"\"\"Calculate needed vertical space for a SequenceVis track. Returns: float: needed vertical space. \"\"\" self . needed_space = self . parameters . arguments [ \"orf_height\" ] * cm return self . needed_space orf_object ( canvas , x_start , x_stop , y_c , strand , height , left_out , right_out , fill_color , stroke_color ) Method for drawing an ORF's polygon. Parameters: canvas ( reportlab . pdfgen . canvas . Canvas ) \u2013 a pdf object. x_start ( float ) \u2013 ORF's start coordinate (already transformed to pdf's) x_stop ( float ) \u2013 ORF's stop coordinate (already transformed to pdf's) y_c ( float ) \u2013 (float): centred y coordinate of a current track. strand ( str ) \u2013 strand of an ORF. height ( float ) \u2013 height of a polygon. left_out ( bool ) \u2013 whether an ORF is out of range on the left. right_out ( bool ) \u2013 whether an ORF is out of range on the right. fill_color ( str ) \u2013 fill color of a polygon. stroke_color ( str ) \u2013 stroke color of a polygon. Returns: None \u2013 None Source code in uorf4u/drawing.py 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 def orf_object ( self , canvas : reportlab . pdfgen . canvas . Canvas , x_start : float , x_stop : float , y_c : float , strand : str , height : float , left_out : bool , right_out : bool , fill_color : str , stroke_color : str ) -> None : \"\"\"Method for drawing an ORF's polygon. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. x_start (float): ORF's start coordinate (already transformed to pdf's) x_stop (float): ORF's stop coordinate (already transformed to pdf's) y_c: (float): centred y coordinate of a current track. strand (str): strand of an ORF. height (float): height of a polygon. left_out (bool): whether an ORF is out of range on the left. right_out (bool): whether an ORF is out of range on the right. fill_color (str): fill color of a polygon. stroke_color (str): stroke color of a polygon. Returns: None \"\"\" fill , stroke = 0 , 0 if stroke_color : canvas . setStrokeColorRGB ( * stroke_color ) stroke = 1 if fill_color : canvas . setFillColorRGB ( * fill_color ) fill = 1 arrow_length = min ( height , ( x_stop - x_start )) p = canvas . beginPath () if strand == \"+\" and not left_out and not right_out : p . moveTo ( x_start , y_c ) p . lineTo ( x_start , y_c + height / 2 ) p . lineTo ( x_stop - arrow_length , y_c + height / 2 ) p . lineTo ( x_stop , y_c ) p . lineTo ( x_stop - arrow_length , y_c - height / 2 ) p . lineTo ( x_start , y_c - height / 2 ) p . lineTo ( x_start , y_c ) elif strand == \"+\" and left_out and not right_out : p . moveTo ( x_start , y_c + height / 2 ) p . lineTo ( x_stop - arrow_length , y_c + height / 2 ) p . lineTo ( x_stop , y_c ) p . lineTo ( x_stop - arrow_length , y_c - height / 2 ) p . lineTo ( x_start , y_c - height / 2 ) elif strand == \"+\" and right_out and not left_out : p . moveTo ( x_stop , y_c + height / 2 ) p . lineTo ( x_start , y_c + height / 2 ) p . lineTo ( x_start , y_c - height / 2 ) p . lineTo ( x_stop , y_c - height / 2 ) elif strand == \"-\" and not left_out and not right_out : p . moveTo ( x_stop , y_c ) p . lineTo ( x_stop , y_c + height / 2 ) p . lineTo ( x_start + arrow_length , y_c + height / 2 ) p . lineTo ( x_start , y_c ) p . lineTo ( x_start + arrow_length , y_c - height / 2 ) p . lineTo ( x_stop , y_c - height / 2 ) p . lineTo ( x_stop , y_c ) elif strand == \"-\" and right_out and not left_out : p . moveTo ( x_stop , y_c + height / 2 ) p . lineTo ( x_start + arrow_length , y_c + height / 2 ) p . lineTo ( x_start , y_c ) p . lineTo ( x_start + arrow_length , y_c - height / 2 ) p . lineTo ( x_stop , y_c - height / 2 ) elif strand == \"-\" and left_out and not right_out : p . moveTo ( x_start , y_c + height / 2 ) p . lineTo ( x_stop , y_c + height / 2 ) p . lineTo ( x_stop , y_c - height / 2 ) p . lineTo ( x_start , y_c - height / 2 ) canvas . drawPath ( p , stroke = stroke , fill = fill ) SequencesLoader Bases: Loader A SequencesLoader object prepares data for a Sequence track object. Attributes: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. prepared_data ( dict ) \u2013 dict with data needed for a visualisation track. Source code in uorf4u/drawing.py 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 class SequencesLoader ( Loader ): \"\"\"A SequencesLoader object prepares data for a Sequence track object. Attributes: parameters (uorf4u.manager.Parameters): Parameters' class object. prepared_data (dict): dict with data needed for a visualisation track. \"\"\" def __init__ ( self , parameters ): \"\"\"Create a SequenceLoader object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( parameters ) def prepare_data ( self , upstream_sequence : dict , conserved_orf , coordinate_system : dict , additional_data : dict ) -> dict : \"\"\"Prepare data for a Title visualisation track. Attributes: upstream_sequence (dict): upstream sequence' data. conserved_orf (uorf4u.data_processing.ORF): conserved ORF on the upstream sequence. coordinate_system (dict): coordinate system of a figure page. additional_data (dict): data needed for a track initialisation. Returns: dict: dictionary with prepared data for visualisation. \"\"\" prepared_data = dict () max_upstream_sequence_length = additional_data [ \"max_upstream_sequence_length\" ] prepared_data [ \"coordinate_system\" ] = coordinate_system prepared_data [ \"label_font_size\" ] = additional_data [ \"label_font_size\" ] prepared_data [ \"label_right_border\" ] = coordinate_system [ \"x_labels_stop\" ] prepared_data [ \"upstream_sequence_line_start_x\" ] = coordinate_system [ \"x_annotation_start\" ] + \\ (( max_upstream_sequence_length - upstream_sequence [ \"useq_upstream_region_length\" ]) * \\ coordinate_system [ \"transformation_coef\" ]) prepared_data [ \"upstream_sequence_line_stop_x\" ] = coordinate_system [ \"x_annotation_start\" ] + \\ ( max_upstream_sequence_length * coordinate_system [ \"transformation_coef\" ]) prepared_data [ \"main_CDS_start_x\" ] = coordinate_system [ \"x_annotation_start\" ] + \\ ( max_upstream_sequence_length * coordinate_system [ \"transformation_coef\" ]) prepared_data [ \"main_CDS_stop_x\" ] = coordinate_system [ \"x_annotation_start\" ] + \\ (( max_upstream_sequence_length + upstream_sequence [ \"useq_downstream_region_length\" ]) * coordinate_system [ \"transformation_coef\" ]) prepared_data [ \"orfs_coordinates_dict\" ] = { k : v for k , v in zip ( upstream_sequence [ \"ORFs\" ], [ self . calculate_orf_position ( i . start , i . stop , \"+\" , upstream_sequence , max_upstream_sequence_length , coordinate_system ) for i in upstream_sequence [ \"ORFs\" ]])} prepared_data [ \"useq_id\" ] = upstream_sequence [ \"id\" ] prepared_data [ \"annotated_orfs\" ] = [ orf for orf in upstream_sequence [ \"ORFs\" ] if orf != conserved_orf ] prepared_data [ \"annotated_orfs\" ] . append ( conserved_orf ) prepared_data [ \"conserved_orf\" ] = conserved_orf if self . parameters . arguments [ \"check_assembly_annotation\" ]: prepared_data [ \"CDSs\" ] = [ i for i in upstream_sequence [ \"locus_annotation\" ] . CDSs if i [ \"relative_start\" ] != upstream_sequence [ \"useq_upstream_region_length\" ]] prepared_data [ \"CDSs_coordinates_dict\" ] = { k : v for k , v in zip ([ i [ \"protein_id\" ] for i in prepared_data [ \"CDSs\" ]], [ self . calculate_orf_position ( i [ \"relative_start\" ], i [ \"relative_stop\" ], i [ \"relative_strand\" ], upstream_sequence , max_upstream_sequence_length , coordinate_system ) for i in prepared_data [ \"CDSs\" ]])} else : prepared_data [ \"CDSs\" ] = None self . prepared_data = prepared_data return prepared_data def calculate_orf_position ( self , start : int , stop : int , strand : str , useq : dict , max_upstream_sequence_length : int , coordinate_system : dict ) -> dict : \"\"\"Transform an ORF's nucleotide coordinates to pdf's coordinates. Arguments: start (int): start coordinate in nt. stop (int): stop coordinate in nt. strand (str): strand of an ORF. useq (dict): current upstream sequence. max_upstream_sequence_length (int): max length of upstream sequences for visualisation. coordinate_system (dict): coordinate system of a figure. Returns: dict: transformed orf's coordinates. \"\"\" orf_coordinates = dict () orf_coordinates [ \"x_start\" ] = coordinate_system [ \"x_annotation_start\" ] + ( max ( 0 , start ) + ( max_upstream_sequence_length - useq [ \"useq_upstream_region_length\" ])) * \\ coordinate_system [ \"transformation_coef\" ] orf_coordinates [ \"x_stop\" ] = coordinate_system [ \"x_annotation_start\" ] + ( min ( stop , useq [ \"length\" ]) + ( max_upstream_sequence_length - useq [ \"useq_upstream_region_length\" ])) * \\ coordinate_system [ \"transformation_coef\" ] orf_coordinates [ \"strand\" ] = strand orf_coordinates [ \"left_out\" ] = start < 0 orf_coordinates [ \"right_out\" ] = stop > useq [ \"length\" ] return orf_coordinates def create_track ( self ) -> SequenceVis : \"\"\"Initialise a Sequence track object. Returns: SequenceVis: visualisation track. \"\"\" return SequenceVis ( self . prepared_data , self . parameters ) __init__ ( parameters ) Create a SequenceLoader object. Parameters: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing.py 574 575 576 577 578 579 580 581 def __init__ ( self , parameters ): \"\"\"Create a SequenceLoader object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( parameters ) calculate_orf_position ( start , stop , strand , useq , max_upstream_sequence_length , coordinate_system ) Transform an ORF's nucleotide coordinates to pdf's coordinates. Parameters: start ( int ) \u2013 start coordinate in nt. stop ( int ) \u2013 stop coordinate in nt. strand ( str ) \u2013 strand of an ORF. useq ( dict ) \u2013 current upstream sequence. max_upstream_sequence_length ( int ) \u2013 max length of upstream sequences for visualisation. coordinate_system ( dict ) \u2013 coordinate system of a figure. Returns: dict ( dict ) \u2013 transformed orf's coordinates. Source code in uorf4u/drawing.py 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 def calculate_orf_position ( self , start : int , stop : int , strand : str , useq : dict , max_upstream_sequence_length : int , coordinate_system : dict ) -> dict : \"\"\"Transform an ORF's nucleotide coordinates to pdf's coordinates. Arguments: start (int): start coordinate in nt. stop (int): stop coordinate in nt. strand (str): strand of an ORF. useq (dict): current upstream sequence. max_upstream_sequence_length (int): max length of upstream sequences for visualisation. coordinate_system (dict): coordinate system of a figure. Returns: dict: transformed orf's coordinates. \"\"\" orf_coordinates = dict () orf_coordinates [ \"x_start\" ] = coordinate_system [ \"x_annotation_start\" ] + ( max ( 0 , start ) + ( max_upstream_sequence_length - useq [ \"useq_upstream_region_length\" ])) * \\ coordinate_system [ \"transformation_coef\" ] orf_coordinates [ \"x_stop\" ] = coordinate_system [ \"x_annotation_start\" ] + ( min ( stop , useq [ \"length\" ]) + ( max_upstream_sequence_length - useq [ \"useq_upstream_region_length\" ])) * \\ coordinate_system [ \"transformation_coef\" ] orf_coordinates [ \"strand\" ] = strand orf_coordinates [ \"left_out\" ] = start < 0 orf_coordinates [ \"right_out\" ] = stop > useq [ \"length\" ] return orf_coordinates create_track () Initialise a Sequence track object. Returns: SequenceVis ( SequenceVis ) \u2013 visualisation track. Source code in uorf4u/drawing.py 675 676 677 678 679 680 681 682 def create_track ( self ) -> SequenceVis : \"\"\"Initialise a Sequence track object. Returns: SequenceVis: visualisation track. \"\"\" return SequenceVis ( self . prepared_data , self . parameters ) prepare_data ( upstream_sequence , conserved_orf , coordinate_system , additional_data ) Prepare data for a Title visualisation track. Attributes: upstream_sequence ( dict ) \u2013 upstream sequence' data. conserved_orf ( uorf4u . data_processing . ORF ) \u2013 conserved ORF on the upstream sequence. coordinate_system ( dict ) \u2013 coordinate system of a figure page. additional_data ( dict ) \u2013 data needed for a track initialisation. Returns: dict ( dict ) \u2013 dictionary with prepared data for visualisation. Source code in uorf4u/drawing.py 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 def prepare_data ( self , upstream_sequence : dict , conserved_orf , coordinate_system : dict , additional_data : dict ) -> dict : \"\"\"Prepare data for a Title visualisation track. Attributes: upstream_sequence (dict): upstream sequence' data. conserved_orf (uorf4u.data_processing.ORF): conserved ORF on the upstream sequence. coordinate_system (dict): coordinate system of a figure page. additional_data (dict): data needed for a track initialisation. Returns: dict: dictionary with prepared data for visualisation. \"\"\" prepared_data = dict () max_upstream_sequence_length = additional_data [ \"max_upstream_sequence_length\" ] prepared_data [ \"coordinate_system\" ] = coordinate_system prepared_data [ \"label_font_size\" ] = additional_data [ \"label_font_size\" ] prepared_data [ \"label_right_border\" ] = coordinate_system [ \"x_labels_stop\" ] prepared_data [ \"upstream_sequence_line_start_x\" ] = coordinate_system [ \"x_annotation_start\" ] + \\ (( max_upstream_sequence_length - upstream_sequence [ \"useq_upstream_region_length\" ]) * \\ coordinate_system [ \"transformation_coef\" ]) prepared_data [ \"upstream_sequence_line_stop_x\" ] = coordinate_system [ \"x_annotation_start\" ] + \\ ( max_upstream_sequence_length * coordinate_system [ \"transformation_coef\" ]) prepared_data [ \"main_CDS_start_x\" ] = coordinate_system [ \"x_annotation_start\" ] + \\ ( max_upstream_sequence_length * coordinate_system [ \"transformation_coef\" ]) prepared_data [ \"main_CDS_stop_x\" ] = coordinate_system [ \"x_annotation_start\" ] + \\ (( max_upstream_sequence_length + upstream_sequence [ \"useq_downstream_region_length\" ]) * coordinate_system [ \"transformation_coef\" ]) prepared_data [ \"orfs_coordinates_dict\" ] = { k : v for k , v in zip ( upstream_sequence [ \"ORFs\" ], [ self . calculate_orf_position ( i . start , i . stop , \"+\" , upstream_sequence , max_upstream_sequence_length , coordinate_system ) for i in upstream_sequence [ \"ORFs\" ]])} prepared_data [ \"useq_id\" ] = upstream_sequence [ \"id\" ] prepared_data [ \"annotated_orfs\" ] = [ orf for orf in upstream_sequence [ \"ORFs\" ] if orf != conserved_orf ] prepared_data [ \"annotated_orfs\" ] . append ( conserved_orf ) prepared_data [ \"conserved_orf\" ] = conserved_orf if self . parameters . arguments [ \"check_assembly_annotation\" ]: prepared_data [ \"CDSs\" ] = [ i for i in upstream_sequence [ \"locus_annotation\" ] . CDSs if i [ \"relative_start\" ] != upstream_sequence [ \"useq_upstream_region_length\" ]] prepared_data [ \"CDSs_coordinates_dict\" ] = { k : v for k , v in zip ([ i [ \"protein_id\" ] for i in prepared_data [ \"CDSs\" ]], [ self . calculate_orf_position ( i [ \"relative_start\" ], i [ \"relative_stop\" ], i [ \"relative_strand\" ], upstream_sequence , max_upstream_sequence_length , coordinate_system ) for i in prepared_data [ \"CDSs\" ]])} else : prepared_data [ \"CDSs\" ] = None self . prepared_data = prepared_data return prepared_data TicsVis Bases: Track TicsVis track draws axis tics. Attributes: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. needed_space ( float ) \u2013 needed vertical space for a track. Source code in uorf4u/drawing.py 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 class TicsVis ( Track ): \"\"\"TicsVis track draws axis tics. Attributes: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. needed_space (float): needed vertical space for a track. \"\"\" def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Create a TicsVis object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( visualisation_data , parameters ) self . needed_space = None def needed_y_space ( self ) -> float : \"\"\"Calculate needed vertical space for a SequenceVis track. Returns: float: needed vertical space. \"\"\" font_type = \"regular\" reportlab . pdfbase . pdfmetrics . registerFont ( reportlab . pdfbase . ttfonts . TTFont ( font_type , self . parameters . arguments [ f \"font_ { font_type } \" ])) face = reportlab . pdfbase . pdfmetrics . getFont ( \"regular\" ) . face if self . parameters . arguments [ \"axis_tics_font_size\" ] == \"auto\" : text_height = self . parameters . arguments [ \"label_height_to_orf_height\" ] * self . parameters . arguments [ \"orf_height\" ] * cm font_size = uorf4u . methods . string_height_to_font_size ( text_height , \"regular\" , self . parameters . arguments ) self . parameters . arguments [ \"axis_tics_font_size\" ] = font_size else : text_height = ( self . parameters . arguments [ \"axis_tics_font_size\" ] * ( face . ascent - face . descent )) / ( 1000 * 1.38 ) self . visualisation_data [ \"tics_height\" ] = 0.7 * text_height self . visualisation_data [ \"text_space\" ] = 1.2 * text_height self . needed_space = self . visualisation_data [ \"tics_height\" ] + self . visualisation_data [ \"text_space\" ] return self . needed_space def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Draw an AxisTics track. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" y_top = self . visualisation_data [ \"y_top\" ] canvas . setLineCap ( 2 ) canvas . setLineWidth ( self . parameters . arguments [ \"axis_tics_line_width\" ]) canvas . setStrokeColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFont ( \"regular\" , self . parameters . arguments [ \"axis_tics_font_size\" ]) canvas . line ( self . visualisation_data [ \"coordinate_system\" ][ \"x_annotation_start\" ], y_top , self . visualisation_data [ \"coordinate_system\" ][ \"x_annotation_stop\" ], y_top ) for tic_label , tic_position in self . visualisation_data [ \"tics\" ] . items (): canvas . line ( tic_position , y_top , tic_position , y_top - self . visualisation_data [ \"tics_height\" ]) if tic_label == - self . visualisation_data [ \"max_upstream_sequence_length\" ]: canvas . drawString ( tic_position , y_top - ( self . visualisation_data [ \"tics_height\" ] + self . visualisation_data [ \"text_space\" ]), str ( tic_label )) elif tic_label == self . visualisation_data [ \"max_downstream_sequence_length\" ]: canvas . drawRightString ( tic_position , y_top - ( self . visualisation_data [ \"tics_height\" ] + self . visualisation_data [ \"text_space\" ]), str ( tic_label )) else : canvas . drawCentredString ( tic_position , y_top - ( self . visualisation_data [ \"tics_height\" ] + self . visualisation_data [ \"text_space\" ]), str ( tic_label )) __init__ ( visualisation_data , parameters ) Create a TicsVis object. Parameters: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing.py 410 411 412 413 414 415 416 417 418 419 def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Create a TicsVis object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( visualisation_data , parameters ) self . needed_space = None draw ( canvas ) Draw an AxisTics track. Parameters: canvas ( reportlab . pdfgen . canvas . Canvas ) \u2013 a pdf object. Returns: None \u2013 None Source code in uorf4u/drawing.py 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Draw an AxisTics track. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" y_top = self . visualisation_data [ \"y_top\" ] canvas . setLineCap ( 2 ) canvas . setLineWidth ( self . parameters . arguments [ \"axis_tics_line_width\" ]) canvas . setStrokeColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFont ( \"regular\" , self . parameters . arguments [ \"axis_tics_font_size\" ]) canvas . line ( self . visualisation_data [ \"coordinate_system\" ][ \"x_annotation_start\" ], y_top , self . visualisation_data [ \"coordinate_system\" ][ \"x_annotation_stop\" ], y_top ) for tic_label , tic_position in self . visualisation_data [ \"tics\" ] . items (): canvas . line ( tic_position , y_top , tic_position , y_top - self . visualisation_data [ \"tics_height\" ]) if tic_label == - self . visualisation_data [ \"max_upstream_sequence_length\" ]: canvas . drawString ( tic_position , y_top - ( self . visualisation_data [ \"tics_height\" ] + self . visualisation_data [ \"text_space\" ]), str ( tic_label )) elif tic_label == self . visualisation_data [ \"max_downstream_sequence_length\" ]: canvas . drawRightString ( tic_position , y_top - ( self . visualisation_data [ \"tics_height\" ] + self . visualisation_data [ \"text_space\" ]), str ( tic_label )) else : canvas . drawCentredString ( tic_position , y_top - ( self . visualisation_data [ \"tics_height\" ] + self . visualisation_data [ \"text_space\" ]), str ( tic_label )) needed_y_space () Calculate needed vertical space for a SequenceVis track. Returns: float ( float ) \u2013 needed vertical space. Source code in uorf4u/drawing.py 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 def needed_y_space ( self ) -> float : \"\"\"Calculate needed vertical space for a SequenceVis track. Returns: float: needed vertical space. \"\"\" font_type = \"regular\" reportlab . pdfbase . pdfmetrics . registerFont ( reportlab . pdfbase . ttfonts . TTFont ( font_type , self . parameters . arguments [ f \"font_ { font_type } \" ])) face = reportlab . pdfbase . pdfmetrics . getFont ( \"regular\" ) . face if self . parameters . arguments [ \"axis_tics_font_size\" ] == \"auto\" : text_height = self . parameters . arguments [ \"label_height_to_orf_height\" ] * self . parameters . arguments [ \"orf_height\" ] * cm font_size = uorf4u . methods . string_height_to_font_size ( text_height , \"regular\" , self . parameters . arguments ) self . parameters . arguments [ \"axis_tics_font_size\" ] = font_size else : text_height = ( self . parameters . arguments [ \"axis_tics_font_size\" ] * ( face . ascent - face . descent )) / ( 1000 * 1.38 ) self . visualisation_data [ \"tics_height\" ] = 0.7 * text_height self . visualisation_data [ \"text_space\" ] = 1.2 * text_height self . needed_space = self . visualisation_data [ \"tics_height\" ] + self . visualisation_data [ \"text_space\" ] return self . needed_space TitleLoader Bases: Loader A TitleLoader object prepares data for a Title track object. Note: Title track currently is not available. Attributes: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. prepared_data ( dict ) \u2013 dict with data needed for a visualisation track. Source code in uorf4u/drawing.py 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 class TitleLoader ( Loader ): \"\"\"A TitleLoader object prepares data for a Title track object. Note: Title track currently is not available. Attributes: parameters (uorf4u.manager.Parameters): Parameters' class object. prepared_data (dict): dict with data needed for a visualisation track. \"\"\" def __init__ ( self , parameters ): \"\"\"Create a TitleLoader object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( parameters ) def prepare_data ( self , coordinate_system : dict , additional_data : dict ) -> dict : \"\"\"Prepare data for Title visualisation track. Attributes: coordinate_system (dict): coordinate system of a figure page. additional_data (dict): data needed for a track initialisation. Returns: dict: dictionary with prepared data for visualisation. \"\"\" prepared_data = dict () prepared_data [ \"title\" ] = \"Title Testing\" prepared_data [ \"coordinate_system\" ] = coordinate_system self . prepared_data = prepared_data return prepared_data def create_track ( self ) -> TitleVis : \"\"\"Initialise a Title track object. Returns: TitleVis: visualisation track. \"\"\" return TitleVis ( self . prepared_data , self . parameters ) __init__ ( parameters ) Create a TitleLoader object. Parameters: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing.py 528 529 530 531 532 533 534 535 def __init__ ( self , parameters ): \"\"\"Create a TitleLoader object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( parameters ) create_track () Initialise a Title track object. Returns: TitleVis ( TitleVis ) \u2013 visualisation track. Source code in uorf4u/drawing.py 554 555 556 557 558 559 560 561 def create_track ( self ) -> TitleVis : \"\"\"Initialise a Title track object. Returns: TitleVis: visualisation track. \"\"\" return TitleVis ( self . prepared_data , self . parameters ) prepare_data ( coordinate_system , additional_data ) Prepare data for Title visualisation track. Attributes: coordinate_system ( dict ) \u2013 coordinate system of a figure page. additional_data ( dict ) \u2013 data needed for a track initialisation. Returns: dict ( dict ) \u2013 dictionary with prepared data for visualisation. Source code in uorf4u/drawing.py 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 def prepare_data ( self , coordinate_system : dict , additional_data : dict ) -> dict : \"\"\"Prepare data for Title visualisation track. Attributes: coordinate_system (dict): coordinate system of a figure page. additional_data (dict): data needed for a track initialisation. Returns: dict: dictionary with prepared data for visualisation. \"\"\" prepared_data = dict () prepared_data [ \"title\" ] = \"Title Testing\" prepared_data [ \"coordinate_system\" ] = coordinate_system self . prepared_data = prepared_data return prepared_data TitleVis Bases: Track Title visualisation track object draws figure's title. Note: This track currently is not supported. Attributes: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing.py 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 class TitleVis ( Track ): \"\"\"Title visualisation track object draws figure's title. Note: This track currently is not supported. Attributes: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Create TitleVis object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . visualisation_data = visualisation_data self . parameters = parameters def needed_y_space ( self ) -> float : \"\"\"Calculate needed vertical space for a Title track. Returns: float: needed vertical space. \"\"\" font_type = self . parameters . arguments [ \"title_font_type\" ] reportlab . pdfbase . pdfmetrics . registerFont ( reportlab . pdfbase . ttfonts . TTFont ( font_type , self . parameters . arguments [ f \"font_ { font_type } \" ])) face = reportlab . pdfbase . pdfmetrics . getFont ( font_type ) . face if self . parameters . arguments [ \"title_font_size\" ] == \"auto\" : text_height = self . parameters . arguments [ \"orf_height\" ] * cm font_size = uorf4u . methods . string_height_to_font_size ( text_height , font_type , self . parameters . arguments ) self . parameters . arguments [ \"title_font_size\" ] = font_size else : text_height = ( self . parameters . arguments [ \"title_font_size\" ] * ( face . ascent - face . descent )) / ( 1000 * 1.38 ) self . visualisation_data [ \"text_height\" ] = text_height self . needed_space = text_height * 1.2 return self . needed_space def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Draw a Title track. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" x_left_border = self . visualisation_data [ \"coordinate_system\" ][ \"x_labels_start\" ] # x_left_border = self.visualisation_data[\"coordinate_system\"][\"x_annotation_start\"] canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFont ( self . parameters . arguments [ \"title_font_type\" ], self . parameters . arguments [ \"title_font_size\" ]) canvas . drawString ( x_left_border , self . visualisation_data [ \"y_top\" ] - self . visualisation_data [ \"text_height\" ], self . visualisation_data [ \"title\" ]) __init__ ( visualisation_data , parameters ) Create TitleVis object. Parameters: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing.py 188 189 190 191 192 193 194 195 196 197 def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Create TitleVis object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . visualisation_data = visualisation_data self . parameters = parameters draw ( canvas ) Draw a Title track. Parameters: canvas ( reportlab . pdfgen . canvas . Canvas ) \u2013 a pdf object. Returns: None \u2013 None Source code in uorf4u/drawing.py 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Draw a Title track. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" x_left_border = self . visualisation_data [ \"coordinate_system\" ][ \"x_labels_start\" ] # x_left_border = self.visualisation_data[\"coordinate_system\"][\"x_annotation_start\"] canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFont ( self . parameters . arguments [ \"title_font_type\" ], self . parameters . arguments [ \"title_font_size\" ]) canvas . drawString ( x_left_border , self . visualisation_data [ \"y_top\" ] - self . visualisation_data [ \"text_height\" ], self . visualisation_data [ \"title\" ]) needed_y_space () Calculate needed vertical space for a Title track. Returns: float ( float ) \u2013 needed vertical space. Source code in uorf4u/drawing.py 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 def needed_y_space ( self ) -> float : \"\"\"Calculate needed vertical space for a Title track. Returns: float: needed vertical space. \"\"\" font_type = self . parameters . arguments [ \"title_font_type\" ] reportlab . pdfbase . pdfmetrics . registerFont ( reportlab . pdfbase . ttfonts . TTFont ( font_type , self . parameters . arguments [ f \"font_ { font_type } \" ])) face = reportlab . pdfbase . pdfmetrics . getFont ( font_type ) . face if self . parameters . arguments [ \"title_font_size\" ] == \"auto\" : text_height = self . parameters . arguments [ \"orf_height\" ] * cm font_size = uorf4u . methods . string_height_to_font_size ( text_height , font_type , self . parameters . arguments ) self . parameters . arguments [ \"title_font_size\" ] = font_size else : text_height = ( self . parameters . arguments [ \"title_font_size\" ] * ( face . ascent - face . descent )) / ( 1000 * 1.38 ) self . visualisation_data [ \"text_height\" ] = text_height self . needed_space = text_height * 1.2 return self . needed_space Track Parent clas for visualisation Tracks. Attributes: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing.py 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 class Track : \"\"\"Parent clas for visualisation Tracks. Attributes: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Parent's constructor for creating a Track object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . visualisation_data = visualisation_data self . parameters = parameters def needed_y_space ( self ) -> None : \"\"\"Empy parent's method for calculation needed vertical space for a track. Returns: None \"\"\" pass def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Empy parent's method for track visualisation. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" pass __init__ ( visualisation_data , parameters ) Parent's constructor for creating a Track object. Parameters: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing.py 144 145 146 147 148 149 150 151 152 153 def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Parent's constructor for creating a Track object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . visualisation_data = visualisation_data self . parameters = parameters draw ( canvas ) Empy parent's method for track visualisation. Parameters: canvas ( reportlab . pdfgen . canvas . Canvas ) \u2013 a pdf object. Returns: None \u2013 None Source code in uorf4u/drawing.py 164 165 166 167 168 169 170 171 172 173 def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Empy parent's method for track visualisation. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" pass needed_y_space () Empy parent's method for calculation needed vertical space for a track. Returns: None \u2013 None Source code in uorf4u/drawing.py 155 156 157 158 159 160 161 162 def needed_y_space ( self ) -> None : \"\"\"Empy parent's method for calculation needed vertical space for a track. Returns: None \"\"\" pass Methods This module provides some methods (e.g. colors tranformation, data copying) used by the tool. copy_package_data () Copy uorf4u package data folder to your current dir. Returns: None \u2013 None Source code in uorf4u/methods.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 def copy_package_data () -> None : \"\"\"Copy uorf4u package data folder to your current dir. Returns: None \"\"\" try : users_dir = os . path . join ( os . getcwd (), 'uorf4u_data' ) internal_dir = os . path . join ( os . path . dirname ( __file__ ), 'uorf4u_data' ) shutil . copytree ( internal_dir , users_dir , ignore = shutil . ignore_patterns ( \"help*\" , \".*\" , \"msa_plot_dir.R\" )) return None except Exception as error : raise uorf4u . manager . uORF4uError ( f \"Unable to copy uorf4u_data folder in your working dir.\" ) from error hex_to_rgb ( value ) Convert HEX color to RGB format. Returns: list ( list ) \u2013 color in rgb format Source code in uorf4u/methods.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 def hex_to_rgb ( value : str ) -> list : \"\"\"Convert HEX color to RGB format. Returns: list: color in rgb format \"\"\" try : value = value . lstrip ( '#' ) lv = len ( value ) rgb = [ i / 255 for i in tuple ( int ( value [ i : i + lv // 3 ], 16 ) for i in range ( 0 , lv , lv // 3 ))] return rgb except Exception as error : raise uorf4u . manager . uORF4uError ( f \"Unable to convert color definition from HEX to RGB. Please check the palette config file.\" ) from error string_height_to_font_size ( height , font_type , parameters ) Parameters: height ( float ) \u2013 available height of the string. font_type ( str ) \u2013 font type (see config file; at this moment only regular is available) parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Returns: float \u2013 font size defined by height Source code in uorf4u/methods.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 def string_height_to_font_size ( height : float , font_type : str , parameters : dict ): \"\"\" Arguments: height (float): available height of the string. font_type (str): font type (see config file; at this moment only regular is available) parameters (uorf4u.manager.Parameters): Parameters' class object. Returns: float: font size defined by height \"\"\" pdfmetrics . registerFont ( TTFont ( font_type , parameters [ f \"font_ { font_type } \" ])) face = pdfmetrics . getFont ( 'regular' ) . face font_size = ( 1000 * 1.38 * height ) / ( face . ascent - face . descent ) return font_size","title":"uorf4u package"},{"location":"API/package/#data_processing-submodule","text":"This module provides data processing including uORFs annotation and conserved subset searching.","title":"data_processing submodule"},{"location":"API/package/#uorf4u.data_processing.Homologues","text":"A Homologues object holds list of proteins homologues and information about them. Attributes: accession_numbers ( list ) \u2013 List of RefSeq accession numbers. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. records ( list ) \u2013 list of RefSeqProtein objects of the proteins. upstream_sequences ( list ) \u2013 List of dicts with SeqRecords objects and other information codon_table ( Bio . Data . CodonTable . CodonTable ) \u2013 Codon table (genetic code). conserved_paths ( list ) \u2013 list of Path's objects (Path class holds list of ORFs from different upstream sequences and information about them). Source code in uorf4u/data_processing.py 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 class Homologues : \"\"\"A Homologues object holds list of proteins homologues and information about them. Attributes: accession_numbers (list): List of RefSeq accession numbers. parameters (uorf4u.manager.Parameters): Parameters' class object. records (list): list of RefSeqProtein objects of the proteins. upstream_sequences (list): List of dicts with SeqRecords objects and other information (including annotated ORFs saved under the 'ORFs' key) about the upstream sequences. codon_table (Bio.Data.CodonTable.CodonTable): Codon table (genetic code). conserved_paths (list): list of Path's objects (Path class holds list of ORFs from different upstream sequences and information about them). \"\"\" def __init__ ( self , accession_numbers : list , parameters : uorf4u . manager . Parameters ): \"\"\"Create a Homologues object. Note: With initialisation it also creates a 'records' attribute - a list of RefSeqProtein objects of proteins based on accession numbers list. Arguments: accession_numbers (list): List of RefSeq accession numbers. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" try : self . accession_numbers = accession_numbers self . parameters = parameters self . records = [ RefSeqProtein ( i , parameters ) for i in accession_numbers ] self . upstream_sequences = None self . codon_table = Bio . Data . CodonTable . unambiguous_dna_by_name [ parameters . arguments [ \"ncbi_genetic_code_name\" ]] self . conserved_paths = None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to create a Homologues class' object.\" ) from error def get_upstream_sequences ( self ) -> list : \"\"\"Get upstream sequences of proteins' genes. Note: A protein may be found in several assemblies (for example in different strains). Returns: list: List of dicts with SeqRecords objects and other information about upstream sequences. \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udce1 Retrieving upstream sequences...\" , file = sys . stdout ) for record in self . records : record . get_assemblies () if self . parameters . arguments [ \"assemblies_list\" ] == 'NA' : assemblies_table = [ f \"accession_number \\t locus_id \\t assembly \\t organism \\t strain \\t tax_id\" ] list_of_protein_with_multiple_assemblies = [] numbers_of_assemblies = [] for record in self . records : if len ( record . assemblies_coordinates ) > 1 : list_of_protein_with_multiple_assemblies . append ( record . accession_number ) numbers_of_assemblies . append ( len ( record . assemblies_coordinates )) for assembly in record . assemblies_coordinates : assemblies_table . append ( f \" { record . accession_number } \\t { assembly [ 'locus_id' ] } \\t { assembly [ 'assembly' ] } \" f \" \\t { assembly [ 'org' ] } \\t { assembly [ 'strain' ] } \\t { assembly [ 'taxid' ] } \" ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) assemblies_table_path = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"assemblies_list.tsv\" ) assemblies_table_file = open ( assemblies_table_path , \"w\" ) assemblies_table_file . write ( \" \\n \" . join ( assemblies_table )) assemblies_table_file . close () if len ( list_of_protein_with_multiple_assemblies ) > 0 : print ( f \"\u2757\ufe0fWarning message: \\n\\t For { len ( list_of_protein_with_multiple_assemblies ) } proteins \" f \"several assemblies were found in identical protein database \\n \" f \" \\t with max number of assemblies per one protein as { max ( numbers_of_assemblies ) } \ud83d\ude31. \\n\\t \" f \"A table with information about the assemblies was saved as a tsv file: \" f \" { assemblies_table_path } . \\n\\t You can edit it and remove lines with assemblies \" f \"you do not want to include in your analysis. \\n \" f \" \\t After filtering, you can use -al cmd parameter with your table as an argument. \\n \" f \" \\t In addition, config file has 'max_number_of_assemblies' parameter \" f \"(set as { self . parameters . arguments [ 'max_number_of_assemblies' ] } ). \\n\\t By default \u2755, it's used \" f \"by uorf4u to limit max number of assemblies included in the analysis; \\n \" f \" \\t and it works only if '-al' option is not provided. In case number of assemblies is more than \" f \"the cutoff, \\n\\t random sampling \ud83c\udfb2 will be used to take only subset of them. \\n\\t \" f \"See documentation \ud83d\udcd6 for details.\" , file = sys . stderr ) else : assemblies_table = pandas . read_table ( self . parameters . arguments [ \"assemblies_list\" ], sep = \" \\t \" ) locus_ids = assemblies_table [ \"locus_id\" ] . to_list () upstream_sequences = [] an_with_no_annotated_useq = [] for record in self . records : assemblies = record . assemblies_coordinates if isinstance ( self . parameters . arguments [ \"max_number_of_assemblies\" ], int ) and \\ self . parameters . arguments [ \"assemblies_list\" ] == \"NA\" : if len ( assemblies ) >= self . parameters . arguments [ \"max_number_of_assemblies\" ]: assemblies = random . sample ( assemblies , self . parameters . arguments [ \"max_number_of_assemblies\" ]) if self . parameters . arguments [ \"assemblies_list\" ] != \"NA\" : assemblies_filtered = [ i for i in assemblies if i [ \"locus_id\" ] in locus_ids ] assemblies = assemblies_filtered record_upstream_sequences = [] for assembly in assemblies : handle = Bio . Entrez . efetch ( db = \"nucleotide\" , rettype = \"fasta\" , retmode = \"txt\" , id = assembly [ \"locus_id\" ]) locus_record = Bio . SeqIO . read ( handle , \"fasta\" ) useq_downstream_region_length = self . parameters . arguments [ \"downstream_region_length\" ] useq_upstream_region_length = self . parameters . arguments [ \"upstream_region_length\" ] if assembly [ \"strand\" ] == \"+\" : useq_start = max ( 0 , assembly [ \"start\" ] - self . parameters . arguments [ \"upstream_region_length\" ]) if useq_start == 0 : useq_upstream_region_length = assembly [ \"start\" ] useq_stop = min ( assembly [ \"start\" ] + self . parameters . arguments [ \"downstream_region_length\" ], len ( locus_record . seq )) if useq_stop == len ( locus_record . seq ): useq_downstream_region_length = len ( locus_record . seq ) - assembly [ \"start\" ] elif assembly [ \"strand\" ] == \"-\" : useq_start = max ( 0 , assembly [ \"stop\" ] - self . parameters . arguments [ \"downstream_region_length\" ]) if useq_start == 0 : useq_downstream_region_length = assembly [ \"stop\" ] useq_stop = min ( len ( locus_record . seq ), assembly [ \"stop\" ] + self . parameters . arguments [ \"upstream_region_length\" ]) if useq_stop == len ( locus_record . seq ): useq_upstream_region_length = len ( locus_record . seq ) - assembly [ \"stop\" ] useq_length = abs ( useq_stop - useq_start ) if useq_length >= self . parameters . arguments [ \"minimal_upstream_region_length\" ]: useq = locus_record . seq [ useq_start : useq_stop ] if assembly [ \"strand\" ] == \"-\" : useq = useq . reverse_complement () if assembly [ \"strain\" ] == \"NA\" : useq_name = assembly [ \"org\" ] elif assembly [ \"strain\" ] in assembly [ \"org\" ]: useq_name = f \" { assembly [ 'org' ] . replace ( assembly [ 'strain' ], '' ) } [ { assembly [ 'strain' ] } ]\" else : useq_name = f \" { assembly [ 'org' ] } [ { assembly [ 'strain' ] } ]\" useq_id = f \" { assembly [ 'locus_id' ] } | { useq_start } - { useq_stop } ( { assembly [ 'strand' ] } )\" # useq_id format: locus_id|start-stop|strand (coordinates in 0-based) useq_record = Bio . SeqRecord . SeqRecord ( useq , id = useq_id , name = useq_name , description = f \"ac: { record . accession_number } |\" f \"org: { assembly [ 'org' ] } |\" f \"strain: { assembly [ 'strain' ] } |\" f \"assembly: { assembly [ 'assembly' ] } |\" f \"length: { useq_length } \" ) useq_dict = dict ( record = useq_record , id = useq_id , locus_id = assembly [ 'locus_id' ], name = useq_name , length = useq_length , start = useq_start , stop = useq_stop , strand = assembly [ \"strand\" ], accession_number = record . accession_number , organism = { assembly [ 'org' ]}, useq_upstream_region_length = useq_upstream_region_length , useq_downstream_region_length = useq_downstream_region_length ) record_upstream_sequences . append ( useq_dict ) upstream_sequences += record_upstream_sequences if len ( record_upstream_sequences ) == 0 : an_with_no_annotated_useq . append ( record . accession_number ) if an_with_no_annotated_useq : print ( f \"\u2757Warning message: \\n\\t No upstream sequences for { len ( an_with_no_annotated_useq ) } protein(s)\" f \" were annotated. \\n\\t Corresponding loci in the nucleotide ncbi database can be too short \ud83d\udccf. \\n \" f \" \\t See 'minimal_upstream_region_length' config parameter description in the documentation.\" , file = sys . stderr ) self . upstream_sequences = upstream_sequences if self . parameters . arguments [ \"verbose\" ]: print ( f \"\u2705 { len ( self . upstream_sequences ) } upstream sequences were obtained.\" , file = sys . stdout ) return self . upstream_sequences except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to retrieve upstream sequences.\" ) from error def save_upstream_sequences ( self ) -> None : \"\"\"Save upstream sequences as a fasta file. Returns: None \"\"\" try : records = [] output_file = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"upstream_sequences.fa\" ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) for useq in self . upstream_sequences : records . append ( useq [ \"record\" ]) Bio . SeqIO . write ( records , output_file , \"fasta\" ) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc8c Fasta file with upstream sequences was saved to { output_file } .\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save a fasta file with upstream sequences.\" ) from error def annotate_orfs ( self ) -> None : \"\"\"Annotate ORFs of upstream sequences. Note: This function updates 'upstream_sequences' attribute. Returns: None \"\"\" if self . upstream_sequences is None : raise uorf4u . manager . uORF4uError ( f \"Error: 'annotate_orfs()' method can't be called.\" f \" Upstream sequences were not found.\" ) try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udd0e ORFs annotating in the upstream sequences...\" , file = sys . stdout ) if self . parameters . arguments [ \"alternative_start_codons\" ]: start_codons_list = self . codon_table . start_codons else : start_codons_list = [ self . parameters . arguments [ \"main_start_codon\" ]] for useq in self . upstream_sequences : useq_index = self . upstream_sequences . index ( useq ) if self . parameters . arguments [ \"check_assembly_annotation\" ]: useq [ \"locus_annotation\" ] = Locus ( useq [ \"locus_id\" ], start_b = useq [ \"start\" ], stop_b = useq [ \"stop\" ], target_strand = useq [ \"strand\" ]) useq [ \"ORFs\" ] = [] for first_position in range (( useq [ \"length\" ] - 3 ) + 1 ): first_codon = useq [ \"record\" ] . seq [ first_position : first_position + 3 ] if first_codon . upper () in start_codons_list : start_codon_position = first_position for second_position in range ( start_codon_position + 3 , ( useq [ \"length\" ] - 3 ) + 1 , 3 ): second_codon = useq [ \"record\" ] . seq [ second_position : second_position + 3 ] if second_codon . upper () in self . codon_table . stop_codons : stop_codon_position = second_position length = stop_codon_position - start_codon_position distance = ( len ( useq [ 'record' ] . seq ) - self . parameters . arguments [ \"downstream_region_length\" ]) - ( stop_codon_position ) id = f \" { useq [ 'locus_id' ] } | { useq [ 'accession_number' ] } |\" \\ f \" { distance } \" # id: locus_id|accession_number|distance_from_the_start_codon_to_the_main_orf name = f \" { useq [ 'name' ] } | { len ( useq [ 'record' ] . seq ) - ( start_codon_position + 1 ) } \" # name: useq_name|distance_from_the_start_codon_to_the_main_orf sd_window_start = max ( [ 0 , ( start_codon_position - self . parameters . arguments [ \"sd_window_length\" ])]) current_orf = ORF ( parameters = self . parameters , id = id , name = name , distance = distance , start = start_codon_position , stop = stop_codon_position , nt_sequence = useq [ \"record\" ] . seq [ start_codon_position : stop_codon_position ], sd_window_seq = useq [ \"record\" ] . seq [ sd_window_start : start_codon_position ], useq_index = useq_index ) if current_orf . length >= self . parameters . arguments [ \"min_orf_length\" ]: useq [ \"ORFs\" ] . append ( current_orf ) if self . parameters . arguments [ \"check_assembly_annotation\" ]: for cds in useq [ \"locus_annotation\" ] . CDSs : if current_orf . stop == cds [ \"relative_stop\" ] and ( ( current_orf . start - cds [ \"relative_start\" ]) % 3 == 0 ): the_same_stop = 1 current_orf . annotation = cds [ \"product_name\" ] if current_orf . start != cds [ \"relative_start\" ]: if current_orf . start < cds [ \"relative_start\" ]: current_orf . annotation += \" (extension)\" else : current_orf . annotation += \" (truncation)\" for annotated_orfs in useq [ \"ORFs\" ]: if current_orf . stop == annotated_orfs . stop and \\ current_orf . id != annotated_orfs . id : current_orf . extended_orfs . append ( annotated_orfs . id ) break number_of_orfs = sum ( len ( i [ \"ORFs\" ]) for i in self . upstream_sequences ) if number_of_orfs == 0 : print ( f \"\u26d4Termination: \\n\\t No ORF was annotated in upstream sequences.\" f \" \\n\\t This run will be terminated.\" , file = sys . stderr ) sys . exit () if self . parameters . arguments [ \"verbose\" ]: print ( f \"\u2705 { number_of_orfs } ORFs were annotated.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to annotate ORFs in upstream sequences.\" ) from error def filter_orfs_by_sd_annotation ( self ) -> None : \"\"\"Filter annotated ORFs by presence the Shine-Dalgarno sequence. Returns: None \"\"\" try : for useq in self . upstream_sequences : orf_list = useq [ \"ORFs\" ] filtered_orf_list = [] for orf in orf_list : orf . calculate_energies () if orf . min_energy < self . parameters . arguments [ \"sd_energy_cutoff\" ]: filtered_orf_list . append ( orf ) useq [ \"ORFs\" ] = filtered_orf_list number_of_orfs = sum ( len ( i [ \"ORFs\" ]) for i in self . upstream_sequences ) if number_of_orfs == 0 : print ( f \"\u26d4Termination: \\n\\t No ORF left after filtering by SD annotation.\" f \" \\n\\t This run will be terminated.\" , file = sys . stderr ) sys . exit () if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83e\uddf9 { number_of_orfs } ORFs remained in the analysis after filtering by presence of the SD sequence.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to filter uORFs by SD sequence presence.\" ) from error def save_annotated_orfs ( self ) -> None : \"\"\"Save information about annotated ORFs as a set of tsv files. Note: tsv files will be saved to the subdir called 'annotated_ORFs' located in 'output_dir'. Returns: None \"\"\" try : colnames = \" \\t \" . join ( [ \"id\" , \"name\" , \"length\" , \"nt_sequence\" , \"aa_sequence\" , \"sd_sequence_window\" , \"extended_orfs\" , \"annotation\" ]) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) output_dir_path = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"annotated_ORFs\" ) if not os . path . exists ( output_dir_path ): os . mkdir ( output_dir_path ) for useq in self . upstream_sequences : orf_list = useq [ \"ORFs\" ] file_name = f \" { useq [ 'locus_id' ] } | { useq [ 'accession_number' ] } \" \\ f \"_ { useq [ 'name' ] . replace ( ' ' , '_' ) . replace ( '/' , '_' ) } \" lines = [ colnames ] for orf in orf_list : if not orf . extended_orfs : extented_orfs_value = \"NA\" else : extented_orfs_value = ';' . join ( orf . extended_orfs ) lines . append ( \" \\t \" . join ( [ orf . id , orf . name , str ( orf . length ), str ( orf . nt_sequence ), str ( orf . aa_sequence ), str ( orf . sd_window_seq_str ), extented_orfs_value , orf . annotation ])) with open ( os . path . join ( output_dir_path , f \" { file_name } .tsv\" ), \"w\" ) as output : output . write ( \" \\n \" . join ( lines )) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc8c tsv files with information about annotated ORFs were saved to { output_dir_path } folder.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save annotated uORFs.\" ) from error def conserved_orf_searching ( self ) -> dict : \"\"\"Search for sets of conserved ORFs in upstream sequences. Note: It returns a dict with conserved ORFs and updates the self.conserved_paths attribute. Returns: dict: Dict with keys as lengths of ORFs' cluster and values as corresponding lists Path's objects. (Path class holds list of ORFs from different upstream sequences and information about them). \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udd0e Searching for conserved ORFs in upstream sequences...\" , file = sys . stdout ) lengths = [] for useq in self . upstream_sequences : for orf in useq [ \"ORFs\" ]: lengths . append ( orf . length ) lengths = sorted ( list ( set ( lengths ))) global_aligner = Bio . Align . PairwiseAligner () global_aligner . mode = \"global\" global_aligner . match_score = self . parameters . arguments [ \"global_match_score\" ] global_aligner . mismatch_score = self . parameters . arguments [ \"global_mismatch_score\" ] global_aligner . open_gap_score = self . parameters . arguments [ \"global_open_gap_score\" ] global_aligner . extend_gap_score = self . parameters . arguments [ \"global_extend_gap_score\" ] global_aligner . target_end_gap_score = self . parameters . arguments [ \"global_target_end_gap_score\" ] global_aligner . query_end_gap_score = self . parameters . arguments [ \"global_query_end_gap_score\" ] length_variance = self . parameters . arguments [ \"orf_length_group_range\" ] number_of_useqs = len ( self . upstream_sequences ) conserved_paths = [] for length in lengths : useq_indexes_with_filtered_orfs = [] filtered_orfs = dict () for useq_index in range ( number_of_useqs ): useq = self . upstream_sequences [ useq_index ] filtered_orfs [ useq_index ] = [] for orf in useq [ \"ORFs\" ]: if abs ( length - orf . length ) <= length_variance : filtered_orfs [ useq_index ] . append ( orf ) orfs_ids = [ i . id for i in filtered_orfs [ useq_index ]] for orf in filtered_orfs [ useq_index ]: if any ( i in orf . extended_orfs for i in orfs_ids ): filtered_orfs [ useq_index ] . remove ( orf ) if len ( filtered_orfs [ useq_index ]) > 0 : useq_indexes_with_filtered_orfs . append ( useq_index ) if len ( useq_indexes_with_filtered_orfs ) / number_of_useqs >= self . parameters . arguments [ \"orfs_presence_cutoff\" ]: if len ( filtered_orfs . keys ()) > self . parameters . arguments [ \"num_of_initial_genome_iteration\" ]: genome_iterator = random . sample ( filtered_orfs . keys (), self . parameters . arguments [ \"num_of_initial_genome_iteration\" ]) else : genome_iterator = filtered_orfs . keys () for initial_useq in genome_iterator : for initial_orf in filtered_orfs [ initial_useq ]: conserved_path = Path ( self . parameters ) conserved_path . update ( initial_orf ) for useq in random . sample ( filtered_orfs . keys (), len ( filtered_orfs . keys ())): if useq != initial_useq and filtered_orfs [ useq ] != []: score_sums = [] for orf in filtered_orfs [ useq ]: score_sum = 0 for path_orf in conserved_path . path : if self . parameters . arguments [ \"alignment_type\" ] == \"nt\" : current_alignment = global_aligner . align ( orf . nt_sequence , path_orf . nt_sequence ) elif self . parameters . arguments [ \"alignment_type\" ] == \"aa\" : current_alignment = global_aligner . align ( orf . aa_sequence , path_orf . aa_sequence ) score_sum += current_alignment . score score_sums . append ( score_sum ) max_score = max ( score_sums ) if max_score > self . parameters . arguments [ \"alignment_score_cutoff\" ]: if score_sums . count ( max_score ) == 1 : selected_orf = filtered_orfs [ useq ][ score_sums . index ( max_score )] else : num_of_candidates = len ( filtered_orfs [ useq ]) highest_score_orfs = [ filtered_orfs [ useq ][ k ] for k in range ( num_of_candidates ) if score_sums [ k ] == max_score ] highest_score_orfs_length_dists = [ orf_it . length - length for orf_it in highest_score_orfs ] min_length_dist = min ( highest_score_orfs_length_dists ) if highest_score_orfs_length_dists . count ( min_length_dist ) == 1 : selected_orf = highest_score_orfs [ highest_score_orfs_length_dists . index ( min_length_dist )] else : num_of_candidates = len ( highest_score_orfs ) the_closest_by_length_orfs = [ highest_score_orfs [ k ] for k in range ( num_of_candidates ) if highest_score_orfs_length_dists [ k ] == min_length_dist ] the_closest_by_length_orfs_lengths = [ orf_it . length for orf_it in the_closest_by_length_orfs ] max_length = max ( the_closest_by_length_orfs_lengths ) selected_orf = the_closest_by_length_orfs [ the_closest_by_length_orfs_lengths . index ( max_length )] conserved_path . update ( selected_orf , max_score ) if len ( conserved_path ) / number_of_useqs >= self . parameters . arguments [ \"orfs_presence_cutoff\" ]: to_save_this_path = 1 for old_path in conserved_paths : fraction_of_identity = conserved_path . calculate_similarity ( old_path ) if fraction_of_identity >= self . parameters . arguments [ \"paths_identity_cutoff\" ]: if conserved_path . score > old_path . score : conserved_paths . remove ( old_path ) elif conserved_path . score <= old_path . score : to_save_this_path = 0 if to_save_this_path == 1 : conserved_path . sort () conserved_paths . append ( conserved_path ) self . conserved_paths = conserved_paths number_of_paths = len ( conserved_paths ) if number_of_paths == 0 : print ( f \"\u26d4Termination: \\n\\t No conserved ORFs set was found.\" f \" \\n\\t This run will be terminated.\" , file = sys . stderr ) sys . exit () if self . parameters . arguments [ \"verbose\" ]: print ( f \"\u2705 { number_of_paths } sets of conserved ORFs were found.\" , file = sys . stdout ) return conserved_paths except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to perform searching for conserved uORFs.\" ) from error def filter_out_similar_paths ( self ) -> None : \"\"\"Filter out duplicates in sets of annotated conserved ORFs. Note: Two paths are considered as duplicates if they share more than half of ORFs (default value, see 'paths_identity_cutoff' config parameter). In case two paths are found as identical, only one with a higher score will be saved. Returns: None \"\"\" try : filtered_paths = [] for path in self . conserved_paths : to_add = 1 for path_filtered in filtered_paths : if path . calculate_similarity ( path_filtered ) > self . parameters . arguments [ \"paths_identity_cutoff\" ]: if path . score < path_filtered . score : to_add = 0 elif path . score == path_filtered . score and ( len ( path ) < len ( path_filtered )): to_add = 0 else : filtered_paths . remove ( path_filtered ) if to_add == 1 : filtered_paths . append ( path ) self . conserved_paths = filtered_paths if self . parameters . arguments [ \"verbose\" ]: num_of_paths = len ( self . conserved_paths ) print ( f \"\ud83e\uddf9 { num_of_paths } set(s) of conserved ORFs remained in the analysis after filtering \" f \"out duplicates.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to filter out duplicates in conserved uORFs sets.\" ) from error def run_msa ( self ) -> None : \"\"\"Run msa tool (muscle) for each path object (set of conserved ORFs). Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83e\uddee Running MSA tool for conserved ORFs.\" , file = sys . stdout ) for path in self . conserved_paths : path . muscle_msa () return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to get MSA of conserved uORFS.\" ) from error def save_msa ( self ) -> None : \"\"\"Save MSA of conserved ORFs as fasta files. Note: Fasta files will be saved to the subdirs: ['nucleotide_msa' - for MSA of nucleotide sequences of ORFs, 'amino_acid_msa' - MSA of amino acid sequences of ORFs, and 'sd_msa' - MSA of SD sequence regions of ORFS). All of them located in your 'output_dir'. Returns: None \"\"\" try : if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_fasta_files\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) for key in output_dirs : if not ( os . path . exists ( output_dirs [ key ])): os . mkdir ( output_dirs [ key ]) for path in self . conserved_paths : for seq_type in self . parameters . arguments [ \"sequences_to_write\" ]: msa = path . msa [ seq_type ] output = os . path . join ( output_dirs [ seq_type ], f \" { path . id } .fa\" ) Bio . AlignIO . write ( msa , output , \"fasta\" ) if self . parameters . arguments [ \"verbose\" ]: delimiter = \", \\n\\t \" print ( f \"\ud83d\udc8c MSA fasta files of conserved ORFs were saved to the folders: \\n \" f \" \\t { delimiter . join ( output_dirs . values ()) } folders.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save MSA of conserved uORFs.\" ) from error def save_orfs_sequences ( self ) -> None : \"\"\"Save sequences of conserved ORFs as fasta files. Note: Fasta files will be saved to the subdirs: ['nucleotide_orfs' - for MSA of nucleotide sequences of ORFs, 'amino_acid_msa' - MSA of amino acid sequences of ORFs, and 'sd_msa' - MSA of SD sequence regions of ORFS). All of them located in your 'output_dir'. Returns: None \"\"\" try : if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" ) sequence_to_write = [ i for i in self . parameters . arguments [ \"sequences_to_write\" ] if i != \"sd\" ] output_dirs = dict ( zip ( sequence_to_write , [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _orfs_fasta_files\" ) for i in sequence_to_write ])) for key in output_dirs : if not ( os . path . exists ( output_dirs [ key ])): os . mkdir ( output_dirs [ key ]) for seq_type in sequence_to_write : for path in self . conserved_paths : records = [] for orf in path . path : if seq_type == \"nt\" : record = Bio . SeqRecord . SeqRecord ( orf . nt_sequence , orf . id , \"\" , orf . name ) if seq_type == \"aa\" : record = Bio . SeqRecord . SeqRecord ( orf . aa_sequence , orf . id , \"\" , orf . name ) records . append ( record ) output = os . path . join ( output_dirs [ seq_type ], f \" { path . id } .fa\" ) Bio . SeqIO . write ( records , output , \"fasta\" ) if self . parameters . arguments [ \"verbose\" ]: delimiter = \", \\n\\t \" print ( f \"\ud83d\udc8c Sequences fasta files of conserved ORFs were saved to the folders: \\n \" f \" \\t { delimiter . join ( output_dirs . values ()) } .\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save sequences of conserved uORFs.\" ) from error def save_results_summary_table ( self ) -> None : \"\"\"Save results summary table. Note: A tsv table will be saved to your output_dir. Returns: None \"\"\" try : colnames = \" \\t \" . join ( [ \"id\" , \"length\" , \"average_distance_to_the_ORF\" , \"aa_alignment_length\" , \"nt_alignment_length\" , \"score\" , \"number_of_orfs\" , \"number_of_orfs/number_of_sequences\" , \"consensus(aa)\" , \"consensus(nt)\" , \"uORFs\" , \"uORFs_annotations\" ]) rows = [ colnames ] for path in self . conserved_paths : annotations = sorted ( set ([ i . annotation for i in path . path ])) if len ( annotations ) > 1 and \"NA\" in annotations : pass # annotations.remove(\"NA\") # To check then row = \" \\t \" . join ( [ path . id , str ( path . length ), str ( statistics . mean ([ i . distance for i in path . path ])), str ( path . msa [ \"aa\" ] . get_alignment_length ()), str ( path . msa [ \"nt\" ] . get_alignment_length ()), str ( path . score ), str ( len ( path )), str ( round ( len ( path ) / len ( self . upstream_sequences ), 3 )), str ( path . msa_consensus [ \"aa\" ]), str ( path . msa_consensus [ \"nt\" ]), ', ' . join ([ i . id for i in path . path ]), ', ' . join ( annotations )]) rows . append ( row ) output_file_path = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"results_summary.tsv\" ) f = open ( output_file_path , \"w\" ) f . write ( \" \\n \" . join ( rows )) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc8c Results summary tsv table saved to: { output_file_path } .\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save results summary table.\" ) from error def plot_ggmsa_figs ( self ) -> None : \"\"\"Plot MSA plots of conserved ORFs saved as fasta files. Note: R script based on ggmsa package [yulab-smu.top/ggmsa] used to produce MSA plots. R script (msa_plot.R) can be found in output_dir. This method uses subprocess to run this R script in the following way: `Rscript {output_dir}/msa_plot.R --msa_fasta path_to_fasta --output output_path --seq_type (nt/aa) --width N(mm) --height M(mm)`. Since during each run of uorf4u a local copy of this script is created in your output_dir, you can change it without any consequences for next uorf4u runs. This method based on _plot_ggmsa_ method of Path class and simply call it for each Path object. Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83c\udfa8 MSA figures plotting...\" , file = sys . stdout ) for path in self . conserved_paths : path . plot_ggmsa () if self . parameters . arguments [ \"verbose\" ]: rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_visualisation\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) delimiter = \", \\n\\t \" print ( f \"\ud83d\udc8c MSA figures were saved to the folders: \\n\\t { delimiter . join ( output_dirs . values ()) } .\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to visualise MSA of conserved uORFs.\" ) from error def plot_logo_figs ( self ) -> None : \"\"\"Plot sequence Logo figures of conserved ORFs saved as fasta files. Note: This method uses logomaker package to produce images. This method based on _plot_logo_ method of Path class and simply call it for each Path object. Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83c\udfa8 Sequence logo figures plotting...\" , file = sys . stdout ) for path in self . conserved_paths : path . plot_logo () if self . parameters . arguments [ \"verbose\" ]: rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _seqlogo_visualisation\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) delimiter = \", \\n\\t \" print ( f \"\ud83d\udc8c Sequence logo figures were saved to the folders: \\n\\t { delimiter . join ( output_dirs . values ()) } \" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to plot sequence logo of conserved uORFs.\" ) from error def plot_annotation ( self ) -> None : \"\"\"Plot loci' annotations figures with conserved ORFs highlighting. Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83c\udfa8 Loci annotations figures plotting...\" , file = sys . stdout ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) output_dir = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"annotation_visualisation\" ) if not os . path . exists ( output_dir ): os . mkdir ( output_dir ) for path in self . conserved_paths : output_file_name = f \" { os . path . join ( output_dir , path . id ) } .pdf\" annotation_plot_manager = uorf4u . drawing . AnnotationPlotManager ( path , self . upstream_sequences , self . parameters ) annotation_plot_manager . define_x_axis_coordinate_system () annotation_plot_manager . create_tracks () annotation_plot_manager . plot ( output_file_name ) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc8c Annotation figures were saved to the { output_dir } folder\" , file = sys . stdout ) except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to plot loci' annotations figures.\" ) from error","title":"Homologues"},{"location":"API/package/#uorf4u.data_processing.Homologues.__init__","text":"Create a Homologues object. Note: With initialisation it also creates a 'records' attribute - a list of RefSeqProtein objects of proteins based on accession numbers list. Parameters: accession_numbers ( list ) \u2013 List of RefSeq accession numbers. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/data_processing.py 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 def __init__ ( self , accession_numbers : list , parameters : uorf4u . manager . Parameters ): \"\"\"Create a Homologues object. Note: With initialisation it also creates a 'records' attribute - a list of RefSeqProtein objects of proteins based on accession numbers list. Arguments: accession_numbers (list): List of RefSeq accession numbers. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" try : self . accession_numbers = accession_numbers self . parameters = parameters self . records = [ RefSeqProtein ( i , parameters ) for i in accession_numbers ] self . upstream_sequences = None self . codon_table = Bio . Data . CodonTable . unambiguous_dna_by_name [ parameters . arguments [ \"ncbi_genetic_code_name\" ]] self . conserved_paths = None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to create a Homologues class' object.\" ) from error","title":"__init__()"},{"location":"API/package/#uorf4u.data_processing.Homologues.annotate_orfs","text":"Annotate ORFs of upstream sequences. Note: This function updates 'upstream_sequences' attribute. Returns: None \u2013 None Source code in uorf4u/data_processing.py 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 def annotate_orfs ( self ) -> None : \"\"\"Annotate ORFs of upstream sequences. Note: This function updates 'upstream_sequences' attribute. Returns: None \"\"\" if self . upstream_sequences is None : raise uorf4u . manager . uORF4uError ( f \"Error: 'annotate_orfs()' method can't be called.\" f \" Upstream sequences were not found.\" ) try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udd0e ORFs annotating in the upstream sequences...\" , file = sys . stdout ) if self . parameters . arguments [ \"alternative_start_codons\" ]: start_codons_list = self . codon_table . start_codons else : start_codons_list = [ self . parameters . arguments [ \"main_start_codon\" ]] for useq in self . upstream_sequences : useq_index = self . upstream_sequences . index ( useq ) if self . parameters . arguments [ \"check_assembly_annotation\" ]: useq [ \"locus_annotation\" ] = Locus ( useq [ \"locus_id\" ], start_b = useq [ \"start\" ], stop_b = useq [ \"stop\" ], target_strand = useq [ \"strand\" ]) useq [ \"ORFs\" ] = [] for first_position in range (( useq [ \"length\" ] - 3 ) + 1 ): first_codon = useq [ \"record\" ] . seq [ first_position : first_position + 3 ] if first_codon . upper () in start_codons_list : start_codon_position = first_position for second_position in range ( start_codon_position + 3 , ( useq [ \"length\" ] - 3 ) + 1 , 3 ): second_codon = useq [ \"record\" ] . seq [ second_position : second_position + 3 ] if second_codon . upper () in self . codon_table . stop_codons : stop_codon_position = second_position length = stop_codon_position - start_codon_position distance = ( len ( useq [ 'record' ] . seq ) - self . parameters . arguments [ \"downstream_region_length\" ]) - ( stop_codon_position ) id = f \" { useq [ 'locus_id' ] } | { useq [ 'accession_number' ] } |\" \\ f \" { distance } \" # id: locus_id|accession_number|distance_from_the_start_codon_to_the_main_orf name = f \" { useq [ 'name' ] } | { len ( useq [ 'record' ] . seq ) - ( start_codon_position + 1 ) } \" # name: useq_name|distance_from_the_start_codon_to_the_main_orf sd_window_start = max ( [ 0 , ( start_codon_position - self . parameters . arguments [ \"sd_window_length\" ])]) current_orf = ORF ( parameters = self . parameters , id = id , name = name , distance = distance , start = start_codon_position , stop = stop_codon_position , nt_sequence = useq [ \"record\" ] . seq [ start_codon_position : stop_codon_position ], sd_window_seq = useq [ \"record\" ] . seq [ sd_window_start : start_codon_position ], useq_index = useq_index ) if current_orf . length >= self . parameters . arguments [ \"min_orf_length\" ]: useq [ \"ORFs\" ] . append ( current_orf ) if self . parameters . arguments [ \"check_assembly_annotation\" ]: for cds in useq [ \"locus_annotation\" ] . CDSs : if current_orf . stop == cds [ \"relative_stop\" ] and ( ( current_orf . start - cds [ \"relative_start\" ]) % 3 == 0 ): the_same_stop = 1 current_orf . annotation = cds [ \"product_name\" ] if current_orf . start != cds [ \"relative_start\" ]: if current_orf . start < cds [ \"relative_start\" ]: current_orf . annotation += \" (extension)\" else : current_orf . annotation += \" (truncation)\" for annotated_orfs in useq [ \"ORFs\" ]: if current_orf . stop == annotated_orfs . stop and \\ current_orf . id != annotated_orfs . id : current_orf . extended_orfs . append ( annotated_orfs . id ) break number_of_orfs = sum ( len ( i [ \"ORFs\" ]) for i in self . upstream_sequences ) if number_of_orfs == 0 : print ( f \"\u26d4Termination: \\n\\t No ORF was annotated in upstream sequences.\" f \" \\n\\t This run will be terminated.\" , file = sys . stderr ) sys . exit () if self . parameters . arguments [ \"verbose\" ]: print ( f \"\u2705 { number_of_orfs } ORFs were annotated.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to annotate ORFs in upstream sequences.\" ) from error","title":"annotate_orfs()"},{"location":"API/package/#uorf4u.data_processing.Homologues.conserved_orf_searching","text":"Search for sets of conserved ORFs in upstream sequences. Note: It returns a dict with conserved ORFs and updates the self.conserved_paths attribute. Returns: dict ( dict ) \u2013 Dict with keys as lengths of ORFs' cluster and values as corresponding lists Path's objects. (Path class holds list of ORFs from different upstream sequences and information about them). Source code in uorf4u/data_processing.py 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 def conserved_orf_searching ( self ) -> dict : \"\"\"Search for sets of conserved ORFs in upstream sequences. Note: It returns a dict with conserved ORFs and updates the self.conserved_paths attribute. Returns: dict: Dict with keys as lengths of ORFs' cluster and values as corresponding lists Path's objects. (Path class holds list of ORFs from different upstream sequences and information about them). \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udd0e Searching for conserved ORFs in upstream sequences...\" , file = sys . stdout ) lengths = [] for useq in self . upstream_sequences : for orf in useq [ \"ORFs\" ]: lengths . append ( orf . length ) lengths = sorted ( list ( set ( lengths ))) global_aligner = Bio . Align . PairwiseAligner () global_aligner . mode = \"global\" global_aligner . match_score = self . parameters . arguments [ \"global_match_score\" ] global_aligner . mismatch_score = self . parameters . arguments [ \"global_mismatch_score\" ] global_aligner . open_gap_score = self . parameters . arguments [ \"global_open_gap_score\" ] global_aligner . extend_gap_score = self . parameters . arguments [ \"global_extend_gap_score\" ] global_aligner . target_end_gap_score = self . parameters . arguments [ \"global_target_end_gap_score\" ] global_aligner . query_end_gap_score = self . parameters . arguments [ \"global_query_end_gap_score\" ] length_variance = self . parameters . arguments [ \"orf_length_group_range\" ] number_of_useqs = len ( self . upstream_sequences ) conserved_paths = [] for length in lengths : useq_indexes_with_filtered_orfs = [] filtered_orfs = dict () for useq_index in range ( number_of_useqs ): useq = self . upstream_sequences [ useq_index ] filtered_orfs [ useq_index ] = [] for orf in useq [ \"ORFs\" ]: if abs ( length - orf . length ) <= length_variance : filtered_orfs [ useq_index ] . append ( orf ) orfs_ids = [ i . id for i in filtered_orfs [ useq_index ]] for orf in filtered_orfs [ useq_index ]: if any ( i in orf . extended_orfs for i in orfs_ids ): filtered_orfs [ useq_index ] . remove ( orf ) if len ( filtered_orfs [ useq_index ]) > 0 : useq_indexes_with_filtered_orfs . append ( useq_index ) if len ( useq_indexes_with_filtered_orfs ) / number_of_useqs >= self . parameters . arguments [ \"orfs_presence_cutoff\" ]: if len ( filtered_orfs . keys ()) > self . parameters . arguments [ \"num_of_initial_genome_iteration\" ]: genome_iterator = random . sample ( filtered_orfs . keys (), self . parameters . arguments [ \"num_of_initial_genome_iteration\" ]) else : genome_iterator = filtered_orfs . keys () for initial_useq in genome_iterator : for initial_orf in filtered_orfs [ initial_useq ]: conserved_path = Path ( self . parameters ) conserved_path . update ( initial_orf ) for useq in random . sample ( filtered_orfs . keys (), len ( filtered_orfs . keys ())): if useq != initial_useq and filtered_orfs [ useq ] != []: score_sums = [] for orf in filtered_orfs [ useq ]: score_sum = 0 for path_orf in conserved_path . path : if self . parameters . arguments [ \"alignment_type\" ] == \"nt\" : current_alignment = global_aligner . align ( orf . nt_sequence , path_orf . nt_sequence ) elif self . parameters . arguments [ \"alignment_type\" ] == \"aa\" : current_alignment = global_aligner . align ( orf . aa_sequence , path_orf . aa_sequence ) score_sum += current_alignment . score score_sums . append ( score_sum ) max_score = max ( score_sums ) if max_score > self . parameters . arguments [ \"alignment_score_cutoff\" ]: if score_sums . count ( max_score ) == 1 : selected_orf = filtered_orfs [ useq ][ score_sums . index ( max_score )] else : num_of_candidates = len ( filtered_orfs [ useq ]) highest_score_orfs = [ filtered_orfs [ useq ][ k ] for k in range ( num_of_candidates ) if score_sums [ k ] == max_score ] highest_score_orfs_length_dists = [ orf_it . length - length for orf_it in highest_score_orfs ] min_length_dist = min ( highest_score_orfs_length_dists ) if highest_score_orfs_length_dists . count ( min_length_dist ) == 1 : selected_orf = highest_score_orfs [ highest_score_orfs_length_dists . index ( min_length_dist )] else : num_of_candidates = len ( highest_score_orfs ) the_closest_by_length_orfs = [ highest_score_orfs [ k ] for k in range ( num_of_candidates ) if highest_score_orfs_length_dists [ k ] == min_length_dist ] the_closest_by_length_orfs_lengths = [ orf_it . length for orf_it in the_closest_by_length_orfs ] max_length = max ( the_closest_by_length_orfs_lengths ) selected_orf = the_closest_by_length_orfs [ the_closest_by_length_orfs_lengths . index ( max_length )] conserved_path . update ( selected_orf , max_score ) if len ( conserved_path ) / number_of_useqs >= self . parameters . arguments [ \"orfs_presence_cutoff\" ]: to_save_this_path = 1 for old_path in conserved_paths : fraction_of_identity = conserved_path . calculate_similarity ( old_path ) if fraction_of_identity >= self . parameters . arguments [ \"paths_identity_cutoff\" ]: if conserved_path . score > old_path . score : conserved_paths . remove ( old_path ) elif conserved_path . score <= old_path . score : to_save_this_path = 0 if to_save_this_path == 1 : conserved_path . sort () conserved_paths . append ( conserved_path ) self . conserved_paths = conserved_paths number_of_paths = len ( conserved_paths ) if number_of_paths == 0 : print ( f \"\u26d4Termination: \\n\\t No conserved ORFs set was found.\" f \" \\n\\t This run will be terminated.\" , file = sys . stderr ) sys . exit () if self . parameters . arguments [ \"verbose\" ]: print ( f \"\u2705 { number_of_paths } sets of conserved ORFs were found.\" , file = sys . stdout ) return conserved_paths except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to perform searching for conserved uORFs.\" ) from error","title":"conserved_orf_searching()"},{"location":"API/package/#uorf4u.data_processing.Homologues.filter_orfs_by_sd_annotation","text":"Filter annotated ORFs by presence the Shine-Dalgarno sequence. Returns: None \u2013 None Source code in uorf4u/data_processing.py 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 def filter_orfs_by_sd_annotation ( self ) -> None : \"\"\"Filter annotated ORFs by presence the Shine-Dalgarno sequence. Returns: None \"\"\" try : for useq in self . upstream_sequences : orf_list = useq [ \"ORFs\" ] filtered_orf_list = [] for orf in orf_list : orf . calculate_energies () if orf . min_energy < self . parameters . arguments [ \"sd_energy_cutoff\" ]: filtered_orf_list . append ( orf ) useq [ \"ORFs\" ] = filtered_orf_list number_of_orfs = sum ( len ( i [ \"ORFs\" ]) for i in self . upstream_sequences ) if number_of_orfs == 0 : print ( f \"\u26d4Termination: \\n\\t No ORF left after filtering by SD annotation.\" f \" \\n\\t This run will be terminated.\" , file = sys . stderr ) sys . exit () if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83e\uddf9 { number_of_orfs } ORFs remained in the analysis after filtering by presence of the SD sequence.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to filter uORFs by SD sequence presence.\" ) from error","title":"filter_orfs_by_sd_annotation()"},{"location":"API/package/#uorf4u.data_processing.Homologues.filter_out_similar_paths","text":"Filter out duplicates in sets of annotated conserved ORFs. Note: Two paths are considered as duplicates if they share more than half of ORFs (default value, see 'paths_identity_cutoff' config parameter). In case two paths are found as identical, only one with a higher score will be saved. Returns: None \u2013 None Source code in uorf4u/data_processing.py 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 def filter_out_similar_paths ( self ) -> None : \"\"\"Filter out duplicates in sets of annotated conserved ORFs. Note: Two paths are considered as duplicates if they share more than half of ORFs (default value, see 'paths_identity_cutoff' config parameter). In case two paths are found as identical, only one with a higher score will be saved. Returns: None \"\"\" try : filtered_paths = [] for path in self . conserved_paths : to_add = 1 for path_filtered in filtered_paths : if path . calculate_similarity ( path_filtered ) > self . parameters . arguments [ \"paths_identity_cutoff\" ]: if path . score < path_filtered . score : to_add = 0 elif path . score == path_filtered . score and ( len ( path ) < len ( path_filtered )): to_add = 0 else : filtered_paths . remove ( path_filtered ) if to_add == 1 : filtered_paths . append ( path ) self . conserved_paths = filtered_paths if self . parameters . arguments [ \"verbose\" ]: num_of_paths = len ( self . conserved_paths ) print ( f \"\ud83e\uddf9 { num_of_paths } set(s) of conserved ORFs remained in the analysis after filtering \" f \"out duplicates.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to filter out duplicates in conserved uORFs sets.\" ) from error","title":"filter_out_similar_paths()"},{"location":"API/package/#uorf4u.data_processing.Homologues.get_upstream_sequences","text":"Get upstream sequences of proteins' genes. Note: A protein may be found in several assemblies (for example in different strains). Returns: list ( list ) \u2013 List of dicts with SeqRecords objects and other information about upstream sequences. Source code in uorf4u/data_processing.py 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 def get_upstream_sequences ( self ) -> list : \"\"\"Get upstream sequences of proteins' genes. Note: A protein may be found in several assemblies (for example in different strains). Returns: list: List of dicts with SeqRecords objects and other information about upstream sequences. \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udce1 Retrieving upstream sequences...\" , file = sys . stdout ) for record in self . records : record . get_assemblies () if self . parameters . arguments [ \"assemblies_list\" ] == 'NA' : assemblies_table = [ f \"accession_number \\t locus_id \\t assembly \\t organism \\t strain \\t tax_id\" ] list_of_protein_with_multiple_assemblies = [] numbers_of_assemblies = [] for record in self . records : if len ( record . assemblies_coordinates ) > 1 : list_of_protein_with_multiple_assemblies . append ( record . accession_number ) numbers_of_assemblies . append ( len ( record . assemblies_coordinates )) for assembly in record . assemblies_coordinates : assemblies_table . append ( f \" { record . accession_number } \\t { assembly [ 'locus_id' ] } \\t { assembly [ 'assembly' ] } \" f \" \\t { assembly [ 'org' ] } \\t { assembly [ 'strain' ] } \\t { assembly [ 'taxid' ] } \" ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) assemblies_table_path = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"assemblies_list.tsv\" ) assemblies_table_file = open ( assemblies_table_path , \"w\" ) assemblies_table_file . write ( \" \\n \" . join ( assemblies_table )) assemblies_table_file . close () if len ( list_of_protein_with_multiple_assemblies ) > 0 : print ( f \"\u2757\ufe0fWarning message: \\n\\t For { len ( list_of_protein_with_multiple_assemblies ) } proteins \" f \"several assemblies were found in identical protein database \\n \" f \" \\t with max number of assemblies per one protein as { max ( numbers_of_assemblies ) } \ud83d\ude31. \\n\\t \" f \"A table with information about the assemblies was saved as a tsv file: \" f \" { assemblies_table_path } . \\n\\t You can edit it and remove lines with assemblies \" f \"you do not want to include in your analysis. \\n \" f \" \\t After filtering, you can use -al cmd parameter with your table as an argument. \\n \" f \" \\t In addition, config file has 'max_number_of_assemblies' parameter \" f \"(set as { self . parameters . arguments [ 'max_number_of_assemblies' ] } ). \\n\\t By default \u2755, it's used \" f \"by uorf4u to limit max number of assemblies included in the analysis; \\n \" f \" \\t and it works only if '-al' option is not provided. In case number of assemblies is more than \" f \"the cutoff, \\n\\t random sampling \ud83c\udfb2 will be used to take only subset of them. \\n\\t \" f \"See documentation \ud83d\udcd6 for details.\" , file = sys . stderr ) else : assemblies_table = pandas . read_table ( self . parameters . arguments [ \"assemblies_list\" ], sep = \" \\t \" ) locus_ids = assemblies_table [ \"locus_id\" ] . to_list () upstream_sequences = [] an_with_no_annotated_useq = [] for record in self . records : assemblies = record . assemblies_coordinates if isinstance ( self . parameters . arguments [ \"max_number_of_assemblies\" ], int ) and \\ self . parameters . arguments [ \"assemblies_list\" ] == \"NA\" : if len ( assemblies ) >= self . parameters . arguments [ \"max_number_of_assemblies\" ]: assemblies = random . sample ( assemblies , self . parameters . arguments [ \"max_number_of_assemblies\" ]) if self . parameters . arguments [ \"assemblies_list\" ] != \"NA\" : assemblies_filtered = [ i for i in assemblies if i [ \"locus_id\" ] in locus_ids ] assemblies = assemblies_filtered record_upstream_sequences = [] for assembly in assemblies : handle = Bio . Entrez . efetch ( db = \"nucleotide\" , rettype = \"fasta\" , retmode = \"txt\" , id = assembly [ \"locus_id\" ]) locus_record = Bio . SeqIO . read ( handle , \"fasta\" ) useq_downstream_region_length = self . parameters . arguments [ \"downstream_region_length\" ] useq_upstream_region_length = self . parameters . arguments [ \"upstream_region_length\" ] if assembly [ \"strand\" ] == \"+\" : useq_start = max ( 0 , assembly [ \"start\" ] - self . parameters . arguments [ \"upstream_region_length\" ]) if useq_start == 0 : useq_upstream_region_length = assembly [ \"start\" ] useq_stop = min ( assembly [ \"start\" ] + self . parameters . arguments [ \"downstream_region_length\" ], len ( locus_record . seq )) if useq_stop == len ( locus_record . seq ): useq_downstream_region_length = len ( locus_record . seq ) - assembly [ \"start\" ] elif assembly [ \"strand\" ] == \"-\" : useq_start = max ( 0 , assembly [ \"stop\" ] - self . parameters . arguments [ \"downstream_region_length\" ]) if useq_start == 0 : useq_downstream_region_length = assembly [ \"stop\" ] useq_stop = min ( len ( locus_record . seq ), assembly [ \"stop\" ] + self . parameters . arguments [ \"upstream_region_length\" ]) if useq_stop == len ( locus_record . seq ): useq_upstream_region_length = len ( locus_record . seq ) - assembly [ \"stop\" ] useq_length = abs ( useq_stop - useq_start ) if useq_length >= self . parameters . arguments [ \"minimal_upstream_region_length\" ]: useq = locus_record . seq [ useq_start : useq_stop ] if assembly [ \"strand\" ] == \"-\" : useq = useq . reverse_complement () if assembly [ \"strain\" ] == \"NA\" : useq_name = assembly [ \"org\" ] elif assembly [ \"strain\" ] in assembly [ \"org\" ]: useq_name = f \" { assembly [ 'org' ] . replace ( assembly [ 'strain' ], '' ) } [ { assembly [ 'strain' ] } ]\" else : useq_name = f \" { assembly [ 'org' ] } [ { assembly [ 'strain' ] } ]\" useq_id = f \" { assembly [ 'locus_id' ] } | { useq_start } - { useq_stop } ( { assembly [ 'strand' ] } )\" # useq_id format: locus_id|start-stop|strand (coordinates in 0-based) useq_record = Bio . SeqRecord . SeqRecord ( useq , id = useq_id , name = useq_name , description = f \"ac: { record . accession_number } |\" f \"org: { assembly [ 'org' ] } |\" f \"strain: { assembly [ 'strain' ] } |\" f \"assembly: { assembly [ 'assembly' ] } |\" f \"length: { useq_length } \" ) useq_dict = dict ( record = useq_record , id = useq_id , locus_id = assembly [ 'locus_id' ], name = useq_name , length = useq_length , start = useq_start , stop = useq_stop , strand = assembly [ \"strand\" ], accession_number = record . accession_number , organism = { assembly [ 'org' ]}, useq_upstream_region_length = useq_upstream_region_length , useq_downstream_region_length = useq_downstream_region_length ) record_upstream_sequences . append ( useq_dict ) upstream_sequences += record_upstream_sequences if len ( record_upstream_sequences ) == 0 : an_with_no_annotated_useq . append ( record . accession_number ) if an_with_no_annotated_useq : print ( f \"\u2757Warning message: \\n\\t No upstream sequences for { len ( an_with_no_annotated_useq ) } protein(s)\" f \" were annotated. \\n\\t Corresponding loci in the nucleotide ncbi database can be too short \ud83d\udccf. \\n \" f \" \\t See 'minimal_upstream_region_length' config parameter description in the documentation.\" , file = sys . stderr ) self . upstream_sequences = upstream_sequences if self . parameters . arguments [ \"verbose\" ]: print ( f \"\u2705 { len ( self . upstream_sequences ) } upstream sequences were obtained.\" , file = sys . stdout ) return self . upstream_sequences except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to retrieve upstream sequences.\" ) from error","title":"get_upstream_sequences()"},{"location":"API/package/#uorf4u.data_processing.Homologues.plot_annotation","text":"Plot loci' annotations figures with conserved ORFs highlighting. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 def plot_annotation ( self ) -> None : \"\"\"Plot loci' annotations figures with conserved ORFs highlighting. Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83c\udfa8 Loci annotations figures plotting...\" , file = sys . stdout ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) output_dir = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"annotation_visualisation\" ) if not os . path . exists ( output_dir ): os . mkdir ( output_dir ) for path in self . conserved_paths : output_file_name = f \" { os . path . join ( output_dir , path . id ) } .pdf\" annotation_plot_manager = uorf4u . drawing . AnnotationPlotManager ( path , self . upstream_sequences , self . parameters ) annotation_plot_manager . define_x_axis_coordinate_system () annotation_plot_manager . create_tracks () annotation_plot_manager . plot ( output_file_name ) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc8c Annotation figures were saved to the { output_dir } folder\" , file = sys . stdout ) except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to plot loci' annotations figures.\" ) from error","title":"plot_annotation()"},{"location":"API/package/#uorf4u.data_processing.Homologues.plot_ggmsa_figs","text":"Plot MSA plots of conserved ORFs saved as fasta files. Note: R script based on ggmsa package [yulab-smu.top/ggmsa] used to produce MSA plots. R script (msa_plot.R) can be found in output_dir. This method uses subprocess to run this R script in the following way: Rscript {output_dir}/msa_plot.R --msa_fasta path_to_fasta --output output_path --seq_type (nt/aa) --width N(mm) --height M(mm) . Since during each run of uorf4u a local copy of this script is created in your output_dir, you can change it without any consequences for next uorf4u runs. This method based on plot_ggmsa method of Path class and simply call it for each Path object. Returns: None \u2013 None Source code in uorf4u/data_processing.py 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 def plot_ggmsa_figs ( self ) -> None : \"\"\"Plot MSA plots of conserved ORFs saved as fasta files. Note: R script based on ggmsa package [yulab-smu.top/ggmsa] used to produce MSA plots. R script (msa_plot.R) can be found in output_dir. This method uses subprocess to run this R script in the following way: `Rscript {output_dir}/msa_plot.R --msa_fasta path_to_fasta --output output_path --seq_type (nt/aa) --width N(mm) --height M(mm)`. Since during each run of uorf4u a local copy of this script is created in your output_dir, you can change it without any consequences for next uorf4u runs. This method based on _plot_ggmsa_ method of Path class and simply call it for each Path object. Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83c\udfa8 MSA figures plotting...\" , file = sys . stdout ) for path in self . conserved_paths : path . plot_ggmsa () if self . parameters . arguments [ \"verbose\" ]: rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_visualisation\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) delimiter = \", \\n\\t \" print ( f \"\ud83d\udc8c MSA figures were saved to the folders: \\n\\t { delimiter . join ( output_dirs . values ()) } .\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to visualise MSA of conserved uORFs.\" ) from error","title":"plot_ggmsa_figs()"},{"location":"API/package/#uorf4u.data_processing.Homologues.plot_logo_figs","text":"Plot sequence Logo figures of conserved ORFs saved as fasta files. Note: This method uses logomaker package to produce images. This method based on plot_logo method of Path class and simply call it for each Path object. Returns: None \u2013 None Source code in uorf4u/data_processing.py 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 def plot_logo_figs ( self ) -> None : \"\"\"Plot sequence Logo figures of conserved ORFs saved as fasta files. Note: This method uses logomaker package to produce images. This method based on _plot_logo_ method of Path class and simply call it for each Path object. Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83c\udfa8 Sequence logo figures plotting...\" , file = sys . stdout ) for path in self . conserved_paths : path . plot_logo () if self . parameters . arguments [ \"verbose\" ]: rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _seqlogo_visualisation\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) delimiter = \", \\n\\t \" print ( f \"\ud83d\udc8c Sequence logo figures were saved to the folders: \\n\\t { delimiter . join ( output_dirs . values ()) } \" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to plot sequence logo of conserved uORFs.\" ) from error","title":"plot_logo_figs()"},{"location":"API/package/#uorf4u.data_processing.Homologues.run_msa","text":"Run msa tool (muscle) for each path object (set of conserved ORFs). Returns: None \u2013 None Source code in uorf4u/data_processing.py 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 def run_msa ( self ) -> None : \"\"\"Run msa tool (muscle) for each path object (set of conserved ORFs). Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83e\uddee Running MSA tool for conserved ORFs.\" , file = sys . stdout ) for path in self . conserved_paths : path . muscle_msa () return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to get MSA of conserved uORFS.\" ) from error","title":"run_msa()"},{"location":"API/package/#uorf4u.data_processing.Homologues.save_annotated_orfs","text":"Save information about annotated ORFs as a set of tsv files. Note: tsv files will be saved to the subdir called 'annotated_ORFs' located in 'output_dir'. Returns: None \u2013 None Source code in uorf4u/data_processing.py 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 def save_annotated_orfs ( self ) -> None : \"\"\"Save information about annotated ORFs as a set of tsv files. Note: tsv files will be saved to the subdir called 'annotated_ORFs' located in 'output_dir'. Returns: None \"\"\" try : colnames = \" \\t \" . join ( [ \"id\" , \"name\" , \"length\" , \"nt_sequence\" , \"aa_sequence\" , \"sd_sequence_window\" , \"extended_orfs\" , \"annotation\" ]) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) output_dir_path = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"annotated_ORFs\" ) if not os . path . exists ( output_dir_path ): os . mkdir ( output_dir_path ) for useq in self . upstream_sequences : orf_list = useq [ \"ORFs\" ] file_name = f \" { useq [ 'locus_id' ] } | { useq [ 'accession_number' ] } \" \\ f \"_ { useq [ 'name' ] . replace ( ' ' , '_' ) . replace ( '/' , '_' ) } \" lines = [ colnames ] for orf in orf_list : if not orf . extended_orfs : extented_orfs_value = \"NA\" else : extented_orfs_value = ';' . join ( orf . extended_orfs ) lines . append ( \" \\t \" . join ( [ orf . id , orf . name , str ( orf . length ), str ( orf . nt_sequence ), str ( orf . aa_sequence ), str ( orf . sd_window_seq_str ), extented_orfs_value , orf . annotation ])) with open ( os . path . join ( output_dir_path , f \" { file_name } .tsv\" ), \"w\" ) as output : output . write ( \" \\n \" . join ( lines )) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc8c tsv files with information about annotated ORFs were saved to { output_dir_path } folder.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save annotated uORFs.\" ) from error","title":"save_annotated_orfs()"},{"location":"API/package/#uorf4u.data_processing.Homologues.save_msa","text":"Save MSA of conserved ORFs as fasta files. Note: Fasta files will be saved to the subdirs: ['nucleotide_msa' - for MSA of nucleotide sequences of ORFs, 'amino_acid_msa' - MSA of amino acid sequences of ORFs, and 'sd_msa' - MSA of SD sequence regions of ORFS). All of them located in your 'output_dir'. Returns: None \u2013 None Source code in uorf4u/data_processing.py 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 def save_msa ( self ) -> None : \"\"\"Save MSA of conserved ORFs as fasta files. Note: Fasta files will be saved to the subdirs: ['nucleotide_msa' - for MSA of nucleotide sequences of ORFs, 'amino_acid_msa' - MSA of amino acid sequences of ORFs, and 'sd_msa' - MSA of SD sequence regions of ORFS). All of them located in your 'output_dir'. Returns: None \"\"\" try : if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_fasta_files\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) for key in output_dirs : if not ( os . path . exists ( output_dirs [ key ])): os . mkdir ( output_dirs [ key ]) for path in self . conserved_paths : for seq_type in self . parameters . arguments [ \"sequences_to_write\" ]: msa = path . msa [ seq_type ] output = os . path . join ( output_dirs [ seq_type ], f \" { path . id } .fa\" ) Bio . AlignIO . write ( msa , output , \"fasta\" ) if self . parameters . arguments [ \"verbose\" ]: delimiter = \", \\n\\t \" print ( f \"\ud83d\udc8c MSA fasta files of conserved ORFs were saved to the folders: \\n \" f \" \\t { delimiter . join ( output_dirs . values ()) } folders.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save MSA of conserved uORFs.\" ) from error","title":"save_msa()"},{"location":"API/package/#uorf4u.data_processing.Homologues.save_orfs_sequences","text":"Save sequences of conserved ORFs as fasta files. Note: Fasta files will be saved to the subdirs: ['nucleotide_orfs' - for MSA of nucleotide sequences of ORFs, 'amino_acid_msa' - MSA of amino acid sequences of ORFs, and 'sd_msa' - MSA of SD sequence regions of ORFS). All of them located in your 'output_dir'. Returns: None \u2013 None Source code in uorf4u/data_processing.py 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 def save_orfs_sequences ( self ) -> None : \"\"\"Save sequences of conserved ORFs as fasta files. Note: Fasta files will be saved to the subdirs: ['nucleotide_orfs' - for MSA of nucleotide sequences of ORFs, 'amino_acid_msa' - MSA of amino acid sequences of ORFs, and 'sd_msa' - MSA of SD sequence regions of ORFS). All of them located in your 'output_dir'. Returns: None \"\"\" try : if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" ) sequence_to_write = [ i for i in self . parameters . arguments [ \"sequences_to_write\" ] if i != \"sd\" ] output_dirs = dict ( zip ( sequence_to_write , [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _orfs_fasta_files\" ) for i in sequence_to_write ])) for key in output_dirs : if not ( os . path . exists ( output_dirs [ key ])): os . mkdir ( output_dirs [ key ]) for seq_type in sequence_to_write : for path in self . conserved_paths : records = [] for orf in path . path : if seq_type == \"nt\" : record = Bio . SeqRecord . SeqRecord ( orf . nt_sequence , orf . id , \"\" , orf . name ) if seq_type == \"aa\" : record = Bio . SeqRecord . SeqRecord ( orf . aa_sequence , orf . id , \"\" , orf . name ) records . append ( record ) output = os . path . join ( output_dirs [ seq_type ], f \" { path . id } .fa\" ) Bio . SeqIO . write ( records , output , \"fasta\" ) if self . parameters . arguments [ \"verbose\" ]: delimiter = \", \\n\\t \" print ( f \"\ud83d\udc8c Sequences fasta files of conserved ORFs were saved to the folders: \\n \" f \" \\t { delimiter . join ( output_dirs . values ()) } .\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save sequences of conserved uORFs.\" ) from error","title":"save_orfs_sequences()"},{"location":"API/package/#uorf4u.data_processing.Homologues.save_results_summary_table","text":"Save results summary table. Note: A tsv table will be saved to your output_dir. Returns: None \u2013 None Source code in uorf4u/data_processing.py 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 def save_results_summary_table ( self ) -> None : \"\"\"Save results summary table. Note: A tsv table will be saved to your output_dir. Returns: None \"\"\" try : colnames = \" \\t \" . join ( [ \"id\" , \"length\" , \"average_distance_to_the_ORF\" , \"aa_alignment_length\" , \"nt_alignment_length\" , \"score\" , \"number_of_orfs\" , \"number_of_orfs/number_of_sequences\" , \"consensus(aa)\" , \"consensus(nt)\" , \"uORFs\" , \"uORFs_annotations\" ]) rows = [ colnames ] for path in self . conserved_paths : annotations = sorted ( set ([ i . annotation for i in path . path ])) if len ( annotations ) > 1 and \"NA\" in annotations : pass # annotations.remove(\"NA\") # To check then row = \" \\t \" . join ( [ path . id , str ( path . length ), str ( statistics . mean ([ i . distance for i in path . path ])), str ( path . msa [ \"aa\" ] . get_alignment_length ()), str ( path . msa [ \"nt\" ] . get_alignment_length ()), str ( path . score ), str ( len ( path )), str ( round ( len ( path ) / len ( self . upstream_sequences ), 3 )), str ( path . msa_consensus [ \"aa\" ]), str ( path . msa_consensus [ \"nt\" ]), ', ' . join ([ i . id for i in path . path ]), ', ' . join ( annotations )]) rows . append ( row ) output_file_path = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"results_summary.tsv\" ) f = open ( output_file_path , \"w\" ) f . write ( \" \\n \" . join ( rows )) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc8c Results summary tsv table saved to: { output_file_path } .\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save results summary table.\" ) from error","title":"save_results_summary_table()"},{"location":"API/package/#uorf4u.data_processing.Homologues.save_upstream_sequences","text":"Save upstream sequences as a fasta file. Returns: None \u2013 None Source code in uorf4u/data_processing.py 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 def save_upstream_sequences ( self ) -> None : \"\"\"Save upstream sequences as a fasta file. Returns: None \"\"\" try : records = [] output_file = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"upstream_sequences.fa\" ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) for useq in self . upstream_sequences : records . append ( useq [ \"record\" ]) Bio . SeqIO . write ( records , output_file , \"fasta\" ) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc8c Fasta file with upstream sequences was saved to { output_file } .\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save a fasta file with upstream sequences.\" ) from error","title":"save_upstream_sequences()"},{"location":"API/package/#uorf4u.data_processing.Locus","text":"A Locus object holds sequence and annotation of the corresponding ncbi Reference Sequence. Attributes: locus_id ( str ) \u2013 a NCBI locus id from the Nucleotide database. locus_record ( Bio . SeqRecord . SeqRecord ) \u2013 a biopython record object of the sequence. CDSs ( list ) \u2013 list of dicts with information about annotated CDS in the locus' sequence. start_b ( int ) \u2013 start of region within annotation should be retrieved. stop_b ( int ) \u2013 stop of region within annotation should be retrieved. Source code in uorf4u/data_processing.py 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 class Locus : \"\"\" A Locus object holds sequence and annotation of the corresponding ncbi Reference Sequence. Attributes: locus_id (str): a NCBI locus id from the Nucleotide database. locus_record (Bio.SeqRecord.SeqRecord): a biopython record object of the sequence. CDSs (list): list of dicts with information about annotated CDS in the locus' sequence. start_b (int): start of region within annotation should be retrieved. stop_b (int): stop of region within annotation should be retrieved. \"\"\" def __init__ ( self , locus_id : str , start_b : int = 0 , stop_b : int = None , target_strand : str = \"NA\" ): \"\"\"Create a Locus object. Note: 0-based format is used for sequence indexing. Arguments: locus_id (str): locus id from the ncbi nucleotide database. start_b (int): start of region within annotation should be retrieved (optional). stop_b (int): stop of region within annotation should be retrieved (optional). target_strand (str): strand of the target object (optional). \"\"\" try : self . locus_id = locus_id handle = Bio . Entrez . efetch ( db = \"nucleotide\" , rettype = \"fasta\" , retmode = \"txt\" , id = locus_id ) self . locus_record = Bio . SeqIO . read ( handle , \"fasta\" ) if stop_b is None : stop_b = len ( self . locus_record . seq ) handle = Bio . Entrez . efetch ( db = \"nucleotide\" , rettype = \"gbwithparts\" , retmode = \"xml\" , id = locus_id ) xml_output = ( handle . read ()) . decode ( \"utf-8\" ) root = xml . etree . ElementTree . fromstring ( xml_output ) self . CDSs = [] for gbfeature in root . iter ( \"GBFeature\" ): if gbfeature . find ( \"GBFeature_key\" ) . text == \"CDS\" : try : starts , stops = [], [] for interval in gbfeature . iter ( \"GBInterval\" ): try : start , stop = int ( interval . find ( \"GBInterval_from\" ) . text ), int ( interval . find ( \"GBInterval_to\" ) . text ) if start > stop : start , stop , strand = stop - 1 , start , \"-\" else : start , stop , strand = start - 1 , stop , \"+\" starts . append ( start ) stops . append ( stop ) except : pass if starts : coordinates = list ( sorted ( zip ( starts , stops ), key = lambda pair : pair [ 0 ])) main_start , main_stop = coordinates [ 0 ][ 0 ], coordinates [ - 1 ][ - 1 ] if strand == \"+\" : main_stop = main_stop - 3 relative_start , relative_stop = main_start - start_b , main_stop - start_b elif strand == \"-\" : main_start = main_start + 3 relative_start_r , relative_stop_r = main_start - start_b , main_stop - start_b useq_length = stop_b - start_b relative_start , relative_stop = useq_length - relative_stop_r , useq_length - relative_start_r if strand == target_strand : relative_strand = \"+\" else : relative_strand = \"-\" if ( start_b <= main_start < stop_b ) or ( start_b <= main_stop < stop_b ): cds_seq = self . locus_record . seq [ main_start : main_stop ] if strand == '-' : cds_seq = cds_seq . reverse_complement () protein_id , product_name = 'NA' , 'NA' for gbqualifier in gbfeature . iter ( \"GBQualifier\" ): if gbqualifier . find ( \"GBQualifier_name\" ) . text == \"protein_id\" : protein_id = gbqualifier . find ( \"GBQualifier_value\" ) . text if gbqualifier . find ( \"GBQualifier_name\" ) . text == \"product\" : product_name = gbqualifier . find ( \"GBQualifier_value\" ) . text if protein_id != 'NA' : if product_name != 'NA' : product_name = f \" { protein_id } ( { product_name } )\" else : product_name = f \" { protein_id } \" self . CDSs . append ( dict ( protein_id = protein_id , product_name = product_name , coordinates = coordinates , nt_seq = cds_seq , main_start = main_start , main_stop = main_stop , strand = strand , relative_start = relative_start , relative_stop = relative_stop , relative_strand = relative_strand )) except : pass except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to create a Locus class' object.\" ) from error","title":"Locus"},{"location":"API/package/#uorf4u.data_processing.Locus.__init__","text":"Create a Locus object. Note: 0-based format is used for sequence indexing. Parameters: locus_id ( str ) \u2013 locus id from the ncbi nucleotide database. start_b ( int ) \u2013 start of region within annotation should be retrieved (optional). stop_b ( int ) \u2013 stop of region within annotation should be retrieved (optional). target_strand ( str ) \u2013 strand of the target object (optional). Source code in uorf4u/data_processing.py 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 def __init__ ( self , locus_id : str , start_b : int = 0 , stop_b : int = None , target_strand : str = \"NA\" ): \"\"\"Create a Locus object. Note: 0-based format is used for sequence indexing. Arguments: locus_id (str): locus id from the ncbi nucleotide database. start_b (int): start of region within annotation should be retrieved (optional). stop_b (int): stop of region within annotation should be retrieved (optional). target_strand (str): strand of the target object (optional). \"\"\" try : self . locus_id = locus_id handle = Bio . Entrez . efetch ( db = \"nucleotide\" , rettype = \"fasta\" , retmode = \"txt\" , id = locus_id ) self . locus_record = Bio . SeqIO . read ( handle , \"fasta\" ) if stop_b is None : stop_b = len ( self . locus_record . seq ) handle = Bio . Entrez . efetch ( db = \"nucleotide\" , rettype = \"gbwithparts\" , retmode = \"xml\" , id = locus_id ) xml_output = ( handle . read ()) . decode ( \"utf-8\" ) root = xml . etree . ElementTree . fromstring ( xml_output ) self . CDSs = [] for gbfeature in root . iter ( \"GBFeature\" ): if gbfeature . find ( \"GBFeature_key\" ) . text == \"CDS\" : try : starts , stops = [], [] for interval in gbfeature . iter ( \"GBInterval\" ): try : start , stop = int ( interval . find ( \"GBInterval_from\" ) . text ), int ( interval . find ( \"GBInterval_to\" ) . text ) if start > stop : start , stop , strand = stop - 1 , start , \"-\" else : start , stop , strand = start - 1 , stop , \"+\" starts . append ( start ) stops . append ( stop ) except : pass if starts : coordinates = list ( sorted ( zip ( starts , stops ), key = lambda pair : pair [ 0 ])) main_start , main_stop = coordinates [ 0 ][ 0 ], coordinates [ - 1 ][ - 1 ] if strand == \"+\" : main_stop = main_stop - 3 relative_start , relative_stop = main_start - start_b , main_stop - start_b elif strand == \"-\" : main_start = main_start + 3 relative_start_r , relative_stop_r = main_start - start_b , main_stop - start_b useq_length = stop_b - start_b relative_start , relative_stop = useq_length - relative_stop_r , useq_length - relative_start_r if strand == target_strand : relative_strand = \"+\" else : relative_strand = \"-\" if ( start_b <= main_start < stop_b ) or ( start_b <= main_stop < stop_b ): cds_seq = self . locus_record . seq [ main_start : main_stop ] if strand == '-' : cds_seq = cds_seq . reverse_complement () protein_id , product_name = 'NA' , 'NA' for gbqualifier in gbfeature . iter ( \"GBQualifier\" ): if gbqualifier . find ( \"GBQualifier_name\" ) . text == \"protein_id\" : protein_id = gbqualifier . find ( \"GBQualifier_value\" ) . text if gbqualifier . find ( \"GBQualifier_name\" ) . text == \"product\" : product_name = gbqualifier . find ( \"GBQualifier_value\" ) . text if protein_id != 'NA' : if product_name != 'NA' : product_name = f \" { protein_id } ( { product_name } )\" else : product_name = f \" { protein_id } \" self . CDSs . append ( dict ( protein_id = protein_id , product_name = product_name , coordinates = coordinates , nt_seq = cds_seq , main_start = main_start , main_stop = main_stop , strand = strand , relative_start = relative_start , relative_stop = relative_stop , relative_strand = relative_strand )) except : pass except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to create a Locus class' object.\" ) from error","title":"__init__()"},{"location":"API/package/#uorf4u.data_processing.ORF","text":"An ORF object holds information about an annotated ORF. Note: It's supposed that the ORFs class' objects will not be used directly by API users since it's only needed for other classes' methods. Attributes: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. id ( str ) \u2013 identifier of the ORF. Format: locus_id|accession_number|distance_from_the_start_codon_to_the_main_orf name ( str ) \u2013 name of the ORF. Format: useq_name|distance_from_the_start_codon_to_the_main_orf sequence_id ( str ) \u2013 identifier of the ORF's sequence (locus id from the ncbi database). start ( int ) \u2013 start position of the ORF on the locus (0-based). stop ( int ) \u2013 stop position of the ORF on the locus (0-based). length ( int ) \u2013 ORF's nucleotide sequence length. nt_sequence ( Bio . Seq . Seq ) \u2013 a Seq object of nucleotide sequence of the ORF. aa_sequence ( Bio . Seq . Seq ) \u2013 a Seq object of amino acid sequence of the ORF. sd_window_seq ( Bio . Seq . Seq ) \u2013 a Seq object of upstream sequence to the start codon of the ORF. min_energy ( float ) \u2013 minimal value of thermodynamic interaction between aSD and putative SD sequences within the upstream sequences to the start codon. putative_sd_sequence ( Bio . Seq . Seq ) \u2013 a Seq object of the putative SD sequence with the minimal energy value. extended_orfs ( list ) \u2013 a list of ORFs with that are in frame with the ORF, but have upstream start codon. Source code in uorf4u/data_processing.py 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 class ORF : \"\"\"An ORF object holds information about an annotated ORF. Note: It's supposed that the ORFs class' objects will not be used directly by API users since it's only needed for other classes' methods. Attributes: parameters (uorf4u.manager.Parameters): Parameters' class object. id (str): identifier of the ORF. Format: locus_id|accession_number|distance_from_the_start_codon_to_the_main_orf name (str): name of the ORF. Format: useq_name|distance_from_the_start_codon_to_the_main_orf sequence_id (str): identifier of the ORF's sequence (locus id from the ncbi database). start (int): start position of the ORF on the locus (0-based). stop (int): stop position of the ORF on the locus (0-based). length (int): ORF's nucleotide sequence length. nt_sequence (Bio.Seq.Seq): a Seq object of nucleotide sequence of the ORF. aa_sequence (Bio.Seq.Seq): a Seq object of amino acid sequence of the ORF. sd_window_seq (Bio.Seq.Seq): a Seq object of upstream sequence to the start codon of the ORF. min_energy (float): minimal value of thermodynamic interaction between aSD and putative SD sequences within the upstream sequences to the start codon. putative_sd_sequence (Bio.Seq.Seq): a Seq object of the putative SD sequence with the minimal energy value. extended_orfs (list): a list of ORFs with that are in frame with the ORF, but have upstream start codon. \"\"\" def __init__ ( self , parameters : uorf4u . manager . Parameters , id : str , name : str , nt_sequence : Bio . Seq . Seq , sd_window_seq : Bio . Seq . Seq , start : int , stop : int , distance : int , useq_index : int , annotation : str = \"NA\" ): \"\"\"Create an ORF object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. id (str): identifier of the ORF. Format: locus_id:distance_from_the_start_codon_to_the_proteins_orf:length. nt_sequence (Bio.Seq.Seq): a Seq object of nucleotide sequence of the ORF. sd_window_seq (Bio.Seq.Seq): a Seq object of upstream sequence to the start codon of the ORF. start (int): start position of the ORF on the locus (0-based). stop (int): stop position of the ORF on the locus (0-based). distance (int): distance to the main ORF. \"\"\" self . parameters = parameters codon_table = Bio . Data . CodonTable . unambiguous_dna_by_name [ # ambiguous can be needed! parameters . arguments [ \"ncbi_genetic_code_name\" ]] codon_table_ambiguous = Bio . Data . CodonTable . ambiguous_dna_by_name [ # ambiguous can be needed! parameters . arguments [ \"ncbi_genetic_code_name\" ]] self . name = name self . distance = distance self . id = id self . sequence_id = id . split ( \":\" )[ 0 ] self . start = start self . stop = stop self . length = len ( nt_sequence ) self . nt_sequence = nt_sequence self . annotation = annotation self . useq_index = useq_index try : self . aa_sequence = self . nt_sequence . translate ( table = codon_table ) except : self . aa_sequence = self . nt_sequence . translate ( table = codon_table_ambiguous ) self . sd_window_seq = sd_window_seq self . extended_orfs = [] self . min_energy = 0 self . putative_sd_sequence = \"NA\" self . sd_window_seq_str = \"NA\" def calculate_energies ( self ) -> None : \"\"\"Calculate energies of putative SD sequences of the upstream sequence. Returns: None \"\"\" # Loading reference energies json file with open ( self . parameters . arguments [ \"ref_energies\" ]) as ref_energy_file : ref_energy = json . load ( ref_energy_file ) sd_seq_length = min ([ len ( i ) for i in ref_energy . keys ()]) # Energies calculations if len ( self . sd_window_seq ) >= min ( ref_energy . values ()): energies = [] for position in range (( len ( self . sd_window_seq ) - sd_seq_length ) + 1 ): try : energies . append ( ref_energy [ self . sd_window_seq [ position : position + sd_seq_length ]]) except : energies . append ( 0 ) if energies : self . min_energy = min ( energies ) if self . min_energy < self . parameters . arguments [ \"sd_energy_cutoff\" ]: sd_start_position = energies . index ( self . min_energy ) # Be careful, it could be more than one! self . putative_sd_sequence = self . sd_window_seq [ sd_start_position : sd_start_position + sd_seq_length ] self . sd_window_seq_str = ( f \" { self . sd_window_seq [ 0 : sd_start_position ] . lower () } \" f \" { self . putative_sd_sequence . upper () } \" f \" { self . sd_window_seq [ sd_start_position : sd_start_position + sd_seq_length :] . lower () } \" ) return None","title":"ORF"},{"location":"API/package/#uorf4u.data_processing.ORF.__init__","text":"Create an ORF object. Parameters: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. id ( str ) \u2013 identifier of the ORF. Format: locus_id:distance_from_the_start_codon_to_the_proteins_orf:length. nt_sequence ( Bio . Seq . Seq ) \u2013 a Seq object of nucleotide sequence of the ORF. sd_window_seq ( Bio . Seq . Seq ) \u2013 a Seq object of upstream sequence to the start codon of the ORF. start ( int ) \u2013 start position of the ORF on the locus (0-based). stop ( int ) \u2013 stop position of the ORF on the locus (0-based). distance ( int ) \u2013 distance to the main ORF. Source code in uorf4u/data_processing.py 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 def __init__ ( self , parameters : uorf4u . manager . Parameters , id : str , name : str , nt_sequence : Bio . Seq . Seq , sd_window_seq : Bio . Seq . Seq , start : int , stop : int , distance : int , useq_index : int , annotation : str = \"NA\" ): \"\"\"Create an ORF object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. id (str): identifier of the ORF. Format: locus_id:distance_from_the_start_codon_to_the_proteins_orf:length. nt_sequence (Bio.Seq.Seq): a Seq object of nucleotide sequence of the ORF. sd_window_seq (Bio.Seq.Seq): a Seq object of upstream sequence to the start codon of the ORF. start (int): start position of the ORF on the locus (0-based). stop (int): stop position of the ORF on the locus (0-based). distance (int): distance to the main ORF. \"\"\" self . parameters = parameters codon_table = Bio . Data . CodonTable . unambiguous_dna_by_name [ # ambiguous can be needed! parameters . arguments [ \"ncbi_genetic_code_name\" ]] codon_table_ambiguous = Bio . Data . CodonTable . ambiguous_dna_by_name [ # ambiguous can be needed! parameters . arguments [ \"ncbi_genetic_code_name\" ]] self . name = name self . distance = distance self . id = id self . sequence_id = id . split ( \":\" )[ 0 ] self . start = start self . stop = stop self . length = len ( nt_sequence ) self . nt_sequence = nt_sequence self . annotation = annotation self . useq_index = useq_index try : self . aa_sequence = self . nt_sequence . translate ( table = codon_table ) except : self . aa_sequence = self . nt_sequence . translate ( table = codon_table_ambiguous ) self . sd_window_seq = sd_window_seq self . extended_orfs = [] self . min_energy = 0 self . putative_sd_sequence = \"NA\" self . sd_window_seq_str = \"NA\"","title":"__init__()"},{"location":"API/package/#uorf4u.data_processing.ORF.calculate_energies","text":"Calculate energies of putative SD sequences of the upstream sequence. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 def calculate_energies ( self ) -> None : \"\"\"Calculate energies of putative SD sequences of the upstream sequence. Returns: None \"\"\" # Loading reference energies json file with open ( self . parameters . arguments [ \"ref_energies\" ]) as ref_energy_file : ref_energy = json . load ( ref_energy_file ) sd_seq_length = min ([ len ( i ) for i in ref_energy . keys ()]) # Energies calculations if len ( self . sd_window_seq ) >= min ( ref_energy . values ()): energies = [] for position in range (( len ( self . sd_window_seq ) - sd_seq_length ) + 1 ): try : energies . append ( ref_energy [ self . sd_window_seq [ position : position + sd_seq_length ]]) except : energies . append ( 0 ) if energies : self . min_energy = min ( energies ) if self . min_energy < self . parameters . arguments [ \"sd_energy_cutoff\" ]: sd_start_position = energies . index ( self . min_energy ) # Be careful, it could be more than one! self . putative_sd_sequence = self . sd_window_seq [ sd_start_position : sd_start_position + sd_seq_length ] self . sd_window_seq_str = ( f \" { self . sd_window_seq [ 0 : sd_start_position ] . lower () } \" f \" { self . putative_sd_sequence . upper () } \" f \" { self . sd_window_seq [ sd_start_position : sd_start_position + sd_seq_length :] . lower () } \" ) return None","title":"calculate_energies()"},{"location":"API/package/#uorf4u.data_processing.Path","text":"A Path object holds information about a list of conserved ORFs. Note: It's supposed that the Path class' objects will not be used directly by API users since it's only needed for other classes' methods. Attributes: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. path ( list ) \u2013 List of the ORF class objects. score ( float ) \u2013 Score of the Path (calculated as sum of pairwise alignments scores of ORFs). msa ( dict ) \u2013 Dict with Multiple sequence alignment (MSA, Bio.Align.MultipleSeqAlignment object) as values for different sequences (nt, aa, sd) as keys. msa_consensus ( dict ) \u2013 Dict with consensus sequence (Bio.Seq.Seq object) as values for different sequences (nt, aa, sd) as keys. length \u2013 length of the nucleotide sequence alignment. id ( str ) \u2013 Path's id (format: length|score|num_of_orfs|average_distance_to_the_main_ORF Source code in uorf4u/data_processing.py 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 class Path : \"\"\"A Path object holds information about a list of conserved ORFs. Note: It's supposed that the Path class' objects will not be used directly by API users since it's only needed for other classes' methods. Attributes: parameters (uorf4u.manager.Parameters): Parameters' class object. path (list): List of the ORF class objects. score (float): Score of the Path (calculated as sum of pairwise alignments scores of ORFs). msa (dict): Dict with Multiple sequence alignment (MSA, Bio.Align.MultipleSeqAlignment object) as values for different sequences (nt, aa, sd) as keys. msa_consensus (dict): Dict with consensus sequence (Bio.Seq.Seq object) as values for different sequences (nt, aa, sd) as keys. length: length of the nucleotide sequence alignment. id (str): Path's id (format: length|score|num_of_orfs|average_distance_to_the_main_ORF \"\"\" def __init__ ( self , parameters : uorf4u . manager . Parameters ): \"\"\"Create a Path object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . parameters = parameters self . path = [] self . score = 0 self . msa = dict () self . msa_consensus = dict () self . id = None self . length = None def update ( self , orf : ORF , score = 0 ): \"\"\"Update a Path with a new ORF. Arguments: orf (ORF): an ORF class' object. score (float): a sum of pairwise alignment scores of the ORF against all ORFs in the Path. Returns: None \"\"\" self . path . append ( orf ) self . score += score def sort ( self ) -> None : \"\"\"Sort list of ORFs by their names. Returns: None \"\"\" sorted_path = [ x for _ , x in sorted ( zip ([ i . name for i in self . path ], self . path ), key = lambda pair : pair [ 0 ])] self . path = sorted_path return None def __len__ ( self ): \"\"\"__len__ magic method for a Path object. Returns: int: length of the path attribute - a number of ORFs in a Path. \"\"\" return len ( self . path ) def calculate_similarity ( self , other ) -> float : \"\"\"Calculate fraction of identical ORFs between two Path object. __Note:__ If two objects have different length, the fraction will be calculated as a number of identical ORFs divided by length of the shortest Path. Returns: float: fraction of identical ORFs. \"\"\" num_of_identical_elements = len ( set ( self . path ) & set ( other . path )) fraction_of_identical_orfs = num_of_identical_elements / min ( len ( self ), len ( other )) return fraction_of_identical_orfs def muscle_msa ( self ) -> None : \"\"\"Run a multiple sequence alignment tool (muscle) for the ORFs nucleotide and amino acid sequences. Note: This method updates nt_msa and aa_msa attributes. Returns: None \"\"\" self . msa = dict () for seq_type in self . parameters . arguments [ \"sequences_to_write\" ]: records = [] for orf in self . path : # record_id = f\"{orf.id}\" # record_description = f\"{(orf.name.split('|')[0])}\" record_id = f \" { ( orf . name . split ( '|' )[ 0 ]) . replace ( ' ' , '_' ) } \" record_description = f \" { orf . id } \" if seq_type == \"nt\" : record = Bio . SeqRecord . SeqRecord ( orf . nt_sequence , record_id , \"\" , record_description ) elif seq_type == \"aa\" : record = Bio . SeqRecord . SeqRecord ( orf . aa_sequence , record_id , \"\" , record_description ) elif seq_type == \"sd\" : record = Bio . SeqRecord . SeqRecord ( orf . sd_window_seq , record_id , \"\" , record_description ) records . append ( record ) temp_input = tempfile . NamedTemporaryFile () Bio . SeqIO . write ( records , temp_input . name , \"fasta\" ) temp_output = tempfile . NamedTemporaryFile () muscle = self . parameters . arguments [ \"muscle_binary\" ] subprocess . run ([ muscle , \"-align\" , temp_input . name , \"-output\" , temp_output . name ], stderr = subprocess . DEVNULL ) temp_input . close () msa = Bio . AlignIO . read ( temp_output . name , \"fasta\" ) msa . sort ( key = lambda r : r . description ) msa_info = Bio . Align . AlignInfo . SummaryInfo ( msa ) msa_consensus = msa_info . gap_consensus ( threshold = self . parameters . arguments [ \"consensus_threshold\" ]) temp_output . close () if seq_type == \"nt\" : self . length = msa . get_alignment_length () self . msa [ seq_type ], self . msa_consensus [ seq_type ] = msa , msa_consensus avr_distance = str ( round ( statistics . mean ([ i . distance for i in self . path ]))) self . id = f \"length- { self . msa [ 'nt' ] . get_alignment_length () } |score\u2013 { round ( self . score ) } |\" \\ f \"num_of_orfs- { len ( self . path ) } |avr_dist- { avr_distance } \" return None def plot_ggmsa ( self ) -> None : \"\"\"Plot MSA of conserved ORFs saved as fasta files. Note: R script based on ggmsa package [yulab-smu.top/ggmsa] used to produce MSA plots. R script (msa_plot.R) can be found in output_dir. This method uses subprocess to run this R script in the following way: `Rscript {output_dir}/msa_plot.R --msa_fasta path_to_fasta --output output_path --seq_type (nt/aa) --width N(mm) --height M(mm)`. Since during each run of uorf4u a local copy of this script is created in your output_dir, you can change it without any consequences for next uorf4u runs. Returns: None \"\"\" rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_visualisation\" ) for i in self . parameters . arguments [ \"sequences_to_write\" ]])) fasta_files_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_fasta_files\" ) for i in self . parameters . arguments [ \"sequences_to_write\" ]])) for o_dir in output_dirs . values (): if not ( os . path . exists ( o_dir )): os . mkdir ( o_dir ) r_script_path = self . parameters . arguments [ \"plot_msa_R_script\" ] r_script_local = os . path . join ( self . parameters . arguments [ \"output_dir\" ], os . path . basename ( r_script_path )) if not ( os . path . exists ( r_script_local )): shutil . copy ( r_script_path , r_script_local ) for s_type in self . parameters . arguments [ \"sequences_to_write\" ]: current_msa = self . msa [ s_type ] if s_type == \"nt\" or s_type == \"sd\" : seq_type = \"nt\" else : seq_type = \"aa\" output_file = os . path . abspath ( os . path . join ( output_dirs [ s_type ], f \" { self . id } .pdf\" )) input_file = os . path . abspath ( os . path . join ( fasta_files_dirs [ s_type ], f \" { self . id } .fa\" )) num_sequences = len ( current_msa ) length_of_alignment = current_msa . get_alignment_length () page_width = ( 50 + length_of_alignment ) * 5 page_height = max ( 17 , ( num_sequences + 5 ) * 3 ) subprocess . run ([ \"Rscript\" , r_script_local , \"--msa_fasta\" , input_file , \"--output\" , output_file , \"--seq_type\" , seq_type , \"--width\" , str ( page_width ), \"--height\" , str ( page_height )]) def plot_logo ( self ) -> None : \"\"\"Plot sequence Logo of conserved ORFs MSA saved as fasta files. Note: This method uses logomaker package to produce images. Returns: None \"\"\" rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _seqlogo_visualisation\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) for o_dir in output_dirs . values (): if not ( os . path . exists ( o_dir )): os . mkdir ( o_dir ) codons = Bio . Data . CodonTable . ambiguous_dna_by_name [ self . parameters . arguments [ \"ncbi_genetic_code_name\" ]] . protein_alphabet nucleotides = Bio . Data . CodonTable . ambiguous_dna_by_name [ self . parameters . arguments [ \"ncbi_genetic_code_name\" ]] . nucleotide_alphabet alphabet = dict ( nt = nucleotides , aa = codons ) for s_type in self . parameters . arguments [ \"sequences_to_write\" ]: current_msa = self . msa [ s_type ] if s_type == \"nt\" or s_type == \"sd\" : seq_type = \"nt\" elif s_type == \"aa\" : seq_type = \"aa\" output_file = os . path . abspath ( os . path . join ( output_dirs [ s_type ], f \" { os . path . basename ( self . id ) } .pdf\" )) msa_length = current_msa . get_alignment_length () num_of_sequences = len ( current_msa ) current_msa_info = Bio . Align . AlignInfo . SummaryInfo ( current_msa ) pos_specific_dict = dict () pos_specific_score_matrix = current_msa_info . pos_specific_score_matrix () for i in alphabet [ seq_type ]: pos_specific_dict [ i ] = [ 0 for j in range ( msa_length )] for i in range ( msa_length ): for element in pos_specific_score_matrix [ i ] . keys (): pos_specific_dict [ element ][ i ] = ( pos_specific_score_matrix [ i ][ element ] / num_of_sequences ) pos = [ i for i in range ( msa_length )] matrix_db = pandas . DataFrame ( pos_specific_dict , index = pos ) used_alphabet = [ k for k , v in pos_specific_dict . items () if sum ( v ) > 0 ] max_value = 1 if self . parameters . arguments [ \"logo_type\" ] == 'information' : info_mat = logomaker . transform_matrix ( matrix_db , from_type = \"probability\" , to_type = \"information\" ) matrix_db = info_mat # max_value = math.log2(len(used_alphabet)) # to update max_value = math . log2 ( len ( alphabet [ seq_type ])) colors = self . parameters . arguments [ f \"palette_ { seq_type } \" ] fig_size = ( max ( 10 , msa_length * 1.3 ), min ( 2.5 , 2.5 * 10 / ( msa_length ** ( 1 / 6 )))) logo = logomaker . Logo ( matrix_db , color_scheme = colors , figsize = fig_size ) logo . style_spines ( visible = False ) logo . style_spines ( spines = [ \"left\" ], visible = True , linewidth = 0.7 ) logo . ax . set_xticks ([]) logo . ax . set_yticks ([ 0 , max_value ]) plt . savefig ( output_file ) plt . close ( logo . fig ) return None","title":"Path"},{"location":"API/package/#uorf4u.data_processing.Path.__init__","text":"Create a Path object. Parameters: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/data_processing.py 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 def __init__ ( self , parameters : uorf4u . manager . Parameters ): \"\"\"Create a Path object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . parameters = parameters self . path = [] self . score = 0 self . msa = dict () self . msa_consensus = dict () self . id = None self . length = None","title":"__init__()"},{"location":"API/package/#uorf4u.data_processing.Path.__len__","text":"len magic method for a Path object. Returns: int \u2013 length of the path attribute - a number of ORFs in a Path. Source code in uorf4u/data_processing.py 1245 1246 1247 1248 1249 1250 1251 1252 def __len__ ( self ): \"\"\"__len__ magic method for a Path object. Returns: int: length of the path attribute - a number of ORFs in a Path. \"\"\" return len ( self . path )","title":"__len__()"},{"location":"API/package/#uorf4u.data_processing.Path.calculate_similarity","text":"Calculate fraction of identical ORFs between two Path object. Note: If two objects have different length, the fraction will be calculated as a number of identical ORFs divided by length of the shortest Path. Returns: float ( float ) \u2013 fraction of identical ORFs. Source code in uorf4u/data_processing.py 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 def calculate_similarity ( self , other ) -> float : \"\"\"Calculate fraction of identical ORFs between two Path object. __Note:__ If two objects have different length, the fraction will be calculated as a number of identical ORFs divided by length of the shortest Path. Returns: float: fraction of identical ORFs. \"\"\" num_of_identical_elements = len ( set ( self . path ) & set ( other . path )) fraction_of_identical_orfs = num_of_identical_elements / min ( len ( self ), len ( other )) return fraction_of_identical_orfs","title":"calculate_similarity()"},{"location":"API/package/#uorf4u.data_processing.Path.muscle_msa","text":"Run a multiple sequence alignment tool (muscle) for the ORFs nucleotide and amino acid sequences. Note: This method updates nt_msa and aa_msa attributes. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 def muscle_msa ( self ) -> None : \"\"\"Run a multiple sequence alignment tool (muscle) for the ORFs nucleotide and amino acid sequences. Note: This method updates nt_msa and aa_msa attributes. Returns: None \"\"\" self . msa = dict () for seq_type in self . parameters . arguments [ \"sequences_to_write\" ]: records = [] for orf in self . path : # record_id = f\"{orf.id}\" # record_description = f\"{(orf.name.split('|')[0])}\" record_id = f \" { ( orf . name . split ( '|' )[ 0 ]) . replace ( ' ' , '_' ) } \" record_description = f \" { orf . id } \" if seq_type == \"nt\" : record = Bio . SeqRecord . SeqRecord ( orf . nt_sequence , record_id , \"\" , record_description ) elif seq_type == \"aa\" : record = Bio . SeqRecord . SeqRecord ( orf . aa_sequence , record_id , \"\" , record_description ) elif seq_type == \"sd\" : record = Bio . SeqRecord . SeqRecord ( orf . sd_window_seq , record_id , \"\" , record_description ) records . append ( record ) temp_input = tempfile . NamedTemporaryFile () Bio . SeqIO . write ( records , temp_input . name , \"fasta\" ) temp_output = tempfile . NamedTemporaryFile () muscle = self . parameters . arguments [ \"muscle_binary\" ] subprocess . run ([ muscle , \"-align\" , temp_input . name , \"-output\" , temp_output . name ], stderr = subprocess . DEVNULL ) temp_input . close () msa = Bio . AlignIO . read ( temp_output . name , \"fasta\" ) msa . sort ( key = lambda r : r . description ) msa_info = Bio . Align . AlignInfo . SummaryInfo ( msa ) msa_consensus = msa_info . gap_consensus ( threshold = self . parameters . arguments [ \"consensus_threshold\" ]) temp_output . close () if seq_type == \"nt\" : self . length = msa . get_alignment_length () self . msa [ seq_type ], self . msa_consensus [ seq_type ] = msa , msa_consensus avr_distance = str ( round ( statistics . mean ([ i . distance for i in self . path ]))) self . id = f \"length- { self . msa [ 'nt' ] . get_alignment_length () } |score\u2013 { round ( self . score ) } |\" \\ f \"num_of_orfs- { len ( self . path ) } |avr_dist- { avr_distance } \" return None","title":"muscle_msa()"},{"location":"API/package/#uorf4u.data_processing.Path.plot_ggmsa","text":"Plot MSA of conserved ORFs saved as fasta files. Note: R script based on ggmsa package [yulab-smu.top/ggmsa] used to produce MSA plots. R script (msa_plot.R) can be found in output_dir. This method uses subprocess to run this R script in the following way: Rscript {output_dir}/msa_plot.R --msa_fasta path_to_fasta --output output_path --seq_type (nt/aa) --width N(mm) --height M(mm) . Since during each run of uorf4u a local copy of this script is created in your output_dir, you can change it without any consequences for next uorf4u runs. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 def plot_ggmsa ( self ) -> None : \"\"\"Plot MSA of conserved ORFs saved as fasta files. Note: R script based on ggmsa package [yulab-smu.top/ggmsa] used to produce MSA plots. R script (msa_plot.R) can be found in output_dir. This method uses subprocess to run this R script in the following way: `Rscript {output_dir}/msa_plot.R --msa_fasta path_to_fasta --output output_path --seq_type (nt/aa) --width N(mm) --height M(mm)`. Since during each run of uorf4u a local copy of this script is created in your output_dir, you can change it without any consequences for next uorf4u runs. Returns: None \"\"\" rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_visualisation\" ) for i in self . parameters . arguments [ \"sequences_to_write\" ]])) fasta_files_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_fasta_files\" ) for i in self . parameters . arguments [ \"sequences_to_write\" ]])) for o_dir in output_dirs . values (): if not ( os . path . exists ( o_dir )): os . mkdir ( o_dir ) r_script_path = self . parameters . arguments [ \"plot_msa_R_script\" ] r_script_local = os . path . join ( self . parameters . arguments [ \"output_dir\" ], os . path . basename ( r_script_path )) if not ( os . path . exists ( r_script_local )): shutil . copy ( r_script_path , r_script_local ) for s_type in self . parameters . arguments [ \"sequences_to_write\" ]: current_msa = self . msa [ s_type ] if s_type == \"nt\" or s_type == \"sd\" : seq_type = \"nt\" else : seq_type = \"aa\" output_file = os . path . abspath ( os . path . join ( output_dirs [ s_type ], f \" { self . id } .pdf\" )) input_file = os . path . abspath ( os . path . join ( fasta_files_dirs [ s_type ], f \" { self . id } .fa\" )) num_sequences = len ( current_msa ) length_of_alignment = current_msa . get_alignment_length () page_width = ( 50 + length_of_alignment ) * 5 page_height = max ( 17 , ( num_sequences + 5 ) * 3 ) subprocess . run ([ \"Rscript\" , r_script_local , \"--msa_fasta\" , input_file , \"--output\" , output_file , \"--seq_type\" , seq_type , \"--width\" , str ( page_width ), \"--height\" , str ( page_height )])","title":"plot_ggmsa()"},{"location":"API/package/#uorf4u.data_processing.Path.plot_logo","text":"Plot sequence Logo of conserved ORFs MSA saved as fasta files. Note: This method uses logomaker package to produce images. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 def plot_logo ( self ) -> None : \"\"\"Plot sequence Logo of conserved ORFs MSA saved as fasta files. Note: This method uses logomaker package to produce images. Returns: None \"\"\" rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _seqlogo_visualisation\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) for o_dir in output_dirs . values (): if not ( os . path . exists ( o_dir )): os . mkdir ( o_dir ) codons = Bio . Data . CodonTable . ambiguous_dna_by_name [ self . parameters . arguments [ \"ncbi_genetic_code_name\" ]] . protein_alphabet nucleotides = Bio . Data . CodonTable . ambiguous_dna_by_name [ self . parameters . arguments [ \"ncbi_genetic_code_name\" ]] . nucleotide_alphabet alphabet = dict ( nt = nucleotides , aa = codons ) for s_type in self . parameters . arguments [ \"sequences_to_write\" ]: current_msa = self . msa [ s_type ] if s_type == \"nt\" or s_type == \"sd\" : seq_type = \"nt\" elif s_type == \"aa\" : seq_type = \"aa\" output_file = os . path . abspath ( os . path . join ( output_dirs [ s_type ], f \" { os . path . basename ( self . id ) } .pdf\" )) msa_length = current_msa . get_alignment_length () num_of_sequences = len ( current_msa ) current_msa_info = Bio . Align . AlignInfo . SummaryInfo ( current_msa ) pos_specific_dict = dict () pos_specific_score_matrix = current_msa_info . pos_specific_score_matrix () for i in alphabet [ seq_type ]: pos_specific_dict [ i ] = [ 0 for j in range ( msa_length )] for i in range ( msa_length ): for element in pos_specific_score_matrix [ i ] . keys (): pos_specific_dict [ element ][ i ] = ( pos_specific_score_matrix [ i ][ element ] / num_of_sequences ) pos = [ i for i in range ( msa_length )] matrix_db = pandas . DataFrame ( pos_specific_dict , index = pos ) used_alphabet = [ k for k , v in pos_specific_dict . items () if sum ( v ) > 0 ] max_value = 1 if self . parameters . arguments [ \"logo_type\" ] == 'information' : info_mat = logomaker . transform_matrix ( matrix_db , from_type = \"probability\" , to_type = \"information\" ) matrix_db = info_mat # max_value = math.log2(len(used_alphabet)) # to update max_value = math . log2 ( len ( alphabet [ seq_type ])) colors = self . parameters . arguments [ f \"palette_ { seq_type } \" ] fig_size = ( max ( 10 , msa_length * 1.3 ), min ( 2.5 , 2.5 * 10 / ( msa_length ** ( 1 / 6 )))) logo = logomaker . Logo ( matrix_db , color_scheme = colors , figsize = fig_size ) logo . style_spines ( visible = False ) logo . style_spines ( spines = [ \"left\" ], visible = True , linewidth = 0.7 ) logo . ax . set_xticks ([]) logo . ax . set_yticks ([ 0 , max_value ]) plt . savefig ( output_file ) plt . close ( logo . fig ) return None","title":"plot_logo()"},{"location":"API/package/#uorf4u.data_processing.Path.sort","text":"Sort list of ORFs by their names. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 def sort ( self ) -> None : \"\"\"Sort list of ORFs by their names. Returns: None \"\"\" sorted_path = [ x for _ , x in sorted ( zip ([ i . name for i in self . path ], self . path ), key = lambda pair : pair [ 0 ])] self . path = sorted_path return None","title":"sort()"},{"location":"API/package/#uorf4u.data_processing.Path.update","text":"Update a Path with a new ORF. Parameters: orf ( ORF ) \u2013 an ORF class' object. score ( float ) \u2013 a sum of pairwise alignment scores of the ORF against all ORFs in the Path. Returns: \u2013 None Source code in uorf4u/data_processing.py 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 def update ( self , orf : ORF , score = 0 ): \"\"\"Update a Path with a new ORF. Arguments: orf (ORF): an ORF class' object. score (float): a sum of pairwise alignment scores of the ORF against all ORFs in the Path. Returns: None \"\"\" self . path . append ( orf ) self . score += score","title":"update()"},{"location":"API/package/#uorf4u.data_processing.RefSeqProtein","text":"A RefSeqProtein object holds a RefSeq protein and information about it. Attributes: accession_number ( str ) \u2013 RefSeq accession number. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. record ( Bio . SeqRecord . SeqRecord ) \u2013 SeqRecord of the ncbi protein db. Can be obtained by the get_record() method. taxid ( str ) \u2013 Taxid of the protein. Can be obtained with get_assemblies() method. kingdom_taxid ( str ) \u2013 Kingdom taxid of a protein. Can be obtained with get_assemblies() method. organism ( str ) \u2013 Organism name of a protein. Can be obtained with get_assemblies() method. name ( str ) \u2013 Protein's product name from the ncbi (if available). assemblies_coordinates ( list ) \u2013 List of dictionaries with information about assemblies' coordinates of the protein obtained from ipg ncbi database. loci ( dict ) \u2013 Dict with keys as locus_ids and values as Locus class' objects. Source code in uorf4u/data_processing.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 class RefSeqProtein : \"\"\"A RefSeqProtein object holds a RefSeq protein and information about it. Attributes: accession_number (str): RefSeq accession number. parameters (uorf4u.manager.Parameters): Parameters' class object. record (Bio.SeqRecord.SeqRecord): SeqRecord of the ncbi protein db. Can be obtained by the get_record() method. taxid (str): Taxid of the protein. Can be obtained with get_assemblies() method. kingdom_taxid (str): Kingdom taxid of a protein. Can be obtained with get_assemblies() method. organism (str): Organism name of a protein. Can be obtained with get_assemblies() method. name (str): Protein's product name from the ncbi (if available). assemblies_coordinates (list): List of dictionaries with information about assemblies' coordinates of the protein obtained from ipg ncbi database. loci (dict): Dict with keys as locus_ids and values as Locus class' objects. \"\"\" def __init__ ( self , accession_number : str , parameters : uorf4u . manager . Parameters ): \"\"\"Create a RefSeqProtein object. Arguments: accession_number (str): RefSeq accession number. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . accession_number = accession_number self . name = \"NA\" self . parameters = parameters self . record = None self . taxid = None self . kingdom_taxid = None self . organism = None self . assemblies_coordinates = None self . loci = None def get_record ( self ) -> Bio . SeqRecord . SeqRecord : \"\"\"Get a SeqRecord object of a protein from the ncbi protein database. Note: This method returns a record and updates the record attribute. Returns: Bio.SeqRecord.SeqRecordRecord: Record of the protein. \"\"\" try : handle = Bio . Entrez . efetch ( db = \"protein\" , id = self . accession_number , rettype = \"gbwithparts\" , retmode = \"text\" ) self . record = Bio . SeqIO . read ( handle , \"gb\" ) return self . record except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to get a SeqRecord of the protein from the ncbi protein database.\" ) from error def get_assemblies ( self ) -> list : \"\"\"Get assemblies (loci) coordinates of a protein. Note: This method returns a list of assemblies coordinates and updates the self.assemblies_coordinates attribute. Returns: list: List of dictionaries with information about assemblies' coordinates of a protein obtained from the ipg ncbi database. \"\"\" try : handle = Bio . Entrez . efetch ( db = \"protein\" , rettype = \"ipg\" , retmode = \"xml\" , id = self . accession_number ) xml_output = ( handle . read ()) . decode ( 'utf-8' ) root = xml . etree . ElementTree . fromstring ( xml_output ) list_of_kingdom_taxid = [] assemblies_coordinates = [] for protein in root . iter ( \"Protein\" ): if protein . attrib [ \"source\" ] == \"RefSeq\" : if \"name\" in protein . attrib . keys (): self . name = protein . attrib [ \"name\" ] self . taxid = protein . attrib [ \"taxid\" ] self . kingdom_taxid = protein . attrib [ \"kingdom_taxid\" ] self . organism = protein . attrib [ \"org\" ] list_of_kingdom_taxid . append ( self . kingdom_taxid ) for cds in protein . iter ( \"CDS\" ): if \"assembly\" not in cds . attrib . keys (): cds . attrib [ \"assembly\" ] = \"NA\" if \"strain\" not in cds . attrib . keys (): cds . attrib [ \"strain\" ] = \"NA\" try : assemblies_coordinates . append ( dict ( locus_id = cds . attrib [ \"accver\" ], start = ( int ( cds . attrib [ \"start\" ]) - 1 ), stop = int ( cds . attrib [ \"stop\" ]), strand = cds . attrib [ 'strand' ], length = int ( cds . attrib [ \"stop\" ]) - ( int ( cds . attrib [ \"start\" ]) - 1 ), assembly = cds . attrib [ \"assembly\" ], strain = cds . attrib [ \"strain\" ], org = cds . attrib [ \"org\" ], taxid = cds . attrib [ \"taxid\" ])) except : print ( f \"\u2755Attention: { cds . attrib [ 'accver' ] } record is not completed and\" f \" cannot be processed\" , file = sys . stderr ) if len ( assemblies_coordinates ) == 0 : print ( f \"\u2757Warning message: \\n\\t No assembly was found for the protein \" f \"' { self . accession_number } '. \\n\\t This protein record can be suppressed by the ncbi.\" , file = sys . stderr ) self . assemblies_coordinates = assemblies_coordinates return assemblies_coordinates except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to get assemblies coordinates of a protein.\" ) from error ''' def get_loci(self, start=-float(\"inf\"), end=float(\"inf\"), strand=\"NA\") -> dict: \"\"\"Get Locus class objects for each sequence from the ncbi nt database on which the protein is annotated. Returns: dict: Dict with keys as locus_ids and values as Locus class' objects. \"\"\" self.loci = dict() for assembly in self.assemblies_coordinates: locus_id = assembly[\"locus_id\"] self.loci[locus_id] = Locus(locus_id, start_b=start, end_b=end, strand=strand) return self.loci ''' def blastp_searching_for_homologues ( self ) -> list : \"\"\"Search for a protein's homologues with blastp against the 'refseq_protein' database. Note: This function does not create a new object's attribute; It only returns a list of accession numbers. Returns: list: List of proteins' accession numbers obtained with blastp searching. This list also contains the query protein's accession number. \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc40 Searching for homologues of { self . accession_number } with blastp against the RefSeq database...\" , file = sys . stdout ) handle = Bio . Blast . NCBIWWW . qblast ( \"blastp\" , \"refseq_protein\" , self . accession_number , expect = self . parameters . arguments [ \"blastp_evalue_cutoff\" ], hitlist_size = self . parameters . arguments [ \"blastp_hit_list_size\" ], alignments = self . parameters . arguments [ \"blastp_max_number_of_alignments\" ]) xml_output = handle . read () hits_an_list = [ self . accession_number ] blastp_stat_dict = dict () blastp_stat_dict [ self . accession_number ] = dict ( pident_to_query_length = \"the query\" , pident_to_sequence_length = \"the query\" , pident_to_alignment_length = \"the query\" , evalue = \"the query\" ) root = xml . etree . ElementTree . fromstring ( xml_output ) query_length = int ( root . find ( \"BlastOutput_query-len\" ) . text ) for hit in root . iter ( \"Hit\" ): hit_id = hit . find ( \"Hit_id\" ) . text . strip ( \"ref\" ) . strip ( \"|\" ) if hit_id != self . accession_number : hit_description = hit . find ( \"Hit_def\" ) . text subject_length = int ( hit . find ( \"Hit_len\" ) . text ) hsp_identity_sum , hsp_positive_sum , hsp_align_length = 0 , 0 , 0 evalue = [] for hsp in hit . iter ( \"Hsp\" ): hsp_identity_sum += int ( hsp . find ( \"Hsp_identity\" ) . text ) hsp_positive_sum += int ( hsp . find ( \"Hsp_positive\" ) . text ) hsp_align_length += int ( hsp . find ( \"Hsp_align-len\" ) . text ) evalue . append ( hsp . find ( \"Hsp_evalue\" ) . text ) pident_to_query_length = hsp_identity_sum / query_length pident_to_seq_length = hsp_identity_sum / subject_length pident_to_alignment_length = hsp_identity_sum / hsp_align_length if pident_to_query_length >= self . parameters . arguments [ \"blastp_pident_to_query_length_cutoff\" ]: blastp_stat_dict [ hit_id ] = dict ( pident_to_query_length = str ( round ( pident_to_query_length , 2 )), pident_to_sequence_length = str ( round ( pident_to_seq_length , 2 )), pident_to_alignment_length = str ( round ( pident_to_alignment_length , 2 )), evalue = \",\" . join ( evalue )) if hit_id not in hits_an_list : hits_an_list . append ( hit_id ) columns = \" \\t \" . join ([ \"accession_number\" , \"name\" , \"pident_to_query_length\" , \"pident_to_sequence_length\" , \"pident_to_alignment_length\" , \"e-value\" ]) table = [ columns ] hits_records_list = [ RefSeqProtein ( i , self . parameters ) for i in hits_an_list ] for rec in hits_records_list : rec . get_assemblies () table . append ( \" \\t \" . join ([ rec . accession_number , rec . name , blastp_stat_dict [ rec . accession_number ][ \"pident_to_query_length\" ], blastp_stat_dict [ rec . accession_number ][ \"pident_to_sequence_length\" ], blastp_stat_dict [ rec . accession_number ][ \"pident_to_alignment_length\" ], blastp_stat_dict [ rec . accession_number ][ \"evalue\" ]])) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) output_filename = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"found_homologues.tsv\" ) f = open ( output_filename , \"w\" ) f . write ( \" \\n \" . join ( table )) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\u2705 { len ( hits_records_list ) - 1 } homologues were found. \" f \"\ud83d\udc8c Summary table saved to: { output_filename } \" , file = sys . stdout ) return hits_an_list except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to perform searching for homologues with blastp.\" ) from error","title":"RefSeqProtein"},{"location":"API/package/#uorf4u.data_processing.RefSeqProtein.__init__","text":"Create a RefSeqProtein object. Parameters: accession_number ( str ) \u2013 RefSeq accession number. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/data_processing.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 def __init__ ( self , accession_number : str , parameters : uorf4u . manager . Parameters ): \"\"\"Create a RefSeqProtein object. Arguments: accession_number (str): RefSeq accession number. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . accession_number = accession_number self . name = \"NA\" self . parameters = parameters self . record = None self . taxid = None self . kingdom_taxid = None self . organism = None self . assemblies_coordinates = None self . loci = None","title":"__init__()"},{"location":"API/package/#uorf4u.data_processing.RefSeqProtein.blastp_searching_for_homologues","text":"Search for a protein's homologues with blastp against the 'refseq_protein' database. Note: This function does not create a new object's attribute; It only returns a list of accession numbers. Returns: list ( list ) \u2013 List of proteins' accession numbers obtained with blastp searching. This list also contains the query protein's accession number. Source code in uorf4u/data_processing.py 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 def blastp_searching_for_homologues ( self ) -> list : \"\"\"Search for a protein's homologues with blastp against the 'refseq_protein' database. Note: This function does not create a new object's attribute; It only returns a list of accession numbers. Returns: list: List of proteins' accession numbers obtained with blastp searching. This list also contains the query protein's accession number. \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc40 Searching for homologues of { self . accession_number } with blastp against the RefSeq database...\" , file = sys . stdout ) handle = Bio . Blast . NCBIWWW . qblast ( \"blastp\" , \"refseq_protein\" , self . accession_number , expect = self . parameters . arguments [ \"blastp_evalue_cutoff\" ], hitlist_size = self . parameters . arguments [ \"blastp_hit_list_size\" ], alignments = self . parameters . arguments [ \"blastp_max_number_of_alignments\" ]) xml_output = handle . read () hits_an_list = [ self . accession_number ] blastp_stat_dict = dict () blastp_stat_dict [ self . accession_number ] = dict ( pident_to_query_length = \"the query\" , pident_to_sequence_length = \"the query\" , pident_to_alignment_length = \"the query\" , evalue = \"the query\" ) root = xml . etree . ElementTree . fromstring ( xml_output ) query_length = int ( root . find ( \"BlastOutput_query-len\" ) . text ) for hit in root . iter ( \"Hit\" ): hit_id = hit . find ( \"Hit_id\" ) . text . strip ( \"ref\" ) . strip ( \"|\" ) if hit_id != self . accession_number : hit_description = hit . find ( \"Hit_def\" ) . text subject_length = int ( hit . find ( \"Hit_len\" ) . text ) hsp_identity_sum , hsp_positive_sum , hsp_align_length = 0 , 0 , 0 evalue = [] for hsp in hit . iter ( \"Hsp\" ): hsp_identity_sum += int ( hsp . find ( \"Hsp_identity\" ) . text ) hsp_positive_sum += int ( hsp . find ( \"Hsp_positive\" ) . text ) hsp_align_length += int ( hsp . find ( \"Hsp_align-len\" ) . text ) evalue . append ( hsp . find ( \"Hsp_evalue\" ) . text ) pident_to_query_length = hsp_identity_sum / query_length pident_to_seq_length = hsp_identity_sum / subject_length pident_to_alignment_length = hsp_identity_sum / hsp_align_length if pident_to_query_length >= self . parameters . arguments [ \"blastp_pident_to_query_length_cutoff\" ]: blastp_stat_dict [ hit_id ] = dict ( pident_to_query_length = str ( round ( pident_to_query_length , 2 )), pident_to_sequence_length = str ( round ( pident_to_seq_length , 2 )), pident_to_alignment_length = str ( round ( pident_to_alignment_length , 2 )), evalue = \",\" . join ( evalue )) if hit_id not in hits_an_list : hits_an_list . append ( hit_id ) columns = \" \\t \" . join ([ \"accession_number\" , \"name\" , \"pident_to_query_length\" , \"pident_to_sequence_length\" , \"pident_to_alignment_length\" , \"e-value\" ]) table = [ columns ] hits_records_list = [ RefSeqProtein ( i , self . parameters ) for i in hits_an_list ] for rec in hits_records_list : rec . get_assemblies () table . append ( \" \\t \" . join ([ rec . accession_number , rec . name , blastp_stat_dict [ rec . accession_number ][ \"pident_to_query_length\" ], blastp_stat_dict [ rec . accession_number ][ \"pident_to_sequence_length\" ], blastp_stat_dict [ rec . accession_number ][ \"pident_to_alignment_length\" ], blastp_stat_dict [ rec . accession_number ][ \"evalue\" ]])) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) output_filename = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"found_homologues.tsv\" ) f = open ( output_filename , \"w\" ) f . write ( \" \\n \" . join ( table )) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\u2705 { len ( hits_records_list ) - 1 } homologues were found. \" f \"\ud83d\udc8c Summary table saved to: { output_filename } \" , file = sys . stdout ) return hits_an_list except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to perform searching for homologues with blastp.\" ) from error","title":"blastp_searching_for_homologues()"},{"location":"API/package/#uorf4u.data_processing.RefSeqProtein.get_assemblies","text":"Get assemblies (loci) coordinates of a protein. Note: This method returns a list of assemblies coordinates and updates the self.assemblies_coordinates attribute. Returns: list ( list ) \u2013 List of dictionaries with information about assemblies' coordinates of a protein obtained from the ipg ncbi database. Source code in uorf4u/data_processing.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 def get_assemblies ( self ) -> list : \"\"\"Get assemblies (loci) coordinates of a protein. Note: This method returns a list of assemblies coordinates and updates the self.assemblies_coordinates attribute. Returns: list: List of dictionaries with information about assemblies' coordinates of a protein obtained from the ipg ncbi database. \"\"\" try : handle = Bio . Entrez . efetch ( db = \"protein\" , rettype = \"ipg\" , retmode = \"xml\" , id = self . accession_number ) xml_output = ( handle . read ()) . decode ( 'utf-8' ) root = xml . etree . ElementTree . fromstring ( xml_output ) list_of_kingdom_taxid = [] assemblies_coordinates = [] for protein in root . iter ( \"Protein\" ): if protein . attrib [ \"source\" ] == \"RefSeq\" : if \"name\" in protein . attrib . keys (): self . name = protein . attrib [ \"name\" ] self . taxid = protein . attrib [ \"taxid\" ] self . kingdom_taxid = protein . attrib [ \"kingdom_taxid\" ] self . organism = protein . attrib [ \"org\" ] list_of_kingdom_taxid . append ( self . kingdom_taxid ) for cds in protein . iter ( \"CDS\" ): if \"assembly\" not in cds . attrib . keys (): cds . attrib [ \"assembly\" ] = \"NA\" if \"strain\" not in cds . attrib . keys (): cds . attrib [ \"strain\" ] = \"NA\" try : assemblies_coordinates . append ( dict ( locus_id = cds . attrib [ \"accver\" ], start = ( int ( cds . attrib [ \"start\" ]) - 1 ), stop = int ( cds . attrib [ \"stop\" ]), strand = cds . attrib [ 'strand' ], length = int ( cds . attrib [ \"stop\" ]) - ( int ( cds . attrib [ \"start\" ]) - 1 ), assembly = cds . attrib [ \"assembly\" ], strain = cds . attrib [ \"strain\" ], org = cds . attrib [ \"org\" ], taxid = cds . attrib [ \"taxid\" ])) except : print ( f \"\u2755Attention: { cds . attrib [ 'accver' ] } record is not completed and\" f \" cannot be processed\" , file = sys . stderr ) if len ( assemblies_coordinates ) == 0 : print ( f \"\u2757Warning message: \\n\\t No assembly was found for the protein \" f \"' { self . accession_number } '. \\n\\t This protein record can be suppressed by the ncbi.\" , file = sys . stderr ) self . assemblies_coordinates = assemblies_coordinates return assemblies_coordinates except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to get assemblies coordinates of a protein.\" ) from error","title":"get_assemblies()"},{"location":"API/package/#uorf4u.data_processing.RefSeqProtein.get_record","text":"Get a SeqRecord object of a protein from the ncbi protein database. Note: This method returns a record and updates the record attribute. Returns: Bio . SeqRecord . SeqRecord \u2013 Bio.SeqRecord.SeqRecordRecord: Record of the protein. Source code in uorf4u/data_processing.py 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 def get_record ( self ) -> Bio . SeqRecord . SeqRecord : \"\"\"Get a SeqRecord object of a protein from the ncbi protein database. Note: This method returns a record and updates the record attribute. Returns: Bio.SeqRecord.SeqRecordRecord: Record of the protein. \"\"\" try : handle = Bio . Entrez . efetch ( db = \"protein\" , id = self . accession_number , rettype = \"gbwithparts\" , retmode = \"text\" ) self . record = Bio . SeqIO . read ( handle , \"gb\" ) return self . record except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to get a SeqRecord of the protein from the ncbi protein database.\" ) from error","title":"get_record()"},{"location":"API/package/#manager-submodule","text":"This module provides managing classes and methods for the tool.","title":"manager submodule"},{"location":"API/package/#uorf4u.manager.Parameters","text":"A Parameters object holds and parse cmd's and config's arguments for the tool. Note: A Parameters object have to be created in each script since it's used by each class of the tool as a mandatory argument. Source code in uorf4u/manager.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 class Parameters : \"\"\"A Parameters object holds and parse cmd's and config's arguments for the tool. Note: A Parameters object have to be created in each script since it's used by each class of the tool as a mandatory argument. \"\"\" def __init__ ( self ): self . arguments = dict ( assemblies_list = \"NA\" , debug = False , verbose = False ) def parse_cmd_arguments ( self ) -> None : parser = argparse . ArgumentParser ( prog = \"uorf4u\" , add_help = False , usage = \"uorf4u [-an accession_number| -hl [ac1, ac2..] | -hlf path ]\" \"[optional arguments]\" ) mutually_exclusive_group = parser . add_mutually_exclusive_group () mutually_exclusive_group . add_argument ( \"-an\" , dest = \"accession_number\" , type = str , default = None ) mutually_exclusive_group . add_argument ( \"-hl\" , dest = \"homologues_list\" , nargs = \"*\" , default = None ) mutually_exclusive_group . add_argument ( \"-hlf\" , dest = \"homologues_list_file\" , type = str , default = None ) # mutually_exclusive_group.add_argument('-useq', dest='upstream_sequences', type=str, default=None) parser . add_argument ( \"--data\" , dest = \"uorf4u_data\" , action = \"store_true\" ) parser . add_argument ( \"-al\" , dest = \"assemblies_list\" , type = str , default = \"NA\" ) parser . add_argument ( \"-at\" , dest = \"alignment_type\" , choices = [ 'nt' , 'aa' , None ], type = str , default = None ) parser . add_argument ( \"-ul\" , dest = \"upstream_region_length\" , type = int , default = None ) parser . add_argument ( \"-bh\" , dest = \"blastp_hit_list_size\" , type = int , default = None ) parser . add_argument ( \"-asc\" , dest = \"alternative_start_codons\" , action = \"store_true\" , default = None ) parser . add_argument ( \"-o\" , dest = \"output_dir\" , type = str , default = None ) parser . add_argument ( \"-c\" , dest = \"config_file\" , type = str , default = \"internal\" ) parser . add_argument ( \"-v\" , \"--version\" , action = 'version' , version = ' %(prog)s 0.4.0' ) parser . add_argument ( \"--verbose\" , \"-verbose\" , dest = \"verbose\" , action = \"store_true\" ) parser . add_argument ( \"--debug\" , \"-debug\" , dest = \"debug\" , action = \"store_true\" ) parser . add_argument ( \"-h\" , \"--help\" , dest = \"help\" , action = \"store_true\" ) args = parser . parse_args () args = vars ( args ) if len ( sys . argv [ 1 :]) == 0 : args [ \"help\" ] = True if args [ \"uorf4u_data\" ]: uorf4u . methods . copy_package_data () sys . exit () if args [ \"help\" ]: help_message_path = os . path . join ( os . path . dirname ( __file__ ), 'uorf4u_data' , \"help.txt\" ) with open ( help_message_path , \"r\" ) as help_message : print ( help_message . read (), file = sys . stdout ) sys . exit () filtered_args = { k : v for k , v in args . items () if v is not None } self . arguments . update ( filtered_args ) def load_config ( self , path = \"internal\" ): try : if path == \"internal\" : path = os . path . join ( os . path . dirname ( __file__ ), \"uorf4u_data\" , \"uorf4u.cfg\" ) config = configs . load ( path ) config = config . get_config () internal_dir = os . path . dirname ( __file__ ) config [ \"root\" ][ \"output_dir\" ] = config [ \"root\" ][ \"output_dir\" ] . replace ( \" {current_date} \" , time . strftime ( \"%Y_%m_ %d -%H_%M\" )) for key in config [ \"root\" ] . keys (): if type ( config [ \"root\" ][ key ]) is str and \" {internal} \" in config [ \"root\" ][ key ]: config [ \"root\" ][ key ] = config [ \"root\" ][ key ] . replace ( \" {internal} \" , os . path . join ( internal_dir , \"uorf4u_data\" )) self . arguments . update ( config [ 'root' ]) self . load_palette () except Exception as error : raise uORF4uError ( \"Unable to parse the specified config file. Please check your config file.\" ) from error def load_palette ( self ): for seq_type in [ \"nt\" , \"aa\" ]: palette_path = self . arguments [ f \"palette_ { seq_type } \" ] palette_pre_dict = configs . load ( palette_path ) . get_config ()[ \"root\" ] palette_dict = dict () for elements , color in palette_pre_dict . items (): for element in elements : palette_dict [ element ] = color self . arguments [ f \"palette_ { seq_type } \" ] = palette_dict def update ( self , parameters ): self . arguments . update ( parameters )","title":"Parameters"},{"location":"API/package/#uorf4u.manager.uORF4uError","text":"Bases: Exception A helper for exceptions parsing inherited from the Exception class. Source code in uorf4u/manager.py 12 13 14 15 16 class uORF4uError ( Exception ): \"\"\"A helper for exceptions parsing inherited from the Exception class. \"\"\" pass","title":"uORF4uError"},{"location":"API/package/#drawing-submodule","text":"This module provides visualisation of loci annotation.","title":"drawing submodule"},{"location":"API/package/#uorf4u.drawing.AnnotationPlotManager","text":"AnnotationPlotManager object holds needed information for annotation visualisation and controls it. Note: It's supposed that the AnnotationPlotManager' objects will not be used directly by API users since visualisation can be controlled by 'plot_annotation' method. Attributes: path ( uorf4u . data_processing . Path ) \u2013 Path class' objects that holds list of conserved ORFs. upstream_sequences ( list ) \u2013 list of dicts with information about upstream sequences. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. coordinate_system ( dict ) \u2013 coordinate system of figure. additional_data ( dict ) \u2013 dict with data for visualisation tracks. Source code in uorf4u/drawing.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 class AnnotationPlotManager : \"\"\" AnnotationPlotManager object holds needed information for annotation visualisation and controls it. Note: It's supposed that the AnnotationPlotManager' objects will not be used directly by API users since visualisation can be controlled by 'plot_annotation' method. Attributes: path (uorf4u.data_processing.Path): Path class' objects that holds list of conserved ORFs. upstream_sequences (list): list of dicts with information about upstream sequences. parameters (uorf4u.manager.Parameters): Parameters' class object. coordinate_system (dict): coordinate system of figure. additional_data (dict): dict with data for visualisation tracks. \"\"\" def __init__ ( self , path , upstream_sequences : list , parameters : uorf4u . manager . Parameters ): \"\"\"Create a AnnotationPlotManager object. Arguments: path (uorf4u.data_processing.Path): Path class' objects that holds list of conserved ORFs. upstream_sequences (list): list of dicts with information about upstream sequences. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . path = path self . upstream_sequences = upstream_sequences self . parameters = parameters self . coordinate_system = dict () self . additional_data = dict () def define_x_axis_coordinate_system ( self ) -> None : \"\"\"Define coordinate system. Returns: None \"\"\" label_height = self . parameters . arguments [ \"label_height_to_orf_height\" ] * self . parameters . arguments [ \"orf_height\" ] * cm label_font_size = uorf4u . methods . string_height_to_font_size ( label_height , \"regular\" , self . parameters . arguments ) max_label_width = max ([ reportlab . pdfbase . pdfmetrics . stringWidth ( i [ \"id\" ], \"regular\" , label_font_size ) for i in self . upstream_sequences ]) self . additional_data [ \"label_font_size\" ] = label_font_size self . additional_data [ \"ordered_upstream_sequences\" ] = [ self . upstream_sequences [ i ] for i in [ orf . useq_index for orf in self . path . path ]] self . additional_data [ \"number_of_sequences\" ] = len ( self . path ) self . additional_data [ \"max_upstream_sequence_length\" ] = max ( i [ \"useq_upstream_region_length\" ] for i in self . additional_data [ \"ordered_upstream_sequences\" ]) self . additional_data [ \"max_downstream_sequence_length\" ] = max ( i [ \"useq_downstream_region_length\" ] for i in self . additional_data [ \"ordered_upstream_sequences\" ]) window_size_nt = self . additional_data [ \"max_upstream_sequence_length\" ] + self . additional_data [ \"max_downstream_sequence_length\" ] if self . parameters . arguments [ \"annotation_width\" ] == \"auto\" : annotation_width = window_size_nt * self . parameters . arguments [ \"mm_per_nt\" ] * mm else : annotation_width = self . parameters . arguments [ \"annotation_width\" ] * cm self . coordinate_system [ \"transformation_coef\" ] = annotation_width / window_size_nt self . coordinate_system [ \"x_labels_start\" ] = self . parameters . arguments [ \"margin\" ] * cm self . coordinate_system [ \"x_labels_stop\" ] = self . coordinate_system [ \"x_labels_start\" ] + max_label_width self . coordinate_system [ \"x_annotation_start\" ] = self . coordinate_system [ \"x_labels_stop\" ] + \\ self . parameters . arguments [ \"label_gap\" ] * cm self . coordinate_system [ \"x_annotation_stop\" ] = self . coordinate_system [ \"x_annotation_start\" ] + annotation_width self . coordinate_system [ \"figure_width\" ] = 2 * self . parameters . arguments [ \"margin\" ] * cm + annotation_width + \\ max_label_width + self . parameters . arguments [ \"label_gap\" ] * cm self . coordinate_system [ \"figure_height\" ] = self . parameters . arguments [ \"margin\" ] * cm return None def create_tracks ( self ) -> None : \"\"\"Create visualisation tracks. Returns: None \"\"\" self . tracks = [] \"\"\" title_loader = TitleLoader(self.parameters) title_loader.prepare_data(self.coordinate_system, self.additional_data) title_track = title_loader.create_track() self.tracks.append(title_track) self.coordinate_system[\"figure_height\"] += title_track.needed_y_space() \"\"\" for index in range ( self . additional_data [ \"number_of_sequences\" ]): upstream_sequence = self . additional_data [ \"ordered_upstream_sequences\" ][ index ] conserved_orf = self . path . path [ index ] sequence_loader = SequencesLoader ( self . parameters ) sequence_loader . prepare_data ( upstream_sequence , conserved_orf , self . coordinate_system , self . additional_data ) track = sequence_loader . create_track () self . tracks . append ( track ) self . coordinate_system [ \"figure_height\" ] += track . needed_y_space () self . coordinate_system [ \"figure_height\" ] += self . parameters . arguments [ \"gap\" ] * cm # if index < self.additional_data[\"number_of_sequences\"] - 1: axis_tics_loader = AxisLoader ( self . parameters ) axis_tics_loader . prepare_data ( self . coordinate_system , self . additional_data ) axis_tics_track = axis_tics_loader . create_track () self . tracks . append ( axis_tics_track ) self . coordinate_system [ \"figure_height\" ] += axis_tics_track . needed_y_space () self . coordinate_system [ \"figure_height\" ] += self . parameters . arguments [ \"margin\" ] * cm def plot ( self , filename ): image = Image ( filename , self . coordinate_system [ \"figure_width\" ], self . coordinate_system [ \"figure_height\" ]) current_y_top = self . coordinate_system [ \"figure_height\" ] - self . parameters . arguments [ \"margin\" ] * cm for track in self . tracks : track . visualisation_data [ \"y_top\" ] = current_y_top track . draw ( image . canvas ) current_y_top -= ( track . needed_space + self . parameters . arguments [ \"gap\" ] * cm ) image . save () return None","title":"AnnotationPlotManager"},{"location":"API/package/#uorf4u.drawing.AnnotationPlotManager.__init__","text":"Create a AnnotationPlotManager object. Parameters: path ( uorf4u . data_processing . Path ) \u2013 Path class' objects that holds list of conserved ORFs. upstream_sequences ( list ) \u2013 list of dicts with information about upstream sequences. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 def __init__ ( self , path , upstream_sequences : list , parameters : uorf4u . manager . Parameters ): \"\"\"Create a AnnotationPlotManager object. Arguments: path (uorf4u.data_processing.Path): Path class' objects that holds list of conserved ORFs. upstream_sequences (list): list of dicts with information about upstream sequences. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . path = path self . upstream_sequences = upstream_sequences self . parameters = parameters self . coordinate_system = dict () self . additional_data = dict ()","title":"__init__()"},{"location":"API/package/#uorf4u.drawing.AnnotationPlotManager.create_tracks","text":"Create visualisation tracks. Returns: None \u2013 None Source code in uorf4u/drawing.py 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 def create_tracks ( self ) -> None : \"\"\"Create visualisation tracks. Returns: None \"\"\" self . tracks = [] \"\"\" title_loader = TitleLoader(self.parameters) title_loader.prepare_data(self.coordinate_system, self.additional_data) title_track = title_loader.create_track() self.tracks.append(title_track) self.coordinate_system[\"figure_height\"] += title_track.needed_y_space() \"\"\" for index in range ( self . additional_data [ \"number_of_sequences\" ]): upstream_sequence = self . additional_data [ \"ordered_upstream_sequences\" ][ index ] conserved_orf = self . path . path [ index ] sequence_loader = SequencesLoader ( self . parameters ) sequence_loader . prepare_data ( upstream_sequence , conserved_orf , self . coordinate_system , self . additional_data ) track = sequence_loader . create_track () self . tracks . append ( track ) self . coordinate_system [ \"figure_height\" ] += track . needed_y_space () self . coordinate_system [ \"figure_height\" ] += self . parameters . arguments [ \"gap\" ] * cm # if index < self.additional_data[\"number_of_sequences\"] - 1: axis_tics_loader = AxisLoader ( self . parameters ) axis_tics_loader . prepare_data ( self . coordinate_system , self . additional_data ) axis_tics_track = axis_tics_loader . create_track () self . tracks . append ( axis_tics_track ) self . coordinate_system [ \"figure_height\" ] += axis_tics_track . needed_y_space () self . coordinate_system [ \"figure_height\" ] += self . parameters . arguments [ \"margin\" ] * cm","title":"create_tracks()"},{"location":"API/package/#uorf4u.drawing.AnnotationPlotManager.define_x_axis_coordinate_system","text":"Define coordinate system. Returns: None \u2013 None Source code in uorf4u/drawing.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 def define_x_axis_coordinate_system ( self ) -> None : \"\"\"Define coordinate system. Returns: None \"\"\" label_height = self . parameters . arguments [ \"label_height_to_orf_height\" ] * self . parameters . arguments [ \"orf_height\" ] * cm label_font_size = uorf4u . methods . string_height_to_font_size ( label_height , \"regular\" , self . parameters . arguments ) max_label_width = max ([ reportlab . pdfbase . pdfmetrics . stringWidth ( i [ \"id\" ], \"regular\" , label_font_size ) for i in self . upstream_sequences ]) self . additional_data [ \"label_font_size\" ] = label_font_size self . additional_data [ \"ordered_upstream_sequences\" ] = [ self . upstream_sequences [ i ] for i in [ orf . useq_index for orf in self . path . path ]] self . additional_data [ \"number_of_sequences\" ] = len ( self . path ) self . additional_data [ \"max_upstream_sequence_length\" ] = max ( i [ \"useq_upstream_region_length\" ] for i in self . additional_data [ \"ordered_upstream_sequences\" ]) self . additional_data [ \"max_downstream_sequence_length\" ] = max ( i [ \"useq_downstream_region_length\" ] for i in self . additional_data [ \"ordered_upstream_sequences\" ]) window_size_nt = self . additional_data [ \"max_upstream_sequence_length\" ] + self . additional_data [ \"max_downstream_sequence_length\" ] if self . parameters . arguments [ \"annotation_width\" ] == \"auto\" : annotation_width = window_size_nt * self . parameters . arguments [ \"mm_per_nt\" ] * mm else : annotation_width = self . parameters . arguments [ \"annotation_width\" ] * cm self . coordinate_system [ \"transformation_coef\" ] = annotation_width / window_size_nt self . coordinate_system [ \"x_labels_start\" ] = self . parameters . arguments [ \"margin\" ] * cm self . coordinate_system [ \"x_labels_stop\" ] = self . coordinate_system [ \"x_labels_start\" ] + max_label_width self . coordinate_system [ \"x_annotation_start\" ] = self . coordinate_system [ \"x_labels_stop\" ] + \\ self . parameters . arguments [ \"label_gap\" ] * cm self . coordinate_system [ \"x_annotation_stop\" ] = self . coordinate_system [ \"x_annotation_start\" ] + annotation_width self . coordinate_system [ \"figure_width\" ] = 2 * self . parameters . arguments [ \"margin\" ] * cm + annotation_width + \\ max_label_width + self . parameters . arguments [ \"label_gap\" ] * cm self . coordinate_system [ \"figure_height\" ] = self . parameters . arguments [ \"margin\" ] * cm return None","title":"define_x_axis_coordinate_system()"},{"location":"API/package/#uorf4u.drawing.AxisLoader","text":"Bases: Loader An AxisLoader object prepares data for an Axis track object. Attributes: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. prepared_data ( dict ) \u2013 dict with data needed for a visualisation track. Source code in uorf4u/drawing.py 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 class AxisLoader ( Loader ): \"\"\"An AxisLoader object prepares data for an Axis track object. Attributes: parameters (uorf4u.manager.Parameters): Parameters' class object. prepared_data (dict): dict with data needed for a visualisation track. \"\"\" def __init__ ( self , parameters ): \"\"\"Create an AxisLoader object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( parameters ) def prepare_data ( self , coordinate_system : dict , additional_data : dict ): \"\"\"Prepare data for an Axis visualisation track. Attributes: coordinate_system (dict): coordinate system of a figure page. additional_data (dict): data needed for a track initialisation. Returns: dict: dictionary with prepared data for visualisation. \"\"\" prepared_data = dict () prepared_data [ \"coordinate_system\" ] = coordinate_system prepared_data [ \"max_upstream_sequence_length\" ] = additional_data [ \"max_upstream_sequence_length\" ] prepared_data [ \"max_downstream_sequence_length\" ] = additional_data [ \"max_downstream_sequence_length\" ] step = int ( round ( additional_data [ \"max_upstream_sequence_length\" ] / 3 , - 2 )) tics = [ - additional_data [ \"max_upstream_sequence_length\" ], 0 , additional_data [ \"max_downstream_sequence_length\" ]] x_tic_centred = int ( round ( - additional_data [ \"max_upstream_sequence_length\" ] / 2 , - 2 )) tics . append ( x_tic_centred ) x_tic_left , x_tic_right = x_tic_centred - step , x_tic_centred + step while x_tic_right < 0 and x_tic_left > - additional_data [ \"max_upstream_sequence_length\" ]: tics . append ( x_tic_left ) tics . append ( x_tic_right ) x_tic_left -= step x_tic_right += step tics . sort () tics_coordinates = [ self . transform_relative_position_to_x_coordinate ( i , coordinate_system , additional_data [ \"max_upstream_sequence_length\" ]) for i in tics ] prepared_data [ \"tics\" ] = { k : v for k , v in zip ( tics , tics_coordinates )} self . prepared_data = prepared_data return prepared_data def transform_relative_position_to_x_coordinate ( self , relative_position : int , coordinate_system : dict , max_upstream_sequence_length : int ) -> float : \"\"\"Transform nucleotide x coordinate to pdf's. Arguments: relative_position (int): nucleotide position coordinate_system (dict): coordinate system of a figure. max_upstream_sequence_length (int): max length of upstream sequences for visualisation. Returns: float: transformed x coordinate. \"\"\" return coordinate_system [ \"x_annotation_start\" ] + ( relative_position + max_upstream_sequence_length ) * \\ coordinate_system [ \"transformation_coef\" ] def create_track ( self ) -> TicsVis : \"\"\"Initialise a Tics track object. Returns: TicsVis: visualisation track. \"\"\" return TicsVis ( self . prepared_data , self . parameters )","title":"AxisLoader"},{"location":"API/package/#uorf4u.drawing.AxisLoader.__init__","text":"Create an AxisLoader object. Parameters: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing.py 695 696 697 698 699 700 701 702 def __init__ ( self , parameters ): \"\"\"Create an AxisLoader object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( parameters )","title":"__init__()"},{"location":"API/package/#uorf4u.drawing.AxisLoader.create_track","text":"Initialise a Tics track object. Returns: TicsVis ( TicsVis ) \u2013 visualisation track. Source code in uorf4u/drawing.py 751 752 753 754 755 756 757 758 def create_track ( self ) -> TicsVis : \"\"\"Initialise a Tics track object. Returns: TicsVis: visualisation track. \"\"\" return TicsVis ( self . prepared_data , self . parameters )","title":"create_track()"},{"location":"API/package/#uorf4u.drawing.AxisLoader.prepare_data","text":"Prepare data for an Axis visualisation track. Attributes: coordinate_system ( dict ) \u2013 coordinate system of a figure page. additional_data ( dict ) \u2013 data needed for a track initialisation. Returns: dict \u2013 dictionary with prepared data for visualisation. Source code in uorf4u/drawing.py 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 def prepare_data ( self , coordinate_system : dict , additional_data : dict ): \"\"\"Prepare data for an Axis visualisation track. Attributes: coordinate_system (dict): coordinate system of a figure page. additional_data (dict): data needed for a track initialisation. Returns: dict: dictionary with prepared data for visualisation. \"\"\" prepared_data = dict () prepared_data [ \"coordinate_system\" ] = coordinate_system prepared_data [ \"max_upstream_sequence_length\" ] = additional_data [ \"max_upstream_sequence_length\" ] prepared_data [ \"max_downstream_sequence_length\" ] = additional_data [ \"max_downstream_sequence_length\" ] step = int ( round ( additional_data [ \"max_upstream_sequence_length\" ] / 3 , - 2 )) tics = [ - additional_data [ \"max_upstream_sequence_length\" ], 0 , additional_data [ \"max_downstream_sequence_length\" ]] x_tic_centred = int ( round ( - additional_data [ \"max_upstream_sequence_length\" ] / 2 , - 2 )) tics . append ( x_tic_centred ) x_tic_left , x_tic_right = x_tic_centred - step , x_tic_centred + step while x_tic_right < 0 and x_tic_left > - additional_data [ \"max_upstream_sequence_length\" ]: tics . append ( x_tic_left ) tics . append ( x_tic_right ) x_tic_left -= step x_tic_right += step tics . sort () tics_coordinates = [ self . transform_relative_position_to_x_coordinate ( i , coordinate_system , additional_data [ \"max_upstream_sequence_length\" ]) for i in tics ] prepared_data [ \"tics\" ] = { k : v for k , v in zip ( tics , tics_coordinates )} self . prepared_data = prepared_data return prepared_data","title":"prepare_data()"},{"location":"API/package/#uorf4u.drawing.AxisLoader.transform_relative_position_to_x_coordinate","text":"Transform nucleotide x coordinate to pdf's. Parameters: relative_position ( int ) \u2013 nucleotide position coordinate_system ( dict ) \u2013 coordinate system of a figure. max_upstream_sequence_length ( int ) \u2013 max length of upstream sequences for visualisation. Returns: float ( float ) \u2013 transformed x coordinate. Source code in uorf4u/drawing.py 736 737 738 739 740 741 742 743 744 745 746 747 748 749 def transform_relative_position_to_x_coordinate ( self , relative_position : int , coordinate_system : dict , max_upstream_sequence_length : int ) -> float : \"\"\"Transform nucleotide x coordinate to pdf's. Arguments: relative_position (int): nucleotide position coordinate_system (dict): coordinate system of a figure. max_upstream_sequence_length (int): max length of upstream sequences for visualisation. Returns: float: transformed x coordinate. \"\"\" return coordinate_system [ \"x_annotation_start\" ] + ( relative_position + max_upstream_sequence_length ) * \\ coordinate_system [ \"transformation_coef\" ]","title":"transform_relative_position_to_x_coordinate()"},{"location":"API/package/#uorf4u.drawing.Image","text":"An Image object holds pdf. Attributes: canvas ( reportlab . pdfgen . canvas . Canvas ) \u2013 pdf object of the reportlab library. Source code in uorf4u/drawing.py 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 class Image : \"\"\"An Image object holds pdf. Attributes: canvas (reportlab.pdfgen.canvas.Canvas): pdf object of the reportlab library. \"\"\" def __init__ ( self , filename : str , width : float , height : float ): \"\"\"Create an Image object. Arguments: filename (str): path and name of a pdf. width (float): width of a pdf. height (float): height of a pdf. \"\"\" self . canvas = reportlab . pdfgen . canvas . Canvas ( filename , pagesize = ( width , height )) def save ( self ) -> None : \"\"\"Save a pdf file. Returns: None \"\"\" self . canvas . save () return None","title":"Image"},{"location":"API/package/#uorf4u.drawing.Image.__init__","text":"Create an Image object. Parameters: filename ( str ) \u2013 path and name of a pdf. width ( float ) \u2013 width of a pdf. height ( float ) \u2013 height of a pdf. Source code in uorf4u/drawing.py 769 770 771 772 773 774 775 776 777 778 def __init__ ( self , filename : str , width : float , height : float ): \"\"\"Create an Image object. Arguments: filename (str): path and name of a pdf. width (float): width of a pdf. height (float): height of a pdf. \"\"\" self . canvas = reportlab . pdfgen . canvas . Canvas ( filename , pagesize = ( width , height ))","title":"__init__()"},{"location":"API/package/#uorf4u.drawing.Image.save","text":"Save a pdf file. Returns: None \u2013 None Source code in uorf4u/drawing.py 780 781 782 783 784 785 786 787 788 def save ( self ) -> None : \"\"\"Save a pdf file. Returns: None \"\"\" self . canvas . save () return None","title":"save()"},{"location":"API/package/#uorf4u.drawing.Loader","text":"Parent class for tracks loaders. Attributes: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. prepared_data ( dict ) \u2013 dict with data needed for visualisation tracks. Source code in uorf4u/drawing.py 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 class Loader : \"\"\"Parent class for tracks loaders. Attributes: parameters (uorf4u.manager.Parameters): Parameters' class object. prepared_data (dict): dict with data needed for visualisation tracks. \"\"\" def __init__ ( self , parameters : uorf4u . manager . Parameters ): \"\"\"Parent's constructor for creating a Loader class object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . parameters = parameters self . prepared_data = None def prepare_data ( self ) -> None : \"\"\"Empty parent's method for data preparation. Returns: None \"\"\" pass def create_track ( self ) -> None : \"\"\"Empty parent's method for initialisation of a track. Returns: None \"\"\" pass","title":"Loader"},{"location":"API/package/#uorf4u.drawing.Loader.__init__","text":"Parent's constructor for creating a Loader class object. Parameters: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing.py 488 489 490 491 492 493 494 495 def __init__ ( self , parameters : uorf4u . manager . Parameters ): \"\"\"Parent's constructor for creating a Loader class object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . parameters = parameters self . prepared_data = None","title":"__init__()"},{"location":"API/package/#uorf4u.drawing.Loader.create_track","text":"Empty parent's method for initialisation of a track. Returns: None \u2013 None Source code in uorf4u/drawing.py 506 507 508 509 510 511 512 513 def create_track ( self ) -> None : \"\"\"Empty parent's method for initialisation of a track. Returns: None \"\"\" pass","title":"create_track()"},{"location":"API/package/#uorf4u.drawing.Loader.prepare_data","text":"Empty parent's method for data preparation. Returns: None \u2013 None Source code in uorf4u/drawing.py 497 498 499 500 501 502 503 504 def prepare_data ( self ) -> None : \"\"\"Empty parent's method for data preparation. Returns: None \"\"\" pass","title":"prepare_data()"},{"location":"API/package/#uorf4u.drawing.SequenceVis","text":"Bases: Track SequenceVis track draws sequences and annotation. Attributes: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. needed_space ( float ) \u2013 needed vertical space for a track. Source code in uorf4u/drawing.py 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 class SequenceVis ( Track ): \"\"\"SequenceVis track draws sequences and annotation. Attributes: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. needed_space (float): needed vertical space for a track. \"\"\" def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Create a SequenceVis object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( visualisation_data , parameters ) self . needed_space = None def needed_y_space ( self ) -> float : \"\"\"Calculate needed vertical space for a SequenceVis track. Returns: float: needed vertical space. \"\"\" self . needed_space = self . parameters . arguments [ \"orf_height\" ] * cm return self . needed_space def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Draw a Sequence track. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" orf_height = self . parameters . arguments [ \"orf_height\" ] * cm y_c = self . visualisation_data [ \"y_top\" ] - 0.5 * orf_height canvas . setStrokeColorRGB ( * uorf4u . methods . get_color ( \"upstream_seq_line_color\" , self . parameters . arguments )) canvas . setLineCap ( 0 ) canvas . setLineWidth ( self . parameters . arguments [ \"upstream_seq_line_width\" ]) canvas . line ( self . visualisation_data [ \"upstream_sequence_line_start_x\" ], y_c , self . visualisation_data [ \"upstream_sequence_line_stop_x\" ], y_c ) # Cleaning the space: canvas . setFillColorRGB ( 1 , 1 , 1 , 1 ) for orf_dict in self . visualisation_data [ \"orfs_coordinates_dict\" ] . values (): # canvas.line(orf_dict[\"x_start\"], y_c, orf_dict[\"x_stop\"], y_c) canvas . rect ( orf_dict [ \"x_start\" ], y_c - orf_height / 2 , orf_dict [ \"x_stop\" ] - orf_dict [ \"x_start\" ], orf_height , stroke = 0 , fill = 1 ) # Labels canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFont ( \"regular\" , self . visualisation_data [ \"label_font_size\" ]) y_l = y_c - 0.5 * ( self . parameters . arguments [ \"label_height_to_orf_height\" ] * orf_height ) canvas . drawRightString ( self . visualisation_data [ \"coordinate_system\" ][ \"x_labels_stop\" ], y_l , self . visualisation_data [ \"useq_id\" ]) # main_CDS canvas . setLineWidth ( self . parameters . arguments [ \"orf_line_width\" ]) canvas . setStrokeColorRGB ( * uorf4u . methods . get_color ( \"cds_seq_stroke_color\" , self . parameters . arguments )) canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"cds_seq_fill_color\" , self . parameters . arguments )) p = canvas . beginPath () p . moveTo ( self . visualisation_data [ \"main_CDS_stop_x\" ], y_c - orf_height / 2 ) p . lineTo ( self . visualisation_data [ \"main_CDS_start_x\" ], y_c - orf_height / 2 ) p . lineTo ( self . visualisation_data [ \"main_CDS_start_x\" ], y_c + orf_height / 2 ) p . lineTo ( self . visualisation_data [ \"main_CDS_stop_x\" ], y_c + orf_height / 2 ) canvas . drawPath ( p , stroke = 1 , fill = 1 ) # Other ORFs: for orf in self . visualisation_data [ \"annotated_orfs\" ]: orf_dict = self . visualisation_data [ \"orfs_coordinates_dict\" ][ orf ] if orf != self . visualisation_data [ \"conserved_orf\" ]: fill_color = None stroke_color = uorf4u . methods . get_color ( \"other_uorfs_stroke_color\" , self . parameters . arguments ) else : fill_color = uorf4u . methods . get_color ( \"conserved_uorfs_fill_color\" , self . parameters . arguments ) stroke_color = uorf4u . methods . get_color ( \"conserved_uorfs_stroke_color\" , self . parameters . arguments ) self . orf_object ( canvas , orf_dict [ \"x_start\" ], orf_dict [ \"x_stop\" ], y_c , orf_dict [ \"strand\" ], orf_height , orf_dict [ \"left_out\" ], orf_dict [ \"right_out\" ], fill_color , stroke_color ) # Annotated in RefSeq CDSs if self . parameters . arguments [ \"check_assembly_annotation\" ]: fill_color = None stroke_color = uorf4u . methods . get_color ( \"annotated_orf_stroke_color\" , self . parameters . arguments ) for protein_id , cds_dict in self . visualisation_data [ \"CDSs_coordinates_dict\" ] . items (): self . orf_object ( canvas , cds_dict [ \"x_start\" ], cds_dict [ \"x_stop\" ], y_c , cds_dict [ \"strand\" ], orf_height , cds_dict [ \"left_out\" ], cds_dict [ \"right_out\" ], fill_color , stroke_color ) return None def orf_object ( self , canvas : reportlab . pdfgen . canvas . Canvas , x_start : float , x_stop : float , y_c : float , strand : str , height : float , left_out : bool , right_out : bool , fill_color : str , stroke_color : str ) -> None : \"\"\"Method for drawing an ORF's polygon. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. x_start (float): ORF's start coordinate (already transformed to pdf's) x_stop (float): ORF's stop coordinate (already transformed to pdf's) y_c: (float): centred y coordinate of a current track. strand (str): strand of an ORF. height (float): height of a polygon. left_out (bool): whether an ORF is out of range on the left. right_out (bool): whether an ORF is out of range on the right. fill_color (str): fill color of a polygon. stroke_color (str): stroke color of a polygon. Returns: None \"\"\" fill , stroke = 0 , 0 if stroke_color : canvas . setStrokeColorRGB ( * stroke_color ) stroke = 1 if fill_color : canvas . setFillColorRGB ( * fill_color ) fill = 1 arrow_length = min ( height , ( x_stop - x_start )) p = canvas . beginPath () if strand == \"+\" and not left_out and not right_out : p . moveTo ( x_start , y_c ) p . lineTo ( x_start , y_c + height / 2 ) p . lineTo ( x_stop - arrow_length , y_c + height / 2 ) p . lineTo ( x_stop , y_c ) p . lineTo ( x_stop - arrow_length , y_c - height / 2 ) p . lineTo ( x_start , y_c - height / 2 ) p . lineTo ( x_start , y_c ) elif strand == \"+\" and left_out and not right_out : p . moveTo ( x_start , y_c + height / 2 ) p . lineTo ( x_stop - arrow_length , y_c + height / 2 ) p . lineTo ( x_stop , y_c ) p . lineTo ( x_stop - arrow_length , y_c - height / 2 ) p . lineTo ( x_start , y_c - height / 2 ) elif strand == \"+\" and right_out and not left_out : p . moveTo ( x_stop , y_c + height / 2 ) p . lineTo ( x_start , y_c + height / 2 ) p . lineTo ( x_start , y_c - height / 2 ) p . lineTo ( x_stop , y_c - height / 2 ) elif strand == \"-\" and not left_out and not right_out : p . moveTo ( x_stop , y_c ) p . lineTo ( x_stop , y_c + height / 2 ) p . lineTo ( x_start + arrow_length , y_c + height / 2 ) p . lineTo ( x_start , y_c ) p . lineTo ( x_start + arrow_length , y_c - height / 2 ) p . lineTo ( x_stop , y_c - height / 2 ) p . lineTo ( x_stop , y_c ) elif strand == \"-\" and right_out and not left_out : p . moveTo ( x_stop , y_c + height / 2 ) p . lineTo ( x_start + arrow_length , y_c + height / 2 ) p . lineTo ( x_start , y_c ) p . lineTo ( x_start + arrow_length , y_c - height / 2 ) p . lineTo ( x_stop , y_c - height / 2 ) elif strand == \"-\" and left_out and not right_out : p . moveTo ( x_start , y_c + height / 2 ) p . lineTo ( x_stop , y_c + height / 2 ) p . lineTo ( x_stop , y_c - height / 2 ) p . lineTo ( x_start , y_c - height / 2 ) canvas . drawPath ( p , stroke = stroke , fill = fill )","title":"SequenceVis"},{"location":"API/package/#uorf4u.drawing.SequenceVis.__init__","text":"Create a SequenceVis object. Parameters: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing.py 248 249 250 251 252 253 254 255 256 257 def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Create a SequenceVis object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( visualisation_data , parameters ) self . needed_space = None","title":"__init__()"},{"location":"API/package/#uorf4u.drawing.SequenceVis.draw","text":"Draw a Sequence track. Parameters: canvas ( reportlab . pdfgen . canvas . Canvas ) \u2013 a pdf object. Returns: None \u2013 None Source code in uorf4u/drawing.py 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Draw a Sequence track. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" orf_height = self . parameters . arguments [ \"orf_height\" ] * cm y_c = self . visualisation_data [ \"y_top\" ] - 0.5 * orf_height canvas . setStrokeColorRGB ( * uorf4u . methods . get_color ( \"upstream_seq_line_color\" , self . parameters . arguments )) canvas . setLineCap ( 0 ) canvas . setLineWidth ( self . parameters . arguments [ \"upstream_seq_line_width\" ]) canvas . line ( self . visualisation_data [ \"upstream_sequence_line_start_x\" ], y_c , self . visualisation_data [ \"upstream_sequence_line_stop_x\" ], y_c ) # Cleaning the space: canvas . setFillColorRGB ( 1 , 1 , 1 , 1 ) for orf_dict in self . visualisation_data [ \"orfs_coordinates_dict\" ] . values (): # canvas.line(orf_dict[\"x_start\"], y_c, orf_dict[\"x_stop\"], y_c) canvas . rect ( orf_dict [ \"x_start\" ], y_c - orf_height / 2 , orf_dict [ \"x_stop\" ] - orf_dict [ \"x_start\" ], orf_height , stroke = 0 , fill = 1 ) # Labels canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFont ( \"regular\" , self . visualisation_data [ \"label_font_size\" ]) y_l = y_c - 0.5 * ( self . parameters . arguments [ \"label_height_to_orf_height\" ] * orf_height ) canvas . drawRightString ( self . visualisation_data [ \"coordinate_system\" ][ \"x_labels_stop\" ], y_l , self . visualisation_data [ \"useq_id\" ]) # main_CDS canvas . setLineWidth ( self . parameters . arguments [ \"orf_line_width\" ]) canvas . setStrokeColorRGB ( * uorf4u . methods . get_color ( \"cds_seq_stroke_color\" , self . parameters . arguments )) canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"cds_seq_fill_color\" , self . parameters . arguments )) p = canvas . beginPath () p . moveTo ( self . visualisation_data [ \"main_CDS_stop_x\" ], y_c - orf_height / 2 ) p . lineTo ( self . visualisation_data [ \"main_CDS_start_x\" ], y_c - orf_height / 2 ) p . lineTo ( self . visualisation_data [ \"main_CDS_start_x\" ], y_c + orf_height / 2 ) p . lineTo ( self . visualisation_data [ \"main_CDS_stop_x\" ], y_c + orf_height / 2 ) canvas . drawPath ( p , stroke = 1 , fill = 1 ) # Other ORFs: for orf in self . visualisation_data [ \"annotated_orfs\" ]: orf_dict = self . visualisation_data [ \"orfs_coordinates_dict\" ][ orf ] if orf != self . visualisation_data [ \"conserved_orf\" ]: fill_color = None stroke_color = uorf4u . methods . get_color ( \"other_uorfs_stroke_color\" , self . parameters . arguments ) else : fill_color = uorf4u . methods . get_color ( \"conserved_uorfs_fill_color\" , self . parameters . arguments ) stroke_color = uorf4u . methods . get_color ( \"conserved_uorfs_stroke_color\" , self . parameters . arguments ) self . orf_object ( canvas , orf_dict [ \"x_start\" ], orf_dict [ \"x_stop\" ], y_c , orf_dict [ \"strand\" ], orf_height , orf_dict [ \"left_out\" ], orf_dict [ \"right_out\" ], fill_color , stroke_color ) # Annotated in RefSeq CDSs if self . parameters . arguments [ \"check_assembly_annotation\" ]: fill_color = None stroke_color = uorf4u . methods . get_color ( \"annotated_orf_stroke_color\" , self . parameters . arguments ) for protein_id , cds_dict in self . visualisation_data [ \"CDSs_coordinates_dict\" ] . items (): self . orf_object ( canvas , cds_dict [ \"x_start\" ], cds_dict [ \"x_stop\" ], y_c , cds_dict [ \"strand\" ], orf_height , cds_dict [ \"left_out\" ], cds_dict [ \"right_out\" ], fill_color , stroke_color ) return None","title":"draw()"},{"location":"API/package/#uorf4u.drawing.SequenceVis.needed_y_space","text":"Calculate needed vertical space for a SequenceVis track. Returns: float ( float ) \u2013 needed vertical space. Source code in uorf4u/drawing.py 259 260 261 262 263 264 265 266 267 def needed_y_space ( self ) -> float : \"\"\"Calculate needed vertical space for a SequenceVis track. Returns: float: needed vertical space. \"\"\" self . needed_space = self . parameters . arguments [ \"orf_height\" ] * cm return self . needed_space","title":"needed_y_space()"},{"location":"API/package/#uorf4u.drawing.SequenceVis.orf_object","text":"Method for drawing an ORF's polygon. Parameters: canvas ( reportlab . pdfgen . canvas . Canvas ) \u2013 a pdf object. x_start ( float ) \u2013 ORF's start coordinate (already transformed to pdf's) x_stop ( float ) \u2013 ORF's stop coordinate (already transformed to pdf's) y_c ( float ) \u2013 (float): centred y coordinate of a current track. strand ( str ) \u2013 strand of an ORF. height ( float ) \u2013 height of a polygon. left_out ( bool ) \u2013 whether an ORF is out of range on the left. right_out ( bool ) \u2013 whether an ORF is out of range on the right. fill_color ( str ) \u2013 fill color of a polygon. stroke_color ( str ) \u2013 stroke color of a polygon. Returns: None \u2013 None Source code in uorf4u/drawing.py 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 def orf_object ( self , canvas : reportlab . pdfgen . canvas . Canvas , x_start : float , x_stop : float , y_c : float , strand : str , height : float , left_out : bool , right_out : bool , fill_color : str , stroke_color : str ) -> None : \"\"\"Method for drawing an ORF's polygon. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. x_start (float): ORF's start coordinate (already transformed to pdf's) x_stop (float): ORF's stop coordinate (already transformed to pdf's) y_c: (float): centred y coordinate of a current track. strand (str): strand of an ORF. height (float): height of a polygon. left_out (bool): whether an ORF is out of range on the left. right_out (bool): whether an ORF is out of range on the right. fill_color (str): fill color of a polygon. stroke_color (str): stroke color of a polygon. Returns: None \"\"\" fill , stroke = 0 , 0 if stroke_color : canvas . setStrokeColorRGB ( * stroke_color ) stroke = 1 if fill_color : canvas . setFillColorRGB ( * fill_color ) fill = 1 arrow_length = min ( height , ( x_stop - x_start )) p = canvas . beginPath () if strand == \"+\" and not left_out and not right_out : p . moveTo ( x_start , y_c ) p . lineTo ( x_start , y_c + height / 2 ) p . lineTo ( x_stop - arrow_length , y_c + height / 2 ) p . lineTo ( x_stop , y_c ) p . lineTo ( x_stop - arrow_length , y_c - height / 2 ) p . lineTo ( x_start , y_c - height / 2 ) p . lineTo ( x_start , y_c ) elif strand == \"+\" and left_out and not right_out : p . moveTo ( x_start , y_c + height / 2 ) p . lineTo ( x_stop - arrow_length , y_c + height / 2 ) p . lineTo ( x_stop , y_c ) p . lineTo ( x_stop - arrow_length , y_c - height / 2 ) p . lineTo ( x_start , y_c - height / 2 ) elif strand == \"+\" and right_out and not left_out : p . moveTo ( x_stop , y_c + height / 2 ) p . lineTo ( x_start , y_c + height / 2 ) p . lineTo ( x_start , y_c - height / 2 ) p . lineTo ( x_stop , y_c - height / 2 ) elif strand == \"-\" and not left_out and not right_out : p . moveTo ( x_stop , y_c ) p . lineTo ( x_stop , y_c + height / 2 ) p . lineTo ( x_start + arrow_length , y_c + height / 2 ) p . lineTo ( x_start , y_c ) p . lineTo ( x_start + arrow_length , y_c - height / 2 ) p . lineTo ( x_stop , y_c - height / 2 ) p . lineTo ( x_stop , y_c ) elif strand == \"-\" and right_out and not left_out : p . moveTo ( x_stop , y_c + height / 2 ) p . lineTo ( x_start + arrow_length , y_c + height / 2 ) p . lineTo ( x_start , y_c ) p . lineTo ( x_start + arrow_length , y_c - height / 2 ) p . lineTo ( x_stop , y_c - height / 2 ) elif strand == \"-\" and left_out and not right_out : p . moveTo ( x_start , y_c + height / 2 ) p . lineTo ( x_stop , y_c + height / 2 ) p . lineTo ( x_stop , y_c - height / 2 ) p . lineTo ( x_start , y_c - height / 2 ) canvas . drawPath ( p , stroke = stroke , fill = fill )","title":"orf_object()"},{"location":"API/package/#uorf4u.drawing.SequencesLoader","text":"Bases: Loader A SequencesLoader object prepares data for a Sequence track object. Attributes: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. prepared_data ( dict ) \u2013 dict with data needed for a visualisation track. Source code in uorf4u/drawing.py 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 class SequencesLoader ( Loader ): \"\"\"A SequencesLoader object prepares data for a Sequence track object. Attributes: parameters (uorf4u.manager.Parameters): Parameters' class object. prepared_data (dict): dict with data needed for a visualisation track. \"\"\" def __init__ ( self , parameters ): \"\"\"Create a SequenceLoader object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( parameters ) def prepare_data ( self , upstream_sequence : dict , conserved_orf , coordinate_system : dict , additional_data : dict ) -> dict : \"\"\"Prepare data for a Title visualisation track. Attributes: upstream_sequence (dict): upstream sequence' data. conserved_orf (uorf4u.data_processing.ORF): conserved ORF on the upstream sequence. coordinate_system (dict): coordinate system of a figure page. additional_data (dict): data needed for a track initialisation. Returns: dict: dictionary with prepared data for visualisation. \"\"\" prepared_data = dict () max_upstream_sequence_length = additional_data [ \"max_upstream_sequence_length\" ] prepared_data [ \"coordinate_system\" ] = coordinate_system prepared_data [ \"label_font_size\" ] = additional_data [ \"label_font_size\" ] prepared_data [ \"label_right_border\" ] = coordinate_system [ \"x_labels_stop\" ] prepared_data [ \"upstream_sequence_line_start_x\" ] = coordinate_system [ \"x_annotation_start\" ] + \\ (( max_upstream_sequence_length - upstream_sequence [ \"useq_upstream_region_length\" ]) * \\ coordinate_system [ \"transformation_coef\" ]) prepared_data [ \"upstream_sequence_line_stop_x\" ] = coordinate_system [ \"x_annotation_start\" ] + \\ ( max_upstream_sequence_length * coordinate_system [ \"transformation_coef\" ]) prepared_data [ \"main_CDS_start_x\" ] = coordinate_system [ \"x_annotation_start\" ] + \\ ( max_upstream_sequence_length * coordinate_system [ \"transformation_coef\" ]) prepared_data [ \"main_CDS_stop_x\" ] = coordinate_system [ \"x_annotation_start\" ] + \\ (( max_upstream_sequence_length + upstream_sequence [ \"useq_downstream_region_length\" ]) * coordinate_system [ \"transformation_coef\" ]) prepared_data [ \"orfs_coordinates_dict\" ] = { k : v for k , v in zip ( upstream_sequence [ \"ORFs\" ], [ self . calculate_orf_position ( i . start , i . stop , \"+\" , upstream_sequence , max_upstream_sequence_length , coordinate_system ) for i in upstream_sequence [ \"ORFs\" ]])} prepared_data [ \"useq_id\" ] = upstream_sequence [ \"id\" ] prepared_data [ \"annotated_orfs\" ] = [ orf for orf in upstream_sequence [ \"ORFs\" ] if orf != conserved_orf ] prepared_data [ \"annotated_orfs\" ] . append ( conserved_orf ) prepared_data [ \"conserved_orf\" ] = conserved_orf if self . parameters . arguments [ \"check_assembly_annotation\" ]: prepared_data [ \"CDSs\" ] = [ i for i in upstream_sequence [ \"locus_annotation\" ] . CDSs if i [ \"relative_start\" ] != upstream_sequence [ \"useq_upstream_region_length\" ]] prepared_data [ \"CDSs_coordinates_dict\" ] = { k : v for k , v in zip ([ i [ \"protein_id\" ] for i in prepared_data [ \"CDSs\" ]], [ self . calculate_orf_position ( i [ \"relative_start\" ], i [ \"relative_stop\" ], i [ \"relative_strand\" ], upstream_sequence , max_upstream_sequence_length , coordinate_system ) for i in prepared_data [ \"CDSs\" ]])} else : prepared_data [ \"CDSs\" ] = None self . prepared_data = prepared_data return prepared_data def calculate_orf_position ( self , start : int , stop : int , strand : str , useq : dict , max_upstream_sequence_length : int , coordinate_system : dict ) -> dict : \"\"\"Transform an ORF's nucleotide coordinates to pdf's coordinates. Arguments: start (int): start coordinate in nt. stop (int): stop coordinate in nt. strand (str): strand of an ORF. useq (dict): current upstream sequence. max_upstream_sequence_length (int): max length of upstream sequences for visualisation. coordinate_system (dict): coordinate system of a figure. Returns: dict: transformed orf's coordinates. \"\"\" orf_coordinates = dict () orf_coordinates [ \"x_start\" ] = coordinate_system [ \"x_annotation_start\" ] + ( max ( 0 , start ) + ( max_upstream_sequence_length - useq [ \"useq_upstream_region_length\" ])) * \\ coordinate_system [ \"transformation_coef\" ] orf_coordinates [ \"x_stop\" ] = coordinate_system [ \"x_annotation_start\" ] + ( min ( stop , useq [ \"length\" ]) + ( max_upstream_sequence_length - useq [ \"useq_upstream_region_length\" ])) * \\ coordinate_system [ \"transformation_coef\" ] orf_coordinates [ \"strand\" ] = strand orf_coordinates [ \"left_out\" ] = start < 0 orf_coordinates [ \"right_out\" ] = stop > useq [ \"length\" ] return orf_coordinates def create_track ( self ) -> SequenceVis : \"\"\"Initialise a Sequence track object. Returns: SequenceVis: visualisation track. \"\"\" return SequenceVis ( self . prepared_data , self . parameters )","title":"SequencesLoader"},{"location":"API/package/#uorf4u.drawing.SequencesLoader.__init__","text":"Create a SequenceLoader object. Parameters: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing.py 574 575 576 577 578 579 580 581 def __init__ ( self , parameters ): \"\"\"Create a SequenceLoader object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( parameters )","title":"__init__()"},{"location":"API/package/#uorf4u.drawing.SequencesLoader.calculate_orf_position","text":"Transform an ORF's nucleotide coordinates to pdf's coordinates. Parameters: start ( int ) \u2013 start coordinate in nt. stop ( int ) \u2013 stop coordinate in nt. strand ( str ) \u2013 strand of an ORF. useq ( dict ) \u2013 current upstream sequence. max_upstream_sequence_length ( int ) \u2013 max length of upstream sequences for visualisation. coordinate_system ( dict ) \u2013 coordinate system of a figure. Returns: dict ( dict ) \u2013 transformed orf's coordinates. Source code in uorf4u/drawing.py 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 def calculate_orf_position ( self , start : int , stop : int , strand : str , useq : dict , max_upstream_sequence_length : int , coordinate_system : dict ) -> dict : \"\"\"Transform an ORF's nucleotide coordinates to pdf's coordinates. Arguments: start (int): start coordinate in nt. stop (int): stop coordinate in nt. strand (str): strand of an ORF. useq (dict): current upstream sequence. max_upstream_sequence_length (int): max length of upstream sequences for visualisation. coordinate_system (dict): coordinate system of a figure. Returns: dict: transformed orf's coordinates. \"\"\" orf_coordinates = dict () orf_coordinates [ \"x_start\" ] = coordinate_system [ \"x_annotation_start\" ] + ( max ( 0 , start ) + ( max_upstream_sequence_length - useq [ \"useq_upstream_region_length\" ])) * \\ coordinate_system [ \"transformation_coef\" ] orf_coordinates [ \"x_stop\" ] = coordinate_system [ \"x_annotation_start\" ] + ( min ( stop , useq [ \"length\" ]) + ( max_upstream_sequence_length - useq [ \"useq_upstream_region_length\" ])) * \\ coordinate_system [ \"transformation_coef\" ] orf_coordinates [ \"strand\" ] = strand orf_coordinates [ \"left_out\" ] = start < 0 orf_coordinates [ \"right_out\" ] = stop > useq [ \"length\" ] return orf_coordinates","title":"calculate_orf_position()"},{"location":"API/package/#uorf4u.drawing.SequencesLoader.create_track","text":"Initialise a Sequence track object. Returns: SequenceVis ( SequenceVis ) \u2013 visualisation track. Source code in uorf4u/drawing.py 675 676 677 678 679 680 681 682 def create_track ( self ) -> SequenceVis : \"\"\"Initialise a Sequence track object. Returns: SequenceVis: visualisation track. \"\"\" return SequenceVis ( self . prepared_data , self . parameters )","title":"create_track()"},{"location":"API/package/#uorf4u.drawing.SequencesLoader.prepare_data","text":"Prepare data for a Title visualisation track. Attributes: upstream_sequence ( dict ) \u2013 upstream sequence' data. conserved_orf ( uorf4u . data_processing . ORF ) \u2013 conserved ORF on the upstream sequence. coordinate_system ( dict ) \u2013 coordinate system of a figure page. additional_data ( dict ) \u2013 data needed for a track initialisation. Returns: dict ( dict ) \u2013 dictionary with prepared data for visualisation. Source code in uorf4u/drawing.py 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 def prepare_data ( self , upstream_sequence : dict , conserved_orf , coordinate_system : dict , additional_data : dict ) -> dict : \"\"\"Prepare data for a Title visualisation track. Attributes: upstream_sequence (dict): upstream sequence' data. conserved_orf (uorf4u.data_processing.ORF): conserved ORF on the upstream sequence. coordinate_system (dict): coordinate system of a figure page. additional_data (dict): data needed for a track initialisation. Returns: dict: dictionary with prepared data for visualisation. \"\"\" prepared_data = dict () max_upstream_sequence_length = additional_data [ \"max_upstream_sequence_length\" ] prepared_data [ \"coordinate_system\" ] = coordinate_system prepared_data [ \"label_font_size\" ] = additional_data [ \"label_font_size\" ] prepared_data [ \"label_right_border\" ] = coordinate_system [ \"x_labels_stop\" ] prepared_data [ \"upstream_sequence_line_start_x\" ] = coordinate_system [ \"x_annotation_start\" ] + \\ (( max_upstream_sequence_length - upstream_sequence [ \"useq_upstream_region_length\" ]) * \\ coordinate_system [ \"transformation_coef\" ]) prepared_data [ \"upstream_sequence_line_stop_x\" ] = coordinate_system [ \"x_annotation_start\" ] + \\ ( max_upstream_sequence_length * coordinate_system [ \"transformation_coef\" ]) prepared_data [ \"main_CDS_start_x\" ] = coordinate_system [ \"x_annotation_start\" ] + \\ ( max_upstream_sequence_length * coordinate_system [ \"transformation_coef\" ]) prepared_data [ \"main_CDS_stop_x\" ] = coordinate_system [ \"x_annotation_start\" ] + \\ (( max_upstream_sequence_length + upstream_sequence [ \"useq_downstream_region_length\" ]) * coordinate_system [ \"transformation_coef\" ]) prepared_data [ \"orfs_coordinates_dict\" ] = { k : v for k , v in zip ( upstream_sequence [ \"ORFs\" ], [ self . calculate_orf_position ( i . start , i . stop , \"+\" , upstream_sequence , max_upstream_sequence_length , coordinate_system ) for i in upstream_sequence [ \"ORFs\" ]])} prepared_data [ \"useq_id\" ] = upstream_sequence [ \"id\" ] prepared_data [ \"annotated_orfs\" ] = [ orf for orf in upstream_sequence [ \"ORFs\" ] if orf != conserved_orf ] prepared_data [ \"annotated_orfs\" ] . append ( conserved_orf ) prepared_data [ \"conserved_orf\" ] = conserved_orf if self . parameters . arguments [ \"check_assembly_annotation\" ]: prepared_data [ \"CDSs\" ] = [ i for i in upstream_sequence [ \"locus_annotation\" ] . CDSs if i [ \"relative_start\" ] != upstream_sequence [ \"useq_upstream_region_length\" ]] prepared_data [ \"CDSs_coordinates_dict\" ] = { k : v for k , v in zip ([ i [ \"protein_id\" ] for i in prepared_data [ \"CDSs\" ]], [ self . calculate_orf_position ( i [ \"relative_start\" ], i [ \"relative_stop\" ], i [ \"relative_strand\" ], upstream_sequence , max_upstream_sequence_length , coordinate_system ) for i in prepared_data [ \"CDSs\" ]])} else : prepared_data [ \"CDSs\" ] = None self . prepared_data = prepared_data return prepared_data","title":"prepare_data()"},{"location":"API/package/#uorf4u.drawing.TicsVis","text":"Bases: Track TicsVis track draws axis tics. Attributes: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. needed_space ( float ) \u2013 needed vertical space for a track. Source code in uorf4u/drawing.py 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 class TicsVis ( Track ): \"\"\"TicsVis track draws axis tics. Attributes: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. needed_space (float): needed vertical space for a track. \"\"\" def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Create a TicsVis object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( visualisation_data , parameters ) self . needed_space = None def needed_y_space ( self ) -> float : \"\"\"Calculate needed vertical space for a SequenceVis track. Returns: float: needed vertical space. \"\"\" font_type = \"regular\" reportlab . pdfbase . pdfmetrics . registerFont ( reportlab . pdfbase . ttfonts . TTFont ( font_type , self . parameters . arguments [ f \"font_ { font_type } \" ])) face = reportlab . pdfbase . pdfmetrics . getFont ( \"regular\" ) . face if self . parameters . arguments [ \"axis_tics_font_size\" ] == \"auto\" : text_height = self . parameters . arguments [ \"label_height_to_orf_height\" ] * self . parameters . arguments [ \"orf_height\" ] * cm font_size = uorf4u . methods . string_height_to_font_size ( text_height , \"regular\" , self . parameters . arguments ) self . parameters . arguments [ \"axis_tics_font_size\" ] = font_size else : text_height = ( self . parameters . arguments [ \"axis_tics_font_size\" ] * ( face . ascent - face . descent )) / ( 1000 * 1.38 ) self . visualisation_data [ \"tics_height\" ] = 0.7 * text_height self . visualisation_data [ \"text_space\" ] = 1.2 * text_height self . needed_space = self . visualisation_data [ \"tics_height\" ] + self . visualisation_data [ \"text_space\" ] return self . needed_space def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Draw an AxisTics track. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" y_top = self . visualisation_data [ \"y_top\" ] canvas . setLineCap ( 2 ) canvas . setLineWidth ( self . parameters . arguments [ \"axis_tics_line_width\" ]) canvas . setStrokeColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFont ( \"regular\" , self . parameters . arguments [ \"axis_tics_font_size\" ]) canvas . line ( self . visualisation_data [ \"coordinate_system\" ][ \"x_annotation_start\" ], y_top , self . visualisation_data [ \"coordinate_system\" ][ \"x_annotation_stop\" ], y_top ) for tic_label , tic_position in self . visualisation_data [ \"tics\" ] . items (): canvas . line ( tic_position , y_top , tic_position , y_top - self . visualisation_data [ \"tics_height\" ]) if tic_label == - self . visualisation_data [ \"max_upstream_sequence_length\" ]: canvas . drawString ( tic_position , y_top - ( self . visualisation_data [ \"tics_height\" ] + self . visualisation_data [ \"text_space\" ]), str ( tic_label )) elif tic_label == self . visualisation_data [ \"max_downstream_sequence_length\" ]: canvas . drawRightString ( tic_position , y_top - ( self . visualisation_data [ \"tics_height\" ] + self . visualisation_data [ \"text_space\" ]), str ( tic_label )) else : canvas . drawCentredString ( tic_position , y_top - ( self . visualisation_data [ \"tics_height\" ] + self . visualisation_data [ \"text_space\" ]), str ( tic_label ))","title":"TicsVis"},{"location":"API/package/#uorf4u.drawing.TicsVis.__init__","text":"Create a TicsVis object. Parameters: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing.py 410 411 412 413 414 415 416 417 418 419 def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Create a TicsVis object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( visualisation_data , parameters ) self . needed_space = None","title":"__init__()"},{"location":"API/package/#uorf4u.drawing.TicsVis.draw","text":"Draw an AxisTics track. Parameters: canvas ( reportlab . pdfgen . canvas . Canvas ) \u2013 a pdf object. Returns: None \u2013 None Source code in uorf4u/drawing.py 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Draw an AxisTics track. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" y_top = self . visualisation_data [ \"y_top\" ] canvas . setLineCap ( 2 ) canvas . setLineWidth ( self . parameters . arguments [ \"axis_tics_line_width\" ]) canvas . setStrokeColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFont ( \"regular\" , self . parameters . arguments [ \"axis_tics_font_size\" ]) canvas . line ( self . visualisation_data [ \"coordinate_system\" ][ \"x_annotation_start\" ], y_top , self . visualisation_data [ \"coordinate_system\" ][ \"x_annotation_stop\" ], y_top ) for tic_label , tic_position in self . visualisation_data [ \"tics\" ] . items (): canvas . line ( tic_position , y_top , tic_position , y_top - self . visualisation_data [ \"tics_height\" ]) if tic_label == - self . visualisation_data [ \"max_upstream_sequence_length\" ]: canvas . drawString ( tic_position , y_top - ( self . visualisation_data [ \"tics_height\" ] + self . visualisation_data [ \"text_space\" ]), str ( tic_label )) elif tic_label == self . visualisation_data [ \"max_downstream_sequence_length\" ]: canvas . drawRightString ( tic_position , y_top - ( self . visualisation_data [ \"tics_height\" ] + self . visualisation_data [ \"text_space\" ]), str ( tic_label )) else : canvas . drawCentredString ( tic_position , y_top - ( self . visualisation_data [ \"tics_height\" ] + self . visualisation_data [ \"text_space\" ]), str ( tic_label ))","title":"draw()"},{"location":"API/package/#uorf4u.drawing.TicsVis.needed_y_space","text":"Calculate needed vertical space for a SequenceVis track. Returns: float ( float ) \u2013 needed vertical space. Source code in uorf4u/drawing.py 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 def needed_y_space ( self ) -> float : \"\"\"Calculate needed vertical space for a SequenceVis track. Returns: float: needed vertical space. \"\"\" font_type = \"regular\" reportlab . pdfbase . pdfmetrics . registerFont ( reportlab . pdfbase . ttfonts . TTFont ( font_type , self . parameters . arguments [ f \"font_ { font_type } \" ])) face = reportlab . pdfbase . pdfmetrics . getFont ( \"regular\" ) . face if self . parameters . arguments [ \"axis_tics_font_size\" ] == \"auto\" : text_height = self . parameters . arguments [ \"label_height_to_orf_height\" ] * self . parameters . arguments [ \"orf_height\" ] * cm font_size = uorf4u . methods . string_height_to_font_size ( text_height , \"regular\" , self . parameters . arguments ) self . parameters . arguments [ \"axis_tics_font_size\" ] = font_size else : text_height = ( self . parameters . arguments [ \"axis_tics_font_size\" ] * ( face . ascent - face . descent )) / ( 1000 * 1.38 ) self . visualisation_data [ \"tics_height\" ] = 0.7 * text_height self . visualisation_data [ \"text_space\" ] = 1.2 * text_height self . needed_space = self . visualisation_data [ \"tics_height\" ] + self . visualisation_data [ \"text_space\" ] return self . needed_space","title":"needed_y_space()"},{"location":"API/package/#uorf4u.drawing.TitleLoader","text":"Bases: Loader A TitleLoader object prepares data for a Title track object. Note: Title track currently is not available. Attributes: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. prepared_data ( dict ) \u2013 dict with data needed for a visualisation track. Source code in uorf4u/drawing.py 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 class TitleLoader ( Loader ): \"\"\"A TitleLoader object prepares data for a Title track object. Note: Title track currently is not available. Attributes: parameters (uorf4u.manager.Parameters): Parameters' class object. prepared_data (dict): dict with data needed for a visualisation track. \"\"\" def __init__ ( self , parameters ): \"\"\"Create a TitleLoader object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( parameters ) def prepare_data ( self , coordinate_system : dict , additional_data : dict ) -> dict : \"\"\"Prepare data for Title visualisation track. Attributes: coordinate_system (dict): coordinate system of a figure page. additional_data (dict): data needed for a track initialisation. Returns: dict: dictionary with prepared data for visualisation. \"\"\" prepared_data = dict () prepared_data [ \"title\" ] = \"Title Testing\" prepared_data [ \"coordinate_system\" ] = coordinate_system self . prepared_data = prepared_data return prepared_data def create_track ( self ) -> TitleVis : \"\"\"Initialise a Title track object. Returns: TitleVis: visualisation track. \"\"\" return TitleVis ( self . prepared_data , self . parameters )","title":"TitleLoader"},{"location":"API/package/#uorf4u.drawing.TitleLoader.__init__","text":"Create a TitleLoader object. Parameters: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing.py 528 529 530 531 532 533 534 535 def __init__ ( self , parameters ): \"\"\"Create a TitleLoader object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( parameters )","title":"__init__()"},{"location":"API/package/#uorf4u.drawing.TitleLoader.create_track","text":"Initialise a Title track object. Returns: TitleVis ( TitleVis ) \u2013 visualisation track. Source code in uorf4u/drawing.py 554 555 556 557 558 559 560 561 def create_track ( self ) -> TitleVis : \"\"\"Initialise a Title track object. Returns: TitleVis: visualisation track. \"\"\" return TitleVis ( self . prepared_data , self . parameters )","title":"create_track()"},{"location":"API/package/#uorf4u.drawing.TitleLoader.prepare_data","text":"Prepare data for Title visualisation track. Attributes: coordinate_system ( dict ) \u2013 coordinate system of a figure page. additional_data ( dict ) \u2013 data needed for a track initialisation. Returns: dict ( dict ) \u2013 dictionary with prepared data for visualisation. Source code in uorf4u/drawing.py 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 def prepare_data ( self , coordinate_system : dict , additional_data : dict ) -> dict : \"\"\"Prepare data for Title visualisation track. Attributes: coordinate_system (dict): coordinate system of a figure page. additional_data (dict): data needed for a track initialisation. Returns: dict: dictionary with prepared data for visualisation. \"\"\" prepared_data = dict () prepared_data [ \"title\" ] = \"Title Testing\" prepared_data [ \"coordinate_system\" ] = coordinate_system self . prepared_data = prepared_data return prepared_data","title":"prepare_data()"},{"location":"API/package/#uorf4u.drawing.TitleVis","text":"Bases: Track Title visualisation track object draws figure's title. Note: This track currently is not supported. Attributes: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing.py 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 class TitleVis ( Track ): \"\"\"Title visualisation track object draws figure's title. Note: This track currently is not supported. Attributes: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Create TitleVis object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . visualisation_data = visualisation_data self . parameters = parameters def needed_y_space ( self ) -> float : \"\"\"Calculate needed vertical space for a Title track. Returns: float: needed vertical space. \"\"\" font_type = self . parameters . arguments [ \"title_font_type\" ] reportlab . pdfbase . pdfmetrics . registerFont ( reportlab . pdfbase . ttfonts . TTFont ( font_type , self . parameters . arguments [ f \"font_ { font_type } \" ])) face = reportlab . pdfbase . pdfmetrics . getFont ( font_type ) . face if self . parameters . arguments [ \"title_font_size\" ] == \"auto\" : text_height = self . parameters . arguments [ \"orf_height\" ] * cm font_size = uorf4u . methods . string_height_to_font_size ( text_height , font_type , self . parameters . arguments ) self . parameters . arguments [ \"title_font_size\" ] = font_size else : text_height = ( self . parameters . arguments [ \"title_font_size\" ] * ( face . ascent - face . descent )) / ( 1000 * 1.38 ) self . visualisation_data [ \"text_height\" ] = text_height self . needed_space = text_height * 1.2 return self . needed_space def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Draw a Title track. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" x_left_border = self . visualisation_data [ \"coordinate_system\" ][ \"x_labels_start\" ] # x_left_border = self.visualisation_data[\"coordinate_system\"][\"x_annotation_start\"] canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFont ( self . parameters . arguments [ \"title_font_type\" ], self . parameters . arguments [ \"title_font_size\" ]) canvas . drawString ( x_left_border , self . visualisation_data [ \"y_top\" ] - self . visualisation_data [ \"text_height\" ], self . visualisation_data [ \"title\" ])","title":"TitleVis"},{"location":"API/package/#uorf4u.drawing.TitleVis.__init__","text":"Create TitleVis object. Parameters: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing.py 188 189 190 191 192 193 194 195 196 197 def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Create TitleVis object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . visualisation_data = visualisation_data self . parameters = parameters","title":"__init__()"},{"location":"API/package/#uorf4u.drawing.TitleVis.draw","text":"Draw a Title track. Parameters: canvas ( reportlab . pdfgen . canvas . Canvas ) \u2013 a pdf object. Returns: None \u2013 None Source code in uorf4u/drawing.py 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Draw a Title track. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" x_left_border = self . visualisation_data [ \"coordinate_system\" ][ \"x_labels_start\" ] # x_left_border = self.visualisation_data[\"coordinate_system\"][\"x_annotation_start\"] canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFont ( self . parameters . arguments [ \"title_font_type\" ], self . parameters . arguments [ \"title_font_size\" ]) canvas . drawString ( x_left_border , self . visualisation_data [ \"y_top\" ] - self . visualisation_data [ \"text_height\" ], self . visualisation_data [ \"title\" ])","title":"draw()"},{"location":"API/package/#uorf4u.drawing.TitleVis.needed_y_space","text":"Calculate needed vertical space for a Title track. Returns: float ( float ) \u2013 needed vertical space. Source code in uorf4u/drawing.py 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 def needed_y_space ( self ) -> float : \"\"\"Calculate needed vertical space for a Title track. Returns: float: needed vertical space. \"\"\" font_type = self . parameters . arguments [ \"title_font_type\" ] reportlab . pdfbase . pdfmetrics . registerFont ( reportlab . pdfbase . ttfonts . TTFont ( font_type , self . parameters . arguments [ f \"font_ { font_type } \" ])) face = reportlab . pdfbase . pdfmetrics . getFont ( font_type ) . face if self . parameters . arguments [ \"title_font_size\" ] == \"auto\" : text_height = self . parameters . arguments [ \"orf_height\" ] * cm font_size = uorf4u . methods . string_height_to_font_size ( text_height , font_type , self . parameters . arguments ) self . parameters . arguments [ \"title_font_size\" ] = font_size else : text_height = ( self . parameters . arguments [ \"title_font_size\" ] * ( face . ascent - face . descent )) / ( 1000 * 1.38 ) self . visualisation_data [ \"text_height\" ] = text_height self . needed_space = text_height * 1.2 return self . needed_space","title":"needed_y_space()"},{"location":"API/package/#uorf4u.drawing.Track","text":"Parent clas for visualisation Tracks. Attributes: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing.py 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 class Track : \"\"\"Parent clas for visualisation Tracks. Attributes: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Parent's constructor for creating a Track object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . visualisation_data = visualisation_data self . parameters = parameters def needed_y_space ( self ) -> None : \"\"\"Empy parent's method for calculation needed vertical space for a track. Returns: None \"\"\" pass def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Empy parent's method for track visualisation. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" pass","title":"Track"},{"location":"API/package/#uorf4u.drawing.Track.__init__","text":"Parent's constructor for creating a Track object. Parameters: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing.py 144 145 146 147 148 149 150 151 152 153 def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Parent's constructor for creating a Track object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . visualisation_data = visualisation_data self . parameters = parameters","title":"__init__()"},{"location":"API/package/#uorf4u.drawing.Track.draw","text":"Empy parent's method for track visualisation. Parameters: canvas ( reportlab . pdfgen . canvas . Canvas ) \u2013 a pdf object. Returns: None \u2013 None Source code in uorf4u/drawing.py 164 165 166 167 168 169 170 171 172 173 def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Empy parent's method for track visualisation. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" pass","title":"draw()"},{"location":"API/package/#uorf4u.drawing.Track.needed_y_space","text":"Empy parent's method for calculation needed vertical space for a track. Returns: None \u2013 None Source code in uorf4u/drawing.py 155 156 157 158 159 160 161 162 def needed_y_space ( self ) -> None : \"\"\"Empy parent's method for calculation needed vertical space for a track. Returns: None \"\"\" pass","title":"needed_y_space()"},{"location":"API/package/#methods","text":"This module provides some methods (e.g. colors tranformation, data copying) used by the tool.","title":"Methods"},{"location":"API/package/#uorf4u.methods.copy_package_data","text":"Copy uorf4u package data folder to your current dir. Returns: None \u2013 None Source code in uorf4u/methods.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 def copy_package_data () -> None : \"\"\"Copy uorf4u package data folder to your current dir. Returns: None \"\"\" try : users_dir = os . path . join ( os . getcwd (), 'uorf4u_data' ) internal_dir = os . path . join ( os . path . dirname ( __file__ ), 'uorf4u_data' ) shutil . copytree ( internal_dir , users_dir , ignore = shutil . ignore_patterns ( \"help*\" , \".*\" , \"msa_plot_dir.R\" )) return None except Exception as error : raise uorf4u . manager . uORF4uError ( f \"Unable to copy uorf4u_data folder in your working dir.\" ) from error","title":"copy_package_data()"},{"location":"API/package/#uorf4u.methods.hex_to_rgb","text":"Convert HEX color to RGB format. Returns: list ( list ) \u2013 color in rgb format Source code in uorf4u/methods.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 def hex_to_rgb ( value : str ) -> list : \"\"\"Convert HEX color to RGB format. Returns: list: color in rgb format \"\"\" try : value = value . lstrip ( '#' ) lv = len ( value ) rgb = [ i / 255 for i in tuple ( int ( value [ i : i + lv // 3 ], 16 ) for i in range ( 0 , lv , lv // 3 ))] return rgb except Exception as error : raise uorf4u . manager . uORF4uError ( f \"Unable to convert color definition from HEX to RGB. Please check the palette config file.\" ) from error","title":"hex_to_rgb()"},{"location":"API/package/#uorf4u.methods.string_height_to_font_size","text":"Parameters: height ( float ) \u2013 available height of the string. font_type ( str ) \u2013 font type (see config file; at this moment only regular is available) parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Returns: float \u2013 font size defined by height Source code in uorf4u/methods.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 def string_height_to_font_size ( height : float , font_type : str , parameters : dict ): \"\"\" Arguments: height (float): available height of the string. font_type (str): font type (see config file; at this moment only regular is available) parameters (uorf4u.manager.Parameters): Parameters' class object. Returns: float: font size defined by height \"\"\" pdfmetrics . registerFont ( TTFont ( font_type , parameters [ f \"font_ { font_type } \" ])) face = pdfmetrics . getFont ( 'regular' ) . face font_size = ( 1000 * 1.38 * height ) / ( face . ascent - face . descent ) return font_size","title":"string_height_to_font_size()"},{"location":"API/usage_examples/","text":"Short example-drived guide to uorf4u API. uorf4u has a simple API allowing it programmatic usage from within a python program. Below we descrive several Python snippets that mimic results of command-line calls. import uorf4u # loading data, parameters initialization parameters = uorf4u . manager . Parameters () parameters . load_config () # Creating RefseqProtein class' object refseq_protein = uorf4u . data_processing . RefSeqProtein ( accession_number = \"#accession number\" , parameters = parameters ) # Searching for protein's homologues with blastp homologues_list = refseq_protein . blastp_searching_for_homologues () # Creating a Homologues class' object homologues = uorf4u . data_processing . Homologues ( homologues_list , parameters ) # Getting upstream sequences and annotating ORFs homologues . get_upstream_sequences () homologues . save_upstream_sequences () homologues . annotate_orfs () homologues . filter_orfs_by_sd_annotation () homologues . save_annotated_orfs () # Searching for conserved ORFs and saving the results homologues . conserved_orf_searching () homologues . filter_out_similar_paths () homologues . run_msa () homologues . save_orfs_sequences () homologues . save_msa () homologues . save_results_summary_table () homologues . plot_annotation () homologues . plot_logo_figs () homologues . plot_ggmsa_figs ()","title":"Usage examples"},{"location":"API/usage_examples/#short-example-drived-guide-to-uorf4u-api","text":"uorf4u has a simple API allowing it programmatic usage from within a python program. Below we descrive several Python snippets that mimic results of command-line calls. import uorf4u # loading data, parameters initialization parameters = uorf4u . manager . Parameters () parameters . load_config () # Creating RefseqProtein class' object refseq_protein = uorf4u . data_processing . RefSeqProtein ( accession_number = \"#accession number\" , parameters = parameters ) # Searching for protein's homologues with blastp homologues_list = refseq_protein . blastp_searching_for_homologues () # Creating a Homologues class' object homologues = uorf4u . data_processing . Homologues ( homologues_list , parameters ) # Getting upstream sequences and annotating ORFs homologues . get_upstream_sequences () homologues . save_upstream_sequences () homologues . annotate_orfs () homologues . filter_orfs_by_sd_annotation () homologues . save_annotated_orfs () # Searching for conserved ORFs and saving the results homologues . conserved_orf_searching () homologues . filter_out_similar_paths () homologues . run_msa () homologues . save_orfs_sequences () homologues . save_msa () homologues . save_results_summary_table () homologues . plot_annotation () homologues . plot_logo_figs () homologues . plot_ggmsa_figs ()","title":"Short example-drived guide to uorf4u API."},{"location":"Parameters/cmd_parameters/","text":"\u0421ommand-line parameters POST-INSTALL DATA --data Creates the uorf4u_data folder in the current working directory. The folder will contain an adjustable configuration file template, palettes, tables as well as the necessary sample data. MANDATORY ARGUMENTS -an Protein's RefSeq accession number. OR -hl Space separated list of proteins accession numbers which will be used as list of homologous. OR -hlf Path to a file with list of accession numbers. File format: one accession number per line, no header. OPTIONAL ARGUMENTS -ul Length of upstream sequences to retrieve for homologous. -bh Max number of blastp hits in homologous searching. -al Path to an assemblies list file. During each run of uorf4u, a tsv table with information about assemblies (from identical protein database, ncbi) for each protein is saved to your output folder (output_dir_name/assemblies_list.tsv). There are cases with multiple assemblies for one protein accession numbers (up to thousands). In case to control assemblies included in the analysis this table can be filtered (simply by removing rows) and then used with this parameter as part of input to the next run. In addition, config file (see config parameters section) has max_number_of_assemblies parameter. It can be used to limit max number of assemblies included in the analysis. In case number of assemblies is more than the cutoff, random sampling will be used to take only subset of them. -at Alignment type used by uorf4u for conserved ORFs searching [default: aa]. -asc Include alternative start codons in uORF annotation step. List of alternative start codons are taken from the ncbi genetic code. -o Output dirname. It will be created if it's not exist. All output dirs will be then created in this folder [default: uorf4u_{current_date}; e.g. uorf4u_2022_07_25-20_41]. -c Path to a configuration file [default: internal]. MISCELLANEOUS ARGUMENTS -h , --help Show help message and exit. -v , --version Show program version. --debug Provide detailed stack trace for debugging purposes. --verbose Show all progress messages [default: False]","title":"Command-line parameters"},{"location":"Parameters/cmd_parameters/#ommand-line-parameters","text":"POST-INSTALL DATA --data Creates the uorf4u_data folder in the current working directory. The folder will contain an adjustable configuration file template, palettes, tables as well as the necessary sample data. MANDATORY ARGUMENTS -an Protein's RefSeq accession number. OR -hl Space separated list of proteins accession numbers which will be used as list of homologous. OR -hlf Path to a file with list of accession numbers. File format: one accession number per line, no header. OPTIONAL ARGUMENTS -ul Length of upstream sequences to retrieve for homologous. -bh Max number of blastp hits in homologous searching. -al Path to an assemblies list file. During each run of uorf4u, a tsv table with information about assemblies (from identical protein database, ncbi) for each protein is saved to your output folder (output_dir_name/assemblies_list.tsv). There are cases with multiple assemblies for one protein accession numbers (up to thousands). In case to control assemblies included in the analysis this table can be filtered (simply by removing rows) and then used with this parameter as part of input to the next run. In addition, config file (see config parameters section) has max_number_of_assemblies parameter. It can be used to limit max number of assemblies included in the analysis. In case number of assemblies is more than the cutoff, random sampling will be used to take only subset of them. -at Alignment type used by uorf4u for conserved ORFs searching [default: aa]. -asc Include alternative start codons in uORF annotation step. List of alternative start codons are taken from the ncbi genetic code. -o Output dirname. It will be created if it's not exist. All output dirs will be then created in this folder [default: uorf4u_{current_date}; e.g. uorf4u_2022_07_25-20_41]. -c Path to a configuration file [default: internal]. MISCELLANEOUS ARGUMENTS -h , --help Show help message and exit. -v , --version Show program version. --debug Provide detailed stack trace for debugging purposes. --verbose Show all progress messages [default: False]","title":"\u0421ommand-line parameters"},{"location":"Parameters/config_parameters/","text":"Configuration file parameters uorf4u configuration file allows detailed customization of the tool's parameters. Below, comments ( placed after ; in each line ) are allowed in configuration files. Here they are used to provide short parameter descriptions. ;[General] ncbi_genetic_code_name = Bacterial upstream_region_length = 1000 minimal_upstream_region_length = 500 downstream_region_length = 100 ;[blastp homologous searching] blastp_evalue_cutoff = 1e-5 blastp_hit_list_size = 200 blastp_max_number_of_alignments = 1000 blastp_pident_to_query_length_cutoff = 0.5 ;[ORF annotation] alternative_start_codons = False main_start_codon = ATG min_orf_length = 9 sd_energy_cutoff = -3 sd_window_length = 20 check_assembly_annotation = 0 ;[conserved ORFs searching] orf_length_group_range = 20 orfs_presence_cutoff = 0.5 paths_identity_cutoff = 0.5 max_number_of_assemblies = 10 num_of_initial_genome_iteration = 200 ;[Pairwise alignment] alignment_type = aa global_match_score = 2 global_mismatch_score = -1 global_open_gap_score = -1 global_extend_gap_score = -1 global_target_end_gap_score = -1 global_query_end_gap_score = -1 alignment_score_cutoff = 0 ;[Multiple Sequence Alignment] consensus_threshold = 0.7 ;[Paths] ref_energies = {internal}/energyRef-CCTCCT.json muscle_binary = {internal}/bin/muscle5.1.macos_arm64 plot_msa_R_script = {internal}/msa_plot.R palette_nt = {internal}/palette_nt.txt palette_aa = {internal}/palette_aa.txt ;[Output] sequences_to_write = nt, aa, sd logo_type = probability output_dir = uorf4u_{current_date} ;------------------------ ;Annotation visualisation ;------------------------ ;[General figure parameters] margin = 0.1 gap = 0.03 label_gap = 0.07 orf_height = 0.15 annotation_width = auto mm_per_nt = 0.04 font_regular = {internal}/fonts/Lato-Regular.ttf font_bold = {internal}/fonts/Lato-Bold.ttf ;[Sequence labels] label_color = #3D3D3D label_color_alpha = 1 label_height_to_orf_height = 0.65 ;[Axis tics] axis_tics_font_size = auto axis_tics_line_width = 0.3 ;[Loci annotations] upstream_seq_line_color = #CECECE upstream_seq_line_color_alpha = 1 upstream_seq_line_width = 0.5 cds_seq_stroke_color = #489143 cds_seq_stroke_color_alpha = 0.8 cds_seq_fill_color = #9ee19b cds_seq_fill_color_alpha = 0.03 orf_line_width = 0.5 conserved_uorfs_stroke_color = #4e4e4e conserved_uorfs_stroke_color_alpha = 1 conserved_uorfs_fill_color = #ee8fb1 conserved_uorfs_fill_color_alpha = 0.6 other_uorfs_stroke_color = #CECECE other_uorfs_stroke_color_alpha = 1 annotated_orf_stroke_color = #3d6f8e annotated_orf_stroke_color_alpha = 1","title":"Configuration file parameters"},{"location":"Parameters/config_parameters/#configuration-file-parameters","text":"uorf4u configuration file allows detailed customization of the tool's parameters. Below, comments ( placed after ; in each line ) are allowed in configuration files. Here they are used to provide short parameter descriptions. ;[General] ncbi_genetic_code_name = Bacterial upstream_region_length = 1000 minimal_upstream_region_length = 500 downstream_region_length = 100 ;[blastp homologous searching] blastp_evalue_cutoff = 1e-5 blastp_hit_list_size = 200 blastp_max_number_of_alignments = 1000 blastp_pident_to_query_length_cutoff = 0.5 ;[ORF annotation] alternative_start_codons = False main_start_codon = ATG min_orf_length = 9 sd_energy_cutoff = -3 sd_window_length = 20 check_assembly_annotation = 0 ;[conserved ORFs searching] orf_length_group_range = 20 orfs_presence_cutoff = 0.5 paths_identity_cutoff = 0.5 max_number_of_assemblies = 10 num_of_initial_genome_iteration = 200 ;[Pairwise alignment] alignment_type = aa global_match_score = 2 global_mismatch_score = -1 global_open_gap_score = -1 global_extend_gap_score = -1 global_target_end_gap_score = -1 global_query_end_gap_score = -1 alignment_score_cutoff = 0 ;[Multiple Sequence Alignment] consensus_threshold = 0.7 ;[Paths] ref_energies = {internal}/energyRef-CCTCCT.json muscle_binary = {internal}/bin/muscle5.1.macos_arm64 plot_msa_R_script = {internal}/msa_plot.R palette_nt = {internal}/palette_nt.txt palette_aa = {internal}/palette_aa.txt ;[Output] sequences_to_write = nt, aa, sd logo_type = probability output_dir = uorf4u_{current_date} ;------------------------ ;Annotation visualisation ;------------------------ ;[General figure parameters] margin = 0.1 gap = 0.03 label_gap = 0.07 orf_height = 0.15 annotation_width = auto mm_per_nt = 0.04 font_regular = {internal}/fonts/Lato-Regular.ttf font_bold = {internal}/fonts/Lato-Bold.ttf ;[Sequence labels] label_color = #3D3D3D label_color_alpha = 1 label_height_to_orf_height = 0.65 ;[Axis tics] axis_tics_font_size = auto axis_tics_line_width = 0.3 ;[Loci annotations] upstream_seq_line_color = #CECECE upstream_seq_line_color_alpha = 1 upstream_seq_line_width = 0.5 cds_seq_stroke_color = #489143 cds_seq_stroke_color_alpha = 0.8 cds_seq_fill_color = #9ee19b cds_seq_fill_color_alpha = 0.03 orf_line_width = 0.5 conserved_uorfs_stroke_color = #4e4e4e conserved_uorfs_stroke_color_alpha = 1 conserved_uorfs_fill_color = #ee8fb1 conserved_uorfs_fill_color_alpha = 0.6 other_uorfs_stroke_color = #CECECE other_uorfs_stroke_color_alpha = 1 annotated_orf_stroke_color = #3d6f8e annotated_orf_stroke_color_alpha = 1","title":"Configuration file parameters"},{"location":"Quickstart/quickstart_guide/","text":"Quickstart guide Here we present several examples of uorf4u usage and the respective command-line parameters. This chapter based on the considering of well-known uORFs that can be cis-acting translation modulators (see a review article Koreaki Ito et.al. 2013 ). Before start, the necessary sample data as well as adjustable tool' configuration files are priveded by uorf4u at the post-install step: uorf4u --data ErmCL One of the well-known bacterial upstream ORFs that regulates its downstream frame is ErmCL. Inducible expression of the downstream Erm resistance gene relies on ribosome stalling on the uORF (ErmCL). Molecular mechanism of ribosome stalling based on the presence of so-called ribosome arrest peptide (RAP) in the ErmCL amino acid sequence. RAPs act in nascent states through interaction with ribosome that leads to translation arrest. RAP-mediated regulations based on presence a particular amino acid sequence (also known as arrest-essential amino acids). For ErmCL (19 codons length) this sequence is IFVI (see the review for more detailed introduction). To test whether uorf4u will be able to find this ORF we can use only accession number of ErmC protein as input! The searching result for \"ErmC\" in ncbi protein database gives us the RefSeq id: WP_001003263.1 , which can be directly used for our searching: uorf4u -an WP_001003263.1 -verbose -o ErmC Note: -verbose and -o parameters are optional. -verbose used to show all progress messages, -o - to specify output folder name (by default it's uorf4u_{current_data} e.g. uorf4u_2022_08_09-15_00). The results will be saved to the ErmC folder with the following structure: Searching with default parameters returns us only one set of conserved ORFs. Let's have a look at the respective amino acid sequence logo and annotation plot (only header of the output figure is shown below for the annotation plot). Fortunately, we can see that one of the most conserved region of the sequence is expected IFVI arrest-essential amino acids. \ud83e\udd73","title":"Quickstart guide"},{"location":"Quickstart/quickstart_guide/#quickstart-guide","text":"Here we present several examples of uorf4u usage and the respective command-line parameters. This chapter based on the considering of well-known uORFs that can be cis-acting translation modulators (see a review article Koreaki Ito et.al. 2013 ). Before start, the necessary sample data as well as adjustable tool' configuration files are priveded by uorf4u at the post-install step: uorf4u --data","title":"Quickstart guide"},{"location":"Quickstart/quickstart_guide/#ermcl","text":"One of the well-known bacterial upstream ORFs that regulates its downstream frame is ErmCL. Inducible expression of the downstream Erm resistance gene relies on ribosome stalling on the uORF (ErmCL). Molecular mechanism of ribosome stalling based on the presence of so-called ribosome arrest peptide (RAP) in the ErmCL amino acid sequence. RAPs act in nascent states through interaction with ribosome that leads to translation arrest. RAP-mediated regulations based on presence a particular amino acid sequence (also known as arrest-essential amino acids). For ErmCL (19 codons length) this sequence is IFVI (see the review for more detailed introduction). To test whether uorf4u will be able to find this ORF we can use only accession number of ErmC protein as input! The searching result for \"ErmC\" in ncbi protein database gives us the RefSeq id: WP_001003263.1 , which can be directly used for our searching: uorf4u -an WP_001003263.1 -verbose -o ErmC Note: -verbose and -o parameters are optional. -verbose used to show all progress messages, -o - to specify output folder name (by default it's uorf4u_{current_data} e.g. uorf4u_2022_08_09-15_00). The results will be saved to the ErmC folder with the following structure: Searching with default parameters returns us only one set of conserved ORFs. Let's have a look at the respective amino acid sequence logo and annotation plot (only header of the output figure is shown below for the annotation plot). Fortunately, we can see that one of the most conserved region of the sequence is expected IFVI arrest-essential amino acids. \ud83e\udd73","title":"ErmCL"},{"location":"VersionLog/versions/","text":"Version log Ver 0.4.0 - 30 August 2022 Visualisation of loci annotation was added. Minor bugs were fixed. Ver 0.3.1 - 17 August 2022 New cmd and configs parameters were added. Annotation of uORFs overlapped with the main CDSs was added. Ver 0.3.0 - 7 August 2022 Algorithm of conserved ORFs searching was updated. New configs parameteres were added. Ver 0.2.1 - 5 August 2022 Annotation parsing bug was fixed. Ver 0.2.0 - 5 August 2022 New cmd and configs parameters were added. New classes and methods were developed. Ver 0.1.5 - 31 July 2022 MSA visualisation functions updated. Bugs were fixed. New cmd and configs parameters were added. Ver 0.1 - 27 July 2022 - Initial release.","title":"Version log"},{"location":"VersionLog/versions/#version-log","text":"Ver 0.4.0 - 30 August 2022 Visualisation of loci annotation was added. Minor bugs were fixed. Ver 0.3.1 - 17 August 2022 New cmd and configs parameters were added. Annotation of uORFs overlapped with the main CDSs was added. Ver 0.3.0 - 7 August 2022 Algorithm of conserved ORFs searching was updated. New configs parameteres were added. Ver 0.2.1 - 5 August 2022 Annotation parsing bug was fixed. Ver 0.2.0 - 5 August 2022 New cmd and configs parameters were added. New classes and methods were developed. Ver 0.1.5 - 31 July 2022 MSA visualisation functions updated. Bugs were fixed. New cmd and configs parameters were added. Ver 0.1 - 27 July 2022 - Initial release.","title":"Version log"}]}