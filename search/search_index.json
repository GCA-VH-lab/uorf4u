{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Description uORF4u is a bioinformatics tool for conserved upstream ORF annotation. Programming language: Python3 OS: MacOS, Linux Python dependencies: biopython, configs, argparse, pandas, statistics, logomaker, matplotlib, reportlab. OS-level dependencies: mafft (v7.490 is included in the package) License: WTFPL Version: 0.8.5 (January 2022) Data analysis pipeline Installation \ud83d\udee0\ufe0f The most stable release of uorf4u can be installed directly from pypi: python3 -m pip install uorf4u The development version is available at github : git clone https://github.com/art-egorov/uorf4u.git cd uorf4u python3 -m pip install --upgrade pip python3 -m pip install wheel python3 setup.py sdist bdist_wheel python3 -m pip install -e . ! If you're a linux user, run uorf4u --linux post-install command once to update paths in the premade config files that set by default for MacOS users. Reference \ud83d\udcc3 If you find uorf4u useful, please cite: Artyom. A. Egorov, Gemma C. Atkinson, uORF4u: a tool for annotation of conserved upstream open reading frames , bioRxiv 2022.10.27.514069; doi: 10.1101/2022.10.27.514069 Contact \ud83d\udcc7 Please contact us by e-mail artem dot egorov AT med dot lu dot se or use Issues to report any technical problems. You can also use Discussions section for sharing your ideas or feature requests! Authors \ud83d\udc68\ud83c\udffb\u200d\ud83d\udcbb uORF4u is developed by Artyom Egorov at the Atkinson Lab , Department of Experimental Medical Science, Lund University, Sweden \ud83c\uddf8\ud83c\uddea. We are open for suggestions to extend and improve svist4get functionality. Please don't hesitate to share your ideas or feature requests.","title":"Home"},{"location":"#_1","text":"","title":""},{"location":"#description","text":"uORF4u is a bioinformatics tool for conserved upstream ORF annotation. Programming language: Python3 OS: MacOS, Linux Python dependencies: biopython, configs, argparse, pandas, statistics, logomaker, matplotlib, reportlab. OS-level dependencies: mafft (v7.490 is included in the package) License: WTFPL Version: 0.8.5 (January 2022)","title":"Description"},{"location":"#data-analysis-pipeline","text":"","title":"Data analysis pipeline"},{"location":"#installation","text":"The most stable release of uorf4u can be installed directly from pypi: python3 -m pip install uorf4u The development version is available at github : git clone https://github.com/art-egorov/uorf4u.git cd uorf4u python3 -m pip install --upgrade pip python3 -m pip install wheel python3 setup.py sdist bdist_wheel python3 -m pip install -e . ! If you're a linux user, run uorf4u --linux post-install command once to update paths in the premade config files that set by default for MacOS users.","title":"Installation \ud83d\udee0\ufe0f"},{"location":"#reference","text":"If you find uorf4u useful, please cite: Artyom. A. Egorov, Gemma C. Atkinson, uORF4u: a tool for annotation of conserved upstream open reading frames , bioRxiv 2022.10.27.514069; doi: 10.1101/2022.10.27.514069","title":"Reference \ud83d\udcc3"},{"location":"#contact","text":"Please contact us by e-mail artem dot egorov AT med dot lu dot se or use Issues to report any technical problems. You can also use Discussions section for sharing your ideas or feature requests!","title":"Contact \ud83d\udcc7"},{"location":"#authors","text":"uORF4u is developed by Artyom Egorov at the Atkinson Lab , Department of Experimental Medical Science, Lund University, Sweden \ud83c\uddf8\ud83c\uddea. We are open for suggestions to extend and improve svist4get functionality. Please don't hesitate to share your ideas or feature requests.","title":"Authors \ud83d\udc68\ud83c\udffb\u200d\ud83d\udcbb"},{"location":"API/package_data_processing/","text":"This module provides data processing including uORFs annotation and conserved subset searching. Homologues A Homologues object holds list of proteins homologues and information about them. Attributes: accession_numbers ( list ) \u2013 List of RefSeq accession numbers. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. records ( list ) \u2013 list of RefSeqProtein objects of the proteins. Source code in uorf4u/data_processing.py 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 class Homologues : \"\"\"A Homologues object holds list of proteins homologues and information about them. Attributes: accession_numbers (list): List of RefSeq accession numbers. parameters (uorf4u.manager.Parameters): Parameters' class object. records (list): list of RefSeqProtein objects of the proteins. \"\"\" def __init__ ( self , accession_numbers : list , parameters : uorf4u . manager . Parameters ): \"\"\"Create a Homologues object. Note: With initialisation it also creates a 'records' attribute - a list of RefSeqProtein objects of proteins based on accession numbers list. Arguments: accession_numbers (list): List of RefSeq accession numbers. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" try : self . accession_numbers = accession_numbers self . parameters = parameters self . records = [ RefSeqProtein ( i , parameters ) for i in accession_numbers ] except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to create a Homologues class' object.\" ) from error def get_upstream_sequences ( self ) -> list : \"\"\"Get upstream sequences of proteins' genes. Note: A protein may be found in multiple assemblies (for example in different strains). Returns: list: List of Bio.SeqRecord.SeqRecord objects of upstream sequences. \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udce1 Retrieving upstream sequences...\" , file = sys . stdout ) for i in range ( 0 , len ( self . records ), 200 ): records_subset = self . records [ i : i + 200 ] accession_numbers = [ record . accession_number for record in records_subset ] handle = Bio . Entrez . efetch ( db = \"protein\" , id = accession_numbers , rettype = \"ipg\" , retmode = \"xml\" ) handle_txt = handle . read () . decode ( 'utf-8' ) for record in records_subset : record . get_assemblies ( handle_txt ) handle_fasta = Bio . Entrez . efetch ( db = \"protein\" , id = accession_numbers , rettype = \"fasta\" , retmode = \"text\" ) fasta_records = Bio . SeqIO . parse ( handle_fasta , \"fasta\" ) for f_record in fasta_records : record_index = accession_numbers . index ( f_record . id ) records_subset [ record_index ] . record = f_record proteins_wo_assemblies = [] if self . parameters . arguments [ \"assemblies_list\" ] == 'NA' : assemblies_table = [ f \"accession_number \\t locus_id \\t assembly \\t organism \\t strain \\t tax_id\" ] list_of_protein_with_multiple_assemblies = [] numbers_of_assemblies = [] for record in self . records : numbers_of_assemblies . append ( len ( record . assemblies_coordinates )) if len ( record . assemblies_coordinates ) == 0 : proteins_wo_assemblies . append ( record . accession_number ) if len ( record . assemblies_coordinates ) > 1 : list_of_protein_with_multiple_assemblies . append ( record . accession_number ) for assembly in record . assemblies_coordinates : assemblies_table . append ( f \" { record . accession_number } \\t \" f \" { assembly [ 'locus_id' ] } : { assembly [ 'start' ] } : { assembly [ 'stop' ] } ( { assembly [ 'strand' ] } )\" f \" \\t { assembly [ 'assembly' ] } \" f \" \\t { assembly [ 'org' ] } \\t { assembly [ 'strain' ] } \\t { assembly [ 'taxid' ] } \" ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) assemblies_table_path = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"assemblies_list.tsv\" ) assemblies_selected_table_path = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"selected_assemblies_list.tsv\" ) assemblies_table_file = open ( assemblies_table_path , \"w\" ) assemblies_table_file . write ( \" \\n \" . join ( assemblies_table )) assemblies_table_file . close () proteins_wo_assemblies_txt = \" \\n \" . join ( proteins_wo_assemblies ) + \" \\n \" proteins_wo_assemblies_path = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"proteins_wo_assembly.txt\" ) proteins_wo_assemblies_file = open ( proteins_wo_assemblies_path , \"w\" ) proteins_wo_assemblies_file . write ( proteins_wo_assemblies_txt ) if numbers_of_assemblies . count ( 0 ) > 0 : print ( f \"\u2757\ufe0fWarning message: \\n\\t For { numbers_of_assemblies . count ( 0 ) } proteins \" f \"no assembly was found. \\n \" f \" \\t These proteins' records can be suppressed by the ncbi \\n\\t \" f \"or they don't have loci that satisfies refseq_sequnces_regex config parameter. \\n\\t \" f \"List of these proteins was saved as: { os . path . basename ( proteins_wo_assemblies_path ) } \" , file = sys . stderr ) if len ( list_of_protein_with_multiple_assemblies ) > 0 : print ( f \"\u2757\ufe0fWarning message: \\n\\t For { len ( list_of_protein_with_multiple_assemblies ) } proteins \" f \"multiple assemblies were found in identical protein database \\n \" f \" \\t with max number of assemblies per one protein as { max ( numbers_of_assemblies ) } \ud83d\ude31. \\n\\t \" f \"A table with information about the assemblies was saved as a tsv file: \" f \" { os . path . basename ( assemblies_table_path ) } . \\n\\t You can edit it and remove lines with assemblies \" f \"you do not want to include in your analysis. \\n \" f \" \\t After filtering, you can use -al cmd parameter with your table as an argument. \\n \" f \" \\t In addition, config file has 'max_number_of_assemblies' parameter \" f \"(set as { self . parameters . arguments [ 'max_number_of_assemblies' ] } ). \\n\\t By default \u2755, it's used \" f \"by uorf4u to limit max number of assemblies included in the analysis; \\n \" f \" \\t and it works only if '-al' option is not provided. In case number of assemblies is more than \" f \"the cutoff, \\n\\t random sampling \ud83c\udfb2 will be used to take only subset of them. \\n\\t \" f \"Selected assemblies information was savead as a tsv file: \" f \" { os . path . basename ( assemblies_selected_table_path ) } \" f \" \\n\\t See documentation \ud83d\udcd6 for details.\" , file = sys . stderr ) else : assemblies_table = pandas . read_table ( self . parameters . arguments [ \"assemblies_list\" ], sep = \" \\t \" ) locus_ids = assemblies_table [ \"locus_id\" ] . to_list () locus_ids = [ id . split ( \":\" )[ 0 ] for id in locus_ids ] upstream_sequences = [] an_with_no_annotated_useq = [] for record in self . records : assemblies = record . assemblies_coordinates if isinstance ( self . parameters . arguments [ \"max_number_of_assemblies\" ], int ) and \\ self . parameters . arguments [ \"assemblies_list\" ] == \"NA\" : if len ( assemblies ) >= self . parameters . arguments [ \"max_number_of_assemblies\" ]: assemblies = random . sample ( assemblies , self . parameters . arguments [ \"max_number_of_assemblies\" ]) if self . parameters . arguments [ \"assemblies_list\" ] != \"NA\" : assemblies_filtered = [ i for i in assemblies if i [ \"locus_id\" ] in locus_ids ] assemblies = assemblies_filtered record . assemblies_coordinates = assemblies assemblies_table = [ f \"accession_number \\t locus_id \\t assembly \\t organism \\t strain \\t tax_id\" ] for record in self . records : for assembly in record . assemblies_coordinates : assemblies_table . append ( f \" { record . accession_number } \\t \" f \" { assembly [ 'locus_id' ] } : { assembly [ 'start' ] } : { assembly [ 'stop' ] } ( { assembly [ 'strand' ] } )\" f \" \\t { assembly [ 'assembly' ] } \" f \" \\t { assembly [ 'org' ] } \\t { assembly [ 'strain' ] } \\t { assembly [ 'taxid' ] } \" ) assemblies_table_file = open ( assemblies_selected_table_path , \"w\" ) assemblies_table_file . write ( \" \\n \" . join ( assemblies_table )) assemblies_table_file . close () lists_of_assemblies = [ record . assemblies_coordinates for record in self . records ] all_assemblies = [ assembly for sublist in lists_of_assemblies for assembly in sublist ] for i in range ( 0 , len ( all_assemblies ), 150 ): assemblies_subset = all_assemblies [ i : i + 150 ] sequences_ids = [ assembly [ \"locus_id\" ] for assembly in assemblies_subset ] handle = Bio . Entrez . efetch ( db = \"nucleotide\" , rettype = \"fasta\" , retmode = \"txt\" , id = sequences_ids ) records = Bio . SeqIO . parse ( handle , \"fasta\" ) for record , assembly in zip ( records , assemblies_subset ): assembly [ \"record\" ] = record for record in self . records : record_upstream_sequences = [] for assembly in record . assemblies_coordinates : locus_record = assembly [ \"record\" ] try : useq_downstream_region_length = min ( self . parameters . arguments [ \"downstream_region_length\" ], len ( record . record . seq ) * 3 ) except : useq_downstream_region_length = self . parameters . arguments [ \"downstream_region_length\" ] useq_upstream_region_length = self . parameters . arguments [ \"upstream_region_length\" ] if assembly [ \"strand\" ] == \"+\" : if self . parameters . arguments [ \"upstream_region_length\" ] == \"all\" : useq_start = 0 else : useq_start = max ( 0 , assembly [ \"start\" ] - self . parameters . arguments [ \"upstream_region_length\" ]) if useq_start == 0 : useq_upstream_region_length = assembly [ \"start\" ] useq_stop = min ( assembly [ \"start\" ] + self . parameters . arguments [ \"downstream_region_length\" ], len ( locus_record . seq )) if useq_stop == len ( locus_record . seq ): useq_downstream_region_length = len ( locus_record . seq ) - assembly [ \"start\" ] elif assembly [ \"strand\" ] == \"-\" : useq_start = max ( 0 , assembly [ \"stop\" ] - self . parameters . arguments [ \"downstream_region_length\" ]) if useq_start == 0 : useq_downstream_region_length = assembly [ \"stop\" ] if self . parameters . arguments [ \"upstream_region_length\" ] == \"all\" : useq_stop = len ( locus_record . seq ) else : useq_stop = min ( len ( locus_record . seq ), assembly [ \"stop\" ] + self . parameters . arguments [ \"upstream_region_length\" ]) if useq_stop == len ( locus_record . seq ): useq_upstream_region_length = len ( locus_record . seq ) - assembly [ \"stop\" ] useq_length = abs ( useq_stop - useq_start ) if self . parameters . arguments [ \"upstream_region_length\" ] != 'all' : if self . parameters . arguments [ \"minimal_upstream_region_length\" ] >= self . parameters . arguments [ \"upstream_region_length\" ]: self . parameters . arguments [ \"minimal_upstream_region_length\" ] = self . parameters . arguments [ \"upstream_region_length\" ] if useq_upstream_region_length >= self . parameters . arguments [ \"minimal_upstream_region_length\" ] or \\ self . parameters . arguments [ \"upstream_region_length\" ] == \"all\" : useq = locus_record . seq [ useq_start : useq_stop ] if assembly [ \"strand\" ] == \"-\" : useq = useq . reverse_complement () if assembly [ \"strain\" ] == \"NA\" : useq_name = assembly [ \"org\" ] elif assembly [ \"strain\" ] in assembly [ \"org\" ]: useq_name = f \" { assembly [ 'org' ] . replace ( assembly [ 'strain' ], '' ) }{ assembly [ 'strain' ] } \" else : useq_name = f \" { assembly [ 'org' ] } { assembly [ 'strain' ] } \" useq_id = f \" { assembly [ 'locus_id' ] } | { useq_start } - { useq_stop } ( { assembly [ 'strand' ] } )|\" \\ f \" { record . accession_number } \" # useq_id = f\"{useq_name}|{assembly['locus_id']}|{record.accession_number}\" useq_label = f \" { useq_name } | { assembly [ 'locus_id' ] } | { record . accession_number } \" useq_annotations = dict ( RefSeq = True , locus_record = locus_record , locus_id = assembly [ 'locus_id' ], length = useq_length , start = useq_start , stop = useq_stop , strand = assembly [ \"strand\" ], accession_number = record . accession_number , organism = assembly [ 'org' ], label = useq_label , upstream_region_length = useq_upstream_region_length , downstream_region_length = useq_downstream_region_length ) useq_record = Bio . SeqRecord . SeqRecord ( useq , id = useq_id , description = useq_name , annotations = useq_annotations ) record_upstream_sequences . append ( useq_record ) upstream_sequences += record_upstream_sequences if len ( record_upstream_sequences ) == 0 : an_with_no_annotated_useq . append ( record . accession_number ) if an_with_no_annotated_useq : print ( f \"\u2757Warning message: \\n\\t No upstream sequences for { len ( an_with_no_annotated_useq ) } protein(s)\" f \" were annotated. \\n\\t Corresponding loci in the nucleotide ncbi database can be too short \ud83d\udccf. \\n \" f \" \\t See 'minimal_upstream_region_length' config parameter description in the documentation.\" , file = sys . stderr ) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\u2705 { len ( upstream_sequences ) } upstream sequences were obtained.\" , file = sys . stdout ) return upstream_sequences except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to retrieve upstream sequences.\" ) from error __init__ ( accession_numbers , parameters ) Create a Homologues object. Note: With initialisation it also creates a 'records' attribute - a list of RefSeqProtein objects of proteins based on accession numbers list. Parameters: accession_numbers ( list ) \u2013 List of RefSeq accession numbers. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/data_processing.py 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 def __init__ ( self , accession_numbers : list , parameters : uorf4u . manager . Parameters ): \"\"\"Create a Homologues object. Note: With initialisation it also creates a 'records' attribute - a list of RefSeqProtein objects of proteins based on accession numbers list. Arguments: accession_numbers (list): List of RefSeq accession numbers. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" try : self . accession_numbers = accession_numbers self . parameters = parameters self . records = [ RefSeqProtein ( i , parameters ) for i in accession_numbers ] except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to create a Homologues class' object.\" ) from error get_upstream_sequences () Get upstream sequences of proteins' genes. Note: A protein may be found in multiple assemblies (for example in different strains). Returns: list ( list ) \u2013 List of Bio.SeqRecord.SeqRecord objects of upstream sequences. Source code in uorf4u/data_processing.py 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 def get_upstream_sequences ( self ) -> list : \"\"\"Get upstream sequences of proteins' genes. Note: A protein may be found in multiple assemblies (for example in different strains). Returns: list: List of Bio.SeqRecord.SeqRecord objects of upstream sequences. \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udce1 Retrieving upstream sequences...\" , file = sys . stdout ) for i in range ( 0 , len ( self . records ), 200 ): records_subset = self . records [ i : i + 200 ] accession_numbers = [ record . accession_number for record in records_subset ] handle = Bio . Entrez . efetch ( db = \"protein\" , id = accession_numbers , rettype = \"ipg\" , retmode = \"xml\" ) handle_txt = handle . read () . decode ( 'utf-8' ) for record in records_subset : record . get_assemblies ( handle_txt ) handle_fasta = Bio . Entrez . efetch ( db = \"protein\" , id = accession_numbers , rettype = \"fasta\" , retmode = \"text\" ) fasta_records = Bio . SeqIO . parse ( handle_fasta , \"fasta\" ) for f_record in fasta_records : record_index = accession_numbers . index ( f_record . id ) records_subset [ record_index ] . record = f_record proteins_wo_assemblies = [] if self . parameters . arguments [ \"assemblies_list\" ] == 'NA' : assemblies_table = [ f \"accession_number \\t locus_id \\t assembly \\t organism \\t strain \\t tax_id\" ] list_of_protein_with_multiple_assemblies = [] numbers_of_assemblies = [] for record in self . records : numbers_of_assemblies . append ( len ( record . assemblies_coordinates )) if len ( record . assemblies_coordinates ) == 0 : proteins_wo_assemblies . append ( record . accession_number ) if len ( record . assemblies_coordinates ) > 1 : list_of_protein_with_multiple_assemblies . append ( record . accession_number ) for assembly in record . assemblies_coordinates : assemblies_table . append ( f \" { record . accession_number } \\t \" f \" { assembly [ 'locus_id' ] } : { assembly [ 'start' ] } : { assembly [ 'stop' ] } ( { assembly [ 'strand' ] } )\" f \" \\t { assembly [ 'assembly' ] } \" f \" \\t { assembly [ 'org' ] } \\t { assembly [ 'strain' ] } \\t { assembly [ 'taxid' ] } \" ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) assemblies_table_path = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"assemblies_list.tsv\" ) assemblies_selected_table_path = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"selected_assemblies_list.tsv\" ) assemblies_table_file = open ( assemblies_table_path , \"w\" ) assemblies_table_file . write ( \" \\n \" . join ( assemblies_table )) assemblies_table_file . close () proteins_wo_assemblies_txt = \" \\n \" . join ( proteins_wo_assemblies ) + \" \\n \" proteins_wo_assemblies_path = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"proteins_wo_assembly.txt\" ) proteins_wo_assemblies_file = open ( proteins_wo_assemblies_path , \"w\" ) proteins_wo_assemblies_file . write ( proteins_wo_assemblies_txt ) if numbers_of_assemblies . count ( 0 ) > 0 : print ( f \"\u2757\ufe0fWarning message: \\n\\t For { numbers_of_assemblies . count ( 0 ) } proteins \" f \"no assembly was found. \\n \" f \" \\t These proteins' records can be suppressed by the ncbi \\n\\t \" f \"or they don't have loci that satisfies refseq_sequnces_regex config parameter. \\n\\t \" f \"List of these proteins was saved as: { os . path . basename ( proteins_wo_assemblies_path ) } \" , file = sys . stderr ) if len ( list_of_protein_with_multiple_assemblies ) > 0 : print ( f \"\u2757\ufe0fWarning message: \\n\\t For { len ( list_of_protein_with_multiple_assemblies ) } proteins \" f \"multiple assemblies were found in identical protein database \\n \" f \" \\t with max number of assemblies per one protein as { max ( numbers_of_assemblies ) } \ud83d\ude31. \\n\\t \" f \"A table with information about the assemblies was saved as a tsv file: \" f \" { os . path . basename ( assemblies_table_path ) } . \\n\\t You can edit it and remove lines with assemblies \" f \"you do not want to include in your analysis. \\n \" f \" \\t After filtering, you can use -al cmd parameter with your table as an argument. \\n \" f \" \\t In addition, config file has 'max_number_of_assemblies' parameter \" f \"(set as { self . parameters . arguments [ 'max_number_of_assemblies' ] } ). \\n\\t By default \u2755, it's used \" f \"by uorf4u to limit max number of assemblies included in the analysis; \\n \" f \" \\t and it works only if '-al' option is not provided. In case number of assemblies is more than \" f \"the cutoff, \\n\\t random sampling \ud83c\udfb2 will be used to take only subset of them. \\n\\t \" f \"Selected assemblies information was savead as a tsv file: \" f \" { os . path . basename ( assemblies_selected_table_path ) } \" f \" \\n\\t See documentation \ud83d\udcd6 for details.\" , file = sys . stderr ) else : assemblies_table = pandas . read_table ( self . parameters . arguments [ \"assemblies_list\" ], sep = \" \\t \" ) locus_ids = assemblies_table [ \"locus_id\" ] . to_list () locus_ids = [ id . split ( \":\" )[ 0 ] for id in locus_ids ] upstream_sequences = [] an_with_no_annotated_useq = [] for record in self . records : assemblies = record . assemblies_coordinates if isinstance ( self . parameters . arguments [ \"max_number_of_assemblies\" ], int ) and \\ self . parameters . arguments [ \"assemblies_list\" ] == \"NA\" : if len ( assemblies ) >= self . parameters . arguments [ \"max_number_of_assemblies\" ]: assemblies = random . sample ( assemblies , self . parameters . arguments [ \"max_number_of_assemblies\" ]) if self . parameters . arguments [ \"assemblies_list\" ] != \"NA\" : assemblies_filtered = [ i for i in assemblies if i [ \"locus_id\" ] in locus_ids ] assemblies = assemblies_filtered record . assemblies_coordinates = assemblies assemblies_table = [ f \"accession_number \\t locus_id \\t assembly \\t organism \\t strain \\t tax_id\" ] for record in self . records : for assembly in record . assemblies_coordinates : assemblies_table . append ( f \" { record . accession_number } \\t \" f \" { assembly [ 'locus_id' ] } : { assembly [ 'start' ] } : { assembly [ 'stop' ] } ( { assembly [ 'strand' ] } )\" f \" \\t { assembly [ 'assembly' ] } \" f \" \\t { assembly [ 'org' ] } \\t { assembly [ 'strain' ] } \\t { assembly [ 'taxid' ] } \" ) assemblies_table_file = open ( assemblies_selected_table_path , \"w\" ) assemblies_table_file . write ( \" \\n \" . join ( assemblies_table )) assemblies_table_file . close () lists_of_assemblies = [ record . assemblies_coordinates for record in self . records ] all_assemblies = [ assembly for sublist in lists_of_assemblies for assembly in sublist ] for i in range ( 0 , len ( all_assemblies ), 150 ): assemblies_subset = all_assemblies [ i : i + 150 ] sequences_ids = [ assembly [ \"locus_id\" ] for assembly in assemblies_subset ] handle = Bio . Entrez . efetch ( db = \"nucleotide\" , rettype = \"fasta\" , retmode = \"txt\" , id = sequences_ids ) records = Bio . SeqIO . parse ( handle , \"fasta\" ) for record , assembly in zip ( records , assemblies_subset ): assembly [ \"record\" ] = record for record in self . records : record_upstream_sequences = [] for assembly in record . assemblies_coordinates : locus_record = assembly [ \"record\" ] try : useq_downstream_region_length = min ( self . parameters . arguments [ \"downstream_region_length\" ], len ( record . record . seq ) * 3 ) except : useq_downstream_region_length = self . parameters . arguments [ \"downstream_region_length\" ] useq_upstream_region_length = self . parameters . arguments [ \"upstream_region_length\" ] if assembly [ \"strand\" ] == \"+\" : if self . parameters . arguments [ \"upstream_region_length\" ] == \"all\" : useq_start = 0 else : useq_start = max ( 0 , assembly [ \"start\" ] - self . parameters . arguments [ \"upstream_region_length\" ]) if useq_start == 0 : useq_upstream_region_length = assembly [ \"start\" ] useq_stop = min ( assembly [ \"start\" ] + self . parameters . arguments [ \"downstream_region_length\" ], len ( locus_record . seq )) if useq_stop == len ( locus_record . seq ): useq_downstream_region_length = len ( locus_record . seq ) - assembly [ \"start\" ] elif assembly [ \"strand\" ] == \"-\" : useq_start = max ( 0 , assembly [ \"stop\" ] - self . parameters . arguments [ \"downstream_region_length\" ]) if useq_start == 0 : useq_downstream_region_length = assembly [ \"stop\" ] if self . parameters . arguments [ \"upstream_region_length\" ] == \"all\" : useq_stop = len ( locus_record . seq ) else : useq_stop = min ( len ( locus_record . seq ), assembly [ \"stop\" ] + self . parameters . arguments [ \"upstream_region_length\" ]) if useq_stop == len ( locus_record . seq ): useq_upstream_region_length = len ( locus_record . seq ) - assembly [ \"stop\" ] useq_length = abs ( useq_stop - useq_start ) if self . parameters . arguments [ \"upstream_region_length\" ] != 'all' : if self . parameters . arguments [ \"minimal_upstream_region_length\" ] >= self . parameters . arguments [ \"upstream_region_length\" ]: self . parameters . arguments [ \"minimal_upstream_region_length\" ] = self . parameters . arguments [ \"upstream_region_length\" ] if useq_upstream_region_length >= self . parameters . arguments [ \"minimal_upstream_region_length\" ] or \\ self . parameters . arguments [ \"upstream_region_length\" ] == \"all\" : useq = locus_record . seq [ useq_start : useq_stop ] if assembly [ \"strand\" ] == \"-\" : useq = useq . reverse_complement () if assembly [ \"strain\" ] == \"NA\" : useq_name = assembly [ \"org\" ] elif assembly [ \"strain\" ] in assembly [ \"org\" ]: useq_name = f \" { assembly [ 'org' ] . replace ( assembly [ 'strain' ], '' ) }{ assembly [ 'strain' ] } \" else : useq_name = f \" { assembly [ 'org' ] } { assembly [ 'strain' ] } \" useq_id = f \" { assembly [ 'locus_id' ] } | { useq_start } - { useq_stop } ( { assembly [ 'strand' ] } )|\" \\ f \" { record . accession_number } \" # useq_id = f\"{useq_name}|{assembly['locus_id']}|{record.accession_number}\" useq_label = f \" { useq_name } | { assembly [ 'locus_id' ] } | { record . accession_number } \" useq_annotations = dict ( RefSeq = True , locus_record = locus_record , locus_id = assembly [ 'locus_id' ], length = useq_length , start = useq_start , stop = useq_stop , strand = assembly [ \"strand\" ], accession_number = record . accession_number , organism = assembly [ 'org' ], label = useq_label , upstream_region_length = useq_upstream_region_length , downstream_region_length = useq_downstream_region_length ) useq_record = Bio . SeqRecord . SeqRecord ( useq , id = useq_id , description = useq_name , annotations = useq_annotations ) record_upstream_sequences . append ( useq_record ) upstream_sequences += record_upstream_sequences if len ( record_upstream_sequences ) == 0 : an_with_no_annotated_useq . append ( record . accession_number ) if an_with_no_annotated_useq : print ( f \"\u2757Warning message: \\n\\t No upstream sequences for { len ( an_with_no_annotated_useq ) } protein(s)\" f \" were annotated. \\n\\t Corresponding loci in the nucleotide ncbi database can be too short \ud83d\udccf. \\n \" f \" \\t See 'minimal_upstream_region_length' config parameter description in the documentation.\" , file = sys . stderr ) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\u2705 { len ( upstream_sequences ) } upstream sequences were obtained.\" , file = sys . stdout ) return upstream_sequences except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to retrieve upstream sequences.\" ) from error Locus A Locus object holds sequence and annotation of the corresponding ncbi Reference Sequence. Attributes: locus_id ( str ) \u2013 a NCBI locus id from the Nucleotide database. locus_record ( Bio . SeqRecord . SeqRecord ) \u2013 a biopython record object of the sequence. CDSs ( list ) \u2013 list of dicts with information about annotated CDS in the locus' sequence. start_b ( int ) \u2013 start of region within annotation should be retrieved. stop_b ( int ) \u2013 stop of region within annotation should be retrieved. Source code in uorf4u/data_processing.py 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 class Locus : \"\"\" A Locus object holds sequence and annotation of the corresponding ncbi Reference Sequence. Attributes: locus_id (str): a NCBI locus id from the Nucleotide database. locus_record (Bio.SeqRecord.SeqRecord): a biopython record object of the sequence. CDSs (list): list of dicts with information about annotated CDS in the locus' sequence. start_b (int): start of region within annotation should be retrieved. stop_b (int): stop of region within annotation should be retrieved. \"\"\" def __init__ ( self , locus_id : str , start_b : int = 0 , stop_b : int = None , target_strand : str = \"NA\" , locus_record = None , xml_output = None ): \"\"\"Create a Locus object. Note: 0-based format is used for sequence indexing. Arguments: locus_id (str): locus id from the ncbi nucleotide database. start_b (int): start of region within annotation should be retrieved (optional). stop_b (int): stop of region within annotation should be retrieved (optional). target_strand (str): strand of the target object (optional). \"\"\" try : self . locus_id = locus_id if not locus_record : handle = Bio . Entrez . efetch ( db = \"nucleotide\" , rettype = \"fasta\" , retmode = \"txt\" , id = locus_id ) self . locus_record = Bio . SeqIO . read ( handle , \"fasta\" ) else : self . locus_record = locus_record if stop_b is None : stop_b = len ( self . locus_record . seq ) if not xml_output : handle = Bio . Entrez . efetch ( db = \"nucleotide\" , rettype = \"gbwithparts\" , retmode = \"xml\" , id = locus_id ) xml_output = ( handle . read ()) . decode ( \"utf-8\" ) root = xml . etree . ElementTree . fromstring ( xml_output ) self . CDSs = [] for gbseq in root . iter ( \"GBSeq\" ): if gbseq . find ( \"GBSeq_accession-version\" ) . text == self . locus_id : for gbfeature in gbseq . iter ( \"GBFeature\" ): if gbfeature . find ( \"GBFeature_key\" ) . text == \"CDS\" : try : starts , stops = [], [] for interval in gbfeature . iter ( \"GBInterval\" ): try : start , stop = int ( interval . find ( \"GBInterval_from\" ) . text ), int ( interval . find ( \"GBInterval_to\" ) . text ) if start > stop : start , stop , strand = stop - 1 , start , \"-\" else : start , stop , strand = start - 1 , stop , \"+\" starts . append ( start ) stops . append ( stop ) except : pass if starts : coordinates = list ( sorted ( zip ( starts , stops ), key = lambda pair : pair [ 0 ])) main_start , main_stop = coordinates [ 0 ][ 0 ], coordinates [ - 1 ][ - 1 ] if strand == \"+\" : main_stop = main_stop - 3 elif strand == \"-\" : main_start = main_start + 3 relative_start , relative_stop = main_start - start_b , main_stop - start_b if strand == target_strand : relative_strand = \"+\" else : relative_strand = \"-\" useq_length = stop_b - start_b if target_strand == \"-\" : relative_start , relative_stop = useq_length - relative_stop , useq_length - relative_start if ( start_b <= main_start < stop_b ) or ( start_b <= main_stop < stop_b ): cds_seq = self . locus_record . seq [ main_start : main_stop ] if strand == '-' : cds_seq = cds_seq . reverse_complement () protein_id , product_name = 'NA' , 'NA' for gbqualifier in gbfeature . iter ( \"GBQualifier\" ): if gbqualifier . find ( \"GBQualifier_name\" ) . text == \"protein_id\" : protein_id = gbqualifier . find ( \"GBQualifier_value\" ) . text if gbqualifier . find ( \"GBQualifier_name\" ) . text == \"product\" : product_name = gbqualifier . find ( \"GBQualifier_value\" ) . text if protein_id != 'NA' : if product_name != 'NA' : product_name = f \" { protein_id } ( { product_name } )\" else : product_name = f \" { protein_id } \" self . CDSs . append ( dict ( protein_id = protein_id , product_name = product_name , coordinates = coordinates , nt_seq = cds_seq , main_start = main_start , main_stop = main_stop , strand = strand , relative_start = relative_start , relative_stop = relative_stop , relative_strand = relative_strand )) except : pass except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to create a Locus class' object.\" ) from error __init__ ( locus_id , start_b = 0 , stop_b = None , target_strand = 'NA' , locus_record = None , xml_output = None ) Create a Locus object. Note: 0-based format is used for sequence indexing. Parameters: locus_id ( str ) \u2013 locus id from the ncbi nucleotide database. start_b ( int ) \u2013 start of region within annotation should be retrieved (optional). stop_b ( int ) \u2013 stop of region within annotation should be retrieved (optional). target_strand ( str ) \u2013 strand of the target object (optional). Source code in uorf4u/data_processing.py 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 def __init__ ( self , locus_id : str , start_b : int = 0 , stop_b : int = None , target_strand : str = \"NA\" , locus_record = None , xml_output = None ): \"\"\"Create a Locus object. Note: 0-based format is used for sequence indexing. Arguments: locus_id (str): locus id from the ncbi nucleotide database. start_b (int): start of region within annotation should be retrieved (optional). stop_b (int): stop of region within annotation should be retrieved (optional). target_strand (str): strand of the target object (optional). \"\"\" try : self . locus_id = locus_id if not locus_record : handle = Bio . Entrez . efetch ( db = \"nucleotide\" , rettype = \"fasta\" , retmode = \"txt\" , id = locus_id ) self . locus_record = Bio . SeqIO . read ( handle , \"fasta\" ) else : self . locus_record = locus_record if stop_b is None : stop_b = len ( self . locus_record . seq ) if not xml_output : handle = Bio . Entrez . efetch ( db = \"nucleotide\" , rettype = \"gbwithparts\" , retmode = \"xml\" , id = locus_id ) xml_output = ( handle . read ()) . decode ( \"utf-8\" ) root = xml . etree . ElementTree . fromstring ( xml_output ) self . CDSs = [] for gbseq in root . iter ( \"GBSeq\" ): if gbseq . find ( \"GBSeq_accession-version\" ) . text == self . locus_id : for gbfeature in gbseq . iter ( \"GBFeature\" ): if gbfeature . find ( \"GBFeature_key\" ) . text == \"CDS\" : try : starts , stops = [], [] for interval in gbfeature . iter ( \"GBInterval\" ): try : start , stop = int ( interval . find ( \"GBInterval_from\" ) . text ), int ( interval . find ( \"GBInterval_to\" ) . text ) if start > stop : start , stop , strand = stop - 1 , start , \"-\" else : start , stop , strand = start - 1 , stop , \"+\" starts . append ( start ) stops . append ( stop ) except : pass if starts : coordinates = list ( sorted ( zip ( starts , stops ), key = lambda pair : pair [ 0 ])) main_start , main_stop = coordinates [ 0 ][ 0 ], coordinates [ - 1 ][ - 1 ] if strand == \"+\" : main_stop = main_stop - 3 elif strand == \"-\" : main_start = main_start + 3 relative_start , relative_stop = main_start - start_b , main_stop - start_b if strand == target_strand : relative_strand = \"+\" else : relative_strand = \"-\" useq_length = stop_b - start_b if target_strand == \"-\" : relative_start , relative_stop = useq_length - relative_stop , useq_length - relative_start if ( start_b <= main_start < stop_b ) or ( start_b <= main_stop < stop_b ): cds_seq = self . locus_record . seq [ main_start : main_stop ] if strand == '-' : cds_seq = cds_seq . reverse_complement () protein_id , product_name = 'NA' , 'NA' for gbqualifier in gbfeature . iter ( \"GBQualifier\" ): if gbqualifier . find ( \"GBQualifier_name\" ) . text == \"protein_id\" : protein_id = gbqualifier . find ( \"GBQualifier_value\" ) . text if gbqualifier . find ( \"GBQualifier_name\" ) . text == \"product\" : product_name = gbqualifier . find ( \"GBQualifier_value\" ) . text if protein_id != 'NA' : if product_name != 'NA' : product_name = f \" { protein_id } ( { product_name } )\" else : product_name = f \" { protein_id } \" self . CDSs . append ( dict ( protein_id = protein_id , product_name = product_name , coordinates = coordinates , nt_seq = cds_seq , main_start = main_start , main_stop = main_stop , strand = strand , relative_start = relative_start , relative_stop = relative_stop , relative_strand = relative_strand )) except : pass except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to create a Locus class' object.\" ) from error ORF An ORF object holds information about an annotated ORF. Note: It's supposed that the ORFs class' objects will not be used directly by API users since it's only needed for other classes' methods. Attributes: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. id ( str ) \u2013 identifier of the ORF. Format: locus_id|accession_number|distance_from_the_start_codon_to_the_main_orf name ( str ) \u2013 name of the ORF. Format: useq_name|distance_from_the_start_codon_to_the_main_orf sequence_id ( str ) \u2013 identifier of the ORF's sequence (locus id from the ncbi database). start ( int ) \u2013 start position of the ORF on the locus (0-based). stop ( int ) \u2013 stop position of the ORF on the locus (0-based). length ( int ) \u2013 ORF's nucleotide sequence length. nt_sequence ( Bio . Seq . Seq ) \u2013 a Seq object of nucleotide sequence of the ORF. aa_sequence ( Bio . Seq . Seq ) \u2013 a Seq object of amino acid sequence of the ORF. sd_window_seq ( Bio . Seq . Seq ) \u2013 a Seq object of upstream sequence to the start codon of the ORF. min_energy ( float ) \u2013 minimal value of thermodynamic interaction between aSD and putative SD sequences within the upstream sequences to the start codon. putative_sd_sequence ( Bio . Seq . Seq ) \u2013 a Seq object of the putative SD sequence with the minimal energy value. extended_orfs ( list ) \u2013 a list of ORFs with that are in frame with the ORF, but have upstream start codon. Source code in uorf4u/data_processing.py 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 class ORF : \"\"\"An ORF object holds information about an annotated ORF. Note: It's supposed that the ORFs class' objects will not be used directly by API users since it's only needed for other classes' methods. Attributes: parameters (uorf4u.manager.Parameters): Parameters' class object. id (str): identifier of the ORF. Format: locus_id|accession_number|distance_from_the_start_codon_to_the_main_orf name (str): name of the ORF. Format: useq_name|distance_from_the_start_codon_to_the_main_orf sequence_id (str): identifier of the ORF's sequence (locus id from the ncbi database). start (int): start position of the ORF on the locus (0-based). stop (int): stop position of the ORF on the locus (0-based). length (int): ORF's nucleotide sequence length. nt_sequence (Bio.Seq.Seq): a Seq object of nucleotide sequence of the ORF. aa_sequence (Bio.Seq.Seq): a Seq object of amino acid sequence of the ORF. sd_window_seq (Bio.Seq.Seq): a Seq object of upstream sequence to the start codon of the ORF. min_energy (float): minimal value of thermodynamic interaction between aSD and putative SD sequences within the upstream sequences to the start codon. putative_sd_sequence (Bio.Seq.Seq): a Seq object of the putative SD sequence with the minimal energy value. extended_orfs (list): a list of ORFs with that are in frame with the ORF, but have upstream start codon. \"\"\" def __init__ ( self , parameters : uorf4u . manager . Parameters , id : str , name : str , nt_sequence : Bio . Seq . Seq , sd_window_seq : Bio . Seq . Seq , start : int , stop : int , distance : int , useq_index : int , annotation : str = \"NA\" ): \"\"\"Create an ORF object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. id (str): identifier of the ORF. Format: locus_id:distance_from_the_start_codon_to_the_proteins_orf:length. nt_sequence (Bio.Seq.Seq): a Seq object of nucleotide sequence of the ORF. sd_window_seq (Bio.Seq.Seq): a Seq object of upstream sequence to the start codon of the ORF. start (int): start position of the ORF on the locus (0-based). stop (int): stop position of the ORF on the locus (0-based). distance (int): distance to the main ORF. \"\"\" self . parameters = parameters codon_table = Bio . Data . CodonTable . unambiguous_dna_by_name [ # ambiguous can be needed! parameters . arguments [ \"ncbi_genetic_code_name\" ]] codon_table_ambiguous = Bio . Data . CodonTable . ambiguous_dna_by_name [ # ambiguous can be needed! parameters . arguments [ \"ncbi_genetic_code_name\" ]] self . name = name self . distance = distance self . id = id self . sequence_id = id . split ( \":\" )[ 0 ] self . start = start self . stop = stop self . length = len ( nt_sequence ) self . nt_sequence = nt_sequence self . annotation = annotation self . useq_index = useq_index try : self . aa_sequence = self . nt_sequence . translate ( table = codon_table ) except : self . aa_sequence = self . nt_sequence . translate ( table = codon_table_ambiguous ) self . sd_window_seq = sd_window_seq self . extended_orfs = [] self . min_energy = 0 self . putative_sd_sequence = \"NA\" self . sd_window_seq_str = \"NA\" self . sd_window_energies = [] def calculate_energies ( self ) -> None : \"\"\"Calculate energies of putative SD sequences of the upstream sequence. Returns: None \"\"\" # Loading reference energies json file with open ( self . parameters . arguments [ \"ref_energies\" ]) as ref_energy_file : ref_energy = json . load ( ref_energy_file ) sd_seq_length = min ([ len ( i ) for i in ref_energy . keys ()]) # Energies calculations if len ( self . sd_window_seq ) >= min ( ref_energy . values ()): energies = [] for position in range (( len ( self . sd_window_seq ) - sd_seq_length ) + 1 ): try : energies . append ( ref_energy [ self . sd_window_seq [ position : position + sd_seq_length ]]) except : energies . append ( 0 ) if energies : self . min_energy = min ( energies ) self . sd_window_energies = [ str ( i ) for i in energies ] if self . min_energy < self . parameters . arguments [ \"sd_energy_cutoff\" ]: sd_start_position = energies . index ( self . min_energy ) # Be careful, it could be more than one! self . putative_sd_sequence = self . sd_window_seq [ sd_start_position : sd_start_position + sd_seq_length ] self . sd_window_seq_str = ( f \" { self . sd_window_seq [ 0 : sd_start_position ] . lower () } \" f \" { self . putative_sd_sequence . upper () } \" f \" { self . sd_window_seq [ sd_start_position + sd_seq_length :] . lower () } \" ) return None __init__ ( parameters , id , name , nt_sequence , sd_window_seq , start , stop , distance , useq_index , annotation = 'NA' ) Create an ORF object. Parameters: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. id ( str ) \u2013 identifier of the ORF. Format: locus_id:distance_from_the_start_codon_to_the_proteins_orf:length. nt_sequence ( Bio . Seq . Seq ) \u2013 a Seq object of nucleotide sequence of the ORF. sd_window_seq ( Bio . Seq . Seq ) \u2013 a Seq object of upstream sequence to the start codon of the ORF. start ( int ) \u2013 start position of the ORF on the locus (0-based). stop ( int ) \u2013 stop position of the ORF on the locus (0-based). distance ( int ) \u2013 distance to the main ORF. Source code in uorf4u/data_processing.py 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 def __init__ ( self , parameters : uorf4u . manager . Parameters , id : str , name : str , nt_sequence : Bio . Seq . Seq , sd_window_seq : Bio . Seq . Seq , start : int , stop : int , distance : int , useq_index : int , annotation : str = \"NA\" ): \"\"\"Create an ORF object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. id (str): identifier of the ORF. Format: locus_id:distance_from_the_start_codon_to_the_proteins_orf:length. nt_sequence (Bio.Seq.Seq): a Seq object of nucleotide sequence of the ORF. sd_window_seq (Bio.Seq.Seq): a Seq object of upstream sequence to the start codon of the ORF. start (int): start position of the ORF on the locus (0-based). stop (int): stop position of the ORF on the locus (0-based). distance (int): distance to the main ORF. \"\"\" self . parameters = parameters codon_table = Bio . Data . CodonTable . unambiguous_dna_by_name [ # ambiguous can be needed! parameters . arguments [ \"ncbi_genetic_code_name\" ]] codon_table_ambiguous = Bio . Data . CodonTable . ambiguous_dna_by_name [ # ambiguous can be needed! parameters . arguments [ \"ncbi_genetic_code_name\" ]] self . name = name self . distance = distance self . id = id self . sequence_id = id . split ( \":\" )[ 0 ] self . start = start self . stop = stop self . length = len ( nt_sequence ) self . nt_sequence = nt_sequence self . annotation = annotation self . useq_index = useq_index try : self . aa_sequence = self . nt_sequence . translate ( table = codon_table ) except : self . aa_sequence = self . nt_sequence . translate ( table = codon_table_ambiguous ) self . sd_window_seq = sd_window_seq self . extended_orfs = [] self . min_energy = 0 self . putative_sd_sequence = \"NA\" self . sd_window_seq_str = \"NA\" self . sd_window_energies = [] calculate_energies () Calculate energies of putative SD sequences of the upstream sequence. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 def calculate_energies ( self ) -> None : \"\"\"Calculate energies of putative SD sequences of the upstream sequence. Returns: None \"\"\" # Loading reference energies json file with open ( self . parameters . arguments [ \"ref_energies\" ]) as ref_energy_file : ref_energy = json . load ( ref_energy_file ) sd_seq_length = min ([ len ( i ) for i in ref_energy . keys ()]) # Energies calculations if len ( self . sd_window_seq ) >= min ( ref_energy . values ()): energies = [] for position in range (( len ( self . sd_window_seq ) - sd_seq_length ) + 1 ): try : energies . append ( ref_energy [ self . sd_window_seq [ position : position + sd_seq_length ]]) except : energies . append ( 0 ) if energies : self . min_energy = min ( energies ) self . sd_window_energies = [ str ( i ) for i in energies ] if self . min_energy < self . parameters . arguments [ \"sd_energy_cutoff\" ]: sd_start_position = energies . index ( self . min_energy ) # Be careful, it could be more than one! self . putative_sd_sequence = self . sd_window_seq [ sd_start_position : sd_start_position + sd_seq_length ] self . sd_window_seq_str = ( f \" { self . sd_window_seq [ 0 : sd_start_position ] . lower () } \" f \" { self . putative_sd_sequence . upper () } \" f \" { self . sd_window_seq [ sd_start_position + sd_seq_length :] . lower () } \" ) return None Path A Path object holds information about a list of conserved ORFs. Note: It's supposed that the Path class' objects will not be used directly by API users since it's only needed for other classes' methods. Attributes: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. path ( list ) \u2013 List of the ORF class objects. score ( float ) \u2013 Score of the Path (calculated as sum of pairwise alignments scores of ORFs). msa ( dict ) \u2013 Dict with Multiple sequence alignment (MSA, Bio.Align.MultipleSeqAlignment object) as values for different sequences (nt, aa, sd) as keys. msa_consensus ( dict ) \u2013 Dict with consensus sequence (Bio.Seq.Seq object) as values for different sequences (nt, aa, sd) as keys. length \u2013 length of the nucleotide sequence alignment. id ( str ) \u2013 Path's id (format: length|score|num_of_orfs|average_distance_to_the_main_ORF Source code in uorf4u/data_processing.py 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 class Path : \"\"\"A Path object holds information about a list of conserved ORFs. Note: It's supposed that the Path class' objects will not be used directly by API users since it's only needed for other classes' methods. Attributes: parameters (uorf4u.manager.Parameters): Parameters' class object. path (list): List of the ORF class objects. score (float): Score of the Path (calculated as sum of pairwise alignments scores of ORFs). msa (dict): Dict with Multiple sequence alignment (MSA, Bio.Align.MultipleSeqAlignment object) as values for different sequences (nt, aa, sd) as keys. msa_consensus (dict): Dict with consensus sequence (Bio.Seq.Seq object) as values for different sequences (nt, aa, sd) as keys. length: length of the nucleotide sequence alignment. id (str): Path's id (format: length|score|num_of_orfs|average_distance_to_the_main_ORF \"\"\" def __init__ ( self , parameters : uorf4u . manager . Parameters ): \"\"\"Create a Path object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . parameters = parameters self . path = [] self . score = 0 self . msa = dict () self . msa_consensus = dict () self . id = None self . length = None def update ( self , orf : ORF , score = 0 ): \"\"\"Update a Path with a new ORF. Arguments: orf (ORF): an ORF class' object. score (float): a sum of pairwise alignment scores of the ORF against all ORFs in the Path. Returns: None \"\"\" self . path . append ( orf ) self . score += score def sort ( self ) -> None : \"\"\"Sort list of ORFs by their names. Returns: None \"\"\" sorted_path = [ x for _ , x in sorted ( zip ([ i . name for i in self . path ], self . path ), key = lambda pair : pair [ 0 ])] self . path = sorted_path return None def __len__ ( self ): \"\"\"__len__ magic method for a Path object. Returns: int: length of the path attribute - a number of ORFs in a Path. \"\"\" return len ( self . path ) def calculate_similarity ( self , other ) -> float : \"\"\"Calculate fraction of identical ORFs between two Path object. __Note:__ If two objects have different length, the fraction will be calculated as a number of identical ORFs divided by length of the shortest Path. Returns: float: fraction of identical ORFs. \"\"\" num_of_identical_elements = len ( set ( self . path ) & set ( other . path )) fraction_of_identical_orfs = num_of_identical_elements / min ( len ( self ), len ( other )) return fraction_of_identical_orfs def muscle_msa ( self ) -> None : \"\"\"Run a multiple sequence alignment tool (muscle) for the ORFs nucleotide and amino acid sequences. Note: This method updates nt_msa and aa_msa attributes. Returns: None \"\"\" self . msa = dict () for seq_type in self . parameters . arguments [ \"sequences_to_write\" ]: records = [] for orf in self . path : # record_id = f\"{orf.id}\" # record_description = f\"{(orf.name.split('|')[0])}\" record_id = f \" { orf . name } \" record_description = \"\" if seq_type == \"nt\" : record = Bio . SeqRecord . SeqRecord ( orf . nt_sequence , record_id , \"\" , record_description ) elif seq_type == \"aa\" : record = Bio . SeqRecord . SeqRecord ( orf . aa_sequence , record_id , \"\" , record_description ) elif seq_type == \"sd\" : record = Bio . SeqRecord . SeqRecord ( orf . sd_window_seq , record_id , \"\" , record_description ) records . append ( record ) temp_input = tempfile . NamedTemporaryFile () Bio . SeqIO . write ( records , temp_input . name , \"fasta\" ) temp_output = tempfile . NamedTemporaryFile () muscle = self . parameters . arguments [ \"muscle_binary\" ] subprocess . run ([ muscle , \"-align\" , temp_input . name , \"-output\" , temp_output . name ], stderr = subprocess . DEVNULL ) temp_input . close () msa = Bio . AlignIO . read ( temp_output . name , \"fasta\" ) # msa.sort(key=lambda r: r.description) msa_info = Bio . Align . AlignInfo . SummaryInfo ( msa ) msa_consensus = msa_info . gap_consensus ( threshold = self . parameters . arguments [ \"consensus_threshold\" ]) temp_output . close () if seq_type == \"nt\" : self . length = msa . get_alignment_length () self . msa [ seq_type ], self . msa_consensus [ seq_type ] = msa , msa_consensus avr_distance = str ( round ( statistics . mean ([ i . distance for i in self . path ]))) self . id = f \"length- { self . msa [ 'nt' ] . get_alignment_length () } |score\u2013 { round ( self . score ) } |\" \\ f \"num_of_orfs- { len ( self . path ) } |avr_dist- { avr_distance } \" return None def maft_msa ( self ) -> None : \"\"\"Run a multiple sequence alignment tool (MAFT) for the ORFs nucleotide and amino acid sequences. Note: This method updates nt_msa and aa_msa attributes. Returns: None \"\"\" self . msa = dict () for seq_type in self . parameters . arguments [ \"sequences_to_write\" ]: records = [] for orf in self . path : # record_id = f\"{orf.id}\" # record_description = f\"{(orf.name.split('|')[0])}\" record_id = f \" { orf . id } \" record_description = orf . name if seq_type == \"nt\" : record = Bio . SeqRecord . SeqRecord ( orf . nt_sequence , record_id , \"\" , record_description ) elif seq_type == \"aa\" : record = Bio . SeqRecord . SeqRecord ( orf . aa_sequence , record_id , \"\" , record_description ) elif seq_type == \"sd\" : record = Bio . SeqRecord . SeqRecord ( orf . sd_window_seq , record_id , \"\" , record_description ) records . append ( record ) temp_input = tempfile . NamedTemporaryFile () Bio . SeqIO . write ( records , temp_input . name , \"fasta\" ) temp_output = tempfile . NamedTemporaryFile () temp_stderr = tempfile . NamedTemporaryFile () maft = self . parameters . arguments [ \"maft_binary\" ] try : subprocess . run ([ maft , \"--auto\" , temp_input . name ], stdout = temp_output , stderr = temp_stderr ) msa = Bio . AlignIO . read ( temp_output . name , \"fasta\" ) temp_stderr . close () temp_output . close () except Exception as error : temp_stderr . seek ( 0 ) temp_output . seek ( 0 ) print ( f \"\ud83e\udd2c MAFFT error message: \\n { temp_stderr . read () } \" , file = sys . stderr ) temp_stderr . close () temp_output . close () raise uorf4u . manager . uORF4uError ( f \"mafft error. If you work on a linux machine,\" f \" run uorf4 --linux.\" ) from error for record in msa : record . description = \" \" . join ( record . description . split ( \" \" )[ 1 :]) # msa.sort(key=lambda r: r.description) # add a parameter for order setting msa_info = Bio . Align . AlignInfo . SummaryInfo ( msa ) msa_consensus = msa_info . gap_consensus ( threshold = self . parameters . arguments [ \"consensus_threshold\" ]) temp_output . close () if seq_type == \"nt\" : self . length = msa . get_alignment_length () self . msa [ seq_type ], self . msa_consensus [ seq_type ] = msa , msa_consensus avr_distance = str ( round ( statistics . mean ([ i . distance for i in self . path ]))) self . id = f \"length- { self . msa [ 'nt' ] . get_alignment_length () } |score\u2013 { round ( self . score ) } |\" \\ f \"num_of_orfs- { len ( self . path ) } |avr_dist- { avr_distance } \" return None def plot_msa ( self ) -> None : \"\"\"Plot MSA of conserved ORFs. Returns: None \"\"\" rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_visualisation\" ) for i in self . parameters . arguments [ \"sequences_to_write\" ]])) for o_dir in output_dirs . values (): if not ( os . path . exists ( o_dir )): os . mkdir ( o_dir ) for s_type in self . parameters . arguments [ \"sequences_to_write\" ]: current_msa = self . msa [ s_type ] if s_type == \"nt\" or s_type == \"sd\" : seq_type = \"nt\" else : seq_type = \"aa\" msa_plot_manager = uorf4u . drawing_msa . MSAPlotManager ( current_msa , self . parameters , seq_type ) msa_plot_manager . define_x_axis_coordinate_system () output_file = os . path . join ( output_dirs [ s_type ], f \" { self . id } .pdf\" ) msa_plot_manager . create_tracks () msa_plot_manager . plot ( output_file ) def plot_ggmsa ( self ) -> None : \"\"\"Plot MSA of conserved ORFs saved as fasta files. Note: R script based on ggmsa package [yulab-smu.top/ggmsa] used to produce MSA plots. R script (msa_plot.R) can be found in output_dir. This method uses subprocess to run this R script in the following way: `Rscript {output_dir}/msa_plot.R --msa_fasta path_to_fasta --output output_path --seq_type (nt/aa) --width N(mm) --height M(mm)`. Since during each run of uorf4u a local copy of this script is created in your output_dir, you can change it without any consequences for next uorf4u runs. Returns: None \"\"\" rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_visualisation\" ) for i in self . parameters . arguments [ \"sequences_to_write\" ]])) fasta_files_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_fasta_files\" ) for i in self . parameters . arguments [ \"sequences_to_write\" ]])) for o_dir in output_dirs . values (): if not ( os . path . exists ( o_dir )): os . mkdir ( o_dir ) r_script_path = self . parameters . arguments [ \"plot_msa_R_script\" ] r_script_local = os . path . join ( self . parameters . arguments [ \"output_dir\" ], os . path . basename ( r_script_path )) if not ( os . path . exists ( r_script_local )): shutil . copy ( r_script_path , r_script_local ) for s_type in self . parameters . arguments [ \"sequences_to_write\" ]: current_msa = self . msa [ s_type ] if s_type == \"nt\" or s_type == \"sd\" : seq_type = \"nt\" else : seq_type = \"aa\" output_dir = os . path . abspath ( os . path . join ( output_dirs [ s_type ])) input_file = os . path . abspath ( os . path . join ( fasta_files_dirs [ s_type ], f \" { self . id } .fa\" )) num_sequences = len ( current_msa ) length_of_alignment = current_msa . get_alignment_length () page_width = ( 50 + length_of_alignment ) * 5 page_height = max ( 17 , ( num_sequences + 5 ) * 3 ) subprocess . run ([ \"Rscript\" , r_script_local , \"--msa_fasta\" , input_file , \"--output\" , output_dir , \"--seq_type\" , seq_type , \"--width\" , str ( page_width ), \"--height\" , str ( page_height )]) def plot_logo ( self ) -> None : \"\"\"Plot sequence Logo of conserved ORFs MSA saved as fasta files. Note: This method uses logomaker package to produce images. Returns: None \"\"\" rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _seqlogo_visualisation\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) for o_dir in output_dirs . values (): if not ( os . path . exists ( o_dir )): os . mkdir ( o_dir ) ambiguous_codon_table = Bio . Data . CodonTable . ambiguous_dna_by_name [ self . parameters . arguments [ \"ncbi_genetic_code_name\" ]] unambiguous_codon_table = Bio . Data . CodonTable . unambiguous_dna_by_name [ self . parameters . arguments [ \"ncbi_genetic_code_name\" ]] alphabet = dict ( nt = set ( ambiguous_codon_table . nucleotide_alphabet ), aa = set ( ambiguous_codon_table . protein_alphabet )) unambiguous_alphabet = dict ( nt = set ( unambiguous_codon_table . nucleotide_alphabet ), aa = set ( unambiguous_codon_table . protein_alphabet )) for s_type in self . parameters . arguments [ \"sequences_to_write\" ]: current_msa = self . msa [ s_type ] if s_type == \"nt\" or s_type == \"sd\" : seq_type = \"nt\" elif s_type == \"aa\" : seq_type = \"aa\" output_file = os . path . abspath ( os . path . join ( output_dirs [ s_type ], os . path . basename ( self . id ))) msa_length = current_msa . get_alignment_length () num_of_sequences = len ( current_msa ) current_msa_info = Bio . Align . AlignInfo . SummaryInfo ( current_msa ) pos_specific_dict = dict () pos_specific_score_matrix = current_msa_info . pos_specific_score_matrix () for i in alphabet [ seq_type ]: pos_specific_dict [ i ] = [ 0 for j in range ( msa_length )] for i in range ( msa_length ): for element in pos_specific_score_matrix [ i ] . keys (): pos_specific_dict [ element . upper ()][ i ] = ( pos_specific_score_matrix [ i ][ element ] / num_of_sequences ) pos = [ i for i in range ( msa_length )] pos_specific_dict = { k : v for k , v in pos_specific_dict . items () if sum ( v ) > 0 or k in unambiguous_alphabet [ seq_type ]} matrix_fr = pandas . DataFrame ( pos_specific_dict , index = pos ) colors = self . parameters . arguments [ f \"colors_ { seq_type } \" ] colors = { k : uorf4u . methods . color_name_to_hex ( v , self . parameters . arguments ) for k , v in colors . items ()} fig_size = ( min ( max ( 10 , msa_length * 1.3 ), (( 2 ** 16 ) - 1 ) / 100 ), min ( 2.5 , 2.5 * 10 / ( msa_length ** ( 1 / 5 )))) if self . parameters . arguments [ \"logo_type\" ] == \"probability\" or \\ self . parameters . arguments [ \"logo_type\" ] == \"both\" : output_file_fr = f \" { output_file } _prob.pdf\" max_value_fr = 1 logo_fr = logomaker . Logo ( matrix_fr , color_scheme = colors , figsize = fig_size , alpha = self . parameters . arguments [ \"logo_alpha\" ], show_spines = False , baseline_width = 0 ) logo_fr . style_spines ( spines = [ \"left\" ], visible = True , linewidth = 0.7 ) logo_fr . ax . set_xticks ([]) logo_fr . ax . set_yticks ([ 0 , max_value_fr ]) plt . savefig ( output_file_fr ) plt . close ( \"all\" ) if self . parameters . arguments [ \"logo_type\" ] == \"information\" or \\ self . parameters . arguments [ \"logo_type\" ] == \"both\" : colors [ \"-\" ] = colors [ \"_\" ] matrix_fr [ \"-\" ] = round (( 1 - matrix_fr . sum ( axis = 1 )), 5 ) if matrix_fr [ \"-\" ] . sum () == 0 : del matrix_fr [ '-' ] matrix_info = logomaker . transform_matrix ( matrix_fr , from_type = \"probability\" , to_type = \"information\" ) max_value_info = math . log2 ( len ( pos_specific_dict . keys ())) output_file_info = f \" { output_file } _info.pdf\" logo_info = logomaker . Logo ( matrix_info , color_scheme = colors , figsize = fig_size , alpha = self . parameters . arguments [ \"logo_alpha\" ], show_spines = False , baseline_width = 0 ) logo_info . style_spines ( spines = [ \"left\" ], visible = True , linewidth = 0.7 ) logo_info . ax . set_xticks ([]) logo_info . ax . set_yticks ([ 0 , max_value_info ]) plt . savefig ( output_file_info ) plt . close ( \"all\" ) return None __init__ ( parameters ) Create a Path object. Parameters: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/data_processing.py 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 def __init__ ( self , parameters : uorf4u . manager . Parameters ): \"\"\"Create a Path object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . parameters = parameters self . path = [] self . score = 0 self . msa = dict () self . msa_consensus = dict () self . id = None self . length = None __len__ () len magic method for a Path object. Returns: int \u2013 length of the path attribute - a number of ORFs in a Path. Source code in uorf4u/data_processing.py 1484 1485 1486 1487 1488 1489 1490 1491 def __len__ ( self ): \"\"\"__len__ magic method for a Path object. Returns: int: length of the path attribute - a number of ORFs in a Path. \"\"\" return len ( self . path ) calculate_similarity ( other ) Calculate fraction of identical ORFs between two Path object. Note: If two objects have different length, the fraction will be calculated as a number of identical ORFs divided by length of the shortest Path. Returns: float ( float ) \u2013 fraction of identical ORFs. Source code in uorf4u/data_processing.py 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 def calculate_similarity ( self , other ) -> float : \"\"\"Calculate fraction of identical ORFs between two Path object. __Note:__ If two objects have different length, the fraction will be calculated as a number of identical ORFs divided by length of the shortest Path. Returns: float: fraction of identical ORFs. \"\"\" num_of_identical_elements = len ( set ( self . path ) & set ( other . path )) fraction_of_identical_orfs = num_of_identical_elements / min ( len ( self ), len ( other )) return fraction_of_identical_orfs maft_msa () Run a multiple sequence alignment tool (MAFT) for the ORFs nucleotide and amino acid sequences. Note: This method updates nt_msa and aa_msa attributes. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 def maft_msa ( self ) -> None : \"\"\"Run a multiple sequence alignment tool (MAFT) for the ORFs nucleotide and amino acid sequences. Note: This method updates nt_msa and aa_msa attributes. Returns: None \"\"\" self . msa = dict () for seq_type in self . parameters . arguments [ \"sequences_to_write\" ]: records = [] for orf in self . path : # record_id = f\"{orf.id}\" # record_description = f\"{(orf.name.split('|')[0])}\" record_id = f \" { orf . id } \" record_description = orf . name if seq_type == \"nt\" : record = Bio . SeqRecord . SeqRecord ( orf . nt_sequence , record_id , \"\" , record_description ) elif seq_type == \"aa\" : record = Bio . SeqRecord . SeqRecord ( orf . aa_sequence , record_id , \"\" , record_description ) elif seq_type == \"sd\" : record = Bio . SeqRecord . SeqRecord ( orf . sd_window_seq , record_id , \"\" , record_description ) records . append ( record ) temp_input = tempfile . NamedTemporaryFile () Bio . SeqIO . write ( records , temp_input . name , \"fasta\" ) temp_output = tempfile . NamedTemporaryFile () temp_stderr = tempfile . NamedTemporaryFile () maft = self . parameters . arguments [ \"maft_binary\" ] try : subprocess . run ([ maft , \"--auto\" , temp_input . name ], stdout = temp_output , stderr = temp_stderr ) msa = Bio . AlignIO . read ( temp_output . name , \"fasta\" ) temp_stderr . close () temp_output . close () except Exception as error : temp_stderr . seek ( 0 ) temp_output . seek ( 0 ) print ( f \"\ud83e\udd2c MAFFT error message: \\n { temp_stderr . read () } \" , file = sys . stderr ) temp_stderr . close () temp_output . close () raise uorf4u . manager . uORF4uError ( f \"mafft error. If you work on a linux machine,\" f \" run uorf4 --linux.\" ) from error for record in msa : record . description = \" \" . join ( record . description . split ( \" \" )[ 1 :]) # msa.sort(key=lambda r: r.description) # add a parameter for order setting msa_info = Bio . Align . AlignInfo . SummaryInfo ( msa ) msa_consensus = msa_info . gap_consensus ( threshold = self . parameters . arguments [ \"consensus_threshold\" ]) temp_output . close () if seq_type == \"nt\" : self . length = msa . get_alignment_length () self . msa [ seq_type ], self . msa_consensus [ seq_type ] = msa , msa_consensus avr_distance = str ( round ( statistics . mean ([ i . distance for i in self . path ]))) self . id = f \"length- { self . msa [ 'nt' ] . get_alignment_length () } |score\u2013 { round ( self . score ) } |\" \\ f \"num_of_orfs- { len ( self . path ) } |avr_dist- { avr_distance } \" return None muscle_msa () Run a multiple sequence alignment tool (muscle) for the ORFs nucleotide and amino acid sequences. Note: This method updates nt_msa and aa_msa attributes. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 def muscle_msa ( self ) -> None : \"\"\"Run a multiple sequence alignment tool (muscle) for the ORFs nucleotide and amino acid sequences. Note: This method updates nt_msa and aa_msa attributes. Returns: None \"\"\" self . msa = dict () for seq_type in self . parameters . arguments [ \"sequences_to_write\" ]: records = [] for orf in self . path : # record_id = f\"{orf.id}\" # record_description = f\"{(orf.name.split('|')[0])}\" record_id = f \" { orf . name } \" record_description = \"\" if seq_type == \"nt\" : record = Bio . SeqRecord . SeqRecord ( orf . nt_sequence , record_id , \"\" , record_description ) elif seq_type == \"aa\" : record = Bio . SeqRecord . SeqRecord ( orf . aa_sequence , record_id , \"\" , record_description ) elif seq_type == \"sd\" : record = Bio . SeqRecord . SeqRecord ( orf . sd_window_seq , record_id , \"\" , record_description ) records . append ( record ) temp_input = tempfile . NamedTemporaryFile () Bio . SeqIO . write ( records , temp_input . name , \"fasta\" ) temp_output = tempfile . NamedTemporaryFile () muscle = self . parameters . arguments [ \"muscle_binary\" ] subprocess . run ([ muscle , \"-align\" , temp_input . name , \"-output\" , temp_output . name ], stderr = subprocess . DEVNULL ) temp_input . close () msa = Bio . AlignIO . read ( temp_output . name , \"fasta\" ) # msa.sort(key=lambda r: r.description) msa_info = Bio . Align . AlignInfo . SummaryInfo ( msa ) msa_consensus = msa_info . gap_consensus ( threshold = self . parameters . arguments [ \"consensus_threshold\" ]) temp_output . close () if seq_type == \"nt\" : self . length = msa . get_alignment_length () self . msa [ seq_type ], self . msa_consensus [ seq_type ] = msa , msa_consensus avr_distance = str ( round ( statistics . mean ([ i . distance for i in self . path ]))) self . id = f \"length- { self . msa [ 'nt' ] . get_alignment_length () } |score\u2013 { round ( self . score ) } |\" \\ f \"num_of_orfs- { len ( self . path ) } |avr_dist- { avr_distance } \" return None plot_ggmsa () Plot MSA of conserved ORFs saved as fasta files. Note: R script based on ggmsa package [yulab-smu.top/ggmsa] used to produce MSA plots. R script (msa_plot.R) can be found in output_dir. This method uses subprocess to run this R script in the following way: Rscript {output_dir}/msa_plot.R --msa_fasta path_to_fasta --output output_path --seq_type (nt/aa) --width N(mm) --height M(mm) . Since during each run of uorf4u a local copy of this script is created in your output_dir, you can change it without any consequences for next uorf4u runs. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 def plot_ggmsa ( self ) -> None : \"\"\"Plot MSA of conserved ORFs saved as fasta files. Note: R script based on ggmsa package [yulab-smu.top/ggmsa] used to produce MSA plots. R script (msa_plot.R) can be found in output_dir. This method uses subprocess to run this R script in the following way: `Rscript {output_dir}/msa_plot.R --msa_fasta path_to_fasta --output output_path --seq_type (nt/aa) --width N(mm) --height M(mm)`. Since during each run of uorf4u a local copy of this script is created in your output_dir, you can change it without any consequences for next uorf4u runs. Returns: None \"\"\" rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_visualisation\" ) for i in self . parameters . arguments [ \"sequences_to_write\" ]])) fasta_files_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_fasta_files\" ) for i in self . parameters . arguments [ \"sequences_to_write\" ]])) for o_dir in output_dirs . values (): if not ( os . path . exists ( o_dir )): os . mkdir ( o_dir ) r_script_path = self . parameters . arguments [ \"plot_msa_R_script\" ] r_script_local = os . path . join ( self . parameters . arguments [ \"output_dir\" ], os . path . basename ( r_script_path )) if not ( os . path . exists ( r_script_local )): shutil . copy ( r_script_path , r_script_local ) for s_type in self . parameters . arguments [ \"sequences_to_write\" ]: current_msa = self . msa [ s_type ] if s_type == \"nt\" or s_type == \"sd\" : seq_type = \"nt\" else : seq_type = \"aa\" output_dir = os . path . abspath ( os . path . join ( output_dirs [ s_type ])) input_file = os . path . abspath ( os . path . join ( fasta_files_dirs [ s_type ], f \" { self . id } .fa\" )) num_sequences = len ( current_msa ) length_of_alignment = current_msa . get_alignment_length () page_width = ( 50 + length_of_alignment ) * 5 page_height = max ( 17 , ( num_sequences + 5 ) * 3 ) subprocess . run ([ \"Rscript\" , r_script_local , \"--msa_fasta\" , input_file , \"--output\" , output_dir , \"--seq_type\" , seq_type , \"--width\" , str ( page_width ), \"--height\" , str ( page_height )]) plot_logo () Plot sequence Logo of conserved ORFs MSA saved as fasta files. Note: This method uses logomaker package to produce images. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 def plot_logo ( self ) -> None : \"\"\"Plot sequence Logo of conserved ORFs MSA saved as fasta files. Note: This method uses logomaker package to produce images. Returns: None \"\"\" rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _seqlogo_visualisation\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) for o_dir in output_dirs . values (): if not ( os . path . exists ( o_dir )): os . mkdir ( o_dir ) ambiguous_codon_table = Bio . Data . CodonTable . ambiguous_dna_by_name [ self . parameters . arguments [ \"ncbi_genetic_code_name\" ]] unambiguous_codon_table = Bio . Data . CodonTable . unambiguous_dna_by_name [ self . parameters . arguments [ \"ncbi_genetic_code_name\" ]] alphabet = dict ( nt = set ( ambiguous_codon_table . nucleotide_alphabet ), aa = set ( ambiguous_codon_table . protein_alphabet )) unambiguous_alphabet = dict ( nt = set ( unambiguous_codon_table . nucleotide_alphabet ), aa = set ( unambiguous_codon_table . protein_alphabet )) for s_type in self . parameters . arguments [ \"sequences_to_write\" ]: current_msa = self . msa [ s_type ] if s_type == \"nt\" or s_type == \"sd\" : seq_type = \"nt\" elif s_type == \"aa\" : seq_type = \"aa\" output_file = os . path . abspath ( os . path . join ( output_dirs [ s_type ], os . path . basename ( self . id ))) msa_length = current_msa . get_alignment_length () num_of_sequences = len ( current_msa ) current_msa_info = Bio . Align . AlignInfo . SummaryInfo ( current_msa ) pos_specific_dict = dict () pos_specific_score_matrix = current_msa_info . pos_specific_score_matrix () for i in alphabet [ seq_type ]: pos_specific_dict [ i ] = [ 0 for j in range ( msa_length )] for i in range ( msa_length ): for element in pos_specific_score_matrix [ i ] . keys (): pos_specific_dict [ element . upper ()][ i ] = ( pos_specific_score_matrix [ i ][ element ] / num_of_sequences ) pos = [ i for i in range ( msa_length )] pos_specific_dict = { k : v for k , v in pos_specific_dict . items () if sum ( v ) > 0 or k in unambiguous_alphabet [ seq_type ]} matrix_fr = pandas . DataFrame ( pos_specific_dict , index = pos ) colors = self . parameters . arguments [ f \"colors_ { seq_type } \" ] colors = { k : uorf4u . methods . color_name_to_hex ( v , self . parameters . arguments ) for k , v in colors . items ()} fig_size = ( min ( max ( 10 , msa_length * 1.3 ), (( 2 ** 16 ) - 1 ) / 100 ), min ( 2.5 , 2.5 * 10 / ( msa_length ** ( 1 / 5 )))) if self . parameters . arguments [ \"logo_type\" ] == \"probability\" or \\ self . parameters . arguments [ \"logo_type\" ] == \"both\" : output_file_fr = f \" { output_file } _prob.pdf\" max_value_fr = 1 logo_fr = logomaker . Logo ( matrix_fr , color_scheme = colors , figsize = fig_size , alpha = self . parameters . arguments [ \"logo_alpha\" ], show_spines = False , baseline_width = 0 ) logo_fr . style_spines ( spines = [ \"left\" ], visible = True , linewidth = 0.7 ) logo_fr . ax . set_xticks ([]) logo_fr . ax . set_yticks ([ 0 , max_value_fr ]) plt . savefig ( output_file_fr ) plt . close ( \"all\" ) if self . parameters . arguments [ \"logo_type\" ] == \"information\" or \\ self . parameters . arguments [ \"logo_type\" ] == \"both\" : colors [ \"-\" ] = colors [ \"_\" ] matrix_fr [ \"-\" ] = round (( 1 - matrix_fr . sum ( axis = 1 )), 5 ) if matrix_fr [ \"-\" ] . sum () == 0 : del matrix_fr [ '-' ] matrix_info = logomaker . transform_matrix ( matrix_fr , from_type = \"probability\" , to_type = \"information\" ) max_value_info = math . log2 ( len ( pos_specific_dict . keys ())) output_file_info = f \" { output_file } _info.pdf\" logo_info = logomaker . Logo ( matrix_info , color_scheme = colors , figsize = fig_size , alpha = self . parameters . arguments [ \"logo_alpha\" ], show_spines = False , baseline_width = 0 ) logo_info . style_spines ( spines = [ \"left\" ], visible = True , linewidth = 0.7 ) logo_info . ax . set_xticks ([]) logo_info . ax . set_yticks ([ 0 , max_value_info ]) plt . savefig ( output_file_info ) plt . close ( \"all\" ) return None plot_msa () Plot MSA of conserved ORFs. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637 def plot_msa ( self ) -> None : \"\"\"Plot MSA of conserved ORFs. Returns: None \"\"\" rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_visualisation\" ) for i in self . parameters . arguments [ \"sequences_to_write\" ]])) for o_dir in output_dirs . values (): if not ( os . path . exists ( o_dir )): os . mkdir ( o_dir ) for s_type in self . parameters . arguments [ \"sequences_to_write\" ]: current_msa = self . msa [ s_type ] if s_type == \"nt\" or s_type == \"sd\" : seq_type = \"nt\" else : seq_type = \"aa\" msa_plot_manager = uorf4u . drawing_msa . MSAPlotManager ( current_msa , self . parameters , seq_type ) msa_plot_manager . define_x_axis_coordinate_system () output_file = os . path . join ( output_dirs [ s_type ], f \" { self . id } .pdf\" ) msa_plot_manager . create_tracks () msa_plot_manager . plot ( output_file ) sort () Sort list of ORFs by their names. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 def sort ( self ) -> None : \"\"\"Sort list of ORFs by their names. Returns: None \"\"\" sorted_path = [ x for _ , x in sorted ( zip ([ i . name for i in self . path ], self . path ), key = lambda pair : pair [ 0 ])] self . path = sorted_path return None update ( orf , score = 0 ) Update a Path with a new ORF. Parameters: orf ( ORF ) \u2013 an ORF class' object. score ( float ) \u2013 a sum of pairwise alignment scores of the ORF against all ORFs in the Path. Returns: \u2013 None Source code in uorf4u/data_processing.py 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 def update ( self , orf : ORF , score = 0 ): \"\"\"Update a Path with a new ORF. Arguments: orf (ORF): an ORF class' object. score (float): a sum of pairwise alignment scores of the ORF against all ORFs in the Path. Returns: None \"\"\" self . path . append ( orf ) self . score += score RefSeqProtein A RefSeqProtein object holds a RefSeq protein and information about it. Attributes: accession_number ( str ) \u2013 RefSeq accession number. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. record ( Bio . SeqRecord . SeqRecord ) \u2013 SeqRecord of the ncbi protein db. Can be obtained by the get_record() method. taxid ( str ) \u2013 Taxid of the protein. Can be obtained with get_assemblies() method. kingdom_taxid ( str ) \u2013 Kingdom taxid of a protein. Can be obtained with get_assemblies() method. organism ( str ) \u2013 Organism name of a protein. Can be obtained with get_assemblies() method. name ( str ) \u2013 Protein's product name from the ncbi (if available). assemblies_coordinates ( list ) \u2013 List of dictionaries with information about assemblies' coordinates of the protein obtained from ipg ncbi database. loci ( dict ) \u2013 Dict with keys as locus_ids and values as Locus class' objects. Source code in uorf4u/data_processing.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 class RefSeqProtein : \"\"\"A RefSeqProtein object holds a RefSeq protein and information about it. Attributes: accession_number (str): RefSeq accession number. parameters (uorf4u.manager.Parameters): Parameters' class object. record (Bio.SeqRecord.SeqRecord): SeqRecord of the ncbi protein db. Can be obtained by the get_record() method. taxid (str): Taxid of the protein. Can be obtained with get_assemblies() method. kingdom_taxid (str): Kingdom taxid of a protein. Can be obtained with get_assemblies() method. organism (str): Organism name of a protein. Can be obtained with get_assemblies() method. name (str): Protein's product name from the ncbi (if available). assemblies_coordinates (list): List of dictionaries with information about assemblies' coordinates of the protein obtained from ipg ncbi database. loci (dict): Dict with keys as locus_ids and values as Locus class' objects. \"\"\" def __init__ ( self , accession_number : str , parameters : uorf4u . manager . Parameters ): \"\"\"Create a RefSeqProtein object. Arguments: accession_number (str): RefSeq accession number. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . accession_number = accession_number self . name = \"NA\" self . parameters = parameters self . record = None self . taxid = None self . kingdom_taxid = None self . organism = None self . assemblies_coordinates = None self . loci = None def get_record ( self ) -> Bio . SeqRecord . SeqRecord : \"\"\"Get a SeqRecord object of a protein from the ncbi protein database. Note: This method returns a record and updates the record attribute. Returns: Bio.SeqRecord.SeqRecordRecord: Record of the protein. \"\"\" try : handle = Bio . Entrez . efetch ( db = \"protein\" , id = self . accession_number , rettype = \"fasta\" , retmode = \"text\" ) self . record = Bio . SeqIO . read ( handle , \"fasta\" ) return self . record except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to get a SeqRecord of the protein from the ncbi protein database.\" ) from error def get_assemblies ( self , xml_output = None ) -> list : \"\"\"Get assemblies (loci) coordinates of a protein. Note: This method returns a list of assemblies coordinates and updates the self.assemblies_coordinates attribute. Returns: list: List of dictionaries with information about assemblies' coordinates of a protein obtained from the ipg ncbi database. \"\"\" try : if not xml_output : handle = Bio . Entrez . efetch ( db = \"protein\" , rettype = \"ipg\" , retmode = \"xml\" , id = self . accession_number ) xml_output = handle . read () . decode ( 'utf-8' ) root = xml . etree . cElementTree . fromstring ( xml_output ) list_of_kingdom_taxid = [] assemblies_coordinates = [] for report in root . iter ( \"IPGReport\" ): product = report . find ( \"Product\" ) if \"product_acc\" in report . attrib . keys (): report_accession_number = report . attrib [ \"product_acc\" ] elif \"accver\" in product . attrib . keys (): report_accession_number = product . attrib [ \"accver\" ] else : report_accession_number = \"\" if report_accession_number == self . accession_number : # be careful for protein in report . iter ( \"Protein\" ): if protein . attrib [ \"source\" ] == \"RefSeq\" : if \"name\" in protein . attrib . keys (): self . name = protein . attrib [ \"name\" ] self . taxid = protein . attrib [ \"taxid\" ] self . kingdom_taxid = protein . attrib [ \"kingdom_taxid\" ] self . organism = protein . attrib [ \"org\" ] list_of_kingdom_taxid . append ( self . kingdom_taxid ) for cds in protein . iter ( \"CDS\" ): to_add = 1 if self . parameters . arguments [ \"filter_refseq_sequences_by_regex\" ]: if not re . search ( rf \" { self . parameters . arguments [ 'refseq_sequences_regex' ] } \" , cds . attrib [ \"accver\" ]): to_add = 0 if to_add == 1 : if \"assembly\" not in cds . attrib . keys (): cds . attrib [ \"assembly\" ] = \"NA\" if \"strain\" not in cds . attrib . keys (): cds . attrib [ \"strain\" ] = \"NA\" try : assemblies_coordinates . append ( dict ( locus_id = cds . attrib [ \"accver\" ], start = ( int ( cds . attrib [ \"start\" ]) - 1 ), stop = int ( cds . attrib [ \"stop\" ]), strand = cds . attrib [ 'strand' ], length = int ( cds . attrib [ \"stop\" ]) - ( int ( cds . attrib [ \"start\" ]) - 1 ), assembly = cds . attrib [ \"assembly\" ], strain = cds . attrib [ \"strain\" ], org = cds . attrib [ \"org\" ], taxid = cds . attrib [ \"taxid\" ])) except : print ( f \"\u2755Attention: { cds . attrib [ 'accver' ] } record is not completed and\" f \" cannot be processed\" , file = sys . stderr ) ''' if len(assemblies_coordinates) == 0: print(f\"\u2757Warning message:\\n\\tNo assembly was found for the protein \" f\"'{self.accession_number}'.\\n\\tThis protein record can be suppressed by the ncbi\\n\\t\" f\"or it has no sequence record that satisfies refseq_sequnces_regex config parameter.\", file=sys.stderr) ''' self . assemblies_coordinates = assemblies_coordinates return assemblies_coordinates except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to get assemblies coordinates of a protein.\" ) from error ''' def get_loci(self, start=-float(\"inf\"), end=float(\"inf\"), strand=\"NA\") -> dict: \"\"\"Get Locus class objects for each sequence from the ncbi nt database on which the protein is annotated. Returns: dict: Dict with keys as locus_ids and values as Locus class' objects. \"\"\" self.loci = dict() for assembly in self.assemblies_coordinates: locus_id = assembly[\"locus_id\"] self.loci[locus_id] = Locus(locus_id, start_b=start, end_b=end, strand=strand) return self.loci ''' def blastp_searching_for_homologues ( self ) -> list : \"\"\"Search for a protein's homologues with blastp against the 'refseq_protein' database. Note: This function does not create a new object's attribute; It only returns a list of accession numbers. Returns: list: List of proteins' accession numbers obtained with blastp searching. This list also contains the query protein's accession number. \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc40 Searching for homologues of { self . accession_number } with blastp against the RefSeq database...\" , file = sys . stdout ) handle = Bio . Blast . NCBIWWW . qblast ( \"blastp\" , \"refseq_protein\" , self . accession_number , expect = self . parameters . arguments [ \"blastp_evalue_cutoff\" ], hitlist_size = self . parameters . arguments [ \"blastp_hit_list_size\" ], alignments = self . parameters . arguments [ \"blastp_max_number_of_alignments\" ]) xml_output = handle . read () hits_an_list = [ self . accession_number ] blastp_stat_dict = dict () blastp_stat_dict [ self . accession_number ] = dict ( pident_to_query_length = \"the query\" , pident_to_sequence_length = \"the query\" , pident_to_alignment_length = \"the query\" , evalue = \"the query\" ) root = xml . etree . ElementTree . fromstring ( xml_output ) query_length = int ( root . find ( \"BlastOutput_query-len\" ) . text ) for hit in root . iter ( \"Hit\" ): hit_id = hit . find ( \"Hit_id\" ) . text . strip ( \"ref\" ) . strip ( \"|\" ) if hit_id != self . accession_number : hit_description = hit . find ( \"Hit_def\" ) . text subject_length = int ( hit . find ( \"Hit_len\" ) . text ) hsp_identity_sum , hsp_positive_sum , hsp_align_length = 0 , 0 , 0 evalue = [] for hsp in hit . iter ( \"Hsp\" ): hsp_identity_sum += int ( hsp . find ( \"Hsp_identity\" ) . text ) hsp_positive_sum += int ( hsp . find ( \"Hsp_positive\" ) . text ) hsp_align_length += int ( hsp . find ( \"Hsp_align-len\" ) . text ) evalue . append ( hsp . find ( \"Hsp_evalue\" ) . text ) pident_to_query_length = hsp_identity_sum / query_length pident_to_seq_length = hsp_identity_sum / subject_length pident_to_alignment_length = hsp_identity_sum / hsp_align_length if pident_to_query_length >= self . parameters . arguments [ \"blastp_pident_to_query_length_cutoff\" ]: blastp_stat_dict [ hit_id ] = dict ( pident_to_query_length = str ( round ( pident_to_query_length , 4 )), pident_to_sequence_length = str ( round ( pident_to_seq_length , 4 )), pident_to_alignment_length = str ( round ( pident_to_alignment_length , 4 )), evalue = \",\" . join ( evalue )) if hit_id not in hits_an_list : hits_an_list . append ( hit_id ) columns = \" \\t \" . join ([ \"accession_number\" , \"name\" , \"pident_to_query_length\" , \"pident_to_sequence_length\" , \"pident_to_alignment_length\" , \"e-value\" ]) table = [ columns ] hits_records_list = [ RefSeqProtein ( i , self . parameters ) for i in hits_an_list ] for i in range ( 0 , len ( hits_records_list ), 200 ): records_subset = hits_records_list [ i : i + 200 ] accession_numbers = [ record . accession_number for record in records_subset ] handle_fasta = Bio . Entrez . efetch ( db = \"protein\" , id = accession_numbers , rettype = \"fasta\" , retmode = \"text\" ) fasta_records = Bio . SeqIO . parse ( handle_fasta , \"fasta\" ) for f_record in fasta_records : record_index = accession_numbers . index ( f_record . id ) records_subset [ record_index ] . name = f_record . description . replace ( f_record . id , \"\" ) . strip () for rec in hits_records_list : table . append ( \" \\t \" . join ([ rec . accession_number , rec . name , blastp_stat_dict [ rec . accession_number ][ \"pident_to_query_length\" ], blastp_stat_dict [ rec . accession_number ][ \"pident_to_sequence_length\" ], blastp_stat_dict [ rec . accession_number ][ \"pident_to_alignment_length\" ], blastp_stat_dict [ rec . accession_number ][ \"evalue\" ]])) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) output_filename = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"found_homologues.tsv\" ) f = open ( output_filename , \"w\" ) f . write ( \" \\n \" . join ( table )) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\u2705 { len ( hits_records_list ) - 1 } homologues were found. \\n \" f \"\ud83d\udc8c Summary table was saved to: { os . path . basename ( output_filename ) } \" , file = sys . stdout ) return hits_an_list except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to perform searching for homologues with blastp.\" ) from error __init__ ( accession_number , parameters ) Create a RefSeqProtein object. Parameters: accession_number ( str ) \u2013 RefSeq accession number. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/data_processing.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 def __init__ ( self , accession_number : str , parameters : uorf4u . manager . Parameters ): \"\"\"Create a RefSeqProtein object. Arguments: accession_number (str): RefSeq accession number. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . accession_number = accession_number self . name = \"NA\" self . parameters = parameters self . record = None self . taxid = None self . kingdom_taxid = None self . organism = None self . assemblies_coordinates = None self . loci = None blastp_searching_for_homologues () Search for a protein's homologues with blastp against the 'refseq_protein' database. Note: This function does not create a new object's attribute; It only returns a list of accession numbers. Returns: list ( list ) \u2013 List of proteins' accession numbers obtained with blastp searching. This list also contains the query protein's accession number. Source code in uorf4u/data_processing.py 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 def blastp_searching_for_homologues ( self ) -> list : \"\"\"Search for a protein's homologues with blastp against the 'refseq_protein' database. Note: This function does not create a new object's attribute; It only returns a list of accession numbers. Returns: list: List of proteins' accession numbers obtained with blastp searching. This list also contains the query protein's accession number. \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc40 Searching for homologues of { self . accession_number } with blastp against the RefSeq database...\" , file = sys . stdout ) handle = Bio . Blast . NCBIWWW . qblast ( \"blastp\" , \"refseq_protein\" , self . accession_number , expect = self . parameters . arguments [ \"blastp_evalue_cutoff\" ], hitlist_size = self . parameters . arguments [ \"blastp_hit_list_size\" ], alignments = self . parameters . arguments [ \"blastp_max_number_of_alignments\" ]) xml_output = handle . read () hits_an_list = [ self . accession_number ] blastp_stat_dict = dict () blastp_stat_dict [ self . accession_number ] = dict ( pident_to_query_length = \"the query\" , pident_to_sequence_length = \"the query\" , pident_to_alignment_length = \"the query\" , evalue = \"the query\" ) root = xml . etree . ElementTree . fromstring ( xml_output ) query_length = int ( root . find ( \"BlastOutput_query-len\" ) . text ) for hit in root . iter ( \"Hit\" ): hit_id = hit . find ( \"Hit_id\" ) . text . strip ( \"ref\" ) . strip ( \"|\" ) if hit_id != self . accession_number : hit_description = hit . find ( \"Hit_def\" ) . text subject_length = int ( hit . find ( \"Hit_len\" ) . text ) hsp_identity_sum , hsp_positive_sum , hsp_align_length = 0 , 0 , 0 evalue = [] for hsp in hit . iter ( \"Hsp\" ): hsp_identity_sum += int ( hsp . find ( \"Hsp_identity\" ) . text ) hsp_positive_sum += int ( hsp . find ( \"Hsp_positive\" ) . text ) hsp_align_length += int ( hsp . find ( \"Hsp_align-len\" ) . text ) evalue . append ( hsp . find ( \"Hsp_evalue\" ) . text ) pident_to_query_length = hsp_identity_sum / query_length pident_to_seq_length = hsp_identity_sum / subject_length pident_to_alignment_length = hsp_identity_sum / hsp_align_length if pident_to_query_length >= self . parameters . arguments [ \"blastp_pident_to_query_length_cutoff\" ]: blastp_stat_dict [ hit_id ] = dict ( pident_to_query_length = str ( round ( pident_to_query_length , 4 )), pident_to_sequence_length = str ( round ( pident_to_seq_length , 4 )), pident_to_alignment_length = str ( round ( pident_to_alignment_length , 4 )), evalue = \",\" . join ( evalue )) if hit_id not in hits_an_list : hits_an_list . append ( hit_id ) columns = \" \\t \" . join ([ \"accession_number\" , \"name\" , \"pident_to_query_length\" , \"pident_to_sequence_length\" , \"pident_to_alignment_length\" , \"e-value\" ]) table = [ columns ] hits_records_list = [ RefSeqProtein ( i , self . parameters ) for i in hits_an_list ] for i in range ( 0 , len ( hits_records_list ), 200 ): records_subset = hits_records_list [ i : i + 200 ] accession_numbers = [ record . accession_number for record in records_subset ] handle_fasta = Bio . Entrez . efetch ( db = \"protein\" , id = accession_numbers , rettype = \"fasta\" , retmode = \"text\" ) fasta_records = Bio . SeqIO . parse ( handle_fasta , \"fasta\" ) for f_record in fasta_records : record_index = accession_numbers . index ( f_record . id ) records_subset [ record_index ] . name = f_record . description . replace ( f_record . id , \"\" ) . strip () for rec in hits_records_list : table . append ( \" \\t \" . join ([ rec . accession_number , rec . name , blastp_stat_dict [ rec . accession_number ][ \"pident_to_query_length\" ], blastp_stat_dict [ rec . accession_number ][ \"pident_to_sequence_length\" ], blastp_stat_dict [ rec . accession_number ][ \"pident_to_alignment_length\" ], blastp_stat_dict [ rec . accession_number ][ \"evalue\" ]])) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) output_filename = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"found_homologues.tsv\" ) f = open ( output_filename , \"w\" ) f . write ( \" \\n \" . join ( table )) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\u2705 { len ( hits_records_list ) - 1 } homologues were found. \\n \" f \"\ud83d\udc8c Summary table was saved to: { os . path . basename ( output_filename ) } \" , file = sys . stdout ) return hits_an_list except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to perform searching for homologues with blastp.\" ) from error get_assemblies ( xml_output = None ) Get assemblies (loci) coordinates of a protein. Note: This method returns a list of assemblies coordinates and updates the self.assemblies_coordinates attribute. Returns: list ( list ) \u2013 List of dictionaries with information about assemblies' coordinates of a protein obtained from the ipg ncbi database. Source code in uorf4u/data_processing.py 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 def get_assemblies ( self , xml_output = None ) -> list : \"\"\"Get assemblies (loci) coordinates of a protein. Note: This method returns a list of assemblies coordinates and updates the self.assemblies_coordinates attribute. Returns: list: List of dictionaries with information about assemblies' coordinates of a protein obtained from the ipg ncbi database. \"\"\" try : if not xml_output : handle = Bio . Entrez . efetch ( db = \"protein\" , rettype = \"ipg\" , retmode = \"xml\" , id = self . accession_number ) xml_output = handle . read () . decode ( 'utf-8' ) root = xml . etree . cElementTree . fromstring ( xml_output ) list_of_kingdom_taxid = [] assemblies_coordinates = [] for report in root . iter ( \"IPGReport\" ): product = report . find ( \"Product\" ) if \"product_acc\" in report . attrib . keys (): report_accession_number = report . attrib [ \"product_acc\" ] elif \"accver\" in product . attrib . keys (): report_accession_number = product . attrib [ \"accver\" ] else : report_accession_number = \"\" if report_accession_number == self . accession_number : # be careful for protein in report . iter ( \"Protein\" ): if protein . attrib [ \"source\" ] == \"RefSeq\" : if \"name\" in protein . attrib . keys (): self . name = protein . attrib [ \"name\" ] self . taxid = protein . attrib [ \"taxid\" ] self . kingdom_taxid = protein . attrib [ \"kingdom_taxid\" ] self . organism = protein . attrib [ \"org\" ] list_of_kingdom_taxid . append ( self . kingdom_taxid ) for cds in protein . iter ( \"CDS\" ): to_add = 1 if self . parameters . arguments [ \"filter_refseq_sequences_by_regex\" ]: if not re . search ( rf \" { self . parameters . arguments [ 'refseq_sequences_regex' ] } \" , cds . attrib [ \"accver\" ]): to_add = 0 if to_add == 1 : if \"assembly\" not in cds . attrib . keys (): cds . attrib [ \"assembly\" ] = \"NA\" if \"strain\" not in cds . attrib . keys (): cds . attrib [ \"strain\" ] = \"NA\" try : assemblies_coordinates . append ( dict ( locus_id = cds . attrib [ \"accver\" ], start = ( int ( cds . attrib [ \"start\" ]) - 1 ), stop = int ( cds . attrib [ \"stop\" ]), strand = cds . attrib [ 'strand' ], length = int ( cds . attrib [ \"stop\" ]) - ( int ( cds . attrib [ \"start\" ]) - 1 ), assembly = cds . attrib [ \"assembly\" ], strain = cds . attrib [ \"strain\" ], org = cds . attrib [ \"org\" ], taxid = cds . attrib [ \"taxid\" ])) except : print ( f \"\u2755Attention: { cds . attrib [ 'accver' ] } record is not completed and\" f \" cannot be processed\" , file = sys . stderr ) ''' if len(assemblies_coordinates) == 0: print(f\"\u2757Warning message:\\n\\tNo assembly was found for the protein \" f\"'{self.accession_number}'.\\n\\tThis protein record can be suppressed by the ncbi\\n\\t\" f\"or it has no sequence record that satisfies refseq_sequnces_regex config parameter.\", file=sys.stderr) ''' self . assemblies_coordinates = assemblies_coordinates return assemblies_coordinates except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to get assemblies coordinates of a protein.\" ) from error get_record () Get a SeqRecord object of a protein from the ncbi protein database. Note: This method returns a record and updates the record attribute. Returns: Bio . SeqRecord . SeqRecord \u2013 Bio.SeqRecord.SeqRecordRecord: Record of the protein. Source code in uorf4u/data_processing.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 def get_record ( self ) -> Bio . SeqRecord . SeqRecord : \"\"\"Get a SeqRecord object of a protein from the ncbi protein database. Note: This method returns a record and updates the record attribute. Returns: Bio.SeqRecord.SeqRecordRecord: Record of the protein. \"\"\" try : handle = Bio . Entrez . efetch ( db = \"protein\" , id = self . accession_number , rettype = \"fasta\" , retmode = \"text\" ) self . record = Bio . SeqIO . read ( handle , \"fasta\" ) return self . record except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to get a SeqRecord of the protein from the ncbi protein database.\" ) from error UpstreamSequences An UpstreamSequences object holds list of upstream sequences records and information about them. Attributes: records ( list ) \u2013 List of Bio.SeqRecord.SeqRecord objects with upstream sequences. (attribute 'annotations' (dict) is used for holding additional information, (e.g. downstream protein_id)). codon_table ( Bio . Data . CodonTable . CodonTable ) \u2013 Codon table (genetic code). conserved_paths ( list ) \u2013 list of Path's objects (Path class holds list of ORFs from different upstream sequences and information about them). Source code in uorf4u/data_processing.py 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 class UpstreamSequences : \"\"\"An UpstreamSequences object holds list of upstream sequences records and information about them. Attributes: records (list): List of Bio.SeqRecord.SeqRecord objects with upstream sequences. (attribute 'annotations' (dict) is used for holding additional information, (e.g. downstream protein_id)). codon_table (Bio.Data.CodonTable.CodonTable): Codon table (genetic code). conserved_paths (list): list of Path's objects (Path class holds list of ORFs from different upstream sequences and information about them). \"\"\" def __init__ ( self , records : list , parameters : uorf4u . manager . Parameters ): \"\"\"Create an UpstreamSequences object. Arguments: records (list): List of Bio.SeqRecord.SeqRecord objects with upstream sequences. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . records = records self . parameters = parameters self . codon_table = Bio . Data . CodonTable . unambiguous_dna_by_name [ parameters . arguments [ \"ncbi_genetic_code_name\" ]] self . conserved_paths = None def save_upstream_sequences ( self ) -> None : \"\"\"Save upstream sequences as a fasta file. Returns: None \"\"\" try : output_file = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"upstream_sequences.fa\" ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) Bio . SeqIO . write ( self . records , output_file , \"fasta\" ) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc8c Fasta file with upstream sequences was saved to { os . path . basename ( output_file ) } .\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save a fasta file with upstream sequences.\" ) from error def annotate_orfs ( self ) -> None : \"\"\"Annotate ORFs in upstream sequences. Note: This function updates 'records' attribute. Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udd0e ORFs annotating in the upstream sequences...\" , file = sys . stdout ) if self . parameters . arguments [ \"alternative_start_codons\" ]: start_codons_list = self . codon_table . start_codons else : start_codons_list = [ self . parameters . arguments [ \"main_start_codon\" ]] if self . parameters . arguments [ \"check_assembly_annotation\" ] and \\ self . records [ 0 ] . annotations [ \"RefSeq\" ]: if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udce1 Assemblies' annotation retrieving...\" , file = sys . stdout ) for i in range ( 0 , len ( self . records ), 100 ): useq_subset = [ record for record in self . records [ i : i + 100 ] if record . annotations [ \"RefSeq\" ]] locus_ids = [ locus . annotations [ \"locus_id\" ] for locus in useq_subset ] handle = Bio . Entrez . efetch ( db = \"nucleotide\" , id = locus_ids , rettype = \"gb\" , retmode = \"xml\" ) handle_txt = handle . read () . decode ( 'utf-8' ) for useq_record in useq_subset : useq_record . annotations [ \"locus_annotation\" ] = Locus ( useq_record . annotations [ \"locus_id\" ], start_b = useq_record . annotations [ \"start\" ], stop_b = useq_record . annotations [ \"stop\" ], target_strand = useq_record . annotations [ \"strand\" ], locus_record = useq_record . annotations [ \"locus_record\" ], xml_output = handle_txt ) for useq_index in range ( len ( self . records )): useq_record = self . records [ useq_index ] useq_record . annotations [ \"ORFs\" ] = [] for first_position in range (( useq_record . annotations [ \"length\" ] - self . parameters . arguments [ \"downstream_region_length\" ]) + 1 ): first_codon = useq_record . seq [ first_position : first_position + 3 ] if first_codon . upper () in start_codons_list : start_codon_position = first_position for second_position in range ( start_codon_position + 3 , ( useq_record . annotations [ \"length\" ] - 3 ) + 1 , 3 ): second_codon = useq_record . seq [ second_position : second_position + 3 ] if second_codon . upper () in self . codon_table . stop_codons : stop_codon_position = second_position orf_length = stop_codon_position - start_codon_position distance = ( useq_record . annotations [ \"length\" ] - self . parameters . arguments [ \"downstream_region_length\" ]) - stop_codon_position distance_sc = ( useq_record . annotations [ \"length\" ] - self . parameters . arguments [ \"downstream_region_length\" ]) - start_codon_position if useq_record . annotations [ \"RefSeq\" ]: orf_id = f \" { useq_record . annotations [ 'locus_id' ] } |\" \\ f \" { useq_record . annotations [ 'accession_number' ] } |\" \\ f \" { distance } \" orf_name = f \" { useq_record . annotations [ 'label' ] } | { distance } \" else : distance = useq_record . annotations [ \"length\" ] - stop_codon_position orf_id = f \" { useq_record . id } | { distance } \" if useq_record . description : orf_name = f \" { useq_record . description } | { orf_id } \" else : orf_name = orf_id sd_window_start = max ( [ 0 , ( start_codon_position - self . parameters . arguments [ \"sd_window_length\" ])]) current_orf = ORF ( parameters = self . parameters , id = orf_id , name = orf_name , distance = distance , start = start_codon_position , stop = stop_codon_position , useq_index = useq_index , nt_sequence = useq_record . seq [ start_codon_position : stop_codon_position ], sd_window_seq = useq_record . seq [ sd_window_start : start_codon_position ]) if current_orf . length >= self . parameters . arguments [ \"min_orf_length\" ] and distance_sc != 0 : useq_record . annotations [ \"ORFs\" ] . append ( current_orf ) if self . parameters . arguments [ \"check_assembly_annotation\" ] and \\ useq_record . annotations [ \"RefSeq\" ]: for cds in useq_record . annotations [ \"locus_annotation\" ] . CDSs : if current_orf . stop == cds [ \"relative_stop\" ] and ( ( current_orf . start - cds [ \"relative_start\" ]) % 3 == 0 ): the_same_stop = 1 current_orf . annotation = cds [ \"product_name\" ] if current_orf . start != cds [ \"relative_start\" ]: if current_orf . start < cds [ \"relative_start\" ]: current_orf . annotation += \" (extension)\" else : current_orf . annotation += \" (truncation)\" for annotated_orfs in useq_record . annotations [ \"ORFs\" ]: if current_orf . stop == annotated_orfs . stop and \\ current_orf . id != annotated_orfs . id : current_orf . extended_orfs . append ( annotated_orfs . id ) break number_of_orfs = sum ( len ( i . annotations [ \"ORFs\" ]) for i in self . records ) if self . parameters . arguments [ \"fast_searching\" ] == \"auto\" : if len ( self . records ) < 5 : self . parameters . arguments [ \"fast_searching\" ] = False elif ( len ( self . records ) >= 100 or number_of_orfs > 1000 ): self . parameters . arguments [ \"fast_searching\" ] = True else : self . parameters . arguments [ \"fast_searching\" ] = False if number_of_orfs == 0 : print ( f \"\u26d4Termination: \\n\\t No ORF was annotated in upstream sequences.\" f \" \\n\\t This run will be terminated.\" , file = sys . stderr ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) with open ( os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"report.txt\" ), \"w\" ) as report_f : report_f . write ( \"Termination: \\n No ORF was annotated in upstream sequences.\" ) sys . exit () if self . parameters . arguments [ \"verbose\" ]: print ( f \"\u2705 { number_of_orfs } ORFs were annotated.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to annotate ORFs in upstream sequences.\" ) from error def filter_orfs_by_sd_annotation ( self ) -> None : \"\"\"Filter annotated ORFs by presence the Shine-Dalgarno sequence. Returns: None \"\"\" try : for useq_record in self . records : orf_list = useq_record . annotations [ \"ORFs\" ] filtered_orf_list = [] for orf in orf_list : orf . calculate_energies () if orf . min_energy < self . parameters . arguments [ \"sd_energy_cutoff\" ]: filtered_orf_list . append ( orf ) useq_record . annotations [ \"ORFs\" ] = filtered_orf_list number_of_orfs = sum ( len ( i . annotations [ \"ORFs\" ]) for i in self . records ) if number_of_orfs == 0 : print ( f \"\u26d4Termination: \\n\\t No ORF left after filtering by SD annotation.\" f \" \\n\\t This run will be terminated.\" , file = sys . stderr ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) with open ( os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"report.txt\" ), \"w\" ) as report_f : report_f . write ( \"Termination: \\n No ORF left after filtering by SD annotation.\" ) sys . exit () if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83e\uddf9 { number_of_orfs } ORFs remained in the analysis after filtering by presence \" f \"of the SD sequence.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to filter uORFs by SD sequence presence.\" ) from error def save_annotated_orfs ( self ) -> None : \"\"\"Save information about annotated ORFs as a set of tsv files. Note: tsv files will be saved to the subdir called 'annotated_ORFs' located in 'output_dir'. Returns: None \"\"\" try : colnames = \" \\t \" . join ( [ \"id\" , \"name\" , \"length\" , \"nt_sequence\" , \"aa_sequence\" , \"sd_sequence_window\" , \"SD-aSD energy\" , \"SD-aSD energies list\" , \"extended_orfs\" , \"annotation\" ]) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) output_dir_path = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"annotated_ORFs\" ) if not os . path . exists ( output_dir_path ): os . mkdir ( output_dir_path ) for useq_record in self . records : file_name = f \" { useq_record . description } | { useq_record . id } \" . replace ( ' ' , '_' ) . replace ( '/' , '_' ) lines = [ colnames ] for orf in useq_record . annotations [ \"ORFs\" ]: if not orf . extended_orfs : extented_orfs_value = \"NA\" else : extented_orfs_value = ';' . join ( orf . extended_orfs ) lines . append ( \" \\t \" . join ( [ orf . id , orf . name , str ( orf . length ), str ( orf . nt_sequence ), str ( orf . aa_sequence ), str ( orf . sd_window_seq_str ), str ( orf . min_energy ), \";\" . join ( orf . sd_window_energies ), extented_orfs_value , orf . annotation ])) with open ( os . path . join ( output_dir_path , f \" { file_name } .tsv\" ), \"w\" ) as output : output . write ( \" \\n \" . join ( lines )) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc8c tsv files with information about annotated ORFs were saved to \" f \" { os . path . basename ( output_dir_path ) } folder.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save annotated uORFs.\" ) from error def conserved_orf_searching ( self ) -> None : \"\"\"Search for sets of conserved ORFs in upstream sequences. Note: This method updates the self.conserved_paths attribute. Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udd0e Searching for conserved ORFs in upstream sequences...\" , file = sys . stdout ) if len ( self . records ) == 1 : raise uorf4u . manager . uORF4uError ( \"At least two sequences required to perform conservation analysis\" ) lengths = [] for record in self . records : for orf in record . annotations [ \"ORFs\" ]: lengths . append ( orf . length ) lengths = sorted ( list ( set ( lengths ))) global_aligner = Bio . Align . PairwiseAligner () global_aligner . mode = \"global\" global_aligner . match_score = self . parameters . arguments [ \"global_match_score\" ] global_aligner . mismatch_score = self . parameters . arguments [ \"global_mismatch_score\" ] global_aligner . open_gap_score = self . parameters . arguments [ \"global_open_gap_score\" ] global_aligner . extend_gap_score = self . parameters . arguments [ \"global_extend_gap_score\" ] global_aligner . target_end_gap_score = self . parameters . arguments [ \"global_target_end_gap_score\" ] global_aligner . query_end_gap_score = self . parameters . arguments [ \"global_query_end_gap_score\" ] length_variance = self . parameters . arguments [ \"orf_length_group_range\" ] number_of_useqs = len ( self . records ) if self . parameters . arguments [ \"fast_searching\" ]: filtered_orfs_dict = dict () for length in lengths : if isinstance ( self . parameters . arguments [ \"orf_length_group_range\" ], float ): length_variance = length * self . parameters . arguments [ \"orf_length_group_range\" ] filtered_orfs = [] useq_with_filtered_orfs = [] for useq_index in range ( number_of_useqs ): useq_record = self . records [ useq_index ] for orf in useq_record . annotations [ \"ORFs\" ]: if abs ( length - orf . length ) <= length_variance : filtered_orfs . append ( orf ) if useq_index not in useq_with_filtered_orfs : useq_with_filtered_orfs . append ( useq_index ) if len ( useq_with_filtered_orfs ) / number_of_useqs >= self . parameters . arguments [ \"orfs_presence_cutoff\" ]: to_add = 1 keys_to_remove = [] for added_length in filtered_orfs_dict . keys (): num_of_identical_elements = len ( set ( filtered_orfs ) & set ( filtered_orfs_dict [ added_length ])) fraction = num_of_identical_elements / min ( len ( filtered_orfs ), len ( filtered_orfs_dict [ added_length ])) if fraction > 0.8 : # to add as a config parameter if len ( filtered_orfs ) >= len ( filtered_orfs_dict [ added_length ]): keys_to_remove . append ( added_length ) else : to_add = 0 for key_to_remove in keys_to_remove : filtered_orfs_dict . pop ( key_to_remove ) if to_add : filtered_orfs_dict [ length ] = filtered_orfs lengths = list ( filtered_orfs_dict . keys ()) conserved_paths = [] for length in lengths : if isinstance ( self . parameters . arguments [ \"orf_length_group_range\" ], float ): length_variance = length * self . parameters . arguments [ \"orf_length_group_range\" ] useq_indexes_with_filtered_orfs = [] filtered_orfs = dict () for useq_index in range ( number_of_useqs ): useq_record = self . records [ useq_index ] filtered_orfs [ useq_index ] = [] for orf in useq_record . annotations [ \"ORFs\" ]: if abs ( length - orf . length ) <= length_variance : filtered_orfs [ useq_index ] . append ( orf ) orfs_ids = [ i . id for i in filtered_orfs [ useq_index ]] for orf in filtered_orfs [ useq_index ]: if any ( i in orf . extended_orfs for i in orfs_ids ): filtered_orfs [ useq_index ] . remove ( orf ) if len ( filtered_orfs [ useq_index ]) > 0 : useq_indexes_with_filtered_orfs . append ( useq_index ) if len ( useq_indexes_with_filtered_orfs ) / number_of_useqs >= self . parameters . arguments [ \"orfs_presence_cutoff\" ]: if self . parameters . arguments [ \"fast_searching\" ]: genome_iterator = random . sample ( filtered_orfs . keys (), max ( 1 , min ( round ( self . parameters . arguments [ \"fast_searching_\" \"fraction_of_initial\" \"_genomes\" ] * len ( useq_indexes_with_filtered_orfs )), self . parameters . arguments [ \"max_num_of_initial_genome_iteration\" ]))) elif len ( filtered_orfs . keys ()) > self . parameters . arguments [ \"max_num_of_initial_genome_iteration\" ]: genome_iterator = random . sample ( filtered_orfs . keys (), self . parameters . arguments [ \"max_num_of_initial_genome_iteration\" ]) else : genome_iterator = filtered_orfs . keys () for initial_useq in genome_iterator : for initial_orf in filtered_orfs [ initial_useq ]: conserved_path = Path ( self . parameters ) conserved_path . update ( initial_orf ) for useq in random . sample ( filtered_orfs . keys (), len ( filtered_orfs . keys ())): if useq != initial_useq and filtered_orfs [ useq ] != []: score_sums = [] for orf in filtered_orfs [ useq ]: score_sum = 0 for path_orf in conserved_path . path : if self . parameters . arguments [ \"alignment_type\" ] == \"nt\" : current_alignment = global_aligner . align ( orf . nt_sequence , path_orf . nt_sequence ) elif self . parameters . arguments [ \"alignment_type\" ] == \"aa\" : current_alignment = global_aligner . align ( orf . aa_sequence , path_orf . aa_sequence ) score_sum += current_alignment . score score_sums . append ( score_sum ) max_score = max ( score_sums ) if max_score > self . parameters . arguments [ \"alignment_score_cutoff\" ]: if score_sums . count ( max_score ) == 1 : selected_orf = filtered_orfs [ useq ][ score_sums . index ( max_score )] else : num_of_candidates = len ( filtered_orfs [ useq ]) highest_score_orfs = [ filtered_orfs [ useq ][ k ] for k in range ( num_of_candidates ) if score_sums [ k ] == max_score ] highest_score_orfs_length_dists = [ orf_it . length - length for orf_it in highest_score_orfs ] min_length_dist = min ( highest_score_orfs_length_dists ) if highest_score_orfs_length_dists . count ( min_length_dist ) == 1 : selected_orf = highest_score_orfs [ highest_score_orfs_length_dists . index ( min_length_dist )] else : num_of_candidates = len ( highest_score_orfs ) the_closest_by_length_orfs = [ highest_score_orfs [ k ] for k in range ( num_of_candidates ) if highest_score_orfs_length_dists [ k ] == min_length_dist ] the_closest_by_length_orfs_lengths = [ orf_it . length for orf_it in the_closest_by_length_orfs ] max_length = max ( the_closest_by_length_orfs_lengths ) selected_orf = the_closest_by_length_orfs [ the_closest_by_length_orfs_lengths . index ( max_length )] conserved_path . update ( selected_orf , max_score ) if len ( conserved_path ) / number_of_useqs >= self . parameters . arguments [ \"orfs_presence_cutoff\" ] and len ( conserved_path ) > 1 : to_save_this_path = 1 for old_path in conserved_paths : fraction_of_identity = conserved_path . calculate_similarity ( old_path ) if fraction_of_identity >= self . parameters . arguments [ \"paths_identity_cutoff\" ]: if conserved_path . score > old_path . score : conserved_paths . remove ( old_path ) elif conserved_path . score <= old_path . score : to_save_this_path = 0 if to_save_this_path == 1 : conserved_path . sort () conserved_paths . append ( conserved_path ) self . conserved_paths = conserved_paths number_of_paths = len ( conserved_paths ) if number_of_paths == 0 : print ( f \"\u26d4Termination: \\n\\t No conserved ORFs set was found.\" f \" \\n\\t This run will be terminated.\" , file = sys . stderr ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) with open ( os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"report.txt\" ), \"w\" ) as report_f : report_f . write ( \"Termination: \\n No conserved ORFs set was found.\" ) sys . exit () if self . parameters . arguments [ \"verbose\" ]: print ( f \"\u2705 { number_of_paths } sets of conserved ORFs were found.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to perform searching for conserved uORFs.\" ) from error def filter_out_similar_paths ( self ) -> None : \"\"\"Filter out duplicates in sets of annotated conserved ORFs. Note: Two paths are considered as duplicates if they share more than half of ORFs (default value, see 'paths_identity_cutoff' config parameter). In case two paths are found as identical, only one with a higher score will be saved. Returns: None \"\"\" try : filtered_paths = [] for path in self . conserved_paths : to_add = 1 for path_filtered in filtered_paths : if path . calculate_similarity ( path_filtered ) > self . parameters . arguments [ \"paths_identity_cutoff\" ]: if path . score < path_filtered . score : to_add = 0 elif path . score == path_filtered . score and ( len ( path ) < len ( path_filtered )): to_add = 0 else : filtered_paths . remove ( path_filtered ) if to_add == 1 : filtered_paths . append ( path ) self . conserved_paths = filtered_paths if self . parameters . arguments [ \"verbose\" ]: num_of_paths = len ( self . conserved_paths ) print ( f \"\ud83e\uddf9 { num_of_paths } set(s) of conserved ORFs remained in the analysis after filtering \" f \"out duplicates.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to filter out duplicates in conserved uORFs sets.\" ) from error def run_msa ( self ) -> None : \"\"\"Run msa tool (muscle) for each path object (set of conserved ORFs). Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83e\uddee Running MSA for conserved ORFs.\" , file = sys . stdout ) for path in self . conserved_paths : path . maft_msa () return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to get MSA of conserved uORFs.\" ) from error def save_msa ( self ) -> None : \"\"\"Save MSA of conserved ORFs as fasta files. Note: Fasta files will be saved to the subdirs: ['nucleotide_msa' - for MSA of nucleotide sequences of ORFs, 'amino_acid_msa' - MSA of amino acid sequences of ORFs, and 'sd_msa' - MSA of SD sequence regions of ORFS). All of them located in your 'output_dir'. Returns: None \"\"\" try : if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_fasta_files\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) for key in output_dirs : if not ( os . path . exists ( output_dirs [ key ])): os . mkdir ( output_dirs [ key ]) for path in self . conserved_paths : for seq_type in self . parameters . arguments [ \"sequences_to_write\" ]: msa = path . msa [ seq_type ] output = os . path . join ( output_dirs [ seq_type ], f \" { path . id } .fa\" ) Bio . AlignIO . write ( msa , output , \"fasta\" ) if self . parameters . arguments [ \"verbose\" ]: output_dirs_v = [ os . path . basename ( i ) for i in output_dirs . values ()] delimiter = \", \\n\\t \" print ( f \"\ud83d\udc8c MSA fasta files of conserved ORFs were saved to the folders: \\n \" f \" \\t { delimiter . join ( output_dirs_v ) } folders.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save MSA of conserved uORFs.\" ) from error def save_orfs_sequences ( self ) -> None : \"\"\"Save sequences of conserved ORFs as fasta files. Note: Fasta files will be saved to the subdirs: ['nucleotide_orfs' - for MSA of nucleotide sequences of ORFs, 'amino_acid_msa' - MSA of amino acid sequences of ORFs, and 'sd_msa' - MSA of SD sequence regions of ORFS). All of them located in your 'output_dir'. Returns: None \"\"\" try : if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" ) sequence_to_write = [ i for i in self . parameters . arguments [ \"sequences_to_write\" ] if i != \"sd\" ] output_dirs = dict ( zip ( sequence_to_write , [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _orfs_fasta_files\" ) for i in sequence_to_write ])) for key in output_dirs : if not ( os . path . exists ( output_dirs [ key ])): os . mkdir ( output_dirs [ key ]) for seq_type in sequence_to_write : for path in self . conserved_paths : records = [] for orf in path . path : if seq_type == \"nt\" : record = Bio . SeqRecord . SeqRecord ( orf . nt_sequence , orf . id , \"\" , orf . name ) if seq_type == \"aa\" : record = Bio . SeqRecord . SeqRecord ( orf . aa_sequence , orf . id , \"\" , orf . name ) records . append ( record ) output = os . path . join ( output_dirs [ seq_type ], f \" { path . id } .fa\" ) Bio . SeqIO . write ( records , output , \"fasta\" ) if self . parameters . arguments [ \"verbose\" ]: delimiter = \", \\n\\t \" output_dirs_v = [ os . path . basename ( i ) for i in output_dirs . values ()] print ( f \"\ud83d\udc8c Sequences fasta files of conserved ORFs were saved to the folders: \\n \" f \" \\t { delimiter . join ( output_dirs_v ) } .\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save sequences of conserved uORFs.\" ) from error def save_results_summary_table ( self ) -> None : \"\"\"Save results summary table. Note: A tsv table will be saved to your output_dir. Returns: None \"\"\" try : colnames = \" \\t \" . join ( [ \"id\" , \"length\" , \"average_distance_to_the_ORF\" , \"aa_alignment_length\" , \"nt_alignment_length\" , \"score\" , \"number_of_orfs\" , \"number_of_orfs/number_of_sequences\" , \"consensus(aa)\" , \"consensus(nt)\" , \"uORFs\" , \"uORFs_annotations\" ]) rows = [ colnames ] for path in self . conserved_paths : annotations = sorted ( set ([ i . annotation for i in path . path ])) if len ( annotations ) > 1 and \"NA\" in annotations : pass # annotations.remove(\"NA\") # To check then row = \" \\t \" . join ( [ path . id , str ( path . length ), str ( statistics . mean ([ i . distance for i in path . path ])), str ( path . msa [ \"aa\" ] . get_alignment_length ()), str ( path . msa [ \"nt\" ] . get_alignment_length ()), str ( path . score ), str ( len ( path )), str ( round ( len ( path ) / len ( self . records ), 3 )), str ( path . msa_consensus [ \"aa\" ]), str ( path . msa_consensus [ \"nt\" ]), ', ' . join ([ i . id for i in path . path ]), ', ' . join ( annotations )]) rows . append ( row ) output_file_path = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"results_summary.tsv\" ) f = open ( output_file_path , \"w\" ) f . write ( \" \\n \" . join ( rows )) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc8c Results summary tsv table saved to: { os . path . basename ( output_file_path ) } .\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save results summary table.\" ) from error def plot_msa_figs ( self ) -> None : \"\"\"Plot MSA plots of conserved ORFs Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83c\udfa8 MSA figures plotting...\" , file = sys . stdout ) for path in self . conserved_paths : path . plot_msa () if self . parameters . arguments [ \"verbose\" ]: rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_visualisation\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) output_dirs_v = [ os . path . basename ( i ) for i in output_dirs . values ()] delimiter = \", \\n\\t \" print ( f \"\ud83d\udc8c MSA figures were saved to the folders: \\n\\t { delimiter . join ( output_dirs_v ) } \" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to plot sequence logo of conserved uORFs.\" ) from error def plot_ggmsa_figs ( self ) -> None : \"\"\"Plot MSA plots of conserved ORFs saved as fasta files. Note: R script based on ggmsa package [yulab-smu.top/ggmsa] used to produce MSA plots. R script (msa_plot.R) can be found in output_dir. This method uses subprocess to run this R script in the following way: `Rscript {output_dir}/msa_plot.R --msa_fasta path_to_fasta --output output_path --seq_type (nt/aa) --width N(mm) --height M(mm)`. Since during each run of uorf4u a local copy of this script is created in your output_dir, you can change it without any consequences for next uorf4u runs. This method based on _plot_ggmsa_ method of Path class and simply call it for each Path object. Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83c\udfa8 MSA figures plotting...\" , file = sys . stdout ) for path in self . conserved_paths : path . plot_ggmsa () if self . parameters . arguments [ \"verbose\" ]: rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_visualisation\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) output_dirs_v = [ os . path . basename ( i ) for i in output_dirs . values ()] delimiter = \", \\n\\t \" print ( f \"\ud83d\udc8c MSA figures were saved to the folders: \\n\\t { delimiter . join ( output_dirs_v ) } .\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to visualise MSA of conserved uORFs.\" ) from error def plot_logo_figs ( self ) -> None : \"\"\"Plot sequence Logo figures of conserved ORFs saved as fasta files. Note: This method uses logomaker package to produce images. This method based on _plot_logo_ method of Path class and simply call it for each Path object. Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83c\udfa8 Sequence logo figures plotting...\" , file = sys . stdout ) for path in self . conserved_paths : path . plot_logo () if self . parameters . arguments [ \"verbose\" ]: rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _seqlogo_visualisation\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) output_dirs_v = [ os . path . basename ( i ) for i in output_dirs . values ()] delimiter = \", \\n\\t \" print ( f \"\ud83d\udc8c Sequence logo figures were saved to the folders: \\n\\t { delimiter . join ( output_dirs_v ) } \" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to plot sequence logo of conserved uORFs.\" ) from error def plot_annotation ( self ) -> None : \"\"\"Plot loci' annotations figures with conserved ORFs highlighting. Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83c\udfa8 Loci annotations figures plotting...\" , file = sys . stdout ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) output_dir = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"annotation_visualisation\" ) if not os . path . exists ( output_dir ): os . mkdir ( output_dir ) for path in self . conserved_paths : output_file_name = f \" { os . path . join ( output_dir , path . id ) } .pdf\" annotation_plot_manager = uorf4u . drawing_annotation . AnnotationPlotManager ( path , self . records , self . parameters ) annotation_plot_manager . define_x_axis_coordinate_system () annotation_plot_manager . create_tracks () annotation_plot_manager . plot ( output_file_name ) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc8c Annotation figures were saved to the folder: { os . path . basename ( output_dir ) } \" , file = sys . stdout ) except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to plot loci' annotations figures.\" ) from error __init__ ( records , parameters ) Create an UpstreamSequences object. Parameters: records ( list ) \u2013 List of Bio.SeqRecord.SeqRecord objects with upstream sequences. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/data_processing.py 604 605 606 607 608 609 610 611 612 613 614 615 616 def __init__ ( self , records : list , parameters : uorf4u . manager . Parameters ): \"\"\"Create an UpstreamSequences object. Arguments: records (list): List of Bio.SeqRecord.SeqRecord objects with upstream sequences. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . records = records self . parameters = parameters self . codon_table = Bio . Data . CodonTable . unambiguous_dna_by_name [ parameters . arguments [ \"ncbi_genetic_code_name\" ]] self . conserved_paths = None annotate_orfs () Annotate ORFs in upstream sequences. Note: This function updates 'records' attribute. Returns: None \u2013 None Source code in uorf4u/data_processing.py 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 def annotate_orfs ( self ) -> None : \"\"\"Annotate ORFs in upstream sequences. Note: This function updates 'records' attribute. Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udd0e ORFs annotating in the upstream sequences...\" , file = sys . stdout ) if self . parameters . arguments [ \"alternative_start_codons\" ]: start_codons_list = self . codon_table . start_codons else : start_codons_list = [ self . parameters . arguments [ \"main_start_codon\" ]] if self . parameters . arguments [ \"check_assembly_annotation\" ] and \\ self . records [ 0 ] . annotations [ \"RefSeq\" ]: if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udce1 Assemblies' annotation retrieving...\" , file = sys . stdout ) for i in range ( 0 , len ( self . records ), 100 ): useq_subset = [ record for record in self . records [ i : i + 100 ] if record . annotations [ \"RefSeq\" ]] locus_ids = [ locus . annotations [ \"locus_id\" ] for locus in useq_subset ] handle = Bio . Entrez . efetch ( db = \"nucleotide\" , id = locus_ids , rettype = \"gb\" , retmode = \"xml\" ) handle_txt = handle . read () . decode ( 'utf-8' ) for useq_record in useq_subset : useq_record . annotations [ \"locus_annotation\" ] = Locus ( useq_record . annotations [ \"locus_id\" ], start_b = useq_record . annotations [ \"start\" ], stop_b = useq_record . annotations [ \"stop\" ], target_strand = useq_record . annotations [ \"strand\" ], locus_record = useq_record . annotations [ \"locus_record\" ], xml_output = handle_txt ) for useq_index in range ( len ( self . records )): useq_record = self . records [ useq_index ] useq_record . annotations [ \"ORFs\" ] = [] for first_position in range (( useq_record . annotations [ \"length\" ] - self . parameters . arguments [ \"downstream_region_length\" ]) + 1 ): first_codon = useq_record . seq [ first_position : first_position + 3 ] if first_codon . upper () in start_codons_list : start_codon_position = first_position for second_position in range ( start_codon_position + 3 , ( useq_record . annotations [ \"length\" ] - 3 ) + 1 , 3 ): second_codon = useq_record . seq [ second_position : second_position + 3 ] if second_codon . upper () in self . codon_table . stop_codons : stop_codon_position = second_position orf_length = stop_codon_position - start_codon_position distance = ( useq_record . annotations [ \"length\" ] - self . parameters . arguments [ \"downstream_region_length\" ]) - stop_codon_position distance_sc = ( useq_record . annotations [ \"length\" ] - self . parameters . arguments [ \"downstream_region_length\" ]) - start_codon_position if useq_record . annotations [ \"RefSeq\" ]: orf_id = f \" { useq_record . annotations [ 'locus_id' ] } |\" \\ f \" { useq_record . annotations [ 'accession_number' ] } |\" \\ f \" { distance } \" orf_name = f \" { useq_record . annotations [ 'label' ] } | { distance } \" else : distance = useq_record . annotations [ \"length\" ] - stop_codon_position orf_id = f \" { useq_record . id } | { distance } \" if useq_record . description : orf_name = f \" { useq_record . description } | { orf_id } \" else : orf_name = orf_id sd_window_start = max ( [ 0 , ( start_codon_position - self . parameters . arguments [ \"sd_window_length\" ])]) current_orf = ORF ( parameters = self . parameters , id = orf_id , name = orf_name , distance = distance , start = start_codon_position , stop = stop_codon_position , useq_index = useq_index , nt_sequence = useq_record . seq [ start_codon_position : stop_codon_position ], sd_window_seq = useq_record . seq [ sd_window_start : start_codon_position ]) if current_orf . length >= self . parameters . arguments [ \"min_orf_length\" ] and distance_sc != 0 : useq_record . annotations [ \"ORFs\" ] . append ( current_orf ) if self . parameters . arguments [ \"check_assembly_annotation\" ] and \\ useq_record . annotations [ \"RefSeq\" ]: for cds in useq_record . annotations [ \"locus_annotation\" ] . CDSs : if current_orf . stop == cds [ \"relative_stop\" ] and ( ( current_orf . start - cds [ \"relative_start\" ]) % 3 == 0 ): the_same_stop = 1 current_orf . annotation = cds [ \"product_name\" ] if current_orf . start != cds [ \"relative_start\" ]: if current_orf . start < cds [ \"relative_start\" ]: current_orf . annotation += \" (extension)\" else : current_orf . annotation += \" (truncation)\" for annotated_orfs in useq_record . annotations [ \"ORFs\" ]: if current_orf . stop == annotated_orfs . stop and \\ current_orf . id != annotated_orfs . id : current_orf . extended_orfs . append ( annotated_orfs . id ) break number_of_orfs = sum ( len ( i . annotations [ \"ORFs\" ]) for i in self . records ) if self . parameters . arguments [ \"fast_searching\" ] == \"auto\" : if len ( self . records ) < 5 : self . parameters . arguments [ \"fast_searching\" ] = False elif ( len ( self . records ) >= 100 or number_of_orfs > 1000 ): self . parameters . arguments [ \"fast_searching\" ] = True else : self . parameters . arguments [ \"fast_searching\" ] = False if number_of_orfs == 0 : print ( f \"\u26d4Termination: \\n\\t No ORF was annotated in upstream sequences.\" f \" \\n\\t This run will be terminated.\" , file = sys . stderr ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) with open ( os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"report.txt\" ), \"w\" ) as report_f : report_f . write ( \"Termination: \\n No ORF was annotated in upstream sequences.\" ) sys . exit () if self . parameters . arguments [ \"verbose\" ]: print ( f \"\u2705 { number_of_orfs } ORFs were annotated.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to annotate ORFs in upstream sequences.\" ) from error conserved_orf_searching () Search for sets of conserved ORFs in upstream sequences. Note: This method updates the self.conserved_paths attribute. Returns: None \u2013 None Source code in uorf4u/data_processing.py 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 def conserved_orf_searching ( self ) -> None : \"\"\"Search for sets of conserved ORFs in upstream sequences. Note: This method updates the self.conserved_paths attribute. Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udd0e Searching for conserved ORFs in upstream sequences...\" , file = sys . stdout ) if len ( self . records ) == 1 : raise uorf4u . manager . uORF4uError ( \"At least two sequences required to perform conservation analysis\" ) lengths = [] for record in self . records : for orf in record . annotations [ \"ORFs\" ]: lengths . append ( orf . length ) lengths = sorted ( list ( set ( lengths ))) global_aligner = Bio . Align . PairwiseAligner () global_aligner . mode = \"global\" global_aligner . match_score = self . parameters . arguments [ \"global_match_score\" ] global_aligner . mismatch_score = self . parameters . arguments [ \"global_mismatch_score\" ] global_aligner . open_gap_score = self . parameters . arguments [ \"global_open_gap_score\" ] global_aligner . extend_gap_score = self . parameters . arguments [ \"global_extend_gap_score\" ] global_aligner . target_end_gap_score = self . parameters . arguments [ \"global_target_end_gap_score\" ] global_aligner . query_end_gap_score = self . parameters . arguments [ \"global_query_end_gap_score\" ] length_variance = self . parameters . arguments [ \"orf_length_group_range\" ] number_of_useqs = len ( self . records ) if self . parameters . arguments [ \"fast_searching\" ]: filtered_orfs_dict = dict () for length in lengths : if isinstance ( self . parameters . arguments [ \"orf_length_group_range\" ], float ): length_variance = length * self . parameters . arguments [ \"orf_length_group_range\" ] filtered_orfs = [] useq_with_filtered_orfs = [] for useq_index in range ( number_of_useqs ): useq_record = self . records [ useq_index ] for orf in useq_record . annotations [ \"ORFs\" ]: if abs ( length - orf . length ) <= length_variance : filtered_orfs . append ( orf ) if useq_index not in useq_with_filtered_orfs : useq_with_filtered_orfs . append ( useq_index ) if len ( useq_with_filtered_orfs ) / number_of_useqs >= self . parameters . arguments [ \"orfs_presence_cutoff\" ]: to_add = 1 keys_to_remove = [] for added_length in filtered_orfs_dict . keys (): num_of_identical_elements = len ( set ( filtered_orfs ) & set ( filtered_orfs_dict [ added_length ])) fraction = num_of_identical_elements / min ( len ( filtered_orfs ), len ( filtered_orfs_dict [ added_length ])) if fraction > 0.8 : # to add as a config parameter if len ( filtered_orfs ) >= len ( filtered_orfs_dict [ added_length ]): keys_to_remove . append ( added_length ) else : to_add = 0 for key_to_remove in keys_to_remove : filtered_orfs_dict . pop ( key_to_remove ) if to_add : filtered_orfs_dict [ length ] = filtered_orfs lengths = list ( filtered_orfs_dict . keys ()) conserved_paths = [] for length in lengths : if isinstance ( self . parameters . arguments [ \"orf_length_group_range\" ], float ): length_variance = length * self . parameters . arguments [ \"orf_length_group_range\" ] useq_indexes_with_filtered_orfs = [] filtered_orfs = dict () for useq_index in range ( number_of_useqs ): useq_record = self . records [ useq_index ] filtered_orfs [ useq_index ] = [] for orf in useq_record . annotations [ \"ORFs\" ]: if abs ( length - orf . length ) <= length_variance : filtered_orfs [ useq_index ] . append ( orf ) orfs_ids = [ i . id for i in filtered_orfs [ useq_index ]] for orf in filtered_orfs [ useq_index ]: if any ( i in orf . extended_orfs for i in orfs_ids ): filtered_orfs [ useq_index ] . remove ( orf ) if len ( filtered_orfs [ useq_index ]) > 0 : useq_indexes_with_filtered_orfs . append ( useq_index ) if len ( useq_indexes_with_filtered_orfs ) / number_of_useqs >= self . parameters . arguments [ \"orfs_presence_cutoff\" ]: if self . parameters . arguments [ \"fast_searching\" ]: genome_iterator = random . sample ( filtered_orfs . keys (), max ( 1 , min ( round ( self . parameters . arguments [ \"fast_searching_\" \"fraction_of_initial\" \"_genomes\" ] * len ( useq_indexes_with_filtered_orfs )), self . parameters . arguments [ \"max_num_of_initial_genome_iteration\" ]))) elif len ( filtered_orfs . keys ()) > self . parameters . arguments [ \"max_num_of_initial_genome_iteration\" ]: genome_iterator = random . sample ( filtered_orfs . keys (), self . parameters . arguments [ \"max_num_of_initial_genome_iteration\" ]) else : genome_iterator = filtered_orfs . keys () for initial_useq in genome_iterator : for initial_orf in filtered_orfs [ initial_useq ]: conserved_path = Path ( self . parameters ) conserved_path . update ( initial_orf ) for useq in random . sample ( filtered_orfs . keys (), len ( filtered_orfs . keys ())): if useq != initial_useq and filtered_orfs [ useq ] != []: score_sums = [] for orf in filtered_orfs [ useq ]: score_sum = 0 for path_orf in conserved_path . path : if self . parameters . arguments [ \"alignment_type\" ] == \"nt\" : current_alignment = global_aligner . align ( orf . nt_sequence , path_orf . nt_sequence ) elif self . parameters . arguments [ \"alignment_type\" ] == \"aa\" : current_alignment = global_aligner . align ( orf . aa_sequence , path_orf . aa_sequence ) score_sum += current_alignment . score score_sums . append ( score_sum ) max_score = max ( score_sums ) if max_score > self . parameters . arguments [ \"alignment_score_cutoff\" ]: if score_sums . count ( max_score ) == 1 : selected_orf = filtered_orfs [ useq ][ score_sums . index ( max_score )] else : num_of_candidates = len ( filtered_orfs [ useq ]) highest_score_orfs = [ filtered_orfs [ useq ][ k ] for k in range ( num_of_candidates ) if score_sums [ k ] == max_score ] highest_score_orfs_length_dists = [ orf_it . length - length for orf_it in highest_score_orfs ] min_length_dist = min ( highest_score_orfs_length_dists ) if highest_score_orfs_length_dists . count ( min_length_dist ) == 1 : selected_orf = highest_score_orfs [ highest_score_orfs_length_dists . index ( min_length_dist )] else : num_of_candidates = len ( highest_score_orfs ) the_closest_by_length_orfs = [ highest_score_orfs [ k ] for k in range ( num_of_candidates ) if highest_score_orfs_length_dists [ k ] == min_length_dist ] the_closest_by_length_orfs_lengths = [ orf_it . length for orf_it in the_closest_by_length_orfs ] max_length = max ( the_closest_by_length_orfs_lengths ) selected_orf = the_closest_by_length_orfs [ the_closest_by_length_orfs_lengths . index ( max_length )] conserved_path . update ( selected_orf , max_score ) if len ( conserved_path ) / number_of_useqs >= self . parameters . arguments [ \"orfs_presence_cutoff\" ] and len ( conserved_path ) > 1 : to_save_this_path = 1 for old_path in conserved_paths : fraction_of_identity = conserved_path . calculate_similarity ( old_path ) if fraction_of_identity >= self . parameters . arguments [ \"paths_identity_cutoff\" ]: if conserved_path . score > old_path . score : conserved_paths . remove ( old_path ) elif conserved_path . score <= old_path . score : to_save_this_path = 0 if to_save_this_path == 1 : conserved_path . sort () conserved_paths . append ( conserved_path ) self . conserved_paths = conserved_paths number_of_paths = len ( conserved_paths ) if number_of_paths == 0 : print ( f \"\u26d4Termination: \\n\\t No conserved ORFs set was found.\" f \" \\n\\t This run will be terminated.\" , file = sys . stderr ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) with open ( os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"report.txt\" ), \"w\" ) as report_f : report_f . write ( \"Termination: \\n No conserved ORFs set was found.\" ) sys . exit () if self . parameters . arguments [ \"verbose\" ]: print ( f \"\u2705 { number_of_paths } sets of conserved ORFs were found.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to perform searching for conserved uORFs.\" ) from error filter_orfs_by_sd_annotation () Filter annotated ORFs by presence the Shine-Dalgarno sequence. Returns: None \u2013 None Source code in uorf4u/data_processing.py 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 def filter_orfs_by_sd_annotation ( self ) -> None : \"\"\"Filter annotated ORFs by presence the Shine-Dalgarno sequence. Returns: None \"\"\" try : for useq_record in self . records : orf_list = useq_record . annotations [ \"ORFs\" ] filtered_orf_list = [] for orf in orf_list : orf . calculate_energies () if orf . min_energy < self . parameters . arguments [ \"sd_energy_cutoff\" ]: filtered_orf_list . append ( orf ) useq_record . annotations [ \"ORFs\" ] = filtered_orf_list number_of_orfs = sum ( len ( i . annotations [ \"ORFs\" ]) for i in self . records ) if number_of_orfs == 0 : print ( f \"\u26d4Termination: \\n\\t No ORF left after filtering by SD annotation.\" f \" \\n\\t This run will be terminated.\" , file = sys . stderr ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) with open ( os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"report.txt\" ), \"w\" ) as report_f : report_f . write ( \"Termination: \\n No ORF left after filtering by SD annotation.\" ) sys . exit () if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83e\uddf9 { number_of_orfs } ORFs remained in the analysis after filtering by presence \" f \"of the SD sequence.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to filter uORFs by SD sequence presence.\" ) from error filter_out_similar_paths () Filter out duplicates in sets of annotated conserved ORFs. Note: Two paths are considered as duplicates if they share more than half of ORFs (default value, see 'paths_identity_cutoff' config parameter). In case two paths are found as identical, only one with a higher score will be saved. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 def filter_out_similar_paths ( self ) -> None : \"\"\"Filter out duplicates in sets of annotated conserved ORFs. Note: Two paths are considered as duplicates if they share more than half of ORFs (default value, see 'paths_identity_cutoff' config parameter). In case two paths are found as identical, only one with a higher score will be saved. Returns: None \"\"\" try : filtered_paths = [] for path in self . conserved_paths : to_add = 1 for path_filtered in filtered_paths : if path . calculate_similarity ( path_filtered ) > self . parameters . arguments [ \"paths_identity_cutoff\" ]: if path . score < path_filtered . score : to_add = 0 elif path . score == path_filtered . score and ( len ( path ) < len ( path_filtered )): to_add = 0 else : filtered_paths . remove ( path_filtered ) if to_add == 1 : filtered_paths . append ( path ) self . conserved_paths = filtered_paths if self . parameters . arguments [ \"verbose\" ]: num_of_paths = len ( self . conserved_paths ) print ( f \"\ud83e\uddf9 { num_of_paths } set(s) of conserved ORFs remained in the analysis after filtering \" f \"out duplicates.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to filter out duplicates in conserved uORFs sets.\" ) from error plot_annotation () Plot loci' annotations figures with conserved ORFs highlighting. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 def plot_annotation ( self ) -> None : \"\"\"Plot loci' annotations figures with conserved ORFs highlighting. Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83c\udfa8 Loci annotations figures plotting...\" , file = sys . stdout ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) output_dir = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"annotation_visualisation\" ) if not os . path . exists ( output_dir ): os . mkdir ( output_dir ) for path in self . conserved_paths : output_file_name = f \" { os . path . join ( output_dir , path . id ) } .pdf\" annotation_plot_manager = uorf4u . drawing_annotation . AnnotationPlotManager ( path , self . records , self . parameters ) annotation_plot_manager . define_x_axis_coordinate_system () annotation_plot_manager . create_tracks () annotation_plot_manager . plot ( output_file_name ) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc8c Annotation figures were saved to the folder: { os . path . basename ( output_dir ) } \" , file = sys . stdout ) except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to plot loci' annotations figures.\" ) from error plot_ggmsa_figs () Plot MSA plots of conserved ORFs saved as fasta files. Note: R script based on ggmsa package [yulab-smu.top/ggmsa] used to produce MSA plots. R script (msa_plot.R) can be found in output_dir. This method uses subprocess to run this R script in the following way: Rscript {output_dir}/msa_plot.R --msa_fasta path_to_fasta --output output_path --seq_type (nt/aa) --width N(mm) --height M(mm) . Since during each run of uorf4u a local copy of this script is created in your output_dir, you can change it without any consequences for next uorf4u runs. This method based on plot_ggmsa method of Path class and simply call it for each Path object. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 def plot_ggmsa_figs ( self ) -> None : \"\"\"Plot MSA plots of conserved ORFs saved as fasta files. Note: R script based on ggmsa package [yulab-smu.top/ggmsa] used to produce MSA plots. R script (msa_plot.R) can be found in output_dir. This method uses subprocess to run this R script in the following way: `Rscript {output_dir}/msa_plot.R --msa_fasta path_to_fasta --output output_path --seq_type (nt/aa) --width N(mm) --height M(mm)`. Since during each run of uorf4u a local copy of this script is created in your output_dir, you can change it without any consequences for next uorf4u runs. This method based on _plot_ggmsa_ method of Path class and simply call it for each Path object. Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83c\udfa8 MSA figures plotting...\" , file = sys . stdout ) for path in self . conserved_paths : path . plot_ggmsa () if self . parameters . arguments [ \"verbose\" ]: rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_visualisation\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) output_dirs_v = [ os . path . basename ( i ) for i in output_dirs . values ()] delimiter = \", \\n\\t \" print ( f \"\ud83d\udc8c MSA figures were saved to the folders: \\n\\t { delimiter . join ( output_dirs_v ) } .\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to visualise MSA of conserved uORFs.\" ) from error plot_logo_figs () Plot sequence Logo figures of conserved ORFs saved as fasta files. Note: This method uses logomaker package to produce images. This method based on plot_logo method of Path class and simply call it for each Path object. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 def plot_logo_figs ( self ) -> None : \"\"\"Plot sequence Logo figures of conserved ORFs saved as fasta files. Note: This method uses logomaker package to produce images. This method based on _plot_logo_ method of Path class and simply call it for each Path object. Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83c\udfa8 Sequence logo figures plotting...\" , file = sys . stdout ) for path in self . conserved_paths : path . plot_logo () if self . parameters . arguments [ \"verbose\" ]: rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _seqlogo_visualisation\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) output_dirs_v = [ os . path . basename ( i ) for i in output_dirs . values ()] delimiter = \", \\n\\t \" print ( f \"\ud83d\udc8c Sequence logo figures were saved to the folders: \\n\\t { delimiter . join ( output_dirs_v ) } \" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to plot sequence logo of conserved uORFs.\" ) from error plot_msa_figs () Plot MSA plots of conserved ORFs Returns: None \u2013 None Source code in uorf4u/data_processing.py 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 def plot_msa_figs ( self ) -> None : \"\"\"Plot MSA plots of conserved ORFs Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83c\udfa8 MSA figures plotting...\" , file = sys . stdout ) for path in self . conserved_paths : path . plot_msa () if self . parameters . arguments [ \"verbose\" ]: rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_visualisation\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) output_dirs_v = [ os . path . basename ( i ) for i in output_dirs . values ()] delimiter = \", \\n\\t \" print ( f \"\ud83d\udc8c MSA figures were saved to the folders: \\n\\t { delimiter . join ( output_dirs_v ) } \" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to plot sequence logo of conserved uORFs.\" ) from error run_msa () Run msa tool (muscle) for each path object (set of conserved ORFs). Returns: None \u2013 None Source code in uorf4u/data_processing.py 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 def run_msa ( self ) -> None : \"\"\"Run msa tool (muscle) for each path object (set of conserved ORFs). Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83e\uddee Running MSA for conserved ORFs.\" , file = sys . stdout ) for path in self . conserved_paths : path . maft_msa () return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to get MSA of conserved uORFs.\" ) from error save_annotated_orfs () Save information about annotated ORFs as a set of tsv files. Note: tsv files will be saved to the subdir called 'annotated_ORFs' located in 'output_dir'. Returns: None \u2013 None Source code in uorf4u/data_processing.py 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 def save_annotated_orfs ( self ) -> None : \"\"\"Save information about annotated ORFs as a set of tsv files. Note: tsv files will be saved to the subdir called 'annotated_ORFs' located in 'output_dir'. Returns: None \"\"\" try : colnames = \" \\t \" . join ( [ \"id\" , \"name\" , \"length\" , \"nt_sequence\" , \"aa_sequence\" , \"sd_sequence_window\" , \"SD-aSD energy\" , \"SD-aSD energies list\" , \"extended_orfs\" , \"annotation\" ]) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) output_dir_path = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"annotated_ORFs\" ) if not os . path . exists ( output_dir_path ): os . mkdir ( output_dir_path ) for useq_record in self . records : file_name = f \" { useq_record . description } | { useq_record . id } \" . replace ( ' ' , '_' ) . replace ( '/' , '_' ) lines = [ colnames ] for orf in useq_record . annotations [ \"ORFs\" ]: if not orf . extended_orfs : extented_orfs_value = \"NA\" else : extented_orfs_value = ';' . join ( orf . extended_orfs ) lines . append ( \" \\t \" . join ( [ orf . id , orf . name , str ( orf . length ), str ( orf . nt_sequence ), str ( orf . aa_sequence ), str ( orf . sd_window_seq_str ), str ( orf . min_energy ), \";\" . join ( orf . sd_window_energies ), extented_orfs_value , orf . annotation ])) with open ( os . path . join ( output_dir_path , f \" { file_name } .tsv\" ), \"w\" ) as output : output . write ( \" \\n \" . join ( lines )) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc8c tsv files with information about annotated ORFs were saved to \" f \" { os . path . basename ( output_dir_path ) } folder.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save annotated uORFs.\" ) from error save_msa () Save MSA of conserved ORFs as fasta files. Note: Fasta files will be saved to the subdirs: ['nucleotide_msa' - for MSA of nucleotide sequences of ORFs, 'amino_acid_msa' - MSA of amino acid sequences of ORFs, and 'sd_msa' - MSA of SD sequence regions of ORFS). All of them located in your 'output_dir'. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 def save_msa ( self ) -> None : \"\"\"Save MSA of conserved ORFs as fasta files. Note: Fasta files will be saved to the subdirs: ['nucleotide_msa' - for MSA of nucleotide sequences of ORFs, 'amino_acid_msa' - MSA of amino acid sequences of ORFs, and 'sd_msa' - MSA of SD sequence regions of ORFS). All of them located in your 'output_dir'. Returns: None \"\"\" try : if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_fasta_files\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) for key in output_dirs : if not ( os . path . exists ( output_dirs [ key ])): os . mkdir ( output_dirs [ key ]) for path in self . conserved_paths : for seq_type in self . parameters . arguments [ \"sequences_to_write\" ]: msa = path . msa [ seq_type ] output = os . path . join ( output_dirs [ seq_type ], f \" { path . id } .fa\" ) Bio . AlignIO . write ( msa , output , \"fasta\" ) if self . parameters . arguments [ \"verbose\" ]: output_dirs_v = [ os . path . basename ( i ) for i in output_dirs . values ()] delimiter = \", \\n\\t \" print ( f \"\ud83d\udc8c MSA fasta files of conserved ORFs were saved to the folders: \\n \" f \" \\t { delimiter . join ( output_dirs_v ) } folders.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save MSA of conserved uORFs.\" ) from error save_orfs_sequences () Save sequences of conserved ORFs as fasta files. Note: Fasta files will be saved to the subdirs: ['nucleotide_orfs' - for MSA of nucleotide sequences of ORFs, 'amino_acid_msa' - MSA of amino acid sequences of ORFs, and 'sd_msa' - MSA of SD sequence regions of ORFS). All of them located in your 'output_dir'. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 def save_orfs_sequences ( self ) -> None : \"\"\"Save sequences of conserved ORFs as fasta files. Note: Fasta files will be saved to the subdirs: ['nucleotide_orfs' - for MSA of nucleotide sequences of ORFs, 'amino_acid_msa' - MSA of amino acid sequences of ORFs, and 'sd_msa' - MSA of SD sequence regions of ORFS). All of them located in your 'output_dir'. Returns: None \"\"\" try : if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" ) sequence_to_write = [ i for i in self . parameters . arguments [ \"sequences_to_write\" ] if i != \"sd\" ] output_dirs = dict ( zip ( sequence_to_write , [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _orfs_fasta_files\" ) for i in sequence_to_write ])) for key in output_dirs : if not ( os . path . exists ( output_dirs [ key ])): os . mkdir ( output_dirs [ key ]) for seq_type in sequence_to_write : for path in self . conserved_paths : records = [] for orf in path . path : if seq_type == \"nt\" : record = Bio . SeqRecord . SeqRecord ( orf . nt_sequence , orf . id , \"\" , orf . name ) if seq_type == \"aa\" : record = Bio . SeqRecord . SeqRecord ( orf . aa_sequence , orf . id , \"\" , orf . name ) records . append ( record ) output = os . path . join ( output_dirs [ seq_type ], f \" { path . id } .fa\" ) Bio . SeqIO . write ( records , output , \"fasta\" ) if self . parameters . arguments [ \"verbose\" ]: delimiter = \", \\n\\t \" output_dirs_v = [ os . path . basename ( i ) for i in output_dirs . values ()] print ( f \"\ud83d\udc8c Sequences fasta files of conserved ORFs were saved to the folders: \\n \" f \" \\t { delimiter . join ( output_dirs_v ) } .\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save sequences of conserved uORFs.\" ) from error save_results_summary_table () Save results summary table. Note: A tsv table will be saved to your output_dir. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 def save_results_summary_table ( self ) -> None : \"\"\"Save results summary table. Note: A tsv table will be saved to your output_dir. Returns: None \"\"\" try : colnames = \" \\t \" . join ( [ \"id\" , \"length\" , \"average_distance_to_the_ORF\" , \"aa_alignment_length\" , \"nt_alignment_length\" , \"score\" , \"number_of_orfs\" , \"number_of_orfs/number_of_sequences\" , \"consensus(aa)\" , \"consensus(nt)\" , \"uORFs\" , \"uORFs_annotations\" ]) rows = [ colnames ] for path in self . conserved_paths : annotations = sorted ( set ([ i . annotation for i in path . path ])) if len ( annotations ) > 1 and \"NA\" in annotations : pass # annotations.remove(\"NA\") # To check then row = \" \\t \" . join ( [ path . id , str ( path . length ), str ( statistics . mean ([ i . distance for i in path . path ])), str ( path . msa [ \"aa\" ] . get_alignment_length ()), str ( path . msa [ \"nt\" ] . get_alignment_length ()), str ( path . score ), str ( len ( path )), str ( round ( len ( path ) / len ( self . records ), 3 )), str ( path . msa_consensus [ \"aa\" ]), str ( path . msa_consensus [ \"nt\" ]), ', ' . join ([ i . id for i in path . path ]), ', ' . join ( annotations )]) rows . append ( row ) output_file_path = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"results_summary.tsv\" ) f = open ( output_file_path , \"w\" ) f . write ( \" \\n \" . join ( rows )) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc8c Results summary tsv table saved to: { os . path . basename ( output_file_path ) } .\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save results summary table.\" ) from error save_upstream_sequences () Save upstream sequences as a fasta file. Returns: None \u2013 None Source code in uorf4u/data_processing.py 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 def save_upstream_sequences ( self ) -> None : \"\"\"Save upstream sequences as a fasta file. Returns: None \"\"\" try : output_file = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"upstream_sequences.fa\" ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) Bio . SeqIO . write ( self . records , output_file , \"fasta\" ) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc8c Fasta file with upstream sequences was saved to { os . path . basename ( output_file ) } .\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save a fasta file with upstream sequences.\" ) from error","title":"uorf4u.data_processing"},{"location":"API/package_data_processing/#uorf4u.data_processing.Homologues","text":"A Homologues object holds list of proteins homologues and information about them. Attributes: accession_numbers ( list ) \u2013 List of RefSeq accession numbers. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. records ( list ) \u2013 list of RefSeqProtein objects of the proteins. Source code in uorf4u/data_processing.py 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 class Homologues : \"\"\"A Homologues object holds list of proteins homologues and information about them. Attributes: accession_numbers (list): List of RefSeq accession numbers. parameters (uorf4u.manager.Parameters): Parameters' class object. records (list): list of RefSeqProtein objects of the proteins. \"\"\" def __init__ ( self , accession_numbers : list , parameters : uorf4u . manager . Parameters ): \"\"\"Create a Homologues object. Note: With initialisation it also creates a 'records' attribute - a list of RefSeqProtein objects of proteins based on accession numbers list. Arguments: accession_numbers (list): List of RefSeq accession numbers. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" try : self . accession_numbers = accession_numbers self . parameters = parameters self . records = [ RefSeqProtein ( i , parameters ) for i in accession_numbers ] except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to create a Homologues class' object.\" ) from error def get_upstream_sequences ( self ) -> list : \"\"\"Get upstream sequences of proteins' genes. Note: A protein may be found in multiple assemblies (for example in different strains). Returns: list: List of Bio.SeqRecord.SeqRecord objects of upstream sequences. \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udce1 Retrieving upstream sequences...\" , file = sys . stdout ) for i in range ( 0 , len ( self . records ), 200 ): records_subset = self . records [ i : i + 200 ] accession_numbers = [ record . accession_number for record in records_subset ] handle = Bio . Entrez . efetch ( db = \"protein\" , id = accession_numbers , rettype = \"ipg\" , retmode = \"xml\" ) handle_txt = handle . read () . decode ( 'utf-8' ) for record in records_subset : record . get_assemblies ( handle_txt ) handle_fasta = Bio . Entrez . efetch ( db = \"protein\" , id = accession_numbers , rettype = \"fasta\" , retmode = \"text\" ) fasta_records = Bio . SeqIO . parse ( handle_fasta , \"fasta\" ) for f_record in fasta_records : record_index = accession_numbers . index ( f_record . id ) records_subset [ record_index ] . record = f_record proteins_wo_assemblies = [] if self . parameters . arguments [ \"assemblies_list\" ] == 'NA' : assemblies_table = [ f \"accession_number \\t locus_id \\t assembly \\t organism \\t strain \\t tax_id\" ] list_of_protein_with_multiple_assemblies = [] numbers_of_assemblies = [] for record in self . records : numbers_of_assemblies . append ( len ( record . assemblies_coordinates )) if len ( record . assemblies_coordinates ) == 0 : proteins_wo_assemblies . append ( record . accession_number ) if len ( record . assemblies_coordinates ) > 1 : list_of_protein_with_multiple_assemblies . append ( record . accession_number ) for assembly in record . assemblies_coordinates : assemblies_table . append ( f \" { record . accession_number } \\t \" f \" { assembly [ 'locus_id' ] } : { assembly [ 'start' ] } : { assembly [ 'stop' ] } ( { assembly [ 'strand' ] } )\" f \" \\t { assembly [ 'assembly' ] } \" f \" \\t { assembly [ 'org' ] } \\t { assembly [ 'strain' ] } \\t { assembly [ 'taxid' ] } \" ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) assemblies_table_path = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"assemblies_list.tsv\" ) assemblies_selected_table_path = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"selected_assemblies_list.tsv\" ) assemblies_table_file = open ( assemblies_table_path , \"w\" ) assemblies_table_file . write ( \" \\n \" . join ( assemblies_table )) assemblies_table_file . close () proteins_wo_assemblies_txt = \" \\n \" . join ( proteins_wo_assemblies ) + \" \\n \" proteins_wo_assemblies_path = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"proteins_wo_assembly.txt\" ) proteins_wo_assemblies_file = open ( proteins_wo_assemblies_path , \"w\" ) proteins_wo_assemblies_file . write ( proteins_wo_assemblies_txt ) if numbers_of_assemblies . count ( 0 ) > 0 : print ( f \"\u2757\ufe0fWarning message: \\n\\t For { numbers_of_assemblies . count ( 0 ) } proteins \" f \"no assembly was found. \\n \" f \" \\t These proteins' records can be suppressed by the ncbi \\n\\t \" f \"or they don't have loci that satisfies refseq_sequnces_regex config parameter. \\n\\t \" f \"List of these proteins was saved as: { os . path . basename ( proteins_wo_assemblies_path ) } \" , file = sys . stderr ) if len ( list_of_protein_with_multiple_assemblies ) > 0 : print ( f \"\u2757\ufe0fWarning message: \\n\\t For { len ( list_of_protein_with_multiple_assemblies ) } proteins \" f \"multiple assemblies were found in identical protein database \\n \" f \" \\t with max number of assemblies per one protein as { max ( numbers_of_assemblies ) } \ud83d\ude31. \\n\\t \" f \"A table with information about the assemblies was saved as a tsv file: \" f \" { os . path . basename ( assemblies_table_path ) } . \\n\\t You can edit it and remove lines with assemblies \" f \"you do not want to include in your analysis. \\n \" f \" \\t After filtering, you can use -al cmd parameter with your table as an argument. \\n \" f \" \\t In addition, config file has 'max_number_of_assemblies' parameter \" f \"(set as { self . parameters . arguments [ 'max_number_of_assemblies' ] } ). \\n\\t By default \u2755, it's used \" f \"by uorf4u to limit max number of assemblies included in the analysis; \\n \" f \" \\t and it works only if '-al' option is not provided. In case number of assemblies is more than \" f \"the cutoff, \\n\\t random sampling \ud83c\udfb2 will be used to take only subset of them. \\n\\t \" f \"Selected assemblies information was savead as a tsv file: \" f \" { os . path . basename ( assemblies_selected_table_path ) } \" f \" \\n\\t See documentation \ud83d\udcd6 for details.\" , file = sys . stderr ) else : assemblies_table = pandas . read_table ( self . parameters . arguments [ \"assemblies_list\" ], sep = \" \\t \" ) locus_ids = assemblies_table [ \"locus_id\" ] . to_list () locus_ids = [ id . split ( \":\" )[ 0 ] for id in locus_ids ] upstream_sequences = [] an_with_no_annotated_useq = [] for record in self . records : assemblies = record . assemblies_coordinates if isinstance ( self . parameters . arguments [ \"max_number_of_assemblies\" ], int ) and \\ self . parameters . arguments [ \"assemblies_list\" ] == \"NA\" : if len ( assemblies ) >= self . parameters . arguments [ \"max_number_of_assemblies\" ]: assemblies = random . sample ( assemblies , self . parameters . arguments [ \"max_number_of_assemblies\" ]) if self . parameters . arguments [ \"assemblies_list\" ] != \"NA\" : assemblies_filtered = [ i for i in assemblies if i [ \"locus_id\" ] in locus_ids ] assemblies = assemblies_filtered record . assemblies_coordinates = assemblies assemblies_table = [ f \"accession_number \\t locus_id \\t assembly \\t organism \\t strain \\t tax_id\" ] for record in self . records : for assembly in record . assemblies_coordinates : assemblies_table . append ( f \" { record . accession_number } \\t \" f \" { assembly [ 'locus_id' ] } : { assembly [ 'start' ] } : { assembly [ 'stop' ] } ( { assembly [ 'strand' ] } )\" f \" \\t { assembly [ 'assembly' ] } \" f \" \\t { assembly [ 'org' ] } \\t { assembly [ 'strain' ] } \\t { assembly [ 'taxid' ] } \" ) assemblies_table_file = open ( assemblies_selected_table_path , \"w\" ) assemblies_table_file . write ( \" \\n \" . join ( assemblies_table )) assemblies_table_file . close () lists_of_assemblies = [ record . assemblies_coordinates for record in self . records ] all_assemblies = [ assembly for sublist in lists_of_assemblies for assembly in sublist ] for i in range ( 0 , len ( all_assemblies ), 150 ): assemblies_subset = all_assemblies [ i : i + 150 ] sequences_ids = [ assembly [ \"locus_id\" ] for assembly in assemblies_subset ] handle = Bio . Entrez . efetch ( db = \"nucleotide\" , rettype = \"fasta\" , retmode = \"txt\" , id = sequences_ids ) records = Bio . SeqIO . parse ( handle , \"fasta\" ) for record , assembly in zip ( records , assemblies_subset ): assembly [ \"record\" ] = record for record in self . records : record_upstream_sequences = [] for assembly in record . assemblies_coordinates : locus_record = assembly [ \"record\" ] try : useq_downstream_region_length = min ( self . parameters . arguments [ \"downstream_region_length\" ], len ( record . record . seq ) * 3 ) except : useq_downstream_region_length = self . parameters . arguments [ \"downstream_region_length\" ] useq_upstream_region_length = self . parameters . arguments [ \"upstream_region_length\" ] if assembly [ \"strand\" ] == \"+\" : if self . parameters . arguments [ \"upstream_region_length\" ] == \"all\" : useq_start = 0 else : useq_start = max ( 0 , assembly [ \"start\" ] - self . parameters . arguments [ \"upstream_region_length\" ]) if useq_start == 0 : useq_upstream_region_length = assembly [ \"start\" ] useq_stop = min ( assembly [ \"start\" ] + self . parameters . arguments [ \"downstream_region_length\" ], len ( locus_record . seq )) if useq_stop == len ( locus_record . seq ): useq_downstream_region_length = len ( locus_record . seq ) - assembly [ \"start\" ] elif assembly [ \"strand\" ] == \"-\" : useq_start = max ( 0 , assembly [ \"stop\" ] - self . parameters . arguments [ \"downstream_region_length\" ]) if useq_start == 0 : useq_downstream_region_length = assembly [ \"stop\" ] if self . parameters . arguments [ \"upstream_region_length\" ] == \"all\" : useq_stop = len ( locus_record . seq ) else : useq_stop = min ( len ( locus_record . seq ), assembly [ \"stop\" ] + self . parameters . arguments [ \"upstream_region_length\" ]) if useq_stop == len ( locus_record . seq ): useq_upstream_region_length = len ( locus_record . seq ) - assembly [ \"stop\" ] useq_length = abs ( useq_stop - useq_start ) if self . parameters . arguments [ \"upstream_region_length\" ] != 'all' : if self . parameters . arguments [ \"minimal_upstream_region_length\" ] >= self . parameters . arguments [ \"upstream_region_length\" ]: self . parameters . arguments [ \"minimal_upstream_region_length\" ] = self . parameters . arguments [ \"upstream_region_length\" ] if useq_upstream_region_length >= self . parameters . arguments [ \"minimal_upstream_region_length\" ] or \\ self . parameters . arguments [ \"upstream_region_length\" ] == \"all\" : useq = locus_record . seq [ useq_start : useq_stop ] if assembly [ \"strand\" ] == \"-\" : useq = useq . reverse_complement () if assembly [ \"strain\" ] == \"NA\" : useq_name = assembly [ \"org\" ] elif assembly [ \"strain\" ] in assembly [ \"org\" ]: useq_name = f \" { assembly [ 'org' ] . replace ( assembly [ 'strain' ], '' ) }{ assembly [ 'strain' ] } \" else : useq_name = f \" { assembly [ 'org' ] } { assembly [ 'strain' ] } \" useq_id = f \" { assembly [ 'locus_id' ] } | { useq_start } - { useq_stop } ( { assembly [ 'strand' ] } )|\" \\ f \" { record . accession_number } \" # useq_id = f\"{useq_name}|{assembly['locus_id']}|{record.accession_number}\" useq_label = f \" { useq_name } | { assembly [ 'locus_id' ] } | { record . accession_number } \" useq_annotations = dict ( RefSeq = True , locus_record = locus_record , locus_id = assembly [ 'locus_id' ], length = useq_length , start = useq_start , stop = useq_stop , strand = assembly [ \"strand\" ], accession_number = record . accession_number , organism = assembly [ 'org' ], label = useq_label , upstream_region_length = useq_upstream_region_length , downstream_region_length = useq_downstream_region_length ) useq_record = Bio . SeqRecord . SeqRecord ( useq , id = useq_id , description = useq_name , annotations = useq_annotations ) record_upstream_sequences . append ( useq_record ) upstream_sequences += record_upstream_sequences if len ( record_upstream_sequences ) == 0 : an_with_no_annotated_useq . append ( record . accession_number ) if an_with_no_annotated_useq : print ( f \"\u2757Warning message: \\n\\t No upstream sequences for { len ( an_with_no_annotated_useq ) } protein(s)\" f \" were annotated. \\n\\t Corresponding loci in the nucleotide ncbi database can be too short \ud83d\udccf. \\n \" f \" \\t See 'minimal_upstream_region_length' config parameter description in the documentation.\" , file = sys . stderr ) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\u2705 { len ( upstream_sequences ) } upstream sequences were obtained.\" , file = sys . stdout ) return upstream_sequences except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to retrieve upstream sequences.\" ) from error","title":"Homologues"},{"location":"API/package_data_processing/#uorf4u.data_processing.Homologues.__init__","text":"Create a Homologues object. Note: With initialisation it also creates a 'records' attribute - a list of RefSeqProtein objects of proteins based on accession numbers list. Parameters: accession_numbers ( list ) \u2013 List of RefSeq accession numbers. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/data_processing.py 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 def __init__ ( self , accession_numbers : list , parameters : uorf4u . manager . Parameters ): \"\"\"Create a Homologues object. Note: With initialisation it also creates a 'records' attribute - a list of RefSeqProtein objects of proteins based on accession numbers list. Arguments: accession_numbers (list): List of RefSeq accession numbers. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" try : self . accession_numbers = accession_numbers self . parameters = parameters self . records = [ RefSeqProtein ( i , parameters ) for i in accession_numbers ] except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to create a Homologues class' object.\" ) from error","title":"__init__()"},{"location":"API/package_data_processing/#uorf4u.data_processing.Homologues.get_upstream_sequences","text":"Get upstream sequences of proteins' genes. Note: A protein may be found in multiple assemblies (for example in different strains). Returns: list ( list ) \u2013 List of Bio.SeqRecord.SeqRecord objects of upstream sequences. Source code in uorf4u/data_processing.py 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 def get_upstream_sequences ( self ) -> list : \"\"\"Get upstream sequences of proteins' genes. Note: A protein may be found in multiple assemblies (for example in different strains). Returns: list: List of Bio.SeqRecord.SeqRecord objects of upstream sequences. \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udce1 Retrieving upstream sequences...\" , file = sys . stdout ) for i in range ( 0 , len ( self . records ), 200 ): records_subset = self . records [ i : i + 200 ] accession_numbers = [ record . accession_number for record in records_subset ] handle = Bio . Entrez . efetch ( db = \"protein\" , id = accession_numbers , rettype = \"ipg\" , retmode = \"xml\" ) handle_txt = handle . read () . decode ( 'utf-8' ) for record in records_subset : record . get_assemblies ( handle_txt ) handle_fasta = Bio . Entrez . efetch ( db = \"protein\" , id = accession_numbers , rettype = \"fasta\" , retmode = \"text\" ) fasta_records = Bio . SeqIO . parse ( handle_fasta , \"fasta\" ) for f_record in fasta_records : record_index = accession_numbers . index ( f_record . id ) records_subset [ record_index ] . record = f_record proteins_wo_assemblies = [] if self . parameters . arguments [ \"assemblies_list\" ] == 'NA' : assemblies_table = [ f \"accession_number \\t locus_id \\t assembly \\t organism \\t strain \\t tax_id\" ] list_of_protein_with_multiple_assemblies = [] numbers_of_assemblies = [] for record in self . records : numbers_of_assemblies . append ( len ( record . assemblies_coordinates )) if len ( record . assemblies_coordinates ) == 0 : proteins_wo_assemblies . append ( record . accession_number ) if len ( record . assemblies_coordinates ) > 1 : list_of_protein_with_multiple_assemblies . append ( record . accession_number ) for assembly in record . assemblies_coordinates : assemblies_table . append ( f \" { record . accession_number } \\t \" f \" { assembly [ 'locus_id' ] } : { assembly [ 'start' ] } : { assembly [ 'stop' ] } ( { assembly [ 'strand' ] } )\" f \" \\t { assembly [ 'assembly' ] } \" f \" \\t { assembly [ 'org' ] } \\t { assembly [ 'strain' ] } \\t { assembly [ 'taxid' ] } \" ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) assemblies_table_path = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"assemblies_list.tsv\" ) assemblies_selected_table_path = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"selected_assemblies_list.tsv\" ) assemblies_table_file = open ( assemblies_table_path , \"w\" ) assemblies_table_file . write ( \" \\n \" . join ( assemblies_table )) assemblies_table_file . close () proteins_wo_assemblies_txt = \" \\n \" . join ( proteins_wo_assemblies ) + \" \\n \" proteins_wo_assemblies_path = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"proteins_wo_assembly.txt\" ) proteins_wo_assemblies_file = open ( proteins_wo_assemblies_path , \"w\" ) proteins_wo_assemblies_file . write ( proteins_wo_assemblies_txt ) if numbers_of_assemblies . count ( 0 ) > 0 : print ( f \"\u2757\ufe0fWarning message: \\n\\t For { numbers_of_assemblies . count ( 0 ) } proteins \" f \"no assembly was found. \\n \" f \" \\t These proteins' records can be suppressed by the ncbi \\n\\t \" f \"or they don't have loci that satisfies refseq_sequnces_regex config parameter. \\n\\t \" f \"List of these proteins was saved as: { os . path . basename ( proteins_wo_assemblies_path ) } \" , file = sys . stderr ) if len ( list_of_protein_with_multiple_assemblies ) > 0 : print ( f \"\u2757\ufe0fWarning message: \\n\\t For { len ( list_of_protein_with_multiple_assemblies ) } proteins \" f \"multiple assemblies were found in identical protein database \\n \" f \" \\t with max number of assemblies per one protein as { max ( numbers_of_assemblies ) } \ud83d\ude31. \\n\\t \" f \"A table with information about the assemblies was saved as a tsv file: \" f \" { os . path . basename ( assemblies_table_path ) } . \\n\\t You can edit it and remove lines with assemblies \" f \"you do not want to include in your analysis. \\n \" f \" \\t After filtering, you can use -al cmd parameter with your table as an argument. \\n \" f \" \\t In addition, config file has 'max_number_of_assemblies' parameter \" f \"(set as { self . parameters . arguments [ 'max_number_of_assemblies' ] } ). \\n\\t By default \u2755, it's used \" f \"by uorf4u to limit max number of assemblies included in the analysis; \\n \" f \" \\t and it works only if '-al' option is not provided. In case number of assemblies is more than \" f \"the cutoff, \\n\\t random sampling \ud83c\udfb2 will be used to take only subset of them. \\n\\t \" f \"Selected assemblies information was savead as a tsv file: \" f \" { os . path . basename ( assemblies_selected_table_path ) } \" f \" \\n\\t See documentation \ud83d\udcd6 for details.\" , file = sys . stderr ) else : assemblies_table = pandas . read_table ( self . parameters . arguments [ \"assemblies_list\" ], sep = \" \\t \" ) locus_ids = assemblies_table [ \"locus_id\" ] . to_list () locus_ids = [ id . split ( \":\" )[ 0 ] for id in locus_ids ] upstream_sequences = [] an_with_no_annotated_useq = [] for record in self . records : assemblies = record . assemblies_coordinates if isinstance ( self . parameters . arguments [ \"max_number_of_assemblies\" ], int ) and \\ self . parameters . arguments [ \"assemblies_list\" ] == \"NA\" : if len ( assemblies ) >= self . parameters . arguments [ \"max_number_of_assemblies\" ]: assemblies = random . sample ( assemblies , self . parameters . arguments [ \"max_number_of_assemblies\" ]) if self . parameters . arguments [ \"assemblies_list\" ] != \"NA\" : assemblies_filtered = [ i for i in assemblies if i [ \"locus_id\" ] in locus_ids ] assemblies = assemblies_filtered record . assemblies_coordinates = assemblies assemblies_table = [ f \"accession_number \\t locus_id \\t assembly \\t organism \\t strain \\t tax_id\" ] for record in self . records : for assembly in record . assemblies_coordinates : assemblies_table . append ( f \" { record . accession_number } \\t \" f \" { assembly [ 'locus_id' ] } : { assembly [ 'start' ] } : { assembly [ 'stop' ] } ( { assembly [ 'strand' ] } )\" f \" \\t { assembly [ 'assembly' ] } \" f \" \\t { assembly [ 'org' ] } \\t { assembly [ 'strain' ] } \\t { assembly [ 'taxid' ] } \" ) assemblies_table_file = open ( assemblies_selected_table_path , \"w\" ) assemblies_table_file . write ( \" \\n \" . join ( assemblies_table )) assemblies_table_file . close () lists_of_assemblies = [ record . assemblies_coordinates for record in self . records ] all_assemblies = [ assembly for sublist in lists_of_assemblies for assembly in sublist ] for i in range ( 0 , len ( all_assemblies ), 150 ): assemblies_subset = all_assemblies [ i : i + 150 ] sequences_ids = [ assembly [ \"locus_id\" ] for assembly in assemblies_subset ] handle = Bio . Entrez . efetch ( db = \"nucleotide\" , rettype = \"fasta\" , retmode = \"txt\" , id = sequences_ids ) records = Bio . SeqIO . parse ( handle , \"fasta\" ) for record , assembly in zip ( records , assemblies_subset ): assembly [ \"record\" ] = record for record in self . records : record_upstream_sequences = [] for assembly in record . assemblies_coordinates : locus_record = assembly [ \"record\" ] try : useq_downstream_region_length = min ( self . parameters . arguments [ \"downstream_region_length\" ], len ( record . record . seq ) * 3 ) except : useq_downstream_region_length = self . parameters . arguments [ \"downstream_region_length\" ] useq_upstream_region_length = self . parameters . arguments [ \"upstream_region_length\" ] if assembly [ \"strand\" ] == \"+\" : if self . parameters . arguments [ \"upstream_region_length\" ] == \"all\" : useq_start = 0 else : useq_start = max ( 0 , assembly [ \"start\" ] - self . parameters . arguments [ \"upstream_region_length\" ]) if useq_start == 0 : useq_upstream_region_length = assembly [ \"start\" ] useq_stop = min ( assembly [ \"start\" ] + self . parameters . arguments [ \"downstream_region_length\" ], len ( locus_record . seq )) if useq_stop == len ( locus_record . seq ): useq_downstream_region_length = len ( locus_record . seq ) - assembly [ \"start\" ] elif assembly [ \"strand\" ] == \"-\" : useq_start = max ( 0 , assembly [ \"stop\" ] - self . parameters . arguments [ \"downstream_region_length\" ]) if useq_start == 0 : useq_downstream_region_length = assembly [ \"stop\" ] if self . parameters . arguments [ \"upstream_region_length\" ] == \"all\" : useq_stop = len ( locus_record . seq ) else : useq_stop = min ( len ( locus_record . seq ), assembly [ \"stop\" ] + self . parameters . arguments [ \"upstream_region_length\" ]) if useq_stop == len ( locus_record . seq ): useq_upstream_region_length = len ( locus_record . seq ) - assembly [ \"stop\" ] useq_length = abs ( useq_stop - useq_start ) if self . parameters . arguments [ \"upstream_region_length\" ] != 'all' : if self . parameters . arguments [ \"minimal_upstream_region_length\" ] >= self . parameters . arguments [ \"upstream_region_length\" ]: self . parameters . arguments [ \"minimal_upstream_region_length\" ] = self . parameters . arguments [ \"upstream_region_length\" ] if useq_upstream_region_length >= self . parameters . arguments [ \"minimal_upstream_region_length\" ] or \\ self . parameters . arguments [ \"upstream_region_length\" ] == \"all\" : useq = locus_record . seq [ useq_start : useq_stop ] if assembly [ \"strand\" ] == \"-\" : useq = useq . reverse_complement () if assembly [ \"strain\" ] == \"NA\" : useq_name = assembly [ \"org\" ] elif assembly [ \"strain\" ] in assembly [ \"org\" ]: useq_name = f \" { assembly [ 'org' ] . replace ( assembly [ 'strain' ], '' ) }{ assembly [ 'strain' ] } \" else : useq_name = f \" { assembly [ 'org' ] } { assembly [ 'strain' ] } \" useq_id = f \" { assembly [ 'locus_id' ] } | { useq_start } - { useq_stop } ( { assembly [ 'strand' ] } )|\" \\ f \" { record . accession_number } \" # useq_id = f\"{useq_name}|{assembly['locus_id']}|{record.accession_number}\" useq_label = f \" { useq_name } | { assembly [ 'locus_id' ] } | { record . accession_number } \" useq_annotations = dict ( RefSeq = True , locus_record = locus_record , locus_id = assembly [ 'locus_id' ], length = useq_length , start = useq_start , stop = useq_stop , strand = assembly [ \"strand\" ], accession_number = record . accession_number , organism = assembly [ 'org' ], label = useq_label , upstream_region_length = useq_upstream_region_length , downstream_region_length = useq_downstream_region_length ) useq_record = Bio . SeqRecord . SeqRecord ( useq , id = useq_id , description = useq_name , annotations = useq_annotations ) record_upstream_sequences . append ( useq_record ) upstream_sequences += record_upstream_sequences if len ( record_upstream_sequences ) == 0 : an_with_no_annotated_useq . append ( record . accession_number ) if an_with_no_annotated_useq : print ( f \"\u2757Warning message: \\n\\t No upstream sequences for { len ( an_with_no_annotated_useq ) } protein(s)\" f \" were annotated. \\n\\t Corresponding loci in the nucleotide ncbi database can be too short \ud83d\udccf. \\n \" f \" \\t See 'minimal_upstream_region_length' config parameter description in the documentation.\" , file = sys . stderr ) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\u2705 { len ( upstream_sequences ) } upstream sequences were obtained.\" , file = sys . stdout ) return upstream_sequences except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to retrieve upstream sequences.\" ) from error","title":"get_upstream_sequences()"},{"location":"API/package_data_processing/#uorf4u.data_processing.Locus","text":"A Locus object holds sequence and annotation of the corresponding ncbi Reference Sequence. Attributes: locus_id ( str ) \u2013 a NCBI locus id from the Nucleotide database. locus_record ( Bio . SeqRecord . SeqRecord ) \u2013 a biopython record object of the sequence. CDSs ( list ) \u2013 list of dicts with information about annotated CDS in the locus' sequence. start_b ( int ) \u2013 start of region within annotation should be retrieved. stop_b ( int ) \u2013 stop of region within annotation should be retrieved. Source code in uorf4u/data_processing.py 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 class Locus : \"\"\" A Locus object holds sequence and annotation of the corresponding ncbi Reference Sequence. Attributes: locus_id (str): a NCBI locus id from the Nucleotide database. locus_record (Bio.SeqRecord.SeqRecord): a biopython record object of the sequence. CDSs (list): list of dicts with information about annotated CDS in the locus' sequence. start_b (int): start of region within annotation should be retrieved. stop_b (int): stop of region within annotation should be retrieved. \"\"\" def __init__ ( self , locus_id : str , start_b : int = 0 , stop_b : int = None , target_strand : str = \"NA\" , locus_record = None , xml_output = None ): \"\"\"Create a Locus object. Note: 0-based format is used for sequence indexing. Arguments: locus_id (str): locus id from the ncbi nucleotide database. start_b (int): start of region within annotation should be retrieved (optional). stop_b (int): stop of region within annotation should be retrieved (optional). target_strand (str): strand of the target object (optional). \"\"\" try : self . locus_id = locus_id if not locus_record : handle = Bio . Entrez . efetch ( db = \"nucleotide\" , rettype = \"fasta\" , retmode = \"txt\" , id = locus_id ) self . locus_record = Bio . SeqIO . read ( handle , \"fasta\" ) else : self . locus_record = locus_record if stop_b is None : stop_b = len ( self . locus_record . seq ) if not xml_output : handle = Bio . Entrez . efetch ( db = \"nucleotide\" , rettype = \"gbwithparts\" , retmode = \"xml\" , id = locus_id ) xml_output = ( handle . read ()) . decode ( \"utf-8\" ) root = xml . etree . ElementTree . fromstring ( xml_output ) self . CDSs = [] for gbseq in root . iter ( \"GBSeq\" ): if gbseq . find ( \"GBSeq_accession-version\" ) . text == self . locus_id : for gbfeature in gbseq . iter ( \"GBFeature\" ): if gbfeature . find ( \"GBFeature_key\" ) . text == \"CDS\" : try : starts , stops = [], [] for interval in gbfeature . iter ( \"GBInterval\" ): try : start , stop = int ( interval . find ( \"GBInterval_from\" ) . text ), int ( interval . find ( \"GBInterval_to\" ) . text ) if start > stop : start , stop , strand = stop - 1 , start , \"-\" else : start , stop , strand = start - 1 , stop , \"+\" starts . append ( start ) stops . append ( stop ) except : pass if starts : coordinates = list ( sorted ( zip ( starts , stops ), key = lambda pair : pair [ 0 ])) main_start , main_stop = coordinates [ 0 ][ 0 ], coordinates [ - 1 ][ - 1 ] if strand == \"+\" : main_stop = main_stop - 3 elif strand == \"-\" : main_start = main_start + 3 relative_start , relative_stop = main_start - start_b , main_stop - start_b if strand == target_strand : relative_strand = \"+\" else : relative_strand = \"-\" useq_length = stop_b - start_b if target_strand == \"-\" : relative_start , relative_stop = useq_length - relative_stop , useq_length - relative_start if ( start_b <= main_start < stop_b ) or ( start_b <= main_stop < stop_b ): cds_seq = self . locus_record . seq [ main_start : main_stop ] if strand == '-' : cds_seq = cds_seq . reverse_complement () protein_id , product_name = 'NA' , 'NA' for gbqualifier in gbfeature . iter ( \"GBQualifier\" ): if gbqualifier . find ( \"GBQualifier_name\" ) . text == \"protein_id\" : protein_id = gbqualifier . find ( \"GBQualifier_value\" ) . text if gbqualifier . find ( \"GBQualifier_name\" ) . text == \"product\" : product_name = gbqualifier . find ( \"GBQualifier_value\" ) . text if protein_id != 'NA' : if product_name != 'NA' : product_name = f \" { protein_id } ( { product_name } )\" else : product_name = f \" { protein_id } \" self . CDSs . append ( dict ( protein_id = protein_id , product_name = product_name , coordinates = coordinates , nt_seq = cds_seq , main_start = main_start , main_stop = main_stop , strand = strand , relative_start = relative_start , relative_stop = relative_stop , relative_strand = relative_strand )) except : pass except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to create a Locus class' object.\" ) from error","title":"Locus"},{"location":"API/package_data_processing/#uorf4u.data_processing.Locus.__init__","text":"Create a Locus object. Note: 0-based format is used for sequence indexing. Parameters: locus_id ( str ) \u2013 locus id from the ncbi nucleotide database. start_b ( int ) \u2013 start of region within annotation should be retrieved (optional). stop_b ( int ) \u2013 stop of region within annotation should be retrieved (optional). target_strand ( str ) \u2013 strand of the target object (optional). Source code in uorf4u/data_processing.py 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 def __init__ ( self , locus_id : str , start_b : int = 0 , stop_b : int = None , target_strand : str = \"NA\" , locus_record = None , xml_output = None ): \"\"\"Create a Locus object. Note: 0-based format is used for sequence indexing. Arguments: locus_id (str): locus id from the ncbi nucleotide database. start_b (int): start of region within annotation should be retrieved (optional). stop_b (int): stop of region within annotation should be retrieved (optional). target_strand (str): strand of the target object (optional). \"\"\" try : self . locus_id = locus_id if not locus_record : handle = Bio . Entrez . efetch ( db = \"nucleotide\" , rettype = \"fasta\" , retmode = \"txt\" , id = locus_id ) self . locus_record = Bio . SeqIO . read ( handle , \"fasta\" ) else : self . locus_record = locus_record if stop_b is None : stop_b = len ( self . locus_record . seq ) if not xml_output : handle = Bio . Entrez . efetch ( db = \"nucleotide\" , rettype = \"gbwithparts\" , retmode = \"xml\" , id = locus_id ) xml_output = ( handle . read ()) . decode ( \"utf-8\" ) root = xml . etree . ElementTree . fromstring ( xml_output ) self . CDSs = [] for gbseq in root . iter ( \"GBSeq\" ): if gbseq . find ( \"GBSeq_accession-version\" ) . text == self . locus_id : for gbfeature in gbseq . iter ( \"GBFeature\" ): if gbfeature . find ( \"GBFeature_key\" ) . text == \"CDS\" : try : starts , stops = [], [] for interval in gbfeature . iter ( \"GBInterval\" ): try : start , stop = int ( interval . find ( \"GBInterval_from\" ) . text ), int ( interval . find ( \"GBInterval_to\" ) . text ) if start > stop : start , stop , strand = stop - 1 , start , \"-\" else : start , stop , strand = start - 1 , stop , \"+\" starts . append ( start ) stops . append ( stop ) except : pass if starts : coordinates = list ( sorted ( zip ( starts , stops ), key = lambda pair : pair [ 0 ])) main_start , main_stop = coordinates [ 0 ][ 0 ], coordinates [ - 1 ][ - 1 ] if strand == \"+\" : main_stop = main_stop - 3 elif strand == \"-\" : main_start = main_start + 3 relative_start , relative_stop = main_start - start_b , main_stop - start_b if strand == target_strand : relative_strand = \"+\" else : relative_strand = \"-\" useq_length = stop_b - start_b if target_strand == \"-\" : relative_start , relative_stop = useq_length - relative_stop , useq_length - relative_start if ( start_b <= main_start < stop_b ) or ( start_b <= main_stop < stop_b ): cds_seq = self . locus_record . seq [ main_start : main_stop ] if strand == '-' : cds_seq = cds_seq . reverse_complement () protein_id , product_name = 'NA' , 'NA' for gbqualifier in gbfeature . iter ( \"GBQualifier\" ): if gbqualifier . find ( \"GBQualifier_name\" ) . text == \"protein_id\" : protein_id = gbqualifier . find ( \"GBQualifier_value\" ) . text if gbqualifier . find ( \"GBQualifier_name\" ) . text == \"product\" : product_name = gbqualifier . find ( \"GBQualifier_value\" ) . text if protein_id != 'NA' : if product_name != 'NA' : product_name = f \" { protein_id } ( { product_name } )\" else : product_name = f \" { protein_id } \" self . CDSs . append ( dict ( protein_id = protein_id , product_name = product_name , coordinates = coordinates , nt_seq = cds_seq , main_start = main_start , main_stop = main_stop , strand = strand , relative_start = relative_start , relative_stop = relative_stop , relative_strand = relative_strand )) except : pass except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to create a Locus class' object.\" ) from error","title":"__init__()"},{"location":"API/package_data_processing/#uorf4u.data_processing.ORF","text":"An ORF object holds information about an annotated ORF. Note: It's supposed that the ORFs class' objects will not be used directly by API users since it's only needed for other classes' methods. Attributes: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. id ( str ) \u2013 identifier of the ORF. Format: locus_id|accession_number|distance_from_the_start_codon_to_the_main_orf name ( str ) \u2013 name of the ORF. Format: useq_name|distance_from_the_start_codon_to_the_main_orf sequence_id ( str ) \u2013 identifier of the ORF's sequence (locus id from the ncbi database). start ( int ) \u2013 start position of the ORF on the locus (0-based). stop ( int ) \u2013 stop position of the ORF on the locus (0-based). length ( int ) \u2013 ORF's nucleotide sequence length. nt_sequence ( Bio . Seq . Seq ) \u2013 a Seq object of nucleotide sequence of the ORF. aa_sequence ( Bio . Seq . Seq ) \u2013 a Seq object of amino acid sequence of the ORF. sd_window_seq ( Bio . Seq . Seq ) \u2013 a Seq object of upstream sequence to the start codon of the ORF. min_energy ( float ) \u2013 minimal value of thermodynamic interaction between aSD and putative SD sequences within the upstream sequences to the start codon. putative_sd_sequence ( Bio . Seq . Seq ) \u2013 a Seq object of the putative SD sequence with the minimal energy value. extended_orfs ( list ) \u2013 a list of ORFs with that are in frame with the ORF, but have upstream start codon. Source code in uorf4u/data_processing.py 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 class ORF : \"\"\"An ORF object holds information about an annotated ORF. Note: It's supposed that the ORFs class' objects will not be used directly by API users since it's only needed for other classes' methods. Attributes: parameters (uorf4u.manager.Parameters): Parameters' class object. id (str): identifier of the ORF. Format: locus_id|accession_number|distance_from_the_start_codon_to_the_main_orf name (str): name of the ORF. Format: useq_name|distance_from_the_start_codon_to_the_main_orf sequence_id (str): identifier of the ORF's sequence (locus id from the ncbi database). start (int): start position of the ORF on the locus (0-based). stop (int): stop position of the ORF on the locus (0-based). length (int): ORF's nucleotide sequence length. nt_sequence (Bio.Seq.Seq): a Seq object of nucleotide sequence of the ORF. aa_sequence (Bio.Seq.Seq): a Seq object of amino acid sequence of the ORF. sd_window_seq (Bio.Seq.Seq): a Seq object of upstream sequence to the start codon of the ORF. min_energy (float): minimal value of thermodynamic interaction between aSD and putative SD sequences within the upstream sequences to the start codon. putative_sd_sequence (Bio.Seq.Seq): a Seq object of the putative SD sequence with the minimal energy value. extended_orfs (list): a list of ORFs with that are in frame with the ORF, but have upstream start codon. \"\"\" def __init__ ( self , parameters : uorf4u . manager . Parameters , id : str , name : str , nt_sequence : Bio . Seq . Seq , sd_window_seq : Bio . Seq . Seq , start : int , stop : int , distance : int , useq_index : int , annotation : str = \"NA\" ): \"\"\"Create an ORF object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. id (str): identifier of the ORF. Format: locus_id:distance_from_the_start_codon_to_the_proteins_orf:length. nt_sequence (Bio.Seq.Seq): a Seq object of nucleotide sequence of the ORF. sd_window_seq (Bio.Seq.Seq): a Seq object of upstream sequence to the start codon of the ORF. start (int): start position of the ORF on the locus (0-based). stop (int): stop position of the ORF on the locus (0-based). distance (int): distance to the main ORF. \"\"\" self . parameters = parameters codon_table = Bio . Data . CodonTable . unambiguous_dna_by_name [ # ambiguous can be needed! parameters . arguments [ \"ncbi_genetic_code_name\" ]] codon_table_ambiguous = Bio . Data . CodonTable . ambiguous_dna_by_name [ # ambiguous can be needed! parameters . arguments [ \"ncbi_genetic_code_name\" ]] self . name = name self . distance = distance self . id = id self . sequence_id = id . split ( \":\" )[ 0 ] self . start = start self . stop = stop self . length = len ( nt_sequence ) self . nt_sequence = nt_sequence self . annotation = annotation self . useq_index = useq_index try : self . aa_sequence = self . nt_sequence . translate ( table = codon_table ) except : self . aa_sequence = self . nt_sequence . translate ( table = codon_table_ambiguous ) self . sd_window_seq = sd_window_seq self . extended_orfs = [] self . min_energy = 0 self . putative_sd_sequence = \"NA\" self . sd_window_seq_str = \"NA\" self . sd_window_energies = [] def calculate_energies ( self ) -> None : \"\"\"Calculate energies of putative SD sequences of the upstream sequence. Returns: None \"\"\" # Loading reference energies json file with open ( self . parameters . arguments [ \"ref_energies\" ]) as ref_energy_file : ref_energy = json . load ( ref_energy_file ) sd_seq_length = min ([ len ( i ) for i in ref_energy . keys ()]) # Energies calculations if len ( self . sd_window_seq ) >= min ( ref_energy . values ()): energies = [] for position in range (( len ( self . sd_window_seq ) - sd_seq_length ) + 1 ): try : energies . append ( ref_energy [ self . sd_window_seq [ position : position + sd_seq_length ]]) except : energies . append ( 0 ) if energies : self . min_energy = min ( energies ) self . sd_window_energies = [ str ( i ) for i in energies ] if self . min_energy < self . parameters . arguments [ \"sd_energy_cutoff\" ]: sd_start_position = energies . index ( self . min_energy ) # Be careful, it could be more than one! self . putative_sd_sequence = self . sd_window_seq [ sd_start_position : sd_start_position + sd_seq_length ] self . sd_window_seq_str = ( f \" { self . sd_window_seq [ 0 : sd_start_position ] . lower () } \" f \" { self . putative_sd_sequence . upper () } \" f \" { self . sd_window_seq [ sd_start_position + sd_seq_length :] . lower () } \" ) return None","title":"ORF"},{"location":"API/package_data_processing/#uorf4u.data_processing.ORF.__init__","text":"Create an ORF object. Parameters: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. id ( str ) \u2013 identifier of the ORF. Format: locus_id:distance_from_the_start_codon_to_the_proteins_orf:length. nt_sequence ( Bio . Seq . Seq ) \u2013 a Seq object of nucleotide sequence of the ORF. sd_window_seq ( Bio . Seq . Seq ) \u2013 a Seq object of upstream sequence to the start codon of the ORF. start ( int ) \u2013 start position of the ORF on the locus (0-based). stop ( int ) \u2013 stop position of the ORF on the locus (0-based). distance ( int ) \u2013 distance to the main ORF. Source code in uorf4u/data_processing.py 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 def __init__ ( self , parameters : uorf4u . manager . Parameters , id : str , name : str , nt_sequence : Bio . Seq . Seq , sd_window_seq : Bio . Seq . Seq , start : int , stop : int , distance : int , useq_index : int , annotation : str = \"NA\" ): \"\"\"Create an ORF object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. id (str): identifier of the ORF. Format: locus_id:distance_from_the_start_codon_to_the_proteins_orf:length. nt_sequence (Bio.Seq.Seq): a Seq object of nucleotide sequence of the ORF. sd_window_seq (Bio.Seq.Seq): a Seq object of upstream sequence to the start codon of the ORF. start (int): start position of the ORF on the locus (0-based). stop (int): stop position of the ORF on the locus (0-based). distance (int): distance to the main ORF. \"\"\" self . parameters = parameters codon_table = Bio . Data . CodonTable . unambiguous_dna_by_name [ # ambiguous can be needed! parameters . arguments [ \"ncbi_genetic_code_name\" ]] codon_table_ambiguous = Bio . Data . CodonTable . ambiguous_dna_by_name [ # ambiguous can be needed! parameters . arguments [ \"ncbi_genetic_code_name\" ]] self . name = name self . distance = distance self . id = id self . sequence_id = id . split ( \":\" )[ 0 ] self . start = start self . stop = stop self . length = len ( nt_sequence ) self . nt_sequence = nt_sequence self . annotation = annotation self . useq_index = useq_index try : self . aa_sequence = self . nt_sequence . translate ( table = codon_table ) except : self . aa_sequence = self . nt_sequence . translate ( table = codon_table_ambiguous ) self . sd_window_seq = sd_window_seq self . extended_orfs = [] self . min_energy = 0 self . putative_sd_sequence = \"NA\" self . sd_window_seq_str = \"NA\" self . sd_window_energies = []","title":"__init__()"},{"location":"API/package_data_processing/#uorf4u.data_processing.ORF.calculate_energies","text":"Calculate energies of putative SD sequences of the upstream sequence. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 def calculate_energies ( self ) -> None : \"\"\"Calculate energies of putative SD sequences of the upstream sequence. Returns: None \"\"\" # Loading reference energies json file with open ( self . parameters . arguments [ \"ref_energies\" ]) as ref_energy_file : ref_energy = json . load ( ref_energy_file ) sd_seq_length = min ([ len ( i ) for i in ref_energy . keys ()]) # Energies calculations if len ( self . sd_window_seq ) >= min ( ref_energy . values ()): energies = [] for position in range (( len ( self . sd_window_seq ) - sd_seq_length ) + 1 ): try : energies . append ( ref_energy [ self . sd_window_seq [ position : position + sd_seq_length ]]) except : energies . append ( 0 ) if energies : self . min_energy = min ( energies ) self . sd_window_energies = [ str ( i ) for i in energies ] if self . min_energy < self . parameters . arguments [ \"sd_energy_cutoff\" ]: sd_start_position = energies . index ( self . min_energy ) # Be careful, it could be more than one! self . putative_sd_sequence = self . sd_window_seq [ sd_start_position : sd_start_position + sd_seq_length ] self . sd_window_seq_str = ( f \" { self . sd_window_seq [ 0 : sd_start_position ] . lower () } \" f \" { self . putative_sd_sequence . upper () } \" f \" { self . sd_window_seq [ sd_start_position + sd_seq_length :] . lower () } \" ) return None","title":"calculate_energies()"},{"location":"API/package_data_processing/#uorf4u.data_processing.Path","text":"A Path object holds information about a list of conserved ORFs. Note: It's supposed that the Path class' objects will not be used directly by API users since it's only needed for other classes' methods. Attributes: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. path ( list ) \u2013 List of the ORF class objects. score ( float ) \u2013 Score of the Path (calculated as sum of pairwise alignments scores of ORFs). msa ( dict ) \u2013 Dict with Multiple sequence alignment (MSA, Bio.Align.MultipleSeqAlignment object) as values for different sequences (nt, aa, sd) as keys. msa_consensus ( dict ) \u2013 Dict with consensus sequence (Bio.Seq.Seq object) as values for different sequences (nt, aa, sd) as keys. length \u2013 length of the nucleotide sequence alignment. id ( str ) \u2013 Path's id (format: length|score|num_of_orfs|average_distance_to_the_main_ORF Source code in uorf4u/data_processing.py 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 class Path : \"\"\"A Path object holds information about a list of conserved ORFs. Note: It's supposed that the Path class' objects will not be used directly by API users since it's only needed for other classes' methods. Attributes: parameters (uorf4u.manager.Parameters): Parameters' class object. path (list): List of the ORF class objects. score (float): Score of the Path (calculated as sum of pairwise alignments scores of ORFs). msa (dict): Dict with Multiple sequence alignment (MSA, Bio.Align.MultipleSeqAlignment object) as values for different sequences (nt, aa, sd) as keys. msa_consensus (dict): Dict with consensus sequence (Bio.Seq.Seq object) as values for different sequences (nt, aa, sd) as keys. length: length of the nucleotide sequence alignment. id (str): Path's id (format: length|score|num_of_orfs|average_distance_to_the_main_ORF \"\"\" def __init__ ( self , parameters : uorf4u . manager . Parameters ): \"\"\"Create a Path object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . parameters = parameters self . path = [] self . score = 0 self . msa = dict () self . msa_consensus = dict () self . id = None self . length = None def update ( self , orf : ORF , score = 0 ): \"\"\"Update a Path with a new ORF. Arguments: orf (ORF): an ORF class' object. score (float): a sum of pairwise alignment scores of the ORF against all ORFs in the Path. Returns: None \"\"\" self . path . append ( orf ) self . score += score def sort ( self ) -> None : \"\"\"Sort list of ORFs by their names. Returns: None \"\"\" sorted_path = [ x for _ , x in sorted ( zip ([ i . name for i in self . path ], self . path ), key = lambda pair : pair [ 0 ])] self . path = sorted_path return None def __len__ ( self ): \"\"\"__len__ magic method for a Path object. Returns: int: length of the path attribute - a number of ORFs in a Path. \"\"\" return len ( self . path ) def calculate_similarity ( self , other ) -> float : \"\"\"Calculate fraction of identical ORFs between two Path object. __Note:__ If two objects have different length, the fraction will be calculated as a number of identical ORFs divided by length of the shortest Path. Returns: float: fraction of identical ORFs. \"\"\" num_of_identical_elements = len ( set ( self . path ) & set ( other . path )) fraction_of_identical_orfs = num_of_identical_elements / min ( len ( self ), len ( other )) return fraction_of_identical_orfs def muscle_msa ( self ) -> None : \"\"\"Run a multiple sequence alignment tool (muscle) for the ORFs nucleotide and amino acid sequences. Note: This method updates nt_msa and aa_msa attributes. Returns: None \"\"\" self . msa = dict () for seq_type in self . parameters . arguments [ \"sequences_to_write\" ]: records = [] for orf in self . path : # record_id = f\"{orf.id}\" # record_description = f\"{(orf.name.split('|')[0])}\" record_id = f \" { orf . name } \" record_description = \"\" if seq_type == \"nt\" : record = Bio . SeqRecord . SeqRecord ( orf . nt_sequence , record_id , \"\" , record_description ) elif seq_type == \"aa\" : record = Bio . SeqRecord . SeqRecord ( orf . aa_sequence , record_id , \"\" , record_description ) elif seq_type == \"sd\" : record = Bio . SeqRecord . SeqRecord ( orf . sd_window_seq , record_id , \"\" , record_description ) records . append ( record ) temp_input = tempfile . NamedTemporaryFile () Bio . SeqIO . write ( records , temp_input . name , \"fasta\" ) temp_output = tempfile . NamedTemporaryFile () muscle = self . parameters . arguments [ \"muscle_binary\" ] subprocess . run ([ muscle , \"-align\" , temp_input . name , \"-output\" , temp_output . name ], stderr = subprocess . DEVNULL ) temp_input . close () msa = Bio . AlignIO . read ( temp_output . name , \"fasta\" ) # msa.sort(key=lambda r: r.description) msa_info = Bio . Align . AlignInfo . SummaryInfo ( msa ) msa_consensus = msa_info . gap_consensus ( threshold = self . parameters . arguments [ \"consensus_threshold\" ]) temp_output . close () if seq_type == \"nt\" : self . length = msa . get_alignment_length () self . msa [ seq_type ], self . msa_consensus [ seq_type ] = msa , msa_consensus avr_distance = str ( round ( statistics . mean ([ i . distance for i in self . path ]))) self . id = f \"length- { self . msa [ 'nt' ] . get_alignment_length () } |score\u2013 { round ( self . score ) } |\" \\ f \"num_of_orfs- { len ( self . path ) } |avr_dist- { avr_distance } \" return None def maft_msa ( self ) -> None : \"\"\"Run a multiple sequence alignment tool (MAFT) for the ORFs nucleotide and amino acid sequences. Note: This method updates nt_msa and aa_msa attributes. Returns: None \"\"\" self . msa = dict () for seq_type in self . parameters . arguments [ \"sequences_to_write\" ]: records = [] for orf in self . path : # record_id = f\"{orf.id}\" # record_description = f\"{(orf.name.split('|')[0])}\" record_id = f \" { orf . id } \" record_description = orf . name if seq_type == \"nt\" : record = Bio . SeqRecord . SeqRecord ( orf . nt_sequence , record_id , \"\" , record_description ) elif seq_type == \"aa\" : record = Bio . SeqRecord . SeqRecord ( orf . aa_sequence , record_id , \"\" , record_description ) elif seq_type == \"sd\" : record = Bio . SeqRecord . SeqRecord ( orf . sd_window_seq , record_id , \"\" , record_description ) records . append ( record ) temp_input = tempfile . NamedTemporaryFile () Bio . SeqIO . write ( records , temp_input . name , \"fasta\" ) temp_output = tempfile . NamedTemporaryFile () temp_stderr = tempfile . NamedTemporaryFile () maft = self . parameters . arguments [ \"maft_binary\" ] try : subprocess . run ([ maft , \"--auto\" , temp_input . name ], stdout = temp_output , stderr = temp_stderr ) msa = Bio . AlignIO . read ( temp_output . name , \"fasta\" ) temp_stderr . close () temp_output . close () except Exception as error : temp_stderr . seek ( 0 ) temp_output . seek ( 0 ) print ( f \"\ud83e\udd2c MAFFT error message: \\n { temp_stderr . read () } \" , file = sys . stderr ) temp_stderr . close () temp_output . close () raise uorf4u . manager . uORF4uError ( f \"mafft error. If you work on a linux machine,\" f \" run uorf4 --linux.\" ) from error for record in msa : record . description = \" \" . join ( record . description . split ( \" \" )[ 1 :]) # msa.sort(key=lambda r: r.description) # add a parameter for order setting msa_info = Bio . Align . AlignInfo . SummaryInfo ( msa ) msa_consensus = msa_info . gap_consensus ( threshold = self . parameters . arguments [ \"consensus_threshold\" ]) temp_output . close () if seq_type == \"nt\" : self . length = msa . get_alignment_length () self . msa [ seq_type ], self . msa_consensus [ seq_type ] = msa , msa_consensus avr_distance = str ( round ( statistics . mean ([ i . distance for i in self . path ]))) self . id = f \"length- { self . msa [ 'nt' ] . get_alignment_length () } |score\u2013 { round ( self . score ) } |\" \\ f \"num_of_orfs- { len ( self . path ) } |avr_dist- { avr_distance } \" return None def plot_msa ( self ) -> None : \"\"\"Plot MSA of conserved ORFs. Returns: None \"\"\" rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_visualisation\" ) for i in self . parameters . arguments [ \"sequences_to_write\" ]])) for o_dir in output_dirs . values (): if not ( os . path . exists ( o_dir )): os . mkdir ( o_dir ) for s_type in self . parameters . arguments [ \"sequences_to_write\" ]: current_msa = self . msa [ s_type ] if s_type == \"nt\" or s_type == \"sd\" : seq_type = \"nt\" else : seq_type = \"aa\" msa_plot_manager = uorf4u . drawing_msa . MSAPlotManager ( current_msa , self . parameters , seq_type ) msa_plot_manager . define_x_axis_coordinate_system () output_file = os . path . join ( output_dirs [ s_type ], f \" { self . id } .pdf\" ) msa_plot_manager . create_tracks () msa_plot_manager . plot ( output_file ) def plot_ggmsa ( self ) -> None : \"\"\"Plot MSA of conserved ORFs saved as fasta files. Note: R script based on ggmsa package [yulab-smu.top/ggmsa] used to produce MSA plots. R script (msa_plot.R) can be found in output_dir. This method uses subprocess to run this R script in the following way: `Rscript {output_dir}/msa_plot.R --msa_fasta path_to_fasta --output output_path --seq_type (nt/aa) --width N(mm) --height M(mm)`. Since during each run of uorf4u a local copy of this script is created in your output_dir, you can change it without any consequences for next uorf4u runs. Returns: None \"\"\" rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_visualisation\" ) for i in self . parameters . arguments [ \"sequences_to_write\" ]])) fasta_files_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_fasta_files\" ) for i in self . parameters . arguments [ \"sequences_to_write\" ]])) for o_dir in output_dirs . values (): if not ( os . path . exists ( o_dir )): os . mkdir ( o_dir ) r_script_path = self . parameters . arguments [ \"plot_msa_R_script\" ] r_script_local = os . path . join ( self . parameters . arguments [ \"output_dir\" ], os . path . basename ( r_script_path )) if not ( os . path . exists ( r_script_local )): shutil . copy ( r_script_path , r_script_local ) for s_type in self . parameters . arguments [ \"sequences_to_write\" ]: current_msa = self . msa [ s_type ] if s_type == \"nt\" or s_type == \"sd\" : seq_type = \"nt\" else : seq_type = \"aa\" output_dir = os . path . abspath ( os . path . join ( output_dirs [ s_type ])) input_file = os . path . abspath ( os . path . join ( fasta_files_dirs [ s_type ], f \" { self . id } .fa\" )) num_sequences = len ( current_msa ) length_of_alignment = current_msa . get_alignment_length () page_width = ( 50 + length_of_alignment ) * 5 page_height = max ( 17 , ( num_sequences + 5 ) * 3 ) subprocess . run ([ \"Rscript\" , r_script_local , \"--msa_fasta\" , input_file , \"--output\" , output_dir , \"--seq_type\" , seq_type , \"--width\" , str ( page_width ), \"--height\" , str ( page_height )]) def plot_logo ( self ) -> None : \"\"\"Plot sequence Logo of conserved ORFs MSA saved as fasta files. Note: This method uses logomaker package to produce images. Returns: None \"\"\" rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _seqlogo_visualisation\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) for o_dir in output_dirs . values (): if not ( os . path . exists ( o_dir )): os . mkdir ( o_dir ) ambiguous_codon_table = Bio . Data . CodonTable . ambiguous_dna_by_name [ self . parameters . arguments [ \"ncbi_genetic_code_name\" ]] unambiguous_codon_table = Bio . Data . CodonTable . unambiguous_dna_by_name [ self . parameters . arguments [ \"ncbi_genetic_code_name\" ]] alphabet = dict ( nt = set ( ambiguous_codon_table . nucleotide_alphabet ), aa = set ( ambiguous_codon_table . protein_alphabet )) unambiguous_alphabet = dict ( nt = set ( unambiguous_codon_table . nucleotide_alphabet ), aa = set ( unambiguous_codon_table . protein_alphabet )) for s_type in self . parameters . arguments [ \"sequences_to_write\" ]: current_msa = self . msa [ s_type ] if s_type == \"nt\" or s_type == \"sd\" : seq_type = \"nt\" elif s_type == \"aa\" : seq_type = \"aa\" output_file = os . path . abspath ( os . path . join ( output_dirs [ s_type ], os . path . basename ( self . id ))) msa_length = current_msa . get_alignment_length () num_of_sequences = len ( current_msa ) current_msa_info = Bio . Align . AlignInfo . SummaryInfo ( current_msa ) pos_specific_dict = dict () pos_specific_score_matrix = current_msa_info . pos_specific_score_matrix () for i in alphabet [ seq_type ]: pos_specific_dict [ i ] = [ 0 for j in range ( msa_length )] for i in range ( msa_length ): for element in pos_specific_score_matrix [ i ] . keys (): pos_specific_dict [ element . upper ()][ i ] = ( pos_specific_score_matrix [ i ][ element ] / num_of_sequences ) pos = [ i for i in range ( msa_length )] pos_specific_dict = { k : v for k , v in pos_specific_dict . items () if sum ( v ) > 0 or k in unambiguous_alphabet [ seq_type ]} matrix_fr = pandas . DataFrame ( pos_specific_dict , index = pos ) colors = self . parameters . arguments [ f \"colors_ { seq_type } \" ] colors = { k : uorf4u . methods . color_name_to_hex ( v , self . parameters . arguments ) for k , v in colors . items ()} fig_size = ( min ( max ( 10 , msa_length * 1.3 ), (( 2 ** 16 ) - 1 ) / 100 ), min ( 2.5 , 2.5 * 10 / ( msa_length ** ( 1 / 5 )))) if self . parameters . arguments [ \"logo_type\" ] == \"probability\" or \\ self . parameters . arguments [ \"logo_type\" ] == \"both\" : output_file_fr = f \" { output_file } _prob.pdf\" max_value_fr = 1 logo_fr = logomaker . Logo ( matrix_fr , color_scheme = colors , figsize = fig_size , alpha = self . parameters . arguments [ \"logo_alpha\" ], show_spines = False , baseline_width = 0 ) logo_fr . style_spines ( spines = [ \"left\" ], visible = True , linewidth = 0.7 ) logo_fr . ax . set_xticks ([]) logo_fr . ax . set_yticks ([ 0 , max_value_fr ]) plt . savefig ( output_file_fr ) plt . close ( \"all\" ) if self . parameters . arguments [ \"logo_type\" ] == \"information\" or \\ self . parameters . arguments [ \"logo_type\" ] == \"both\" : colors [ \"-\" ] = colors [ \"_\" ] matrix_fr [ \"-\" ] = round (( 1 - matrix_fr . sum ( axis = 1 )), 5 ) if matrix_fr [ \"-\" ] . sum () == 0 : del matrix_fr [ '-' ] matrix_info = logomaker . transform_matrix ( matrix_fr , from_type = \"probability\" , to_type = \"information\" ) max_value_info = math . log2 ( len ( pos_specific_dict . keys ())) output_file_info = f \" { output_file } _info.pdf\" logo_info = logomaker . Logo ( matrix_info , color_scheme = colors , figsize = fig_size , alpha = self . parameters . arguments [ \"logo_alpha\" ], show_spines = False , baseline_width = 0 ) logo_info . style_spines ( spines = [ \"left\" ], visible = True , linewidth = 0.7 ) logo_info . ax . set_xticks ([]) logo_info . ax . set_yticks ([ 0 , max_value_info ]) plt . savefig ( output_file_info ) plt . close ( \"all\" ) return None","title":"Path"},{"location":"API/package_data_processing/#uorf4u.data_processing.Path.__init__","text":"Create a Path object. Parameters: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/data_processing.py 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 def __init__ ( self , parameters : uorf4u . manager . Parameters ): \"\"\"Create a Path object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . parameters = parameters self . path = [] self . score = 0 self . msa = dict () self . msa_consensus = dict () self . id = None self . length = None","title":"__init__()"},{"location":"API/package_data_processing/#uorf4u.data_processing.Path.__len__","text":"len magic method for a Path object. Returns: int \u2013 length of the path attribute - a number of ORFs in a Path. Source code in uorf4u/data_processing.py 1484 1485 1486 1487 1488 1489 1490 1491 def __len__ ( self ): \"\"\"__len__ magic method for a Path object. Returns: int: length of the path attribute - a number of ORFs in a Path. \"\"\" return len ( self . path )","title":"__len__()"},{"location":"API/package_data_processing/#uorf4u.data_processing.Path.calculate_similarity","text":"Calculate fraction of identical ORFs between two Path object. Note: If two objects have different length, the fraction will be calculated as a number of identical ORFs divided by length of the shortest Path. Returns: float ( float ) \u2013 fraction of identical ORFs. Source code in uorf4u/data_processing.py 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 def calculate_similarity ( self , other ) -> float : \"\"\"Calculate fraction of identical ORFs between two Path object. __Note:__ If two objects have different length, the fraction will be calculated as a number of identical ORFs divided by length of the shortest Path. Returns: float: fraction of identical ORFs. \"\"\" num_of_identical_elements = len ( set ( self . path ) & set ( other . path )) fraction_of_identical_orfs = num_of_identical_elements / min ( len ( self ), len ( other )) return fraction_of_identical_orfs","title":"calculate_similarity()"},{"location":"API/package_data_processing/#uorf4u.data_processing.Path.maft_msa","text":"Run a multiple sequence alignment tool (MAFT) for the ORFs nucleotide and amino acid sequences. Note: This method updates nt_msa and aa_msa attributes. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 def maft_msa ( self ) -> None : \"\"\"Run a multiple sequence alignment tool (MAFT) for the ORFs nucleotide and amino acid sequences. Note: This method updates nt_msa and aa_msa attributes. Returns: None \"\"\" self . msa = dict () for seq_type in self . parameters . arguments [ \"sequences_to_write\" ]: records = [] for orf in self . path : # record_id = f\"{orf.id}\" # record_description = f\"{(orf.name.split('|')[0])}\" record_id = f \" { orf . id } \" record_description = orf . name if seq_type == \"nt\" : record = Bio . SeqRecord . SeqRecord ( orf . nt_sequence , record_id , \"\" , record_description ) elif seq_type == \"aa\" : record = Bio . SeqRecord . SeqRecord ( orf . aa_sequence , record_id , \"\" , record_description ) elif seq_type == \"sd\" : record = Bio . SeqRecord . SeqRecord ( orf . sd_window_seq , record_id , \"\" , record_description ) records . append ( record ) temp_input = tempfile . NamedTemporaryFile () Bio . SeqIO . write ( records , temp_input . name , \"fasta\" ) temp_output = tempfile . NamedTemporaryFile () temp_stderr = tempfile . NamedTemporaryFile () maft = self . parameters . arguments [ \"maft_binary\" ] try : subprocess . run ([ maft , \"--auto\" , temp_input . name ], stdout = temp_output , stderr = temp_stderr ) msa = Bio . AlignIO . read ( temp_output . name , \"fasta\" ) temp_stderr . close () temp_output . close () except Exception as error : temp_stderr . seek ( 0 ) temp_output . seek ( 0 ) print ( f \"\ud83e\udd2c MAFFT error message: \\n { temp_stderr . read () } \" , file = sys . stderr ) temp_stderr . close () temp_output . close () raise uorf4u . manager . uORF4uError ( f \"mafft error. If you work on a linux machine,\" f \" run uorf4 --linux.\" ) from error for record in msa : record . description = \" \" . join ( record . description . split ( \" \" )[ 1 :]) # msa.sort(key=lambda r: r.description) # add a parameter for order setting msa_info = Bio . Align . AlignInfo . SummaryInfo ( msa ) msa_consensus = msa_info . gap_consensus ( threshold = self . parameters . arguments [ \"consensus_threshold\" ]) temp_output . close () if seq_type == \"nt\" : self . length = msa . get_alignment_length () self . msa [ seq_type ], self . msa_consensus [ seq_type ] = msa , msa_consensus avr_distance = str ( round ( statistics . mean ([ i . distance for i in self . path ]))) self . id = f \"length- { self . msa [ 'nt' ] . get_alignment_length () } |score\u2013 { round ( self . score ) } |\" \\ f \"num_of_orfs- { len ( self . path ) } |avr_dist- { avr_distance } \" return None","title":"maft_msa()"},{"location":"API/package_data_processing/#uorf4u.data_processing.Path.muscle_msa","text":"Run a multiple sequence alignment tool (muscle) for the ORFs nucleotide and amino acid sequences. Note: This method updates nt_msa and aa_msa attributes. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 def muscle_msa ( self ) -> None : \"\"\"Run a multiple sequence alignment tool (muscle) for the ORFs nucleotide and amino acid sequences. Note: This method updates nt_msa and aa_msa attributes. Returns: None \"\"\" self . msa = dict () for seq_type in self . parameters . arguments [ \"sequences_to_write\" ]: records = [] for orf in self . path : # record_id = f\"{orf.id}\" # record_description = f\"{(orf.name.split('|')[0])}\" record_id = f \" { orf . name } \" record_description = \"\" if seq_type == \"nt\" : record = Bio . SeqRecord . SeqRecord ( orf . nt_sequence , record_id , \"\" , record_description ) elif seq_type == \"aa\" : record = Bio . SeqRecord . SeqRecord ( orf . aa_sequence , record_id , \"\" , record_description ) elif seq_type == \"sd\" : record = Bio . SeqRecord . SeqRecord ( orf . sd_window_seq , record_id , \"\" , record_description ) records . append ( record ) temp_input = tempfile . NamedTemporaryFile () Bio . SeqIO . write ( records , temp_input . name , \"fasta\" ) temp_output = tempfile . NamedTemporaryFile () muscle = self . parameters . arguments [ \"muscle_binary\" ] subprocess . run ([ muscle , \"-align\" , temp_input . name , \"-output\" , temp_output . name ], stderr = subprocess . DEVNULL ) temp_input . close () msa = Bio . AlignIO . read ( temp_output . name , \"fasta\" ) # msa.sort(key=lambda r: r.description) msa_info = Bio . Align . AlignInfo . SummaryInfo ( msa ) msa_consensus = msa_info . gap_consensus ( threshold = self . parameters . arguments [ \"consensus_threshold\" ]) temp_output . close () if seq_type == \"nt\" : self . length = msa . get_alignment_length () self . msa [ seq_type ], self . msa_consensus [ seq_type ] = msa , msa_consensus avr_distance = str ( round ( statistics . mean ([ i . distance for i in self . path ]))) self . id = f \"length- { self . msa [ 'nt' ] . get_alignment_length () } |score\u2013 { round ( self . score ) } |\" \\ f \"num_of_orfs- { len ( self . path ) } |avr_dist- { avr_distance } \" return None","title":"muscle_msa()"},{"location":"API/package_data_processing/#uorf4u.data_processing.Path.plot_ggmsa","text":"Plot MSA of conserved ORFs saved as fasta files. Note: R script based on ggmsa package [yulab-smu.top/ggmsa] used to produce MSA plots. R script (msa_plot.R) can be found in output_dir. This method uses subprocess to run this R script in the following way: Rscript {output_dir}/msa_plot.R --msa_fasta path_to_fasta --output output_path --seq_type (nt/aa) --width N(mm) --height M(mm) . Since during each run of uorf4u a local copy of this script is created in your output_dir, you can change it without any consequences for next uorf4u runs. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 def plot_ggmsa ( self ) -> None : \"\"\"Plot MSA of conserved ORFs saved as fasta files. Note: R script based on ggmsa package [yulab-smu.top/ggmsa] used to produce MSA plots. R script (msa_plot.R) can be found in output_dir. This method uses subprocess to run this R script in the following way: `Rscript {output_dir}/msa_plot.R --msa_fasta path_to_fasta --output output_path --seq_type (nt/aa) --width N(mm) --height M(mm)`. Since during each run of uorf4u a local copy of this script is created in your output_dir, you can change it without any consequences for next uorf4u runs. Returns: None \"\"\" rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_visualisation\" ) for i in self . parameters . arguments [ \"sequences_to_write\" ]])) fasta_files_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_fasta_files\" ) for i in self . parameters . arguments [ \"sequences_to_write\" ]])) for o_dir in output_dirs . values (): if not ( os . path . exists ( o_dir )): os . mkdir ( o_dir ) r_script_path = self . parameters . arguments [ \"plot_msa_R_script\" ] r_script_local = os . path . join ( self . parameters . arguments [ \"output_dir\" ], os . path . basename ( r_script_path )) if not ( os . path . exists ( r_script_local )): shutil . copy ( r_script_path , r_script_local ) for s_type in self . parameters . arguments [ \"sequences_to_write\" ]: current_msa = self . msa [ s_type ] if s_type == \"nt\" or s_type == \"sd\" : seq_type = \"nt\" else : seq_type = \"aa\" output_dir = os . path . abspath ( os . path . join ( output_dirs [ s_type ])) input_file = os . path . abspath ( os . path . join ( fasta_files_dirs [ s_type ], f \" { self . id } .fa\" )) num_sequences = len ( current_msa ) length_of_alignment = current_msa . get_alignment_length () page_width = ( 50 + length_of_alignment ) * 5 page_height = max ( 17 , ( num_sequences + 5 ) * 3 ) subprocess . run ([ \"Rscript\" , r_script_local , \"--msa_fasta\" , input_file , \"--output\" , output_dir , \"--seq_type\" , seq_type , \"--width\" , str ( page_width ), \"--height\" , str ( page_height )])","title":"plot_ggmsa()"},{"location":"API/package_data_processing/#uorf4u.data_processing.Path.plot_logo","text":"Plot sequence Logo of conserved ORFs MSA saved as fasta files. Note: This method uses logomaker package to produce images. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 def plot_logo ( self ) -> None : \"\"\"Plot sequence Logo of conserved ORFs MSA saved as fasta files. Note: This method uses logomaker package to produce images. Returns: None \"\"\" rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _seqlogo_visualisation\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) for o_dir in output_dirs . values (): if not ( os . path . exists ( o_dir )): os . mkdir ( o_dir ) ambiguous_codon_table = Bio . Data . CodonTable . ambiguous_dna_by_name [ self . parameters . arguments [ \"ncbi_genetic_code_name\" ]] unambiguous_codon_table = Bio . Data . CodonTable . unambiguous_dna_by_name [ self . parameters . arguments [ \"ncbi_genetic_code_name\" ]] alphabet = dict ( nt = set ( ambiguous_codon_table . nucleotide_alphabet ), aa = set ( ambiguous_codon_table . protein_alphabet )) unambiguous_alphabet = dict ( nt = set ( unambiguous_codon_table . nucleotide_alphabet ), aa = set ( unambiguous_codon_table . protein_alphabet )) for s_type in self . parameters . arguments [ \"sequences_to_write\" ]: current_msa = self . msa [ s_type ] if s_type == \"nt\" or s_type == \"sd\" : seq_type = \"nt\" elif s_type == \"aa\" : seq_type = \"aa\" output_file = os . path . abspath ( os . path . join ( output_dirs [ s_type ], os . path . basename ( self . id ))) msa_length = current_msa . get_alignment_length () num_of_sequences = len ( current_msa ) current_msa_info = Bio . Align . AlignInfo . SummaryInfo ( current_msa ) pos_specific_dict = dict () pos_specific_score_matrix = current_msa_info . pos_specific_score_matrix () for i in alphabet [ seq_type ]: pos_specific_dict [ i ] = [ 0 for j in range ( msa_length )] for i in range ( msa_length ): for element in pos_specific_score_matrix [ i ] . keys (): pos_specific_dict [ element . upper ()][ i ] = ( pos_specific_score_matrix [ i ][ element ] / num_of_sequences ) pos = [ i for i in range ( msa_length )] pos_specific_dict = { k : v for k , v in pos_specific_dict . items () if sum ( v ) > 0 or k in unambiguous_alphabet [ seq_type ]} matrix_fr = pandas . DataFrame ( pos_specific_dict , index = pos ) colors = self . parameters . arguments [ f \"colors_ { seq_type } \" ] colors = { k : uorf4u . methods . color_name_to_hex ( v , self . parameters . arguments ) for k , v in colors . items ()} fig_size = ( min ( max ( 10 , msa_length * 1.3 ), (( 2 ** 16 ) - 1 ) / 100 ), min ( 2.5 , 2.5 * 10 / ( msa_length ** ( 1 / 5 )))) if self . parameters . arguments [ \"logo_type\" ] == \"probability\" or \\ self . parameters . arguments [ \"logo_type\" ] == \"both\" : output_file_fr = f \" { output_file } _prob.pdf\" max_value_fr = 1 logo_fr = logomaker . Logo ( matrix_fr , color_scheme = colors , figsize = fig_size , alpha = self . parameters . arguments [ \"logo_alpha\" ], show_spines = False , baseline_width = 0 ) logo_fr . style_spines ( spines = [ \"left\" ], visible = True , linewidth = 0.7 ) logo_fr . ax . set_xticks ([]) logo_fr . ax . set_yticks ([ 0 , max_value_fr ]) plt . savefig ( output_file_fr ) plt . close ( \"all\" ) if self . parameters . arguments [ \"logo_type\" ] == \"information\" or \\ self . parameters . arguments [ \"logo_type\" ] == \"both\" : colors [ \"-\" ] = colors [ \"_\" ] matrix_fr [ \"-\" ] = round (( 1 - matrix_fr . sum ( axis = 1 )), 5 ) if matrix_fr [ \"-\" ] . sum () == 0 : del matrix_fr [ '-' ] matrix_info = logomaker . transform_matrix ( matrix_fr , from_type = \"probability\" , to_type = \"information\" ) max_value_info = math . log2 ( len ( pos_specific_dict . keys ())) output_file_info = f \" { output_file } _info.pdf\" logo_info = logomaker . Logo ( matrix_info , color_scheme = colors , figsize = fig_size , alpha = self . parameters . arguments [ \"logo_alpha\" ], show_spines = False , baseline_width = 0 ) logo_info . style_spines ( spines = [ \"left\" ], visible = True , linewidth = 0.7 ) logo_info . ax . set_xticks ([]) logo_info . ax . set_yticks ([ 0 , max_value_info ]) plt . savefig ( output_file_info ) plt . close ( \"all\" ) return None","title":"plot_logo()"},{"location":"API/package_data_processing/#uorf4u.data_processing.Path.plot_msa","text":"Plot MSA of conserved ORFs. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637 def plot_msa ( self ) -> None : \"\"\"Plot MSA of conserved ORFs. Returns: None \"\"\" rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_visualisation\" ) for i in self . parameters . arguments [ \"sequences_to_write\" ]])) for o_dir in output_dirs . values (): if not ( os . path . exists ( o_dir )): os . mkdir ( o_dir ) for s_type in self . parameters . arguments [ \"sequences_to_write\" ]: current_msa = self . msa [ s_type ] if s_type == \"nt\" or s_type == \"sd\" : seq_type = \"nt\" else : seq_type = \"aa\" msa_plot_manager = uorf4u . drawing_msa . MSAPlotManager ( current_msa , self . parameters , seq_type ) msa_plot_manager . define_x_axis_coordinate_system () output_file = os . path . join ( output_dirs [ s_type ], f \" { self . id } .pdf\" ) msa_plot_manager . create_tracks () msa_plot_manager . plot ( output_file )","title":"plot_msa()"},{"location":"API/package_data_processing/#uorf4u.data_processing.Path.sort","text":"Sort list of ORFs by their names. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 def sort ( self ) -> None : \"\"\"Sort list of ORFs by their names. Returns: None \"\"\" sorted_path = [ x for _ , x in sorted ( zip ([ i . name for i in self . path ], self . path ), key = lambda pair : pair [ 0 ])] self . path = sorted_path return None","title":"sort()"},{"location":"API/package_data_processing/#uorf4u.data_processing.Path.update","text":"Update a Path with a new ORF. Parameters: orf ( ORF ) \u2013 an ORF class' object. score ( float ) \u2013 a sum of pairwise alignment scores of the ORF against all ORFs in the Path. Returns: \u2013 None Source code in uorf4u/data_processing.py 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 def update ( self , orf : ORF , score = 0 ): \"\"\"Update a Path with a new ORF. Arguments: orf (ORF): an ORF class' object. score (float): a sum of pairwise alignment scores of the ORF against all ORFs in the Path. Returns: None \"\"\" self . path . append ( orf ) self . score += score","title":"update()"},{"location":"API/package_data_processing/#uorf4u.data_processing.RefSeqProtein","text":"A RefSeqProtein object holds a RefSeq protein and information about it. Attributes: accession_number ( str ) \u2013 RefSeq accession number. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. record ( Bio . SeqRecord . SeqRecord ) \u2013 SeqRecord of the ncbi protein db. Can be obtained by the get_record() method. taxid ( str ) \u2013 Taxid of the protein. Can be obtained with get_assemblies() method. kingdom_taxid ( str ) \u2013 Kingdom taxid of a protein. Can be obtained with get_assemblies() method. organism ( str ) \u2013 Organism name of a protein. Can be obtained with get_assemblies() method. name ( str ) \u2013 Protein's product name from the ncbi (if available). assemblies_coordinates ( list ) \u2013 List of dictionaries with information about assemblies' coordinates of the protein obtained from ipg ncbi database. loci ( dict ) \u2013 Dict with keys as locus_ids and values as Locus class' objects. Source code in uorf4u/data_processing.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 class RefSeqProtein : \"\"\"A RefSeqProtein object holds a RefSeq protein and information about it. Attributes: accession_number (str): RefSeq accession number. parameters (uorf4u.manager.Parameters): Parameters' class object. record (Bio.SeqRecord.SeqRecord): SeqRecord of the ncbi protein db. Can be obtained by the get_record() method. taxid (str): Taxid of the protein. Can be obtained with get_assemblies() method. kingdom_taxid (str): Kingdom taxid of a protein. Can be obtained with get_assemblies() method. organism (str): Organism name of a protein. Can be obtained with get_assemblies() method. name (str): Protein's product name from the ncbi (if available). assemblies_coordinates (list): List of dictionaries with information about assemblies' coordinates of the protein obtained from ipg ncbi database. loci (dict): Dict with keys as locus_ids and values as Locus class' objects. \"\"\" def __init__ ( self , accession_number : str , parameters : uorf4u . manager . Parameters ): \"\"\"Create a RefSeqProtein object. Arguments: accession_number (str): RefSeq accession number. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . accession_number = accession_number self . name = \"NA\" self . parameters = parameters self . record = None self . taxid = None self . kingdom_taxid = None self . organism = None self . assemblies_coordinates = None self . loci = None def get_record ( self ) -> Bio . SeqRecord . SeqRecord : \"\"\"Get a SeqRecord object of a protein from the ncbi protein database. Note: This method returns a record and updates the record attribute. Returns: Bio.SeqRecord.SeqRecordRecord: Record of the protein. \"\"\" try : handle = Bio . Entrez . efetch ( db = \"protein\" , id = self . accession_number , rettype = \"fasta\" , retmode = \"text\" ) self . record = Bio . SeqIO . read ( handle , \"fasta\" ) return self . record except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to get a SeqRecord of the protein from the ncbi protein database.\" ) from error def get_assemblies ( self , xml_output = None ) -> list : \"\"\"Get assemblies (loci) coordinates of a protein. Note: This method returns a list of assemblies coordinates and updates the self.assemblies_coordinates attribute. Returns: list: List of dictionaries with information about assemblies' coordinates of a protein obtained from the ipg ncbi database. \"\"\" try : if not xml_output : handle = Bio . Entrez . efetch ( db = \"protein\" , rettype = \"ipg\" , retmode = \"xml\" , id = self . accession_number ) xml_output = handle . read () . decode ( 'utf-8' ) root = xml . etree . cElementTree . fromstring ( xml_output ) list_of_kingdom_taxid = [] assemblies_coordinates = [] for report in root . iter ( \"IPGReport\" ): product = report . find ( \"Product\" ) if \"product_acc\" in report . attrib . keys (): report_accession_number = report . attrib [ \"product_acc\" ] elif \"accver\" in product . attrib . keys (): report_accession_number = product . attrib [ \"accver\" ] else : report_accession_number = \"\" if report_accession_number == self . accession_number : # be careful for protein in report . iter ( \"Protein\" ): if protein . attrib [ \"source\" ] == \"RefSeq\" : if \"name\" in protein . attrib . keys (): self . name = protein . attrib [ \"name\" ] self . taxid = protein . attrib [ \"taxid\" ] self . kingdom_taxid = protein . attrib [ \"kingdom_taxid\" ] self . organism = protein . attrib [ \"org\" ] list_of_kingdom_taxid . append ( self . kingdom_taxid ) for cds in protein . iter ( \"CDS\" ): to_add = 1 if self . parameters . arguments [ \"filter_refseq_sequences_by_regex\" ]: if not re . search ( rf \" { self . parameters . arguments [ 'refseq_sequences_regex' ] } \" , cds . attrib [ \"accver\" ]): to_add = 0 if to_add == 1 : if \"assembly\" not in cds . attrib . keys (): cds . attrib [ \"assembly\" ] = \"NA\" if \"strain\" not in cds . attrib . keys (): cds . attrib [ \"strain\" ] = \"NA\" try : assemblies_coordinates . append ( dict ( locus_id = cds . attrib [ \"accver\" ], start = ( int ( cds . attrib [ \"start\" ]) - 1 ), stop = int ( cds . attrib [ \"stop\" ]), strand = cds . attrib [ 'strand' ], length = int ( cds . attrib [ \"stop\" ]) - ( int ( cds . attrib [ \"start\" ]) - 1 ), assembly = cds . attrib [ \"assembly\" ], strain = cds . attrib [ \"strain\" ], org = cds . attrib [ \"org\" ], taxid = cds . attrib [ \"taxid\" ])) except : print ( f \"\u2755Attention: { cds . attrib [ 'accver' ] } record is not completed and\" f \" cannot be processed\" , file = sys . stderr ) ''' if len(assemblies_coordinates) == 0: print(f\"\u2757Warning message:\\n\\tNo assembly was found for the protein \" f\"'{self.accession_number}'.\\n\\tThis protein record can be suppressed by the ncbi\\n\\t\" f\"or it has no sequence record that satisfies refseq_sequnces_regex config parameter.\", file=sys.stderr) ''' self . assemblies_coordinates = assemblies_coordinates return assemblies_coordinates except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to get assemblies coordinates of a protein.\" ) from error ''' def get_loci(self, start=-float(\"inf\"), end=float(\"inf\"), strand=\"NA\") -> dict: \"\"\"Get Locus class objects for each sequence from the ncbi nt database on which the protein is annotated. Returns: dict: Dict with keys as locus_ids and values as Locus class' objects. \"\"\" self.loci = dict() for assembly in self.assemblies_coordinates: locus_id = assembly[\"locus_id\"] self.loci[locus_id] = Locus(locus_id, start_b=start, end_b=end, strand=strand) return self.loci ''' def blastp_searching_for_homologues ( self ) -> list : \"\"\"Search for a protein's homologues with blastp against the 'refseq_protein' database. Note: This function does not create a new object's attribute; It only returns a list of accession numbers. Returns: list: List of proteins' accession numbers obtained with blastp searching. This list also contains the query protein's accession number. \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc40 Searching for homologues of { self . accession_number } with blastp against the RefSeq database...\" , file = sys . stdout ) handle = Bio . Blast . NCBIWWW . qblast ( \"blastp\" , \"refseq_protein\" , self . accession_number , expect = self . parameters . arguments [ \"blastp_evalue_cutoff\" ], hitlist_size = self . parameters . arguments [ \"blastp_hit_list_size\" ], alignments = self . parameters . arguments [ \"blastp_max_number_of_alignments\" ]) xml_output = handle . read () hits_an_list = [ self . accession_number ] blastp_stat_dict = dict () blastp_stat_dict [ self . accession_number ] = dict ( pident_to_query_length = \"the query\" , pident_to_sequence_length = \"the query\" , pident_to_alignment_length = \"the query\" , evalue = \"the query\" ) root = xml . etree . ElementTree . fromstring ( xml_output ) query_length = int ( root . find ( \"BlastOutput_query-len\" ) . text ) for hit in root . iter ( \"Hit\" ): hit_id = hit . find ( \"Hit_id\" ) . text . strip ( \"ref\" ) . strip ( \"|\" ) if hit_id != self . accession_number : hit_description = hit . find ( \"Hit_def\" ) . text subject_length = int ( hit . find ( \"Hit_len\" ) . text ) hsp_identity_sum , hsp_positive_sum , hsp_align_length = 0 , 0 , 0 evalue = [] for hsp in hit . iter ( \"Hsp\" ): hsp_identity_sum += int ( hsp . find ( \"Hsp_identity\" ) . text ) hsp_positive_sum += int ( hsp . find ( \"Hsp_positive\" ) . text ) hsp_align_length += int ( hsp . find ( \"Hsp_align-len\" ) . text ) evalue . append ( hsp . find ( \"Hsp_evalue\" ) . text ) pident_to_query_length = hsp_identity_sum / query_length pident_to_seq_length = hsp_identity_sum / subject_length pident_to_alignment_length = hsp_identity_sum / hsp_align_length if pident_to_query_length >= self . parameters . arguments [ \"blastp_pident_to_query_length_cutoff\" ]: blastp_stat_dict [ hit_id ] = dict ( pident_to_query_length = str ( round ( pident_to_query_length , 4 )), pident_to_sequence_length = str ( round ( pident_to_seq_length , 4 )), pident_to_alignment_length = str ( round ( pident_to_alignment_length , 4 )), evalue = \",\" . join ( evalue )) if hit_id not in hits_an_list : hits_an_list . append ( hit_id ) columns = \" \\t \" . join ([ \"accession_number\" , \"name\" , \"pident_to_query_length\" , \"pident_to_sequence_length\" , \"pident_to_alignment_length\" , \"e-value\" ]) table = [ columns ] hits_records_list = [ RefSeqProtein ( i , self . parameters ) for i in hits_an_list ] for i in range ( 0 , len ( hits_records_list ), 200 ): records_subset = hits_records_list [ i : i + 200 ] accession_numbers = [ record . accession_number for record in records_subset ] handle_fasta = Bio . Entrez . efetch ( db = \"protein\" , id = accession_numbers , rettype = \"fasta\" , retmode = \"text\" ) fasta_records = Bio . SeqIO . parse ( handle_fasta , \"fasta\" ) for f_record in fasta_records : record_index = accession_numbers . index ( f_record . id ) records_subset [ record_index ] . name = f_record . description . replace ( f_record . id , \"\" ) . strip () for rec in hits_records_list : table . append ( \" \\t \" . join ([ rec . accession_number , rec . name , blastp_stat_dict [ rec . accession_number ][ \"pident_to_query_length\" ], blastp_stat_dict [ rec . accession_number ][ \"pident_to_sequence_length\" ], blastp_stat_dict [ rec . accession_number ][ \"pident_to_alignment_length\" ], blastp_stat_dict [ rec . accession_number ][ \"evalue\" ]])) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) output_filename = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"found_homologues.tsv\" ) f = open ( output_filename , \"w\" ) f . write ( \" \\n \" . join ( table )) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\u2705 { len ( hits_records_list ) - 1 } homologues were found. \\n \" f \"\ud83d\udc8c Summary table was saved to: { os . path . basename ( output_filename ) } \" , file = sys . stdout ) return hits_an_list except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to perform searching for homologues with blastp.\" ) from error","title":"RefSeqProtein"},{"location":"API/package_data_processing/#uorf4u.data_processing.RefSeqProtein.__init__","text":"Create a RefSeqProtein object. Parameters: accession_number ( str ) \u2013 RefSeq accession number. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/data_processing.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 def __init__ ( self , accession_number : str , parameters : uorf4u . manager . Parameters ): \"\"\"Create a RefSeqProtein object. Arguments: accession_number (str): RefSeq accession number. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . accession_number = accession_number self . name = \"NA\" self . parameters = parameters self . record = None self . taxid = None self . kingdom_taxid = None self . organism = None self . assemblies_coordinates = None self . loci = None","title":"__init__()"},{"location":"API/package_data_processing/#uorf4u.data_processing.RefSeqProtein.blastp_searching_for_homologues","text":"Search for a protein's homologues with blastp against the 'refseq_protein' database. Note: This function does not create a new object's attribute; It only returns a list of accession numbers. Returns: list ( list ) \u2013 List of proteins' accession numbers obtained with blastp searching. This list also contains the query protein's accession number. Source code in uorf4u/data_processing.py 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 def blastp_searching_for_homologues ( self ) -> list : \"\"\"Search for a protein's homologues with blastp against the 'refseq_protein' database. Note: This function does not create a new object's attribute; It only returns a list of accession numbers. Returns: list: List of proteins' accession numbers obtained with blastp searching. This list also contains the query protein's accession number. \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc40 Searching for homologues of { self . accession_number } with blastp against the RefSeq database...\" , file = sys . stdout ) handle = Bio . Blast . NCBIWWW . qblast ( \"blastp\" , \"refseq_protein\" , self . accession_number , expect = self . parameters . arguments [ \"blastp_evalue_cutoff\" ], hitlist_size = self . parameters . arguments [ \"blastp_hit_list_size\" ], alignments = self . parameters . arguments [ \"blastp_max_number_of_alignments\" ]) xml_output = handle . read () hits_an_list = [ self . accession_number ] blastp_stat_dict = dict () blastp_stat_dict [ self . accession_number ] = dict ( pident_to_query_length = \"the query\" , pident_to_sequence_length = \"the query\" , pident_to_alignment_length = \"the query\" , evalue = \"the query\" ) root = xml . etree . ElementTree . fromstring ( xml_output ) query_length = int ( root . find ( \"BlastOutput_query-len\" ) . text ) for hit in root . iter ( \"Hit\" ): hit_id = hit . find ( \"Hit_id\" ) . text . strip ( \"ref\" ) . strip ( \"|\" ) if hit_id != self . accession_number : hit_description = hit . find ( \"Hit_def\" ) . text subject_length = int ( hit . find ( \"Hit_len\" ) . text ) hsp_identity_sum , hsp_positive_sum , hsp_align_length = 0 , 0 , 0 evalue = [] for hsp in hit . iter ( \"Hsp\" ): hsp_identity_sum += int ( hsp . find ( \"Hsp_identity\" ) . text ) hsp_positive_sum += int ( hsp . find ( \"Hsp_positive\" ) . text ) hsp_align_length += int ( hsp . find ( \"Hsp_align-len\" ) . text ) evalue . append ( hsp . find ( \"Hsp_evalue\" ) . text ) pident_to_query_length = hsp_identity_sum / query_length pident_to_seq_length = hsp_identity_sum / subject_length pident_to_alignment_length = hsp_identity_sum / hsp_align_length if pident_to_query_length >= self . parameters . arguments [ \"blastp_pident_to_query_length_cutoff\" ]: blastp_stat_dict [ hit_id ] = dict ( pident_to_query_length = str ( round ( pident_to_query_length , 4 )), pident_to_sequence_length = str ( round ( pident_to_seq_length , 4 )), pident_to_alignment_length = str ( round ( pident_to_alignment_length , 4 )), evalue = \",\" . join ( evalue )) if hit_id not in hits_an_list : hits_an_list . append ( hit_id ) columns = \" \\t \" . join ([ \"accession_number\" , \"name\" , \"pident_to_query_length\" , \"pident_to_sequence_length\" , \"pident_to_alignment_length\" , \"e-value\" ]) table = [ columns ] hits_records_list = [ RefSeqProtein ( i , self . parameters ) for i in hits_an_list ] for i in range ( 0 , len ( hits_records_list ), 200 ): records_subset = hits_records_list [ i : i + 200 ] accession_numbers = [ record . accession_number for record in records_subset ] handle_fasta = Bio . Entrez . efetch ( db = \"protein\" , id = accession_numbers , rettype = \"fasta\" , retmode = \"text\" ) fasta_records = Bio . SeqIO . parse ( handle_fasta , \"fasta\" ) for f_record in fasta_records : record_index = accession_numbers . index ( f_record . id ) records_subset [ record_index ] . name = f_record . description . replace ( f_record . id , \"\" ) . strip () for rec in hits_records_list : table . append ( \" \\t \" . join ([ rec . accession_number , rec . name , blastp_stat_dict [ rec . accession_number ][ \"pident_to_query_length\" ], blastp_stat_dict [ rec . accession_number ][ \"pident_to_sequence_length\" ], blastp_stat_dict [ rec . accession_number ][ \"pident_to_alignment_length\" ], blastp_stat_dict [ rec . accession_number ][ \"evalue\" ]])) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) output_filename = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"found_homologues.tsv\" ) f = open ( output_filename , \"w\" ) f . write ( \" \\n \" . join ( table )) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\u2705 { len ( hits_records_list ) - 1 } homologues were found. \\n \" f \"\ud83d\udc8c Summary table was saved to: { os . path . basename ( output_filename ) } \" , file = sys . stdout ) return hits_an_list except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to perform searching for homologues with blastp.\" ) from error","title":"blastp_searching_for_homologues()"},{"location":"API/package_data_processing/#uorf4u.data_processing.RefSeqProtein.get_assemblies","text":"Get assemblies (loci) coordinates of a protein. Note: This method returns a list of assemblies coordinates and updates the self.assemblies_coordinates attribute. Returns: list ( list ) \u2013 List of dictionaries with information about assemblies' coordinates of a protein obtained from the ipg ncbi database. Source code in uorf4u/data_processing.py 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 def get_assemblies ( self , xml_output = None ) -> list : \"\"\"Get assemblies (loci) coordinates of a protein. Note: This method returns a list of assemblies coordinates and updates the self.assemblies_coordinates attribute. Returns: list: List of dictionaries with information about assemblies' coordinates of a protein obtained from the ipg ncbi database. \"\"\" try : if not xml_output : handle = Bio . Entrez . efetch ( db = \"protein\" , rettype = \"ipg\" , retmode = \"xml\" , id = self . accession_number ) xml_output = handle . read () . decode ( 'utf-8' ) root = xml . etree . cElementTree . fromstring ( xml_output ) list_of_kingdom_taxid = [] assemblies_coordinates = [] for report in root . iter ( \"IPGReport\" ): product = report . find ( \"Product\" ) if \"product_acc\" in report . attrib . keys (): report_accession_number = report . attrib [ \"product_acc\" ] elif \"accver\" in product . attrib . keys (): report_accession_number = product . attrib [ \"accver\" ] else : report_accession_number = \"\" if report_accession_number == self . accession_number : # be careful for protein in report . iter ( \"Protein\" ): if protein . attrib [ \"source\" ] == \"RefSeq\" : if \"name\" in protein . attrib . keys (): self . name = protein . attrib [ \"name\" ] self . taxid = protein . attrib [ \"taxid\" ] self . kingdom_taxid = protein . attrib [ \"kingdom_taxid\" ] self . organism = protein . attrib [ \"org\" ] list_of_kingdom_taxid . append ( self . kingdom_taxid ) for cds in protein . iter ( \"CDS\" ): to_add = 1 if self . parameters . arguments [ \"filter_refseq_sequences_by_regex\" ]: if not re . search ( rf \" { self . parameters . arguments [ 'refseq_sequences_regex' ] } \" , cds . attrib [ \"accver\" ]): to_add = 0 if to_add == 1 : if \"assembly\" not in cds . attrib . keys (): cds . attrib [ \"assembly\" ] = \"NA\" if \"strain\" not in cds . attrib . keys (): cds . attrib [ \"strain\" ] = \"NA\" try : assemblies_coordinates . append ( dict ( locus_id = cds . attrib [ \"accver\" ], start = ( int ( cds . attrib [ \"start\" ]) - 1 ), stop = int ( cds . attrib [ \"stop\" ]), strand = cds . attrib [ 'strand' ], length = int ( cds . attrib [ \"stop\" ]) - ( int ( cds . attrib [ \"start\" ]) - 1 ), assembly = cds . attrib [ \"assembly\" ], strain = cds . attrib [ \"strain\" ], org = cds . attrib [ \"org\" ], taxid = cds . attrib [ \"taxid\" ])) except : print ( f \"\u2755Attention: { cds . attrib [ 'accver' ] } record is not completed and\" f \" cannot be processed\" , file = sys . stderr ) ''' if len(assemblies_coordinates) == 0: print(f\"\u2757Warning message:\\n\\tNo assembly was found for the protein \" f\"'{self.accession_number}'.\\n\\tThis protein record can be suppressed by the ncbi\\n\\t\" f\"or it has no sequence record that satisfies refseq_sequnces_regex config parameter.\", file=sys.stderr) ''' self . assemblies_coordinates = assemblies_coordinates return assemblies_coordinates except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to get assemblies coordinates of a protein.\" ) from error","title":"get_assemblies()"},{"location":"API/package_data_processing/#uorf4u.data_processing.RefSeqProtein.get_record","text":"Get a SeqRecord object of a protein from the ncbi protein database. Note: This method returns a record and updates the record attribute. Returns: Bio . SeqRecord . SeqRecord \u2013 Bio.SeqRecord.SeqRecordRecord: Record of the protein. Source code in uorf4u/data_processing.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 def get_record ( self ) -> Bio . SeqRecord . SeqRecord : \"\"\"Get a SeqRecord object of a protein from the ncbi protein database. Note: This method returns a record and updates the record attribute. Returns: Bio.SeqRecord.SeqRecordRecord: Record of the protein. \"\"\" try : handle = Bio . Entrez . efetch ( db = \"protein\" , id = self . accession_number , rettype = \"fasta\" , retmode = \"text\" ) self . record = Bio . SeqIO . read ( handle , \"fasta\" ) return self . record except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to get a SeqRecord of the protein from the ncbi protein database.\" ) from error","title":"get_record()"},{"location":"API/package_data_processing/#uorf4u.data_processing.UpstreamSequences","text":"An UpstreamSequences object holds list of upstream sequences records and information about them. Attributes: records ( list ) \u2013 List of Bio.SeqRecord.SeqRecord objects with upstream sequences. (attribute 'annotations' (dict) is used for holding additional information, (e.g. downstream protein_id)). codon_table ( Bio . Data . CodonTable . CodonTable ) \u2013 Codon table (genetic code). conserved_paths ( list ) \u2013 list of Path's objects (Path class holds list of ORFs from different upstream sequences and information about them). Source code in uorf4u/data_processing.py 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 class UpstreamSequences : \"\"\"An UpstreamSequences object holds list of upstream sequences records and information about them. Attributes: records (list): List of Bio.SeqRecord.SeqRecord objects with upstream sequences. (attribute 'annotations' (dict) is used for holding additional information, (e.g. downstream protein_id)). codon_table (Bio.Data.CodonTable.CodonTable): Codon table (genetic code). conserved_paths (list): list of Path's objects (Path class holds list of ORFs from different upstream sequences and information about them). \"\"\" def __init__ ( self , records : list , parameters : uorf4u . manager . Parameters ): \"\"\"Create an UpstreamSequences object. Arguments: records (list): List of Bio.SeqRecord.SeqRecord objects with upstream sequences. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . records = records self . parameters = parameters self . codon_table = Bio . Data . CodonTable . unambiguous_dna_by_name [ parameters . arguments [ \"ncbi_genetic_code_name\" ]] self . conserved_paths = None def save_upstream_sequences ( self ) -> None : \"\"\"Save upstream sequences as a fasta file. Returns: None \"\"\" try : output_file = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"upstream_sequences.fa\" ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) Bio . SeqIO . write ( self . records , output_file , \"fasta\" ) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc8c Fasta file with upstream sequences was saved to { os . path . basename ( output_file ) } .\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save a fasta file with upstream sequences.\" ) from error def annotate_orfs ( self ) -> None : \"\"\"Annotate ORFs in upstream sequences. Note: This function updates 'records' attribute. Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udd0e ORFs annotating in the upstream sequences...\" , file = sys . stdout ) if self . parameters . arguments [ \"alternative_start_codons\" ]: start_codons_list = self . codon_table . start_codons else : start_codons_list = [ self . parameters . arguments [ \"main_start_codon\" ]] if self . parameters . arguments [ \"check_assembly_annotation\" ] and \\ self . records [ 0 ] . annotations [ \"RefSeq\" ]: if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udce1 Assemblies' annotation retrieving...\" , file = sys . stdout ) for i in range ( 0 , len ( self . records ), 100 ): useq_subset = [ record for record in self . records [ i : i + 100 ] if record . annotations [ \"RefSeq\" ]] locus_ids = [ locus . annotations [ \"locus_id\" ] for locus in useq_subset ] handle = Bio . Entrez . efetch ( db = \"nucleotide\" , id = locus_ids , rettype = \"gb\" , retmode = \"xml\" ) handle_txt = handle . read () . decode ( 'utf-8' ) for useq_record in useq_subset : useq_record . annotations [ \"locus_annotation\" ] = Locus ( useq_record . annotations [ \"locus_id\" ], start_b = useq_record . annotations [ \"start\" ], stop_b = useq_record . annotations [ \"stop\" ], target_strand = useq_record . annotations [ \"strand\" ], locus_record = useq_record . annotations [ \"locus_record\" ], xml_output = handle_txt ) for useq_index in range ( len ( self . records )): useq_record = self . records [ useq_index ] useq_record . annotations [ \"ORFs\" ] = [] for first_position in range (( useq_record . annotations [ \"length\" ] - self . parameters . arguments [ \"downstream_region_length\" ]) + 1 ): first_codon = useq_record . seq [ first_position : first_position + 3 ] if first_codon . upper () in start_codons_list : start_codon_position = first_position for second_position in range ( start_codon_position + 3 , ( useq_record . annotations [ \"length\" ] - 3 ) + 1 , 3 ): second_codon = useq_record . seq [ second_position : second_position + 3 ] if second_codon . upper () in self . codon_table . stop_codons : stop_codon_position = second_position orf_length = stop_codon_position - start_codon_position distance = ( useq_record . annotations [ \"length\" ] - self . parameters . arguments [ \"downstream_region_length\" ]) - stop_codon_position distance_sc = ( useq_record . annotations [ \"length\" ] - self . parameters . arguments [ \"downstream_region_length\" ]) - start_codon_position if useq_record . annotations [ \"RefSeq\" ]: orf_id = f \" { useq_record . annotations [ 'locus_id' ] } |\" \\ f \" { useq_record . annotations [ 'accession_number' ] } |\" \\ f \" { distance } \" orf_name = f \" { useq_record . annotations [ 'label' ] } | { distance } \" else : distance = useq_record . annotations [ \"length\" ] - stop_codon_position orf_id = f \" { useq_record . id } | { distance } \" if useq_record . description : orf_name = f \" { useq_record . description } | { orf_id } \" else : orf_name = orf_id sd_window_start = max ( [ 0 , ( start_codon_position - self . parameters . arguments [ \"sd_window_length\" ])]) current_orf = ORF ( parameters = self . parameters , id = orf_id , name = orf_name , distance = distance , start = start_codon_position , stop = stop_codon_position , useq_index = useq_index , nt_sequence = useq_record . seq [ start_codon_position : stop_codon_position ], sd_window_seq = useq_record . seq [ sd_window_start : start_codon_position ]) if current_orf . length >= self . parameters . arguments [ \"min_orf_length\" ] and distance_sc != 0 : useq_record . annotations [ \"ORFs\" ] . append ( current_orf ) if self . parameters . arguments [ \"check_assembly_annotation\" ] and \\ useq_record . annotations [ \"RefSeq\" ]: for cds in useq_record . annotations [ \"locus_annotation\" ] . CDSs : if current_orf . stop == cds [ \"relative_stop\" ] and ( ( current_orf . start - cds [ \"relative_start\" ]) % 3 == 0 ): the_same_stop = 1 current_orf . annotation = cds [ \"product_name\" ] if current_orf . start != cds [ \"relative_start\" ]: if current_orf . start < cds [ \"relative_start\" ]: current_orf . annotation += \" (extension)\" else : current_orf . annotation += \" (truncation)\" for annotated_orfs in useq_record . annotations [ \"ORFs\" ]: if current_orf . stop == annotated_orfs . stop and \\ current_orf . id != annotated_orfs . id : current_orf . extended_orfs . append ( annotated_orfs . id ) break number_of_orfs = sum ( len ( i . annotations [ \"ORFs\" ]) for i in self . records ) if self . parameters . arguments [ \"fast_searching\" ] == \"auto\" : if len ( self . records ) < 5 : self . parameters . arguments [ \"fast_searching\" ] = False elif ( len ( self . records ) >= 100 or number_of_orfs > 1000 ): self . parameters . arguments [ \"fast_searching\" ] = True else : self . parameters . arguments [ \"fast_searching\" ] = False if number_of_orfs == 0 : print ( f \"\u26d4Termination: \\n\\t No ORF was annotated in upstream sequences.\" f \" \\n\\t This run will be terminated.\" , file = sys . stderr ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) with open ( os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"report.txt\" ), \"w\" ) as report_f : report_f . write ( \"Termination: \\n No ORF was annotated in upstream sequences.\" ) sys . exit () if self . parameters . arguments [ \"verbose\" ]: print ( f \"\u2705 { number_of_orfs } ORFs were annotated.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to annotate ORFs in upstream sequences.\" ) from error def filter_orfs_by_sd_annotation ( self ) -> None : \"\"\"Filter annotated ORFs by presence the Shine-Dalgarno sequence. Returns: None \"\"\" try : for useq_record in self . records : orf_list = useq_record . annotations [ \"ORFs\" ] filtered_orf_list = [] for orf in orf_list : orf . calculate_energies () if orf . min_energy < self . parameters . arguments [ \"sd_energy_cutoff\" ]: filtered_orf_list . append ( orf ) useq_record . annotations [ \"ORFs\" ] = filtered_orf_list number_of_orfs = sum ( len ( i . annotations [ \"ORFs\" ]) for i in self . records ) if number_of_orfs == 0 : print ( f \"\u26d4Termination: \\n\\t No ORF left after filtering by SD annotation.\" f \" \\n\\t This run will be terminated.\" , file = sys . stderr ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) with open ( os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"report.txt\" ), \"w\" ) as report_f : report_f . write ( \"Termination: \\n No ORF left after filtering by SD annotation.\" ) sys . exit () if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83e\uddf9 { number_of_orfs } ORFs remained in the analysis after filtering by presence \" f \"of the SD sequence.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to filter uORFs by SD sequence presence.\" ) from error def save_annotated_orfs ( self ) -> None : \"\"\"Save information about annotated ORFs as a set of tsv files. Note: tsv files will be saved to the subdir called 'annotated_ORFs' located in 'output_dir'. Returns: None \"\"\" try : colnames = \" \\t \" . join ( [ \"id\" , \"name\" , \"length\" , \"nt_sequence\" , \"aa_sequence\" , \"sd_sequence_window\" , \"SD-aSD energy\" , \"SD-aSD energies list\" , \"extended_orfs\" , \"annotation\" ]) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) output_dir_path = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"annotated_ORFs\" ) if not os . path . exists ( output_dir_path ): os . mkdir ( output_dir_path ) for useq_record in self . records : file_name = f \" { useq_record . description } | { useq_record . id } \" . replace ( ' ' , '_' ) . replace ( '/' , '_' ) lines = [ colnames ] for orf in useq_record . annotations [ \"ORFs\" ]: if not orf . extended_orfs : extented_orfs_value = \"NA\" else : extented_orfs_value = ';' . join ( orf . extended_orfs ) lines . append ( \" \\t \" . join ( [ orf . id , orf . name , str ( orf . length ), str ( orf . nt_sequence ), str ( orf . aa_sequence ), str ( orf . sd_window_seq_str ), str ( orf . min_energy ), \";\" . join ( orf . sd_window_energies ), extented_orfs_value , orf . annotation ])) with open ( os . path . join ( output_dir_path , f \" { file_name } .tsv\" ), \"w\" ) as output : output . write ( \" \\n \" . join ( lines )) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc8c tsv files with information about annotated ORFs were saved to \" f \" { os . path . basename ( output_dir_path ) } folder.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save annotated uORFs.\" ) from error def conserved_orf_searching ( self ) -> None : \"\"\"Search for sets of conserved ORFs in upstream sequences. Note: This method updates the self.conserved_paths attribute. Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udd0e Searching for conserved ORFs in upstream sequences...\" , file = sys . stdout ) if len ( self . records ) == 1 : raise uorf4u . manager . uORF4uError ( \"At least two sequences required to perform conservation analysis\" ) lengths = [] for record in self . records : for orf in record . annotations [ \"ORFs\" ]: lengths . append ( orf . length ) lengths = sorted ( list ( set ( lengths ))) global_aligner = Bio . Align . PairwiseAligner () global_aligner . mode = \"global\" global_aligner . match_score = self . parameters . arguments [ \"global_match_score\" ] global_aligner . mismatch_score = self . parameters . arguments [ \"global_mismatch_score\" ] global_aligner . open_gap_score = self . parameters . arguments [ \"global_open_gap_score\" ] global_aligner . extend_gap_score = self . parameters . arguments [ \"global_extend_gap_score\" ] global_aligner . target_end_gap_score = self . parameters . arguments [ \"global_target_end_gap_score\" ] global_aligner . query_end_gap_score = self . parameters . arguments [ \"global_query_end_gap_score\" ] length_variance = self . parameters . arguments [ \"orf_length_group_range\" ] number_of_useqs = len ( self . records ) if self . parameters . arguments [ \"fast_searching\" ]: filtered_orfs_dict = dict () for length in lengths : if isinstance ( self . parameters . arguments [ \"orf_length_group_range\" ], float ): length_variance = length * self . parameters . arguments [ \"orf_length_group_range\" ] filtered_orfs = [] useq_with_filtered_orfs = [] for useq_index in range ( number_of_useqs ): useq_record = self . records [ useq_index ] for orf in useq_record . annotations [ \"ORFs\" ]: if abs ( length - orf . length ) <= length_variance : filtered_orfs . append ( orf ) if useq_index not in useq_with_filtered_orfs : useq_with_filtered_orfs . append ( useq_index ) if len ( useq_with_filtered_orfs ) / number_of_useqs >= self . parameters . arguments [ \"orfs_presence_cutoff\" ]: to_add = 1 keys_to_remove = [] for added_length in filtered_orfs_dict . keys (): num_of_identical_elements = len ( set ( filtered_orfs ) & set ( filtered_orfs_dict [ added_length ])) fraction = num_of_identical_elements / min ( len ( filtered_orfs ), len ( filtered_orfs_dict [ added_length ])) if fraction > 0.8 : # to add as a config parameter if len ( filtered_orfs ) >= len ( filtered_orfs_dict [ added_length ]): keys_to_remove . append ( added_length ) else : to_add = 0 for key_to_remove in keys_to_remove : filtered_orfs_dict . pop ( key_to_remove ) if to_add : filtered_orfs_dict [ length ] = filtered_orfs lengths = list ( filtered_orfs_dict . keys ()) conserved_paths = [] for length in lengths : if isinstance ( self . parameters . arguments [ \"orf_length_group_range\" ], float ): length_variance = length * self . parameters . arguments [ \"orf_length_group_range\" ] useq_indexes_with_filtered_orfs = [] filtered_orfs = dict () for useq_index in range ( number_of_useqs ): useq_record = self . records [ useq_index ] filtered_orfs [ useq_index ] = [] for orf in useq_record . annotations [ \"ORFs\" ]: if abs ( length - orf . length ) <= length_variance : filtered_orfs [ useq_index ] . append ( orf ) orfs_ids = [ i . id for i in filtered_orfs [ useq_index ]] for orf in filtered_orfs [ useq_index ]: if any ( i in orf . extended_orfs for i in orfs_ids ): filtered_orfs [ useq_index ] . remove ( orf ) if len ( filtered_orfs [ useq_index ]) > 0 : useq_indexes_with_filtered_orfs . append ( useq_index ) if len ( useq_indexes_with_filtered_orfs ) / number_of_useqs >= self . parameters . arguments [ \"orfs_presence_cutoff\" ]: if self . parameters . arguments [ \"fast_searching\" ]: genome_iterator = random . sample ( filtered_orfs . keys (), max ( 1 , min ( round ( self . parameters . arguments [ \"fast_searching_\" \"fraction_of_initial\" \"_genomes\" ] * len ( useq_indexes_with_filtered_orfs )), self . parameters . arguments [ \"max_num_of_initial_genome_iteration\" ]))) elif len ( filtered_orfs . keys ()) > self . parameters . arguments [ \"max_num_of_initial_genome_iteration\" ]: genome_iterator = random . sample ( filtered_orfs . keys (), self . parameters . arguments [ \"max_num_of_initial_genome_iteration\" ]) else : genome_iterator = filtered_orfs . keys () for initial_useq in genome_iterator : for initial_orf in filtered_orfs [ initial_useq ]: conserved_path = Path ( self . parameters ) conserved_path . update ( initial_orf ) for useq in random . sample ( filtered_orfs . keys (), len ( filtered_orfs . keys ())): if useq != initial_useq and filtered_orfs [ useq ] != []: score_sums = [] for orf in filtered_orfs [ useq ]: score_sum = 0 for path_orf in conserved_path . path : if self . parameters . arguments [ \"alignment_type\" ] == \"nt\" : current_alignment = global_aligner . align ( orf . nt_sequence , path_orf . nt_sequence ) elif self . parameters . arguments [ \"alignment_type\" ] == \"aa\" : current_alignment = global_aligner . align ( orf . aa_sequence , path_orf . aa_sequence ) score_sum += current_alignment . score score_sums . append ( score_sum ) max_score = max ( score_sums ) if max_score > self . parameters . arguments [ \"alignment_score_cutoff\" ]: if score_sums . count ( max_score ) == 1 : selected_orf = filtered_orfs [ useq ][ score_sums . index ( max_score )] else : num_of_candidates = len ( filtered_orfs [ useq ]) highest_score_orfs = [ filtered_orfs [ useq ][ k ] for k in range ( num_of_candidates ) if score_sums [ k ] == max_score ] highest_score_orfs_length_dists = [ orf_it . length - length for orf_it in highest_score_orfs ] min_length_dist = min ( highest_score_orfs_length_dists ) if highest_score_orfs_length_dists . count ( min_length_dist ) == 1 : selected_orf = highest_score_orfs [ highest_score_orfs_length_dists . index ( min_length_dist )] else : num_of_candidates = len ( highest_score_orfs ) the_closest_by_length_orfs = [ highest_score_orfs [ k ] for k in range ( num_of_candidates ) if highest_score_orfs_length_dists [ k ] == min_length_dist ] the_closest_by_length_orfs_lengths = [ orf_it . length for orf_it in the_closest_by_length_orfs ] max_length = max ( the_closest_by_length_orfs_lengths ) selected_orf = the_closest_by_length_orfs [ the_closest_by_length_orfs_lengths . index ( max_length )] conserved_path . update ( selected_orf , max_score ) if len ( conserved_path ) / number_of_useqs >= self . parameters . arguments [ \"orfs_presence_cutoff\" ] and len ( conserved_path ) > 1 : to_save_this_path = 1 for old_path in conserved_paths : fraction_of_identity = conserved_path . calculate_similarity ( old_path ) if fraction_of_identity >= self . parameters . arguments [ \"paths_identity_cutoff\" ]: if conserved_path . score > old_path . score : conserved_paths . remove ( old_path ) elif conserved_path . score <= old_path . score : to_save_this_path = 0 if to_save_this_path == 1 : conserved_path . sort () conserved_paths . append ( conserved_path ) self . conserved_paths = conserved_paths number_of_paths = len ( conserved_paths ) if number_of_paths == 0 : print ( f \"\u26d4Termination: \\n\\t No conserved ORFs set was found.\" f \" \\n\\t This run will be terminated.\" , file = sys . stderr ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) with open ( os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"report.txt\" ), \"w\" ) as report_f : report_f . write ( \"Termination: \\n No conserved ORFs set was found.\" ) sys . exit () if self . parameters . arguments [ \"verbose\" ]: print ( f \"\u2705 { number_of_paths } sets of conserved ORFs were found.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to perform searching for conserved uORFs.\" ) from error def filter_out_similar_paths ( self ) -> None : \"\"\"Filter out duplicates in sets of annotated conserved ORFs. Note: Two paths are considered as duplicates if they share more than half of ORFs (default value, see 'paths_identity_cutoff' config parameter). In case two paths are found as identical, only one with a higher score will be saved. Returns: None \"\"\" try : filtered_paths = [] for path in self . conserved_paths : to_add = 1 for path_filtered in filtered_paths : if path . calculate_similarity ( path_filtered ) > self . parameters . arguments [ \"paths_identity_cutoff\" ]: if path . score < path_filtered . score : to_add = 0 elif path . score == path_filtered . score and ( len ( path ) < len ( path_filtered )): to_add = 0 else : filtered_paths . remove ( path_filtered ) if to_add == 1 : filtered_paths . append ( path ) self . conserved_paths = filtered_paths if self . parameters . arguments [ \"verbose\" ]: num_of_paths = len ( self . conserved_paths ) print ( f \"\ud83e\uddf9 { num_of_paths } set(s) of conserved ORFs remained in the analysis after filtering \" f \"out duplicates.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to filter out duplicates in conserved uORFs sets.\" ) from error def run_msa ( self ) -> None : \"\"\"Run msa tool (muscle) for each path object (set of conserved ORFs). Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83e\uddee Running MSA for conserved ORFs.\" , file = sys . stdout ) for path in self . conserved_paths : path . maft_msa () return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to get MSA of conserved uORFs.\" ) from error def save_msa ( self ) -> None : \"\"\"Save MSA of conserved ORFs as fasta files. Note: Fasta files will be saved to the subdirs: ['nucleotide_msa' - for MSA of nucleotide sequences of ORFs, 'amino_acid_msa' - MSA of amino acid sequences of ORFs, and 'sd_msa' - MSA of SD sequence regions of ORFS). All of them located in your 'output_dir'. Returns: None \"\"\" try : if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_fasta_files\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) for key in output_dirs : if not ( os . path . exists ( output_dirs [ key ])): os . mkdir ( output_dirs [ key ]) for path in self . conserved_paths : for seq_type in self . parameters . arguments [ \"sequences_to_write\" ]: msa = path . msa [ seq_type ] output = os . path . join ( output_dirs [ seq_type ], f \" { path . id } .fa\" ) Bio . AlignIO . write ( msa , output , \"fasta\" ) if self . parameters . arguments [ \"verbose\" ]: output_dirs_v = [ os . path . basename ( i ) for i in output_dirs . values ()] delimiter = \", \\n\\t \" print ( f \"\ud83d\udc8c MSA fasta files of conserved ORFs were saved to the folders: \\n \" f \" \\t { delimiter . join ( output_dirs_v ) } folders.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save MSA of conserved uORFs.\" ) from error def save_orfs_sequences ( self ) -> None : \"\"\"Save sequences of conserved ORFs as fasta files. Note: Fasta files will be saved to the subdirs: ['nucleotide_orfs' - for MSA of nucleotide sequences of ORFs, 'amino_acid_msa' - MSA of amino acid sequences of ORFs, and 'sd_msa' - MSA of SD sequence regions of ORFS). All of them located in your 'output_dir'. Returns: None \"\"\" try : if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" ) sequence_to_write = [ i for i in self . parameters . arguments [ \"sequences_to_write\" ] if i != \"sd\" ] output_dirs = dict ( zip ( sequence_to_write , [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _orfs_fasta_files\" ) for i in sequence_to_write ])) for key in output_dirs : if not ( os . path . exists ( output_dirs [ key ])): os . mkdir ( output_dirs [ key ]) for seq_type in sequence_to_write : for path in self . conserved_paths : records = [] for orf in path . path : if seq_type == \"nt\" : record = Bio . SeqRecord . SeqRecord ( orf . nt_sequence , orf . id , \"\" , orf . name ) if seq_type == \"aa\" : record = Bio . SeqRecord . SeqRecord ( orf . aa_sequence , orf . id , \"\" , orf . name ) records . append ( record ) output = os . path . join ( output_dirs [ seq_type ], f \" { path . id } .fa\" ) Bio . SeqIO . write ( records , output , \"fasta\" ) if self . parameters . arguments [ \"verbose\" ]: delimiter = \", \\n\\t \" output_dirs_v = [ os . path . basename ( i ) for i in output_dirs . values ()] print ( f \"\ud83d\udc8c Sequences fasta files of conserved ORFs were saved to the folders: \\n \" f \" \\t { delimiter . join ( output_dirs_v ) } .\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save sequences of conserved uORFs.\" ) from error def save_results_summary_table ( self ) -> None : \"\"\"Save results summary table. Note: A tsv table will be saved to your output_dir. Returns: None \"\"\" try : colnames = \" \\t \" . join ( [ \"id\" , \"length\" , \"average_distance_to_the_ORF\" , \"aa_alignment_length\" , \"nt_alignment_length\" , \"score\" , \"number_of_orfs\" , \"number_of_orfs/number_of_sequences\" , \"consensus(aa)\" , \"consensus(nt)\" , \"uORFs\" , \"uORFs_annotations\" ]) rows = [ colnames ] for path in self . conserved_paths : annotations = sorted ( set ([ i . annotation for i in path . path ])) if len ( annotations ) > 1 and \"NA\" in annotations : pass # annotations.remove(\"NA\") # To check then row = \" \\t \" . join ( [ path . id , str ( path . length ), str ( statistics . mean ([ i . distance for i in path . path ])), str ( path . msa [ \"aa\" ] . get_alignment_length ()), str ( path . msa [ \"nt\" ] . get_alignment_length ()), str ( path . score ), str ( len ( path )), str ( round ( len ( path ) / len ( self . records ), 3 )), str ( path . msa_consensus [ \"aa\" ]), str ( path . msa_consensus [ \"nt\" ]), ', ' . join ([ i . id for i in path . path ]), ', ' . join ( annotations )]) rows . append ( row ) output_file_path = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"results_summary.tsv\" ) f = open ( output_file_path , \"w\" ) f . write ( \" \\n \" . join ( rows )) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc8c Results summary tsv table saved to: { os . path . basename ( output_file_path ) } .\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save results summary table.\" ) from error def plot_msa_figs ( self ) -> None : \"\"\"Plot MSA plots of conserved ORFs Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83c\udfa8 MSA figures plotting...\" , file = sys . stdout ) for path in self . conserved_paths : path . plot_msa () if self . parameters . arguments [ \"verbose\" ]: rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_visualisation\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) output_dirs_v = [ os . path . basename ( i ) for i in output_dirs . values ()] delimiter = \", \\n\\t \" print ( f \"\ud83d\udc8c MSA figures were saved to the folders: \\n\\t { delimiter . join ( output_dirs_v ) } \" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to plot sequence logo of conserved uORFs.\" ) from error def plot_ggmsa_figs ( self ) -> None : \"\"\"Plot MSA plots of conserved ORFs saved as fasta files. Note: R script based on ggmsa package [yulab-smu.top/ggmsa] used to produce MSA plots. R script (msa_plot.R) can be found in output_dir. This method uses subprocess to run this R script in the following way: `Rscript {output_dir}/msa_plot.R --msa_fasta path_to_fasta --output output_path --seq_type (nt/aa) --width N(mm) --height M(mm)`. Since during each run of uorf4u a local copy of this script is created in your output_dir, you can change it without any consequences for next uorf4u runs. This method based on _plot_ggmsa_ method of Path class and simply call it for each Path object. Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83c\udfa8 MSA figures plotting...\" , file = sys . stdout ) for path in self . conserved_paths : path . plot_ggmsa () if self . parameters . arguments [ \"verbose\" ]: rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_visualisation\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) output_dirs_v = [ os . path . basename ( i ) for i in output_dirs . values ()] delimiter = \", \\n\\t \" print ( f \"\ud83d\udc8c MSA figures were saved to the folders: \\n\\t { delimiter . join ( output_dirs_v ) } .\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to visualise MSA of conserved uORFs.\" ) from error def plot_logo_figs ( self ) -> None : \"\"\"Plot sequence Logo figures of conserved ORFs saved as fasta files. Note: This method uses logomaker package to produce images. This method based on _plot_logo_ method of Path class and simply call it for each Path object. Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83c\udfa8 Sequence logo figures plotting...\" , file = sys . stdout ) for path in self . conserved_paths : path . plot_logo () if self . parameters . arguments [ \"verbose\" ]: rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _seqlogo_visualisation\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) output_dirs_v = [ os . path . basename ( i ) for i in output_dirs . values ()] delimiter = \", \\n\\t \" print ( f \"\ud83d\udc8c Sequence logo figures were saved to the folders: \\n\\t { delimiter . join ( output_dirs_v ) } \" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to plot sequence logo of conserved uORFs.\" ) from error def plot_annotation ( self ) -> None : \"\"\"Plot loci' annotations figures with conserved ORFs highlighting. Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83c\udfa8 Loci annotations figures plotting...\" , file = sys . stdout ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) output_dir = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"annotation_visualisation\" ) if not os . path . exists ( output_dir ): os . mkdir ( output_dir ) for path in self . conserved_paths : output_file_name = f \" { os . path . join ( output_dir , path . id ) } .pdf\" annotation_plot_manager = uorf4u . drawing_annotation . AnnotationPlotManager ( path , self . records , self . parameters ) annotation_plot_manager . define_x_axis_coordinate_system () annotation_plot_manager . create_tracks () annotation_plot_manager . plot ( output_file_name ) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc8c Annotation figures were saved to the folder: { os . path . basename ( output_dir ) } \" , file = sys . stdout ) except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to plot loci' annotations figures.\" ) from error","title":"UpstreamSequences"},{"location":"API/package_data_processing/#uorf4u.data_processing.UpstreamSequences.__init__","text":"Create an UpstreamSequences object. Parameters: records ( list ) \u2013 List of Bio.SeqRecord.SeqRecord objects with upstream sequences. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/data_processing.py 604 605 606 607 608 609 610 611 612 613 614 615 616 def __init__ ( self , records : list , parameters : uorf4u . manager . Parameters ): \"\"\"Create an UpstreamSequences object. Arguments: records (list): List of Bio.SeqRecord.SeqRecord objects with upstream sequences. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . records = records self . parameters = parameters self . codon_table = Bio . Data . CodonTable . unambiguous_dna_by_name [ parameters . arguments [ \"ncbi_genetic_code_name\" ]] self . conserved_paths = None","title":"__init__()"},{"location":"API/package_data_processing/#uorf4u.data_processing.UpstreamSequences.annotate_orfs","text":"Annotate ORFs in upstream sequences. Note: This function updates 'records' attribute. Returns: None \u2013 None Source code in uorf4u/data_processing.py 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 def annotate_orfs ( self ) -> None : \"\"\"Annotate ORFs in upstream sequences. Note: This function updates 'records' attribute. Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udd0e ORFs annotating in the upstream sequences...\" , file = sys . stdout ) if self . parameters . arguments [ \"alternative_start_codons\" ]: start_codons_list = self . codon_table . start_codons else : start_codons_list = [ self . parameters . arguments [ \"main_start_codon\" ]] if self . parameters . arguments [ \"check_assembly_annotation\" ] and \\ self . records [ 0 ] . annotations [ \"RefSeq\" ]: if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udce1 Assemblies' annotation retrieving...\" , file = sys . stdout ) for i in range ( 0 , len ( self . records ), 100 ): useq_subset = [ record for record in self . records [ i : i + 100 ] if record . annotations [ \"RefSeq\" ]] locus_ids = [ locus . annotations [ \"locus_id\" ] for locus in useq_subset ] handle = Bio . Entrez . efetch ( db = \"nucleotide\" , id = locus_ids , rettype = \"gb\" , retmode = \"xml\" ) handle_txt = handle . read () . decode ( 'utf-8' ) for useq_record in useq_subset : useq_record . annotations [ \"locus_annotation\" ] = Locus ( useq_record . annotations [ \"locus_id\" ], start_b = useq_record . annotations [ \"start\" ], stop_b = useq_record . annotations [ \"stop\" ], target_strand = useq_record . annotations [ \"strand\" ], locus_record = useq_record . annotations [ \"locus_record\" ], xml_output = handle_txt ) for useq_index in range ( len ( self . records )): useq_record = self . records [ useq_index ] useq_record . annotations [ \"ORFs\" ] = [] for first_position in range (( useq_record . annotations [ \"length\" ] - self . parameters . arguments [ \"downstream_region_length\" ]) + 1 ): first_codon = useq_record . seq [ first_position : first_position + 3 ] if first_codon . upper () in start_codons_list : start_codon_position = first_position for second_position in range ( start_codon_position + 3 , ( useq_record . annotations [ \"length\" ] - 3 ) + 1 , 3 ): second_codon = useq_record . seq [ second_position : second_position + 3 ] if second_codon . upper () in self . codon_table . stop_codons : stop_codon_position = second_position orf_length = stop_codon_position - start_codon_position distance = ( useq_record . annotations [ \"length\" ] - self . parameters . arguments [ \"downstream_region_length\" ]) - stop_codon_position distance_sc = ( useq_record . annotations [ \"length\" ] - self . parameters . arguments [ \"downstream_region_length\" ]) - start_codon_position if useq_record . annotations [ \"RefSeq\" ]: orf_id = f \" { useq_record . annotations [ 'locus_id' ] } |\" \\ f \" { useq_record . annotations [ 'accession_number' ] } |\" \\ f \" { distance } \" orf_name = f \" { useq_record . annotations [ 'label' ] } | { distance } \" else : distance = useq_record . annotations [ \"length\" ] - stop_codon_position orf_id = f \" { useq_record . id } | { distance } \" if useq_record . description : orf_name = f \" { useq_record . description } | { orf_id } \" else : orf_name = orf_id sd_window_start = max ( [ 0 , ( start_codon_position - self . parameters . arguments [ \"sd_window_length\" ])]) current_orf = ORF ( parameters = self . parameters , id = orf_id , name = orf_name , distance = distance , start = start_codon_position , stop = stop_codon_position , useq_index = useq_index , nt_sequence = useq_record . seq [ start_codon_position : stop_codon_position ], sd_window_seq = useq_record . seq [ sd_window_start : start_codon_position ]) if current_orf . length >= self . parameters . arguments [ \"min_orf_length\" ] and distance_sc != 0 : useq_record . annotations [ \"ORFs\" ] . append ( current_orf ) if self . parameters . arguments [ \"check_assembly_annotation\" ] and \\ useq_record . annotations [ \"RefSeq\" ]: for cds in useq_record . annotations [ \"locus_annotation\" ] . CDSs : if current_orf . stop == cds [ \"relative_stop\" ] and ( ( current_orf . start - cds [ \"relative_start\" ]) % 3 == 0 ): the_same_stop = 1 current_orf . annotation = cds [ \"product_name\" ] if current_orf . start != cds [ \"relative_start\" ]: if current_orf . start < cds [ \"relative_start\" ]: current_orf . annotation += \" (extension)\" else : current_orf . annotation += \" (truncation)\" for annotated_orfs in useq_record . annotations [ \"ORFs\" ]: if current_orf . stop == annotated_orfs . stop and \\ current_orf . id != annotated_orfs . id : current_orf . extended_orfs . append ( annotated_orfs . id ) break number_of_orfs = sum ( len ( i . annotations [ \"ORFs\" ]) for i in self . records ) if self . parameters . arguments [ \"fast_searching\" ] == \"auto\" : if len ( self . records ) < 5 : self . parameters . arguments [ \"fast_searching\" ] = False elif ( len ( self . records ) >= 100 or number_of_orfs > 1000 ): self . parameters . arguments [ \"fast_searching\" ] = True else : self . parameters . arguments [ \"fast_searching\" ] = False if number_of_orfs == 0 : print ( f \"\u26d4Termination: \\n\\t No ORF was annotated in upstream sequences.\" f \" \\n\\t This run will be terminated.\" , file = sys . stderr ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) with open ( os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"report.txt\" ), \"w\" ) as report_f : report_f . write ( \"Termination: \\n No ORF was annotated in upstream sequences.\" ) sys . exit () if self . parameters . arguments [ \"verbose\" ]: print ( f \"\u2705 { number_of_orfs } ORFs were annotated.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to annotate ORFs in upstream sequences.\" ) from error","title":"annotate_orfs()"},{"location":"API/package_data_processing/#uorf4u.data_processing.UpstreamSequences.conserved_orf_searching","text":"Search for sets of conserved ORFs in upstream sequences. Note: This method updates the self.conserved_paths attribute. Returns: None \u2013 None Source code in uorf4u/data_processing.py 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 def conserved_orf_searching ( self ) -> None : \"\"\"Search for sets of conserved ORFs in upstream sequences. Note: This method updates the self.conserved_paths attribute. Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udd0e Searching for conserved ORFs in upstream sequences...\" , file = sys . stdout ) if len ( self . records ) == 1 : raise uorf4u . manager . uORF4uError ( \"At least two sequences required to perform conservation analysis\" ) lengths = [] for record in self . records : for orf in record . annotations [ \"ORFs\" ]: lengths . append ( orf . length ) lengths = sorted ( list ( set ( lengths ))) global_aligner = Bio . Align . PairwiseAligner () global_aligner . mode = \"global\" global_aligner . match_score = self . parameters . arguments [ \"global_match_score\" ] global_aligner . mismatch_score = self . parameters . arguments [ \"global_mismatch_score\" ] global_aligner . open_gap_score = self . parameters . arguments [ \"global_open_gap_score\" ] global_aligner . extend_gap_score = self . parameters . arguments [ \"global_extend_gap_score\" ] global_aligner . target_end_gap_score = self . parameters . arguments [ \"global_target_end_gap_score\" ] global_aligner . query_end_gap_score = self . parameters . arguments [ \"global_query_end_gap_score\" ] length_variance = self . parameters . arguments [ \"orf_length_group_range\" ] number_of_useqs = len ( self . records ) if self . parameters . arguments [ \"fast_searching\" ]: filtered_orfs_dict = dict () for length in lengths : if isinstance ( self . parameters . arguments [ \"orf_length_group_range\" ], float ): length_variance = length * self . parameters . arguments [ \"orf_length_group_range\" ] filtered_orfs = [] useq_with_filtered_orfs = [] for useq_index in range ( number_of_useqs ): useq_record = self . records [ useq_index ] for orf in useq_record . annotations [ \"ORFs\" ]: if abs ( length - orf . length ) <= length_variance : filtered_orfs . append ( orf ) if useq_index not in useq_with_filtered_orfs : useq_with_filtered_orfs . append ( useq_index ) if len ( useq_with_filtered_orfs ) / number_of_useqs >= self . parameters . arguments [ \"orfs_presence_cutoff\" ]: to_add = 1 keys_to_remove = [] for added_length in filtered_orfs_dict . keys (): num_of_identical_elements = len ( set ( filtered_orfs ) & set ( filtered_orfs_dict [ added_length ])) fraction = num_of_identical_elements / min ( len ( filtered_orfs ), len ( filtered_orfs_dict [ added_length ])) if fraction > 0.8 : # to add as a config parameter if len ( filtered_orfs ) >= len ( filtered_orfs_dict [ added_length ]): keys_to_remove . append ( added_length ) else : to_add = 0 for key_to_remove in keys_to_remove : filtered_orfs_dict . pop ( key_to_remove ) if to_add : filtered_orfs_dict [ length ] = filtered_orfs lengths = list ( filtered_orfs_dict . keys ()) conserved_paths = [] for length in lengths : if isinstance ( self . parameters . arguments [ \"orf_length_group_range\" ], float ): length_variance = length * self . parameters . arguments [ \"orf_length_group_range\" ] useq_indexes_with_filtered_orfs = [] filtered_orfs = dict () for useq_index in range ( number_of_useqs ): useq_record = self . records [ useq_index ] filtered_orfs [ useq_index ] = [] for orf in useq_record . annotations [ \"ORFs\" ]: if abs ( length - orf . length ) <= length_variance : filtered_orfs [ useq_index ] . append ( orf ) orfs_ids = [ i . id for i in filtered_orfs [ useq_index ]] for orf in filtered_orfs [ useq_index ]: if any ( i in orf . extended_orfs for i in orfs_ids ): filtered_orfs [ useq_index ] . remove ( orf ) if len ( filtered_orfs [ useq_index ]) > 0 : useq_indexes_with_filtered_orfs . append ( useq_index ) if len ( useq_indexes_with_filtered_orfs ) / number_of_useqs >= self . parameters . arguments [ \"orfs_presence_cutoff\" ]: if self . parameters . arguments [ \"fast_searching\" ]: genome_iterator = random . sample ( filtered_orfs . keys (), max ( 1 , min ( round ( self . parameters . arguments [ \"fast_searching_\" \"fraction_of_initial\" \"_genomes\" ] * len ( useq_indexes_with_filtered_orfs )), self . parameters . arguments [ \"max_num_of_initial_genome_iteration\" ]))) elif len ( filtered_orfs . keys ()) > self . parameters . arguments [ \"max_num_of_initial_genome_iteration\" ]: genome_iterator = random . sample ( filtered_orfs . keys (), self . parameters . arguments [ \"max_num_of_initial_genome_iteration\" ]) else : genome_iterator = filtered_orfs . keys () for initial_useq in genome_iterator : for initial_orf in filtered_orfs [ initial_useq ]: conserved_path = Path ( self . parameters ) conserved_path . update ( initial_orf ) for useq in random . sample ( filtered_orfs . keys (), len ( filtered_orfs . keys ())): if useq != initial_useq and filtered_orfs [ useq ] != []: score_sums = [] for orf in filtered_orfs [ useq ]: score_sum = 0 for path_orf in conserved_path . path : if self . parameters . arguments [ \"alignment_type\" ] == \"nt\" : current_alignment = global_aligner . align ( orf . nt_sequence , path_orf . nt_sequence ) elif self . parameters . arguments [ \"alignment_type\" ] == \"aa\" : current_alignment = global_aligner . align ( orf . aa_sequence , path_orf . aa_sequence ) score_sum += current_alignment . score score_sums . append ( score_sum ) max_score = max ( score_sums ) if max_score > self . parameters . arguments [ \"alignment_score_cutoff\" ]: if score_sums . count ( max_score ) == 1 : selected_orf = filtered_orfs [ useq ][ score_sums . index ( max_score )] else : num_of_candidates = len ( filtered_orfs [ useq ]) highest_score_orfs = [ filtered_orfs [ useq ][ k ] for k in range ( num_of_candidates ) if score_sums [ k ] == max_score ] highest_score_orfs_length_dists = [ orf_it . length - length for orf_it in highest_score_orfs ] min_length_dist = min ( highest_score_orfs_length_dists ) if highest_score_orfs_length_dists . count ( min_length_dist ) == 1 : selected_orf = highest_score_orfs [ highest_score_orfs_length_dists . index ( min_length_dist )] else : num_of_candidates = len ( highest_score_orfs ) the_closest_by_length_orfs = [ highest_score_orfs [ k ] for k in range ( num_of_candidates ) if highest_score_orfs_length_dists [ k ] == min_length_dist ] the_closest_by_length_orfs_lengths = [ orf_it . length for orf_it in the_closest_by_length_orfs ] max_length = max ( the_closest_by_length_orfs_lengths ) selected_orf = the_closest_by_length_orfs [ the_closest_by_length_orfs_lengths . index ( max_length )] conserved_path . update ( selected_orf , max_score ) if len ( conserved_path ) / number_of_useqs >= self . parameters . arguments [ \"orfs_presence_cutoff\" ] and len ( conserved_path ) > 1 : to_save_this_path = 1 for old_path in conserved_paths : fraction_of_identity = conserved_path . calculate_similarity ( old_path ) if fraction_of_identity >= self . parameters . arguments [ \"paths_identity_cutoff\" ]: if conserved_path . score > old_path . score : conserved_paths . remove ( old_path ) elif conserved_path . score <= old_path . score : to_save_this_path = 0 if to_save_this_path == 1 : conserved_path . sort () conserved_paths . append ( conserved_path ) self . conserved_paths = conserved_paths number_of_paths = len ( conserved_paths ) if number_of_paths == 0 : print ( f \"\u26d4Termination: \\n\\t No conserved ORFs set was found.\" f \" \\n\\t This run will be terminated.\" , file = sys . stderr ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) with open ( os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"report.txt\" ), \"w\" ) as report_f : report_f . write ( \"Termination: \\n No conserved ORFs set was found.\" ) sys . exit () if self . parameters . arguments [ \"verbose\" ]: print ( f \"\u2705 { number_of_paths } sets of conserved ORFs were found.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to perform searching for conserved uORFs.\" ) from error","title":"conserved_orf_searching()"},{"location":"API/package_data_processing/#uorf4u.data_processing.UpstreamSequences.filter_orfs_by_sd_annotation","text":"Filter annotated ORFs by presence the Shine-Dalgarno sequence. Returns: None \u2013 None Source code in uorf4u/data_processing.py 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 def filter_orfs_by_sd_annotation ( self ) -> None : \"\"\"Filter annotated ORFs by presence the Shine-Dalgarno sequence. Returns: None \"\"\" try : for useq_record in self . records : orf_list = useq_record . annotations [ \"ORFs\" ] filtered_orf_list = [] for orf in orf_list : orf . calculate_energies () if orf . min_energy < self . parameters . arguments [ \"sd_energy_cutoff\" ]: filtered_orf_list . append ( orf ) useq_record . annotations [ \"ORFs\" ] = filtered_orf_list number_of_orfs = sum ( len ( i . annotations [ \"ORFs\" ]) for i in self . records ) if number_of_orfs == 0 : print ( f \"\u26d4Termination: \\n\\t No ORF left after filtering by SD annotation.\" f \" \\n\\t This run will be terminated.\" , file = sys . stderr ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) with open ( os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"report.txt\" ), \"w\" ) as report_f : report_f . write ( \"Termination: \\n No ORF left after filtering by SD annotation.\" ) sys . exit () if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83e\uddf9 { number_of_orfs } ORFs remained in the analysis after filtering by presence \" f \"of the SD sequence.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to filter uORFs by SD sequence presence.\" ) from error","title":"filter_orfs_by_sd_annotation()"},{"location":"API/package_data_processing/#uorf4u.data_processing.UpstreamSequences.filter_out_similar_paths","text":"Filter out duplicates in sets of annotated conserved ORFs. Note: Two paths are considered as duplicates if they share more than half of ORFs (default value, see 'paths_identity_cutoff' config parameter). In case two paths are found as identical, only one with a higher score will be saved. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 def filter_out_similar_paths ( self ) -> None : \"\"\"Filter out duplicates in sets of annotated conserved ORFs. Note: Two paths are considered as duplicates if they share more than half of ORFs (default value, see 'paths_identity_cutoff' config parameter). In case two paths are found as identical, only one with a higher score will be saved. Returns: None \"\"\" try : filtered_paths = [] for path in self . conserved_paths : to_add = 1 for path_filtered in filtered_paths : if path . calculate_similarity ( path_filtered ) > self . parameters . arguments [ \"paths_identity_cutoff\" ]: if path . score < path_filtered . score : to_add = 0 elif path . score == path_filtered . score and ( len ( path ) < len ( path_filtered )): to_add = 0 else : filtered_paths . remove ( path_filtered ) if to_add == 1 : filtered_paths . append ( path ) self . conserved_paths = filtered_paths if self . parameters . arguments [ \"verbose\" ]: num_of_paths = len ( self . conserved_paths ) print ( f \"\ud83e\uddf9 { num_of_paths } set(s) of conserved ORFs remained in the analysis after filtering \" f \"out duplicates.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to filter out duplicates in conserved uORFs sets.\" ) from error","title":"filter_out_similar_paths()"},{"location":"API/package_data_processing/#uorf4u.data_processing.UpstreamSequences.plot_annotation","text":"Plot loci' annotations figures with conserved ORFs highlighting. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 def plot_annotation ( self ) -> None : \"\"\"Plot loci' annotations figures with conserved ORFs highlighting. Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83c\udfa8 Loci annotations figures plotting...\" , file = sys . stdout ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) output_dir = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"annotation_visualisation\" ) if not os . path . exists ( output_dir ): os . mkdir ( output_dir ) for path in self . conserved_paths : output_file_name = f \" { os . path . join ( output_dir , path . id ) } .pdf\" annotation_plot_manager = uorf4u . drawing_annotation . AnnotationPlotManager ( path , self . records , self . parameters ) annotation_plot_manager . define_x_axis_coordinate_system () annotation_plot_manager . create_tracks () annotation_plot_manager . plot ( output_file_name ) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc8c Annotation figures were saved to the folder: { os . path . basename ( output_dir ) } \" , file = sys . stdout ) except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to plot loci' annotations figures.\" ) from error","title":"plot_annotation()"},{"location":"API/package_data_processing/#uorf4u.data_processing.UpstreamSequences.plot_ggmsa_figs","text":"Plot MSA plots of conserved ORFs saved as fasta files. Note: R script based on ggmsa package [yulab-smu.top/ggmsa] used to produce MSA plots. R script (msa_plot.R) can be found in output_dir. This method uses subprocess to run this R script in the following way: Rscript {output_dir}/msa_plot.R --msa_fasta path_to_fasta --output output_path --seq_type (nt/aa) --width N(mm) --height M(mm) . Since during each run of uorf4u a local copy of this script is created in your output_dir, you can change it without any consequences for next uorf4u runs. This method based on plot_ggmsa method of Path class and simply call it for each Path object. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 def plot_ggmsa_figs ( self ) -> None : \"\"\"Plot MSA plots of conserved ORFs saved as fasta files. Note: R script based on ggmsa package [yulab-smu.top/ggmsa] used to produce MSA plots. R script (msa_plot.R) can be found in output_dir. This method uses subprocess to run this R script in the following way: `Rscript {output_dir}/msa_plot.R --msa_fasta path_to_fasta --output output_path --seq_type (nt/aa) --width N(mm) --height M(mm)`. Since during each run of uorf4u a local copy of this script is created in your output_dir, you can change it without any consequences for next uorf4u runs. This method based on _plot_ggmsa_ method of Path class and simply call it for each Path object. Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83c\udfa8 MSA figures plotting...\" , file = sys . stdout ) for path in self . conserved_paths : path . plot_ggmsa () if self . parameters . arguments [ \"verbose\" ]: rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_visualisation\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) output_dirs_v = [ os . path . basename ( i ) for i in output_dirs . values ()] delimiter = \", \\n\\t \" print ( f \"\ud83d\udc8c MSA figures were saved to the folders: \\n\\t { delimiter . join ( output_dirs_v ) } .\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to visualise MSA of conserved uORFs.\" ) from error","title":"plot_ggmsa_figs()"},{"location":"API/package_data_processing/#uorf4u.data_processing.UpstreamSequences.plot_logo_figs","text":"Plot sequence Logo figures of conserved ORFs saved as fasta files. Note: This method uses logomaker package to produce images. This method based on plot_logo method of Path class and simply call it for each Path object. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 def plot_logo_figs ( self ) -> None : \"\"\"Plot sequence Logo figures of conserved ORFs saved as fasta files. Note: This method uses logomaker package to produce images. This method based on _plot_logo_ method of Path class and simply call it for each Path object. Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83c\udfa8 Sequence logo figures plotting...\" , file = sys . stdout ) for path in self . conserved_paths : path . plot_logo () if self . parameters . arguments [ \"verbose\" ]: rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _seqlogo_visualisation\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) output_dirs_v = [ os . path . basename ( i ) for i in output_dirs . values ()] delimiter = \", \\n\\t \" print ( f \"\ud83d\udc8c Sequence logo figures were saved to the folders: \\n\\t { delimiter . join ( output_dirs_v ) } \" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to plot sequence logo of conserved uORFs.\" ) from error","title":"plot_logo_figs()"},{"location":"API/package_data_processing/#uorf4u.data_processing.UpstreamSequences.plot_msa_figs","text":"Plot MSA plots of conserved ORFs Returns: None \u2013 None Source code in uorf4u/data_processing.py 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 def plot_msa_figs ( self ) -> None : \"\"\"Plot MSA plots of conserved ORFs Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83c\udfa8 MSA figures plotting...\" , file = sys . stdout ) for path in self . conserved_paths : path . plot_msa () if self . parameters . arguments [ \"verbose\" ]: rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_visualisation\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) output_dirs_v = [ os . path . basename ( i ) for i in output_dirs . values ()] delimiter = \", \\n\\t \" print ( f \"\ud83d\udc8c MSA figures were saved to the folders: \\n\\t { delimiter . join ( output_dirs_v ) } \" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to plot sequence logo of conserved uORFs.\" ) from error","title":"plot_msa_figs()"},{"location":"API/package_data_processing/#uorf4u.data_processing.UpstreamSequences.run_msa","text":"Run msa tool (muscle) for each path object (set of conserved ORFs). Returns: None \u2013 None Source code in uorf4u/data_processing.py 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 def run_msa ( self ) -> None : \"\"\"Run msa tool (muscle) for each path object (set of conserved ORFs). Returns: None \"\"\" try : if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83e\uddee Running MSA for conserved ORFs.\" , file = sys . stdout ) for path in self . conserved_paths : path . maft_msa () return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to get MSA of conserved uORFs.\" ) from error","title":"run_msa()"},{"location":"API/package_data_processing/#uorf4u.data_processing.UpstreamSequences.save_annotated_orfs","text":"Save information about annotated ORFs as a set of tsv files. Note: tsv files will be saved to the subdir called 'annotated_ORFs' located in 'output_dir'. Returns: None \u2013 None Source code in uorf4u/data_processing.py 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 def save_annotated_orfs ( self ) -> None : \"\"\"Save information about annotated ORFs as a set of tsv files. Note: tsv files will be saved to the subdir called 'annotated_ORFs' located in 'output_dir'. Returns: None \"\"\" try : colnames = \" \\t \" . join ( [ \"id\" , \"name\" , \"length\" , \"nt_sequence\" , \"aa_sequence\" , \"sd_sequence_window\" , \"SD-aSD energy\" , \"SD-aSD energies list\" , \"extended_orfs\" , \"annotation\" ]) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) output_dir_path = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"annotated_ORFs\" ) if not os . path . exists ( output_dir_path ): os . mkdir ( output_dir_path ) for useq_record in self . records : file_name = f \" { useq_record . description } | { useq_record . id } \" . replace ( ' ' , '_' ) . replace ( '/' , '_' ) lines = [ colnames ] for orf in useq_record . annotations [ \"ORFs\" ]: if not orf . extended_orfs : extented_orfs_value = \"NA\" else : extented_orfs_value = ';' . join ( orf . extended_orfs ) lines . append ( \" \\t \" . join ( [ orf . id , orf . name , str ( orf . length ), str ( orf . nt_sequence ), str ( orf . aa_sequence ), str ( orf . sd_window_seq_str ), str ( orf . min_energy ), \";\" . join ( orf . sd_window_energies ), extented_orfs_value , orf . annotation ])) with open ( os . path . join ( output_dir_path , f \" { file_name } .tsv\" ), \"w\" ) as output : output . write ( \" \\n \" . join ( lines )) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc8c tsv files with information about annotated ORFs were saved to \" f \" { os . path . basename ( output_dir_path ) } folder.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save annotated uORFs.\" ) from error","title":"save_annotated_orfs()"},{"location":"API/package_data_processing/#uorf4u.data_processing.UpstreamSequences.save_msa","text":"Save MSA of conserved ORFs as fasta files. Note: Fasta files will be saved to the subdirs: ['nucleotide_msa' - for MSA of nucleotide sequences of ORFs, 'amino_acid_msa' - MSA of amino acid sequences of ORFs, and 'sd_msa' - MSA of SD sequence regions of ORFS). All of them located in your 'output_dir'. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 def save_msa ( self ) -> None : \"\"\"Save MSA of conserved ORFs as fasta files. Note: Fasta files will be saved to the subdirs: ['nucleotide_msa' - for MSA of nucleotide sequences of ORFs, 'amino_acid_msa' - MSA of amino acid sequences of ORFs, and 'sd_msa' - MSA of SD sequence regions of ORFS). All of them located in your 'output_dir'. Returns: None \"\"\" try : if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" , sd = \"sd\" ) output_dirs = dict ( zip ( self . parameters . arguments [ \"sequences_to_write\" ], [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _msa_fasta_files\" ) for i in self . parameters . arguments [ 'sequences_to_write' ]])) for key in output_dirs : if not ( os . path . exists ( output_dirs [ key ])): os . mkdir ( output_dirs [ key ]) for path in self . conserved_paths : for seq_type in self . parameters . arguments [ \"sequences_to_write\" ]: msa = path . msa [ seq_type ] output = os . path . join ( output_dirs [ seq_type ], f \" { path . id } .fa\" ) Bio . AlignIO . write ( msa , output , \"fasta\" ) if self . parameters . arguments [ \"verbose\" ]: output_dirs_v = [ os . path . basename ( i ) for i in output_dirs . values ()] delimiter = \", \\n\\t \" print ( f \"\ud83d\udc8c MSA fasta files of conserved ORFs were saved to the folders: \\n \" f \" \\t { delimiter . join ( output_dirs_v ) } folders.\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save MSA of conserved uORFs.\" ) from error","title":"save_msa()"},{"location":"API/package_data_processing/#uorf4u.data_processing.UpstreamSequences.save_orfs_sequences","text":"Save sequences of conserved ORFs as fasta files. Note: Fasta files will be saved to the subdirs: ['nucleotide_orfs' - for MSA of nucleotide sequences of ORFs, 'amino_acid_msa' - MSA of amino acid sequences of ORFs, and 'sd_msa' - MSA of SD sequence regions of ORFS). All of them located in your 'output_dir'. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 def save_orfs_sequences ( self ) -> None : \"\"\"Save sequences of conserved ORFs as fasta files. Note: Fasta files will be saved to the subdirs: ['nucleotide_orfs' - for MSA of nucleotide sequences of ORFs, 'amino_acid_msa' - MSA of amino acid sequences of ORFs, and 'sd_msa' - MSA of SD sequence regions of ORFS). All of them located in your 'output_dir'. Returns: None \"\"\" try : if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) rename_dict = dict ( nt = \"nucleotide\" , aa = \"amino_acid\" ) sequence_to_write = [ i for i in self . parameters . arguments [ \"sequences_to_write\" ] if i != \"sd\" ] output_dirs = dict ( zip ( sequence_to_write , [ os . path . join ( self . parameters . arguments [ \"output_dir\" ], f \" { rename_dict [ i ] } _orfs_fasta_files\" ) for i in sequence_to_write ])) for key in output_dirs : if not ( os . path . exists ( output_dirs [ key ])): os . mkdir ( output_dirs [ key ]) for seq_type in sequence_to_write : for path in self . conserved_paths : records = [] for orf in path . path : if seq_type == \"nt\" : record = Bio . SeqRecord . SeqRecord ( orf . nt_sequence , orf . id , \"\" , orf . name ) if seq_type == \"aa\" : record = Bio . SeqRecord . SeqRecord ( orf . aa_sequence , orf . id , \"\" , orf . name ) records . append ( record ) output = os . path . join ( output_dirs [ seq_type ], f \" { path . id } .fa\" ) Bio . SeqIO . write ( records , output , \"fasta\" ) if self . parameters . arguments [ \"verbose\" ]: delimiter = \", \\n\\t \" output_dirs_v = [ os . path . basename ( i ) for i in output_dirs . values ()] print ( f \"\ud83d\udc8c Sequences fasta files of conserved ORFs were saved to the folders: \\n \" f \" \\t { delimiter . join ( output_dirs_v ) } .\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save sequences of conserved uORFs.\" ) from error","title":"save_orfs_sequences()"},{"location":"API/package_data_processing/#uorf4u.data_processing.UpstreamSequences.save_results_summary_table","text":"Save results summary table. Note: A tsv table will be saved to your output_dir. Returns: None \u2013 None Source code in uorf4u/data_processing.py 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 def save_results_summary_table ( self ) -> None : \"\"\"Save results summary table. Note: A tsv table will be saved to your output_dir. Returns: None \"\"\" try : colnames = \" \\t \" . join ( [ \"id\" , \"length\" , \"average_distance_to_the_ORF\" , \"aa_alignment_length\" , \"nt_alignment_length\" , \"score\" , \"number_of_orfs\" , \"number_of_orfs/number_of_sequences\" , \"consensus(aa)\" , \"consensus(nt)\" , \"uORFs\" , \"uORFs_annotations\" ]) rows = [ colnames ] for path in self . conserved_paths : annotations = sorted ( set ([ i . annotation for i in path . path ])) if len ( annotations ) > 1 and \"NA\" in annotations : pass # annotations.remove(\"NA\") # To check then row = \" \\t \" . join ( [ path . id , str ( path . length ), str ( statistics . mean ([ i . distance for i in path . path ])), str ( path . msa [ \"aa\" ] . get_alignment_length ()), str ( path . msa [ \"nt\" ] . get_alignment_length ()), str ( path . score ), str ( len ( path )), str ( round ( len ( path ) / len ( self . records ), 3 )), str ( path . msa_consensus [ \"aa\" ]), str ( path . msa_consensus [ \"nt\" ]), ', ' . join ([ i . id for i in path . path ]), ', ' . join ( annotations )]) rows . append ( row ) output_file_path = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"results_summary.tsv\" ) f = open ( output_file_path , \"w\" ) f . write ( \" \\n \" . join ( rows )) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc8c Results summary tsv table saved to: { os . path . basename ( output_file_path ) } .\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save results summary table.\" ) from error","title":"save_results_summary_table()"},{"location":"API/package_data_processing/#uorf4u.data_processing.UpstreamSequences.save_upstream_sequences","text":"Save upstream sequences as a fasta file. Returns: None \u2013 None Source code in uorf4u/data_processing.py 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 def save_upstream_sequences ( self ) -> None : \"\"\"Save upstream sequences as a fasta file. Returns: None \"\"\" try : output_file = os . path . join ( self . parameters . arguments [ \"output_dir\" ], \"upstream_sequences.fa\" ) if not os . path . exists ( self . parameters . arguments [ \"output_dir\" ]): os . mkdir ( self . parameters . arguments [ \"output_dir\" ]) Bio . SeqIO . write ( self . records , output_file , \"fasta\" ) if self . parameters . arguments [ \"verbose\" ]: print ( f \"\ud83d\udc8c Fasta file with upstream sequences was saved to { os . path . basename ( output_file ) } .\" , file = sys . stdout ) return None except Exception as error : raise uorf4u . manager . uORF4uError ( \"Unable to save a fasta file with upstream sequences.\" ) from error","title":"save_upstream_sequences()"},{"location":"API/package_drawing/","text":"This module provides visualisation of loci annotation. AnnotationPlotManager AnnotationPlotManager object holds needed information for annotation visualisation and controls it. Note: It's supposed that the AnnotationPlotManager' objects will not be used directly by API users since visualisation can be controlled by 'plot_annotation' method. Attributes: path ( uorf4u . data_processing . Path ) \u2013 Path class' objects that holds list of conserved ORFs. upstream_sequences ( list ) \u2013 list of dicts with information about upstream sequences. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. coordinate_system ( dict ) \u2013 coordinate system of figure. additional_data ( dict ) \u2013 dict with data for visualisation tracks. Source code in uorf4u/drawing_annotation.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 class AnnotationPlotManager : \"\"\" AnnotationPlotManager object holds needed information for annotation visualisation and controls it. Note: It's supposed that the AnnotationPlotManager' objects will not be used directly by API users since visualisation can be controlled by 'plot_annotation' method. Attributes: path (uorf4u.data_processing.Path): Path class' objects that holds list of conserved ORFs. upstream_sequences (list): list of dicts with information about upstream sequences. parameters (uorf4u.manager.Parameters): Parameters' class object. coordinate_system (dict): coordinate system of figure. additional_data (dict): dict with data for visualisation tracks. \"\"\" def __init__ ( self , path , upstream_sequences : list , parameters : uorf4u . manager . Parameters ): \"\"\"Create a AnnotationPlotManager object. Arguments: path (uorf4u.data_processing.Path): Path class' objects that holds list of conserved ORFs. upstream_sequences (list): list of dicts with information about upstream sequences. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . path = path self . upstream_sequences = upstream_sequences self . parameters = parameters self . coordinate_system = dict () self . additional_data = dict () def define_x_axis_coordinate_system ( self ) -> None : \"\"\"Define coordinate system. Returns: None \"\"\" label_height = self . parameters . arguments [ \"label_height_to_orf_height\" ] * self . parameters . arguments [ \"orf_height\" ] * cm label_font_size = uorf4u . methods . string_height_to_font_size ( label_height , \"regular\" , self . parameters . arguments ) self . additional_data [ \"label_font_size\" ] = label_font_size self . additional_data [ \"ordered_upstream_sequences\" ] = [ self . upstream_sequences [ i ] for i in [ orf . useq_index for orf in self . path . path ]] max_label_width = max ([ reportlab . pdfbase . pdfmetrics . stringWidth ( i . annotations [ \"label\" ], \"regular\" , label_font_size ) for i in self . additional_data [ \"ordered_upstream_sequences\" ]]) self . additional_data [ \"number_of_sequences\" ] = len ( self . path ) self . additional_data [ \"max_upstream_sequence_length\" ] = max ( i . annotations [ \"upstream_region_length\" ] for i in self . additional_data [ \"ordered_upstream_sequences\" ]) self . additional_data [ \"max_downstream_sequence_length\" ] = max ( i . annotations [ \"downstream_region_length\" ] for i in self . additional_data [ \"ordered_upstream_sequences\" ]) window_size_nt = self . additional_data [ \"max_upstream_sequence_length\" ] + self . additional_data [ \"max_downstream_sequence_length\" ] if self . parameters . arguments [ \"annotation_width\" ] == \"auto\" : annotation_width = window_size_nt * self . parameters . arguments [ \"mm_per_nt\" ] * mm else : annotation_width = self . parameters . arguments [ \"annotation_width\" ] * cm self . coordinate_system [ \"transformation_coef\" ] = annotation_width / window_size_nt self . coordinate_system [ \"x_labels_start\" ] = self . parameters . arguments [ \"margin\" ] * cm self . coordinate_system [ \"x_labels_stop\" ] = self . coordinate_system [ \"x_labels_start\" ] + max_label_width self . coordinate_system [ \"x_annotation_start\" ] = self . coordinate_system [ \"x_labels_stop\" ] + \\ self . parameters . arguments [ \"label_gap\" ] * cm self . coordinate_system [ \"x_annotation_stop\" ] = self . coordinate_system [ \"x_annotation_start\" ] + annotation_width self . coordinate_system [ \"figure_width\" ] = 2 * self . parameters . arguments [ \"margin\" ] * cm + annotation_width + \\ max_label_width + self . parameters . arguments [ \"label_gap\" ] * cm self . coordinate_system [ \"figure_height\" ] = self . parameters . arguments [ \"margin\" ] * cm return None def create_tracks ( self ) -> None : \"\"\"Create visualisation tracks. Returns: None \"\"\" self . tracks = [] \"\"\" title_loader = TitleLoader(self.parameters) title_loader.prepare_data(self.coordinate_system, self.additional_data) title_track = title_loader.create_track() self.tracks.append(title_track) self.coordinate_system[\"figure_height\"] += title_track.needed_y_space() \"\"\" for index in range ( self . additional_data [ \"number_of_sequences\" ]): upstream_sequence = self . additional_data [ \"ordered_upstream_sequences\" ][ index ] conserved_orf = self . path . path [ index ] sequence_loader = SequencesLoader ( self . parameters ) sequence_loader . prepare_data ( upstream_sequence , conserved_orf , self . coordinate_system , self . additional_data ) track = sequence_loader . create_track () self . tracks . append ( track ) self . coordinate_system [ \"figure_height\" ] += track . needed_y_space () self . coordinate_system [ \"figure_height\" ] += self . parameters . arguments [ \"gap\" ] * cm # if index < self.additional_data[\"number_of_sequences\"] - 1: axis_tics_loader = AxisLoader ( self . parameters ) axis_tics_loader . prepare_data ( self . coordinate_system , self . additional_data ) axis_tics_track = axis_tics_loader . create_track () self . tracks . append ( axis_tics_track ) self . coordinate_system [ \"figure_height\" ] += axis_tics_track . needed_y_space () self . coordinate_system [ \"figure_height\" ] += self . parameters . arguments [ \"margin\" ] * cm def plot ( self , filename ): image = Image ( filename , self . coordinate_system [ \"figure_width\" ], self . coordinate_system [ \"figure_height\" ]) current_y_top = self . coordinate_system [ \"figure_height\" ] - self . parameters . arguments [ \"margin\" ] * cm for track in self . tracks : track . visualisation_data [ \"y_top\" ] = current_y_top track . draw ( image . canvas ) current_y_top -= ( track . needed_space + self . parameters . arguments [ \"gap\" ] * cm ) image . save () return None __init__ ( path , upstream_sequences , parameters ) Create a AnnotationPlotManager object. Parameters: path ( uorf4u . data_processing . Path ) \u2013 Path class' objects that holds list of conserved ORFs. upstream_sequences ( list ) \u2013 list of dicts with information about upstream sequences. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing_annotation.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 def __init__ ( self , path , upstream_sequences : list , parameters : uorf4u . manager . Parameters ): \"\"\"Create a AnnotationPlotManager object. Arguments: path (uorf4u.data_processing.Path): Path class' objects that holds list of conserved ORFs. upstream_sequences (list): list of dicts with information about upstream sequences. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . path = path self . upstream_sequences = upstream_sequences self . parameters = parameters self . coordinate_system = dict () self . additional_data = dict () create_tracks () Create visualisation tracks. Returns: None \u2013 None Source code in uorf4u/drawing_annotation.py 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 def create_tracks ( self ) -> None : \"\"\"Create visualisation tracks. Returns: None \"\"\" self . tracks = [] \"\"\" title_loader = TitleLoader(self.parameters) title_loader.prepare_data(self.coordinate_system, self.additional_data) title_track = title_loader.create_track() self.tracks.append(title_track) self.coordinate_system[\"figure_height\"] += title_track.needed_y_space() \"\"\" for index in range ( self . additional_data [ \"number_of_sequences\" ]): upstream_sequence = self . additional_data [ \"ordered_upstream_sequences\" ][ index ] conserved_orf = self . path . path [ index ] sequence_loader = SequencesLoader ( self . parameters ) sequence_loader . prepare_data ( upstream_sequence , conserved_orf , self . coordinate_system , self . additional_data ) track = sequence_loader . create_track () self . tracks . append ( track ) self . coordinate_system [ \"figure_height\" ] += track . needed_y_space () self . coordinate_system [ \"figure_height\" ] += self . parameters . arguments [ \"gap\" ] * cm # if index < self.additional_data[\"number_of_sequences\"] - 1: axis_tics_loader = AxisLoader ( self . parameters ) axis_tics_loader . prepare_data ( self . coordinate_system , self . additional_data ) axis_tics_track = axis_tics_loader . create_track () self . tracks . append ( axis_tics_track ) self . coordinate_system [ \"figure_height\" ] += axis_tics_track . needed_y_space () self . coordinate_system [ \"figure_height\" ] += self . parameters . arguments [ \"margin\" ] * cm define_x_axis_coordinate_system () Define coordinate system. Returns: None \u2013 None Source code in uorf4u/drawing_annotation.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 def define_x_axis_coordinate_system ( self ) -> None : \"\"\"Define coordinate system. Returns: None \"\"\" label_height = self . parameters . arguments [ \"label_height_to_orf_height\" ] * self . parameters . arguments [ \"orf_height\" ] * cm label_font_size = uorf4u . methods . string_height_to_font_size ( label_height , \"regular\" , self . parameters . arguments ) self . additional_data [ \"label_font_size\" ] = label_font_size self . additional_data [ \"ordered_upstream_sequences\" ] = [ self . upstream_sequences [ i ] for i in [ orf . useq_index for orf in self . path . path ]] max_label_width = max ([ reportlab . pdfbase . pdfmetrics . stringWidth ( i . annotations [ \"label\" ], \"regular\" , label_font_size ) for i in self . additional_data [ \"ordered_upstream_sequences\" ]]) self . additional_data [ \"number_of_sequences\" ] = len ( self . path ) self . additional_data [ \"max_upstream_sequence_length\" ] = max ( i . annotations [ \"upstream_region_length\" ] for i in self . additional_data [ \"ordered_upstream_sequences\" ]) self . additional_data [ \"max_downstream_sequence_length\" ] = max ( i . annotations [ \"downstream_region_length\" ] for i in self . additional_data [ \"ordered_upstream_sequences\" ]) window_size_nt = self . additional_data [ \"max_upstream_sequence_length\" ] + self . additional_data [ \"max_downstream_sequence_length\" ] if self . parameters . arguments [ \"annotation_width\" ] == \"auto\" : annotation_width = window_size_nt * self . parameters . arguments [ \"mm_per_nt\" ] * mm else : annotation_width = self . parameters . arguments [ \"annotation_width\" ] * cm self . coordinate_system [ \"transformation_coef\" ] = annotation_width / window_size_nt self . coordinate_system [ \"x_labels_start\" ] = self . parameters . arguments [ \"margin\" ] * cm self . coordinate_system [ \"x_labels_stop\" ] = self . coordinate_system [ \"x_labels_start\" ] + max_label_width self . coordinate_system [ \"x_annotation_start\" ] = self . coordinate_system [ \"x_labels_stop\" ] + \\ self . parameters . arguments [ \"label_gap\" ] * cm self . coordinate_system [ \"x_annotation_stop\" ] = self . coordinate_system [ \"x_annotation_start\" ] + annotation_width self . coordinate_system [ \"figure_width\" ] = 2 * self . parameters . arguments [ \"margin\" ] * cm + annotation_width + \\ max_label_width + self . parameters . arguments [ \"label_gap\" ] * cm self . coordinate_system [ \"figure_height\" ] = self . parameters . arguments [ \"margin\" ] * cm return None AxisLoader Bases: Loader An AxisLoader object prepares data for an Axis track object. Attributes: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. prepared_data ( dict ) \u2013 dict with data needed for a visualisation track. Source code in uorf4u/drawing_annotation.py 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 class AxisLoader ( Loader ): \"\"\"An AxisLoader object prepares data for an Axis track object. Attributes: parameters (uorf4u.manager.Parameters): Parameters' class object. prepared_data (dict): dict with data needed for a visualisation track. \"\"\" def __init__ ( self , parameters ): \"\"\"Create an AxisLoader object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( parameters ) def prepare_data ( self , coordinate_system : dict , additional_data : dict ): \"\"\"Prepare data for an Axis visualisation track. Attributes: coordinate_system (dict): coordinate system of a figure page. additional_data (dict): data needed for a track initialisation. Returns: dict: dictionary with prepared data for visualisation. \"\"\" prepared_data = dict () prepared_data [ \"coordinate_system\" ] = coordinate_system prepared_data [ \"max_upstream_sequence_length\" ] = additional_data [ \"max_upstream_sequence_length\" ] prepared_data [ \"max_downstream_sequence_length\" ] = additional_data [ \"max_downstream_sequence_length\" ] step = int ( round ( additional_data [ \"max_upstream_sequence_length\" ] / 2 , - 2 )) tics = [ - additional_data [ \"max_upstream_sequence_length\" ], 0 , additional_data [ \"max_downstream_sequence_length\" ]] x_tic_centred = int ( round ( - additional_data [ \"max_upstream_sequence_length\" ] / 2 , - 2 )) tics . append ( x_tic_centred ) x_tic_left , x_tic_right = x_tic_centred - step , x_tic_centred + step while x_tic_right < 0 and x_tic_left > - additional_data [ \"max_upstream_sequence_length\" ]: tics . append ( x_tic_left ) tics . append ( x_tic_right ) x_tic_left -= step x_tic_right += step tics . sort () tics_coordinates = [ self . transform_relative_position_to_x_coordinate ( i , coordinate_system , additional_data [ \"max_upstream_sequence_length\" ]) for i in tics ] prepared_data [ \"tics\" ] = { k : v for k , v in zip ( tics , tics_coordinates )} self . prepared_data = prepared_data return prepared_data def transform_relative_position_to_x_coordinate ( self , relative_position : int , coordinate_system : dict , max_upstream_sequence_length : int ) -> float : \"\"\"Transform nucleotide x coordinate to pdf's. Arguments: relative_position (int): nucleotide position coordinate_system (dict): coordinate system of a figure. max_upstream_sequence_length (int): max length of upstream sequences for visualisation. Returns: float: transformed x coordinate. \"\"\" return coordinate_system [ \"x_annotation_start\" ] + ( relative_position + max_upstream_sequence_length ) * \\ coordinate_system [ \"transformation_coef\" ] def create_track ( self ) -> TicsVis : \"\"\"Initialise a Tics track object. Returns: TicsVis: visualisation track. \"\"\" return TicsVis ( self . prepared_data , self . parameters ) __init__ ( parameters ) Create an AxisLoader object. Parameters: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing_annotation.py 706 707 708 709 710 711 712 713 def __init__ ( self , parameters ): \"\"\"Create an AxisLoader object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( parameters ) create_track () Initialise a Tics track object. Returns: TicsVis ( TicsVis ) \u2013 visualisation track. Source code in uorf4u/drawing_annotation.py 762 763 764 765 766 767 768 769 def create_track ( self ) -> TicsVis : \"\"\"Initialise a Tics track object. Returns: TicsVis: visualisation track. \"\"\" return TicsVis ( self . prepared_data , self . parameters ) prepare_data ( coordinate_system , additional_data ) Prepare data for an Axis visualisation track. Attributes: coordinate_system ( dict ) \u2013 coordinate system of a figure page. additional_data ( dict ) \u2013 data needed for a track initialisation. Returns: dict \u2013 dictionary with prepared data for visualisation. Source code in uorf4u/drawing_annotation.py 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 def prepare_data ( self , coordinate_system : dict , additional_data : dict ): \"\"\"Prepare data for an Axis visualisation track. Attributes: coordinate_system (dict): coordinate system of a figure page. additional_data (dict): data needed for a track initialisation. Returns: dict: dictionary with prepared data for visualisation. \"\"\" prepared_data = dict () prepared_data [ \"coordinate_system\" ] = coordinate_system prepared_data [ \"max_upstream_sequence_length\" ] = additional_data [ \"max_upstream_sequence_length\" ] prepared_data [ \"max_downstream_sequence_length\" ] = additional_data [ \"max_downstream_sequence_length\" ] step = int ( round ( additional_data [ \"max_upstream_sequence_length\" ] / 2 , - 2 )) tics = [ - additional_data [ \"max_upstream_sequence_length\" ], 0 , additional_data [ \"max_downstream_sequence_length\" ]] x_tic_centred = int ( round ( - additional_data [ \"max_upstream_sequence_length\" ] / 2 , - 2 )) tics . append ( x_tic_centred ) x_tic_left , x_tic_right = x_tic_centred - step , x_tic_centred + step while x_tic_right < 0 and x_tic_left > - additional_data [ \"max_upstream_sequence_length\" ]: tics . append ( x_tic_left ) tics . append ( x_tic_right ) x_tic_left -= step x_tic_right += step tics . sort () tics_coordinates = [ self . transform_relative_position_to_x_coordinate ( i , coordinate_system , additional_data [ \"max_upstream_sequence_length\" ]) for i in tics ] prepared_data [ \"tics\" ] = { k : v for k , v in zip ( tics , tics_coordinates )} self . prepared_data = prepared_data return prepared_data transform_relative_position_to_x_coordinate ( relative_position , coordinate_system , max_upstream_sequence_length ) Transform nucleotide x coordinate to pdf's. Parameters: relative_position ( int ) \u2013 nucleotide position coordinate_system ( dict ) \u2013 coordinate system of a figure. max_upstream_sequence_length ( int ) \u2013 max length of upstream sequences for visualisation. Returns: float ( float ) \u2013 transformed x coordinate. Source code in uorf4u/drawing_annotation.py 747 748 749 750 751 752 753 754 755 756 757 758 759 760 def transform_relative_position_to_x_coordinate ( self , relative_position : int , coordinate_system : dict , max_upstream_sequence_length : int ) -> float : \"\"\"Transform nucleotide x coordinate to pdf's. Arguments: relative_position (int): nucleotide position coordinate_system (dict): coordinate system of a figure. max_upstream_sequence_length (int): max length of upstream sequences for visualisation. Returns: float: transformed x coordinate. \"\"\" return coordinate_system [ \"x_annotation_start\" ] + ( relative_position + max_upstream_sequence_length ) * \\ coordinate_system [ \"transformation_coef\" ] Image An Image object holds pdf. Attributes: canvas ( reportlab . pdfgen . canvas . Canvas ) \u2013 pdf object of the reportlab library. Source code in uorf4u/drawing_annotation.py 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 class Image : \"\"\"An Image object holds pdf. Attributes: canvas (reportlab.pdfgen.canvas.Canvas): pdf object of the reportlab library. \"\"\" def __init__ ( self , filename : str , width : float , height : float ): \"\"\"Create an Image object. Arguments: filename (str): path and name of a pdf. width (float): width of a pdf. height (float): height of a pdf. \"\"\" self . canvas = reportlab . pdfgen . canvas . Canvas ( filename , pagesize = ( width , height )) def save ( self ) -> None : \"\"\"Save a pdf file. Returns: None \"\"\" self . canvas . save () return None __init__ ( filename , width , height ) Create an Image object. Parameters: filename ( str ) \u2013 path and name of a pdf. width ( float ) \u2013 width of a pdf. height ( float ) \u2013 height of a pdf. Source code in uorf4u/drawing_annotation.py 780 781 782 783 784 785 786 787 788 789 def __init__ ( self , filename : str , width : float , height : float ): \"\"\"Create an Image object. Arguments: filename (str): path and name of a pdf. width (float): width of a pdf. height (float): height of a pdf. \"\"\" self . canvas = reportlab . pdfgen . canvas . Canvas ( filename , pagesize = ( width , height )) save () Save a pdf file. Returns: None \u2013 None Source code in uorf4u/drawing_annotation.py 791 792 793 794 795 796 797 798 799 def save ( self ) -> None : \"\"\"Save a pdf file. Returns: None \"\"\" self . canvas . save () return None Loader Parent class for tracks loaders. Attributes: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. prepared_data ( dict ) \u2013 dict with data needed for visualisation tracks. Source code in uorf4u/drawing_annotation.py 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 class Loader : \"\"\"Parent class for tracks loaders. Attributes: parameters (uorf4u.manager.Parameters): Parameters' class object. prepared_data (dict): dict with data needed for visualisation tracks. \"\"\" def __init__ ( self , parameters : uorf4u . manager . Parameters ): \"\"\"Parent's constructor for creating a Loader class object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . parameters = parameters self . prepared_data = None def prepare_data ( self ) -> None : \"\"\"Empty parent's method for data preparation. Returns: None \"\"\" pass def create_track ( self ) -> None : \"\"\"Empty parent's method for initialisation of a track. Returns: None \"\"\" pass __init__ ( parameters ) Parent's constructor for creating a Loader class object. Parameters: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing_annotation.py 499 500 501 502 503 504 505 506 def __init__ ( self , parameters : uorf4u . manager . Parameters ): \"\"\"Parent's constructor for creating a Loader class object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . parameters = parameters self . prepared_data = None create_track () Empty parent's method for initialisation of a track. Returns: None \u2013 None Source code in uorf4u/drawing_annotation.py 517 518 519 520 521 522 523 524 def create_track ( self ) -> None : \"\"\"Empty parent's method for initialisation of a track. Returns: None \"\"\" pass prepare_data () Empty parent's method for data preparation. Returns: None \u2013 None Source code in uorf4u/drawing_annotation.py 508 509 510 511 512 513 514 515 def prepare_data ( self ) -> None : \"\"\"Empty parent's method for data preparation. Returns: None \"\"\" pass SequenceVis Bases: Track SequenceVis track draws sequences and annotation. Attributes: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. needed_space ( float ) \u2013 needed vertical space for a track. Source code in uorf4u/drawing_annotation.py 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 class SequenceVis ( Track ): \"\"\"SequenceVis track draws sequences and annotation. Attributes: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. needed_space (float): needed vertical space for a track. \"\"\" def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Create a SequenceVis object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( visualisation_data , parameters ) self . needed_space = None def needed_y_space ( self ) -> float : \"\"\"Calculate needed vertical space for a SequenceVis track. Returns: float: needed vertical space. \"\"\" self . needed_space = self . parameters . arguments [ \"orf_height\" ] * cm return self . needed_space def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Draw a Sequence track. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" orf_height = self . parameters . arguments [ \"orf_height\" ] * cm y_c = self . visualisation_data [ \"y_top\" ] - 0.5 * orf_height x_offset = 0.5 * self . parameters . arguments [ \"upstream_seq_line_width\" ] canvas . setStrokeColorRGB ( * uorf4u . methods . get_color ( \"upstream_seq_line_color\" , self . parameters . arguments )) canvas . setLineCap ( 0 ) canvas . setLineWidth ( self . parameters . arguments [ \"upstream_seq_line_width\" ]) canvas . line ( self . visualisation_data [ \"upstream_sequence_line_start_x\" ], y_c , self . visualisation_data [ \"upstream_sequence_line_stop_x\" ] - x_offset , y_c ) # Cleaning the space: canvas . setFillColorRGB canvas . setStrokeColorRGB ( 1 , 1 , 1 , 1 ) for orf_dict in self . visualisation_data [ \"orfs_coordinates_dict\" ] . values (): canvas . setLineWidth ( self . parameters . arguments [ \"upstream_seq_line_width\" ] * 1.5 ) canvas . line ( orf_dict [ \"x_start\" ], y_c , orf_dict [ \"x_stop\" ], y_c ) #canvas.rect(orf_dict[\"x_start\"], y_c - orf_height / 2, orf_dict[\"x_stop\"] - orf_dict[\"x_start\"], orf_height, # stroke=0, fill=1) if self . parameters . arguments [ \"check_assembly_annotation\" ] and \\ \"fasta\" not in self . parameters . cmd_arguments . keys (): for protein_id , cds_dict in self . visualisation_data [ \"CDSs_coordinates_dict\" ] . items (): canvas . line ( cds_dict [ \"x_start\" ], y_c , cds_dict [ \"x_stop\" ], y_c ) canvas . setLineWidth ( self . parameters . arguments [ \"upstream_seq_line_width\" ]) # Labels canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFont ( \"regular\" , self . visualisation_data [ \"label_font_size\" ]) y_l = y_c - 0.5 * ( self . parameters . arguments [ \"label_height_to_orf_height\" ] * orf_height ) canvas . drawRightString ( self . visualisation_data [ \"coordinate_system\" ][ \"x_labels_stop\" ], y_l , self . visualisation_data [ \"useq_label\" ]) # main_CDS canvas . setLineWidth ( self . parameters . arguments [ \"orf_line_width\" ]) canvas . setStrokeColorRGB ( * uorf4u . methods . get_color ( \"cds_seq_stroke_color\" , self . parameters . arguments )) canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"cds_seq_fill_color\" , self . parameters . arguments )) p = canvas . beginPath () p . moveTo ( self . visualisation_data [ \"main_CDS_stop_x\" ], y_c - orf_height / 2 ) p . lineTo ( self . visualisation_data [ \"main_CDS_start_x\" ], y_c - orf_height / 2 ) p . lineTo ( self . visualisation_data [ \"main_CDS_start_x\" ], y_c + orf_height / 2 ) p . lineTo ( self . visualisation_data [ \"main_CDS_stop_x\" ], y_c + orf_height / 2 ) canvas . drawPath ( p , stroke = 1 , fill = 1 ) # Other ORFs: for orf in self . visualisation_data [ \"annotated_orfs\" ]: orf_dict = self . visualisation_data [ \"orfs_coordinates_dict\" ][ orf ] if orf != self . visualisation_data [ \"conserved_orf\" ]: fill_color = None stroke_color = uorf4u . methods . get_color ( \"other_uorfs_stroke_color\" , self . parameters . arguments ) else : fill_color = uorf4u . methods . get_color ( \"conserved_uorfs_fill_color\" , self . parameters . arguments ) stroke_color = uorf4u . methods . get_color ( \"conserved_uorfs_stroke_color\" , self . parameters . arguments ) self . orf_object ( canvas , orf_dict [ \"x_start\" ], orf_dict [ \"x_stop\" ], y_c , orf_dict [ \"strand\" ], orf_height , orf_dict [ \"left_out\" ], orf_dict [ \"right_out\" ], fill_color , stroke_color ) # Annotated in RefSeq CDSs if self . parameters . arguments [ \"check_assembly_annotation\" ] and \\ \"fasta\" not in self . parameters . cmd_arguments . keys (): fill_color = None stroke_color = uorf4u . methods . get_color ( \"annotated_orf_stroke_color\" , self . parameters . arguments ) for protein_id , cds_dict in self . visualisation_data [ \"CDSs_coordinates_dict\" ] . items (): self . orf_object ( canvas , cds_dict [ \"x_start\" ], cds_dict [ \"x_stop\" ], y_c , cds_dict [ \"strand\" ], orf_height , cds_dict [ \"left_out\" ], cds_dict [ \"right_out\" ], fill_color , stroke_color ) return None def orf_object ( self , canvas : reportlab . pdfgen . canvas . Canvas , x_start : float , x_stop : float , y_c : float , strand : str , height : float , left_out : bool , right_out : bool , fill_color : str , stroke_color : str ) -> None : \"\"\"Method for drawing an ORF's polygon. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. x_start (float): ORF's start coordinate (already transformed to pdf's) x_stop (float): ORF's stop coordinate (already transformed to pdf's) y_c: (float): centred y coordinate of a current track. strand (str): strand of an ORF. height (float): height of a polygon. left_out (bool): whether an ORF is out of range on the left. right_out (bool): whether an ORF is out of range on the right. fill_color (str): fill color of a polygon. stroke_color (str): stroke color of a polygon. Returns: None \"\"\" fill , stroke = 0 , 0 if stroke_color : canvas . setStrokeColorRGB ( * stroke_color ) stroke = 1 if fill_color : canvas . setFillColorRGB ( * fill_color ) fill = 1 arrow_length = min ( height , ( x_stop - x_start )) p = canvas . beginPath () if strand == \"+\" and not left_out and not right_out : p . moveTo ( x_start , y_c ) p . lineTo ( x_start , y_c + height / 2 ) p . lineTo ( x_stop - arrow_length , y_c + height / 2 ) p . lineTo ( x_stop , y_c ) p . lineTo ( x_stop - arrow_length , y_c - height / 2 ) p . lineTo ( x_start , y_c - height / 2 ) p . lineTo ( x_start , y_c ) elif strand == \"+\" and left_out and not right_out : p . moveTo ( x_start , y_c + height / 2 ) p . lineTo ( x_stop - arrow_length , y_c + height / 2 ) p . lineTo ( x_stop , y_c ) p . lineTo ( x_stop - arrow_length , y_c - height / 2 ) p . lineTo ( x_start , y_c - height / 2 ) elif strand == \"+\" and right_out and not left_out : p . moveTo ( x_stop , y_c + height / 2 ) p . lineTo ( x_start , y_c + height / 2 ) p . lineTo ( x_start , y_c - height / 2 ) p . lineTo ( x_stop , y_c - height / 2 ) elif strand == \"-\" and not left_out and not right_out : p . moveTo ( x_stop , y_c ) p . lineTo ( x_stop , y_c + height / 2 ) p . lineTo ( x_start + arrow_length , y_c + height / 2 ) p . lineTo ( x_start , y_c ) p . lineTo ( x_start + arrow_length , y_c - height / 2 ) p . lineTo ( x_stop , y_c - height / 2 ) p . lineTo ( x_stop , y_c ) elif strand == \"-\" and right_out and not left_out : p . moveTo ( x_stop , y_c + height / 2 ) p . lineTo ( x_start + arrow_length , y_c + height / 2 ) p . lineTo ( x_start , y_c ) p . lineTo ( x_start + arrow_length , y_c - height / 2 ) p . lineTo ( x_stop , y_c - height / 2 ) elif strand == \"-\" and left_out and not right_out : p . moveTo ( x_start , y_c + height / 2 ) p . lineTo ( x_stop , y_c + height / 2 ) p . lineTo ( x_stop , y_c - height / 2 ) p . lineTo ( x_start , y_c - height / 2 ) canvas . drawPath ( p , stroke = stroke , fill = fill ) __init__ ( visualisation_data , parameters ) Create a SequenceVis object. Parameters: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing_annotation.py 247 248 249 250 251 252 253 254 255 256 def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Create a SequenceVis object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( visualisation_data , parameters ) self . needed_space = None draw ( canvas ) Draw a Sequence track. Parameters: canvas ( reportlab . pdfgen . canvas . Canvas ) \u2013 a pdf object. Returns: None \u2013 None Source code in uorf4u/drawing_annotation.py 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Draw a Sequence track. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" orf_height = self . parameters . arguments [ \"orf_height\" ] * cm y_c = self . visualisation_data [ \"y_top\" ] - 0.5 * orf_height x_offset = 0.5 * self . parameters . arguments [ \"upstream_seq_line_width\" ] canvas . setStrokeColorRGB ( * uorf4u . methods . get_color ( \"upstream_seq_line_color\" , self . parameters . arguments )) canvas . setLineCap ( 0 ) canvas . setLineWidth ( self . parameters . arguments [ \"upstream_seq_line_width\" ]) canvas . line ( self . visualisation_data [ \"upstream_sequence_line_start_x\" ], y_c , self . visualisation_data [ \"upstream_sequence_line_stop_x\" ] - x_offset , y_c ) # Cleaning the space: canvas . setFillColorRGB canvas . setStrokeColorRGB ( 1 , 1 , 1 , 1 ) for orf_dict in self . visualisation_data [ \"orfs_coordinates_dict\" ] . values (): canvas . setLineWidth ( self . parameters . arguments [ \"upstream_seq_line_width\" ] * 1.5 ) canvas . line ( orf_dict [ \"x_start\" ], y_c , orf_dict [ \"x_stop\" ], y_c ) #canvas.rect(orf_dict[\"x_start\"], y_c - orf_height / 2, orf_dict[\"x_stop\"] - orf_dict[\"x_start\"], orf_height, # stroke=0, fill=1) if self . parameters . arguments [ \"check_assembly_annotation\" ] and \\ \"fasta\" not in self . parameters . cmd_arguments . keys (): for protein_id , cds_dict in self . visualisation_data [ \"CDSs_coordinates_dict\" ] . items (): canvas . line ( cds_dict [ \"x_start\" ], y_c , cds_dict [ \"x_stop\" ], y_c ) canvas . setLineWidth ( self . parameters . arguments [ \"upstream_seq_line_width\" ]) # Labels canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFont ( \"regular\" , self . visualisation_data [ \"label_font_size\" ]) y_l = y_c - 0.5 * ( self . parameters . arguments [ \"label_height_to_orf_height\" ] * orf_height ) canvas . drawRightString ( self . visualisation_data [ \"coordinate_system\" ][ \"x_labels_stop\" ], y_l , self . visualisation_data [ \"useq_label\" ]) # main_CDS canvas . setLineWidth ( self . parameters . arguments [ \"orf_line_width\" ]) canvas . setStrokeColorRGB ( * uorf4u . methods . get_color ( \"cds_seq_stroke_color\" , self . parameters . arguments )) canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"cds_seq_fill_color\" , self . parameters . arguments )) p = canvas . beginPath () p . moveTo ( self . visualisation_data [ \"main_CDS_stop_x\" ], y_c - orf_height / 2 ) p . lineTo ( self . visualisation_data [ \"main_CDS_start_x\" ], y_c - orf_height / 2 ) p . lineTo ( self . visualisation_data [ \"main_CDS_start_x\" ], y_c + orf_height / 2 ) p . lineTo ( self . visualisation_data [ \"main_CDS_stop_x\" ], y_c + orf_height / 2 ) canvas . drawPath ( p , stroke = 1 , fill = 1 ) # Other ORFs: for orf in self . visualisation_data [ \"annotated_orfs\" ]: orf_dict = self . visualisation_data [ \"orfs_coordinates_dict\" ][ orf ] if orf != self . visualisation_data [ \"conserved_orf\" ]: fill_color = None stroke_color = uorf4u . methods . get_color ( \"other_uorfs_stroke_color\" , self . parameters . arguments ) else : fill_color = uorf4u . methods . get_color ( \"conserved_uorfs_fill_color\" , self . parameters . arguments ) stroke_color = uorf4u . methods . get_color ( \"conserved_uorfs_stroke_color\" , self . parameters . arguments ) self . orf_object ( canvas , orf_dict [ \"x_start\" ], orf_dict [ \"x_stop\" ], y_c , orf_dict [ \"strand\" ], orf_height , orf_dict [ \"left_out\" ], orf_dict [ \"right_out\" ], fill_color , stroke_color ) # Annotated in RefSeq CDSs if self . parameters . arguments [ \"check_assembly_annotation\" ] and \\ \"fasta\" not in self . parameters . cmd_arguments . keys (): fill_color = None stroke_color = uorf4u . methods . get_color ( \"annotated_orf_stroke_color\" , self . parameters . arguments ) for protein_id , cds_dict in self . visualisation_data [ \"CDSs_coordinates_dict\" ] . items (): self . orf_object ( canvas , cds_dict [ \"x_start\" ], cds_dict [ \"x_stop\" ], y_c , cds_dict [ \"strand\" ], orf_height , cds_dict [ \"left_out\" ], cds_dict [ \"right_out\" ], fill_color , stroke_color ) return None needed_y_space () Calculate needed vertical space for a SequenceVis track. Returns: float ( float ) \u2013 needed vertical space. Source code in uorf4u/drawing_annotation.py 258 259 260 261 262 263 264 265 266 def needed_y_space ( self ) -> float : \"\"\"Calculate needed vertical space for a SequenceVis track. Returns: float: needed vertical space. \"\"\" self . needed_space = self . parameters . arguments [ \"orf_height\" ] * cm return self . needed_space orf_object ( canvas , x_start , x_stop , y_c , strand , height , left_out , right_out , fill_color , stroke_color ) Method for drawing an ORF's polygon. Parameters: canvas ( reportlab . pdfgen . canvas . Canvas ) \u2013 a pdf object. x_start ( float ) \u2013 ORF's start coordinate (already transformed to pdf's) x_stop ( float ) \u2013 ORF's stop coordinate (already transformed to pdf's) y_c ( float ) \u2013 (float): centred y coordinate of a current track. strand ( str ) \u2013 strand of an ORF. height ( float ) \u2013 height of a polygon. left_out ( bool ) \u2013 whether an ORF is out of range on the left. right_out ( bool ) \u2013 whether an ORF is out of range on the right. fill_color ( str ) \u2013 fill color of a polygon. stroke_color ( str ) \u2013 stroke color of a polygon. Returns: None \u2013 None Source code in uorf4u/drawing_annotation.py 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 def orf_object ( self , canvas : reportlab . pdfgen . canvas . Canvas , x_start : float , x_stop : float , y_c : float , strand : str , height : float , left_out : bool , right_out : bool , fill_color : str , stroke_color : str ) -> None : \"\"\"Method for drawing an ORF's polygon. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. x_start (float): ORF's start coordinate (already transformed to pdf's) x_stop (float): ORF's stop coordinate (already transformed to pdf's) y_c: (float): centred y coordinate of a current track. strand (str): strand of an ORF. height (float): height of a polygon. left_out (bool): whether an ORF is out of range on the left. right_out (bool): whether an ORF is out of range on the right. fill_color (str): fill color of a polygon. stroke_color (str): stroke color of a polygon. Returns: None \"\"\" fill , stroke = 0 , 0 if stroke_color : canvas . setStrokeColorRGB ( * stroke_color ) stroke = 1 if fill_color : canvas . setFillColorRGB ( * fill_color ) fill = 1 arrow_length = min ( height , ( x_stop - x_start )) p = canvas . beginPath () if strand == \"+\" and not left_out and not right_out : p . moveTo ( x_start , y_c ) p . lineTo ( x_start , y_c + height / 2 ) p . lineTo ( x_stop - arrow_length , y_c + height / 2 ) p . lineTo ( x_stop , y_c ) p . lineTo ( x_stop - arrow_length , y_c - height / 2 ) p . lineTo ( x_start , y_c - height / 2 ) p . lineTo ( x_start , y_c ) elif strand == \"+\" and left_out and not right_out : p . moveTo ( x_start , y_c + height / 2 ) p . lineTo ( x_stop - arrow_length , y_c + height / 2 ) p . lineTo ( x_stop , y_c ) p . lineTo ( x_stop - arrow_length , y_c - height / 2 ) p . lineTo ( x_start , y_c - height / 2 ) elif strand == \"+\" and right_out and not left_out : p . moveTo ( x_stop , y_c + height / 2 ) p . lineTo ( x_start , y_c + height / 2 ) p . lineTo ( x_start , y_c - height / 2 ) p . lineTo ( x_stop , y_c - height / 2 ) elif strand == \"-\" and not left_out and not right_out : p . moveTo ( x_stop , y_c ) p . lineTo ( x_stop , y_c + height / 2 ) p . lineTo ( x_start + arrow_length , y_c + height / 2 ) p . lineTo ( x_start , y_c ) p . lineTo ( x_start + arrow_length , y_c - height / 2 ) p . lineTo ( x_stop , y_c - height / 2 ) p . lineTo ( x_stop , y_c ) elif strand == \"-\" and right_out and not left_out : p . moveTo ( x_stop , y_c + height / 2 ) p . lineTo ( x_start + arrow_length , y_c + height / 2 ) p . lineTo ( x_start , y_c ) p . lineTo ( x_start + arrow_length , y_c - height / 2 ) p . lineTo ( x_stop , y_c - height / 2 ) elif strand == \"-\" and left_out and not right_out : p . moveTo ( x_start , y_c + height / 2 ) p . lineTo ( x_stop , y_c + height / 2 ) p . lineTo ( x_stop , y_c - height / 2 ) p . lineTo ( x_start , y_c - height / 2 ) canvas . drawPath ( p , stroke = stroke , fill = fill ) SequencesLoader Bases: Loader A SequencesLoader object prepares data for a Sequence track object. Attributes: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. prepared_data ( dict ) \u2013 dict with data needed for a visualisation track. Source code in uorf4u/drawing_annotation.py 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 class SequencesLoader ( Loader ): \"\"\"A SequencesLoader object prepares data for a Sequence track object. Attributes: parameters (uorf4u.manager.Parameters): Parameters' class object. prepared_data (dict): dict with data needed for a visualisation track. \"\"\" def __init__ ( self , parameters ): \"\"\"Create a SequenceLoader object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( parameters ) def prepare_data ( self , upstream_sequence : Bio . SeqRecord . SeqRecord , conserved_orf , coordinate_system : dict , additional_data : dict ) -> dict : \"\"\"Prepare data for a Title visualisation track. Attributes: upstream_sequence (dict): upstream sequence' data. conserved_orf (uorf4u.data_processing.ORF): conserved ORF on the upstream sequence. coordinate_system (dict): coordinate system of a figure page. additional_data (dict): data needed for a track initialisation. Returns: dict: dictionary with prepared data for visualisation. \"\"\" prepared_data = dict () max_upstream_sequence_length = additional_data [ \"max_upstream_sequence_length\" ] prepared_data [ \"coordinate_system\" ] = coordinate_system prepared_data [ \"label_font_size\" ] = additional_data [ \"label_font_size\" ] prepared_data [ \"label_right_border\" ] = coordinate_system [ \"x_labels_stop\" ] prepared_data [ \"upstream_sequence_line_start_x\" ] = coordinate_system [ \"x_annotation_start\" ] + \\ (( max_upstream_sequence_length - upstream_sequence . annotations [ \"upstream_region_length\" ]) * \\ coordinate_system [ \"transformation_coef\" ]) prepared_data [ \"upstream_sequence_line_stop_x\" ] = coordinate_system [ \"x_annotation_start\" ] + \\ ( max_upstream_sequence_length * coordinate_system [ \"transformation_coef\" ]) prepared_data [ \"main_CDS_start_x\" ] = coordinate_system [ \"x_annotation_start\" ] + \\ ( max_upstream_sequence_length * coordinate_system [ \"transformation_coef\" ]) prepared_data [ \"main_CDS_stop_x\" ] = coordinate_system [ \"x_annotation_start\" ] + \\ (( max_upstream_sequence_length + upstream_sequence . annotations [ \"downstream_region_length\" ]) * coordinate_system [ \"transformation_coef\" ]) prepared_data [ \"orfs_coordinates_dict\" ] = { k : v for k , v in zip ( upstream_sequence . annotations [ \"ORFs\" ], [ self . calculate_orf_position ( i . start , i . stop , \"+\" , upstream_sequence , max_upstream_sequence_length , coordinate_system ) for i in upstream_sequence . annotations [ \"ORFs\" ]])} prepared_data [ \"useq_label\" ] = upstream_sequence . annotations [ \"label\" ] prepared_data [ \"annotated_orfs\" ] = [ orf for orf in upstream_sequence . annotations [ \"ORFs\" ] if orf != conserved_orf ] prepared_data [ \"annotated_orfs\" ] . append ( conserved_orf ) prepared_data [ \"conserved_orf\" ] = conserved_orf if self . parameters . arguments [ \"check_assembly_annotation\" ] and upstream_sequence . annotations [ \"RefSeq\" ]: prepared_data [ \"CDSs\" ] = [ i for i in upstream_sequence . annotations [ \"locus_annotation\" ] . CDSs if i [ \"relative_start\" ] != upstream_sequence . annotations [ \"upstream_region_length\" ]] prepared_data [ \"CDSs_coordinates_dict\" ] = { k : v for k , v in zip ([ i [ \"protein_id\" ] for i in prepared_data [ \"CDSs\" ]], [ self . calculate_orf_position ( i [ \"relative_start\" ], i [ \"relative_stop\" ], i [ \"relative_strand\" ], upstream_sequence , max_upstream_sequence_length , coordinate_system ) for i in prepared_data [ \"CDSs\" ]])} else : prepared_data [ \"CDSs\" ] = None self . prepared_data = prepared_data return prepared_data def calculate_orf_position ( self , start : int , stop : int , strand : str , useq : Bio . SeqRecord . SeqRecord , max_upstream_sequence_length : int , coordinate_system : dict ) -> dict : \"\"\"Transform an ORF's nucleotide coordinates to pdf's coordinates. Arguments: start (int): start coordinate in nt. stop (int): stop coordinate in nt. strand (str): strand of an ORF. useq (dict): current upstream sequence. max_upstream_sequence_length (int): max length of upstream sequences for visualisation. coordinate_system (dict): coordinate system of a figure. Returns: dict: transformed orf's coordinates. \"\"\" orf_coordinates = dict () orf_coordinates [ \"x_start\" ] = coordinate_system [ \"x_annotation_start\" ] + ( max ( 0 , start ) + ( max_upstream_sequence_length - useq . annotations [ \"upstream_region_length\" ])) * \\ coordinate_system [ \"transformation_coef\" ] orf_coordinates [ \"x_stop\" ] = coordinate_system [ \"x_annotation_start\" ] + ( min ( stop , useq . annotations [ \"length\" ]) + ( max_upstream_sequence_length - useq . annotations [ \"upstream_region_length\" ])) * \\ coordinate_system [ \"transformation_coef\" ] orf_coordinates [ \"strand\" ] = strand orf_coordinates [ \"left_out\" ] = start < 0 orf_coordinates [ \"right_out\" ] = stop > useq . annotations [ \"length\" ] return orf_coordinates def create_track ( self ) -> SequenceVis : \"\"\"Initialise a Sequence track object. Returns: SequenceVis: visualisation track. \"\"\" return SequenceVis ( self . prepared_data , self . parameters ) __init__ ( parameters ) Create a SequenceLoader object. Parameters: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing_annotation.py 585 586 587 588 589 590 591 592 def __init__ ( self , parameters ): \"\"\"Create a SequenceLoader object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( parameters ) calculate_orf_position ( start , stop , strand , useq , max_upstream_sequence_length , coordinate_system ) Transform an ORF's nucleotide coordinates to pdf's coordinates. Parameters: start ( int ) \u2013 start coordinate in nt. stop ( int ) \u2013 stop coordinate in nt. strand ( str ) \u2013 strand of an ORF. useq ( dict ) \u2013 current upstream sequence. max_upstream_sequence_length ( int ) \u2013 max length of upstream sequences for visualisation. coordinate_system ( dict ) \u2013 coordinate system of a figure. Returns: dict ( dict ) \u2013 transformed orf's coordinates. Source code in uorf4u/drawing_annotation.py 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 def calculate_orf_position ( self , start : int , stop : int , strand : str , useq : Bio . SeqRecord . SeqRecord , max_upstream_sequence_length : int , coordinate_system : dict ) -> dict : \"\"\"Transform an ORF's nucleotide coordinates to pdf's coordinates. Arguments: start (int): start coordinate in nt. stop (int): stop coordinate in nt. strand (str): strand of an ORF. useq (dict): current upstream sequence. max_upstream_sequence_length (int): max length of upstream sequences for visualisation. coordinate_system (dict): coordinate system of a figure. Returns: dict: transformed orf's coordinates. \"\"\" orf_coordinates = dict () orf_coordinates [ \"x_start\" ] = coordinate_system [ \"x_annotation_start\" ] + ( max ( 0 , start ) + ( max_upstream_sequence_length - useq . annotations [ \"upstream_region_length\" ])) * \\ coordinate_system [ \"transformation_coef\" ] orf_coordinates [ \"x_stop\" ] = coordinate_system [ \"x_annotation_start\" ] + ( min ( stop , useq . annotations [ \"length\" ]) + ( max_upstream_sequence_length - useq . annotations [ \"upstream_region_length\" ])) * \\ coordinate_system [ \"transformation_coef\" ] orf_coordinates [ \"strand\" ] = strand orf_coordinates [ \"left_out\" ] = start < 0 orf_coordinates [ \"right_out\" ] = stop > useq . annotations [ \"length\" ] return orf_coordinates create_track () Initialise a Sequence track object. Returns: SequenceVis ( SequenceVis ) \u2013 visualisation track. Source code in uorf4u/drawing_annotation.py 686 687 688 689 690 691 692 693 def create_track ( self ) -> SequenceVis : \"\"\"Initialise a Sequence track object. Returns: SequenceVis: visualisation track. \"\"\" return SequenceVis ( self . prepared_data , self . parameters ) prepare_data ( upstream_sequence , conserved_orf , coordinate_system , additional_data ) Prepare data for a Title visualisation track. Attributes: upstream_sequence ( dict ) \u2013 upstream sequence' data. conserved_orf ( uorf4u . data_processing . ORF ) \u2013 conserved ORF on the upstream sequence. coordinate_system ( dict ) \u2013 coordinate system of a figure page. additional_data ( dict ) \u2013 data needed for a track initialisation. Returns: dict ( dict ) \u2013 dictionary with prepared data for visualisation. Source code in uorf4u/drawing_annotation.py 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 def prepare_data ( self , upstream_sequence : Bio . SeqRecord . SeqRecord , conserved_orf , coordinate_system : dict , additional_data : dict ) -> dict : \"\"\"Prepare data for a Title visualisation track. Attributes: upstream_sequence (dict): upstream sequence' data. conserved_orf (uorf4u.data_processing.ORF): conserved ORF on the upstream sequence. coordinate_system (dict): coordinate system of a figure page. additional_data (dict): data needed for a track initialisation. Returns: dict: dictionary with prepared data for visualisation. \"\"\" prepared_data = dict () max_upstream_sequence_length = additional_data [ \"max_upstream_sequence_length\" ] prepared_data [ \"coordinate_system\" ] = coordinate_system prepared_data [ \"label_font_size\" ] = additional_data [ \"label_font_size\" ] prepared_data [ \"label_right_border\" ] = coordinate_system [ \"x_labels_stop\" ] prepared_data [ \"upstream_sequence_line_start_x\" ] = coordinate_system [ \"x_annotation_start\" ] + \\ (( max_upstream_sequence_length - upstream_sequence . annotations [ \"upstream_region_length\" ]) * \\ coordinate_system [ \"transformation_coef\" ]) prepared_data [ \"upstream_sequence_line_stop_x\" ] = coordinate_system [ \"x_annotation_start\" ] + \\ ( max_upstream_sequence_length * coordinate_system [ \"transformation_coef\" ]) prepared_data [ \"main_CDS_start_x\" ] = coordinate_system [ \"x_annotation_start\" ] + \\ ( max_upstream_sequence_length * coordinate_system [ \"transformation_coef\" ]) prepared_data [ \"main_CDS_stop_x\" ] = coordinate_system [ \"x_annotation_start\" ] + \\ (( max_upstream_sequence_length + upstream_sequence . annotations [ \"downstream_region_length\" ]) * coordinate_system [ \"transformation_coef\" ]) prepared_data [ \"orfs_coordinates_dict\" ] = { k : v for k , v in zip ( upstream_sequence . annotations [ \"ORFs\" ], [ self . calculate_orf_position ( i . start , i . stop , \"+\" , upstream_sequence , max_upstream_sequence_length , coordinate_system ) for i in upstream_sequence . annotations [ \"ORFs\" ]])} prepared_data [ \"useq_label\" ] = upstream_sequence . annotations [ \"label\" ] prepared_data [ \"annotated_orfs\" ] = [ orf for orf in upstream_sequence . annotations [ \"ORFs\" ] if orf != conserved_orf ] prepared_data [ \"annotated_orfs\" ] . append ( conserved_orf ) prepared_data [ \"conserved_orf\" ] = conserved_orf if self . parameters . arguments [ \"check_assembly_annotation\" ] and upstream_sequence . annotations [ \"RefSeq\" ]: prepared_data [ \"CDSs\" ] = [ i for i in upstream_sequence . annotations [ \"locus_annotation\" ] . CDSs if i [ \"relative_start\" ] != upstream_sequence . annotations [ \"upstream_region_length\" ]] prepared_data [ \"CDSs_coordinates_dict\" ] = { k : v for k , v in zip ([ i [ \"protein_id\" ] for i in prepared_data [ \"CDSs\" ]], [ self . calculate_orf_position ( i [ \"relative_start\" ], i [ \"relative_stop\" ], i [ \"relative_strand\" ], upstream_sequence , max_upstream_sequence_length , coordinate_system ) for i in prepared_data [ \"CDSs\" ]])} else : prepared_data [ \"CDSs\" ] = None self . prepared_data = prepared_data return prepared_data TicsVis Bases: Track TicsVis track draws axis tics. Attributes: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. needed_space ( float ) \u2013 needed vertical space for a track. Source code in uorf4u/drawing_annotation.py 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 class TicsVis ( Track ): \"\"\"TicsVis track draws axis tics. Attributes: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. needed_space (float): needed vertical space for a track. \"\"\" def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Create a TicsVis object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( visualisation_data , parameters ) self . needed_space = None def needed_y_space ( self ) -> float : \"\"\"Calculate needed vertical space for a SequenceVis track. Returns: float: needed vertical space. \"\"\" font_type = \"regular\" reportlab . pdfbase . pdfmetrics . registerFont ( reportlab . pdfbase . ttfonts . TTFont ( font_type , self . parameters . arguments [ f \"font_ { font_type } \" ])) face = reportlab . pdfbase . pdfmetrics . getFont ( \"regular\" ) . face if self . parameters . arguments [ \"axis_tics_font_size\" ] == \"auto\" : text_height = self . parameters . arguments [ \"label_height_to_orf_height\" ] * self . parameters . arguments [ \"orf_height\" ] * cm font_size = uorf4u . methods . string_height_to_font_size ( text_height , \"regular\" , self . parameters . arguments ) self . parameters . arguments [ \"axis_tics_font_size\" ] = font_size else : text_height = ( self . parameters . arguments [ \"axis_tics_font_size\" ] * ( face . ascent - face . descent )) / ( 1000 * 1.38 ) self . visualisation_data [ \"tics_height\" ] = 0.7 * text_height self . visualisation_data [ \"text_space\" ] = 1.2 * text_height self . needed_space = self . visualisation_data [ \"tics_height\" ] + self . visualisation_data [ \"text_space\" ] return self . needed_space def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Draw an AxisTics track. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" y_top = self . visualisation_data [ \"y_top\" ] canvas . setLineCap ( 2 ) canvas . setLineWidth ( self . parameters . arguments [ \"axis_tics_line_width\" ]) canvas . setStrokeColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFont ( \"regular\" , self . parameters . arguments [ \"axis_tics_font_size\" ]) canvas . line ( self . visualisation_data [ \"coordinate_system\" ][ \"x_annotation_start\" ], y_top , self . visualisation_data [ \"coordinate_system\" ][ \"x_annotation_stop\" ], y_top ) for tic_label , tic_position in self . visualisation_data [ \"tics\" ] . items (): canvas . line ( tic_position , y_top , tic_position , y_top - self . visualisation_data [ \"tics_height\" ]) if tic_label == - self . visualisation_data [ \"max_upstream_sequence_length\" ]: canvas . drawString ( tic_position , y_top - ( self . visualisation_data [ \"tics_height\" ] + self . visualisation_data [ \"text_space\" ]), str ( tic_label )) elif tic_label == self . visualisation_data [ \"max_downstream_sequence_length\" ]: canvas . drawRightString ( tic_position , y_top - ( self . visualisation_data [ \"tics_height\" ] + self . visualisation_data [ \"text_space\" ]), str ( tic_label )) else : canvas . drawCentredString ( tic_position , y_top - ( self . visualisation_data [ \"tics_height\" ] + self . visualisation_data [ \"text_space\" ]), str ( tic_label )) __init__ ( visualisation_data , parameters ) Create a TicsVis object. Parameters: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing_annotation.py 421 422 423 424 425 426 427 428 429 430 def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Create a TicsVis object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( visualisation_data , parameters ) self . needed_space = None draw ( canvas ) Draw an AxisTics track. Parameters: canvas ( reportlab . pdfgen . canvas . Canvas ) \u2013 a pdf object. Returns: None \u2013 None Source code in uorf4u/drawing_annotation.py 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Draw an AxisTics track. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" y_top = self . visualisation_data [ \"y_top\" ] canvas . setLineCap ( 2 ) canvas . setLineWidth ( self . parameters . arguments [ \"axis_tics_line_width\" ]) canvas . setStrokeColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFont ( \"regular\" , self . parameters . arguments [ \"axis_tics_font_size\" ]) canvas . line ( self . visualisation_data [ \"coordinate_system\" ][ \"x_annotation_start\" ], y_top , self . visualisation_data [ \"coordinate_system\" ][ \"x_annotation_stop\" ], y_top ) for tic_label , tic_position in self . visualisation_data [ \"tics\" ] . items (): canvas . line ( tic_position , y_top , tic_position , y_top - self . visualisation_data [ \"tics_height\" ]) if tic_label == - self . visualisation_data [ \"max_upstream_sequence_length\" ]: canvas . drawString ( tic_position , y_top - ( self . visualisation_data [ \"tics_height\" ] + self . visualisation_data [ \"text_space\" ]), str ( tic_label )) elif tic_label == self . visualisation_data [ \"max_downstream_sequence_length\" ]: canvas . drawRightString ( tic_position , y_top - ( self . visualisation_data [ \"tics_height\" ] + self . visualisation_data [ \"text_space\" ]), str ( tic_label )) else : canvas . drawCentredString ( tic_position , y_top - ( self . visualisation_data [ \"tics_height\" ] + self . visualisation_data [ \"text_space\" ]), str ( tic_label )) needed_y_space () Calculate needed vertical space for a SequenceVis track. Returns: float ( float ) \u2013 needed vertical space. Source code in uorf4u/drawing_annotation.py 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 def needed_y_space ( self ) -> float : \"\"\"Calculate needed vertical space for a SequenceVis track. Returns: float: needed vertical space. \"\"\" font_type = \"regular\" reportlab . pdfbase . pdfmetrics . registerFont ( reportlab . pdfbase . ttfonts . TTFont ( font_type , self . parameters . arguments [ f \"font_ { font_type } \" ])) face = reportlab . pdfbase . pdfmetrics . getFont ( \"regular\" ) . face if self . parameters . arguments [ \"axis_tics_font_size\" ] == \"auto\" : text_height = self . parameters . arguments [ \"label_height_to_orf_height\" ] * self . parameters . arguments [ \"orf_height\" ] * cm font_size = uorf4u . methods . string_height_to_font_size ( text_height , \"regular\" , self . parameters . arguments ) self . parameters . arguments [ \"axis_tics_font_size\" ] = font_size else : text_height = ( self . parameters . arguments [ \"axis_tics_font_size\" ] * ( face . ascent - face . descent )) / ( 1000 * 1.38 ) self . visualisation_data [ \"tics_height\" ] = 0.7 * text_height self . visualisation_data [ \"text_space\" ] = 1.2 * text_height self . needed_space = self . visualisation_data [ \"tics_height\" ] + self . visualisation_data [ \"text_space\" ] return self . needed_space TitleLoader Bases: Loader A TitleLoader object prepares data for a Title track object. Note: Title track currently is not available. Attributes: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. prepared_data ( dict ) \u2013 dict with data needed for a visualisation track. Source code in uorf4u/drawing_annotation.py 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 class TitleLoader ( Loader ): \"\"\"A TitleLoader object prepares data for a Title track object. Note: Title track currently is not available. Attributes: parameters (uorf4u.manager.Parameters): Parameters' class object. prepared_data (dict): dict with data needed for a visualisation track. \"\"\" def __init__ ( self , parameters ): \"\"\"Create a TitleLoader object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( parameters ) def prepare_data ( self , coordinate_system : dict , additional_data : dict ) -> dict : \"\"\"Prepare data for Title visualisation track. Attributes: coordinate_system (dict): coordinate system of a figure page. additional_data (dict): data needed for a track initialisation. Returns: dict: dictionary with prepared data for visualisation. \"\"\" prepared_data = dict () prepared_data [ \"title\" ] = \"Title Testing\" prepared_data [ \"coordinate_system\" ] = coordinate_system self . prepared_data = prepared_data return prepared_data def create_track ( self ) -> TitleVis : \"\"\"Initialise a Title track object. Returns: TitleVis: visualisation track. \"\"\" return TitleVis ( self . prepared_data , self . parameters ) __init__ ( parameters ) Create a TitleLoader object. Parameters: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing_annotation.py 539 540 541 542 543 544 545 546 def __init__ ( self , parameters ): \"\"\"Create a TitleLoader object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( parameters ) create_track () Initialise a Title track object. Returns: TitleVis ( TitleVis ) \u2013 visualisation track. Source code in uorf4u/drawing_annotation.py 565 566 567 568 569 570 571 572 def create_track ( self ) -> TitleVis : \"\"\"Initialise a Title track object. Returns: TitleVis: visualisation track. \"\"\" return TitleVis ( self . prepared_data , self . parameters ) prepare_data ( coordinate_system , additional_data ) Prepare data for Title visualisation track. Attributes: coordinate_system ( dict ) \u2013 coordinate system of a figure page. additional_data ( dict ) \u2013 data needed for a track initialisation. Returns: dict ( dict ) \u2013 dictionary with prepared data for visualisation. Source code in uorf4u/drawing_annotation.py 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 def prepare_data ( self , coordinate_system : dict , additional_data : dict ) -> dict : \"\"\"Prepare data for Title visualisation track. Attributes: coordinate_system (dict): coordinate system of a figure page. additional_data (dict): data needed for a track initialisation. Returns: dict: dictionary with prepared data for visualisation. \"\"\" prepared_data = dict () prepared_data [ \"title\" ] = \"Title Testing\" prepared_data [ \"coordinate_system\" ] = coordinate_system self . prepared_data = prepared_data return prepared_data TitleVis Bases: Track Title visualisation track object draws figure's title. Note: This track currently is not supported. Attributes: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing_annotation.py 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 class TitleVis ( Track ): \"\"\"Title visualisation track object draws figure's title. Note: This track currently is not supported. Attributes: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Create TitleVis object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . visualisation_data = visualisation_data self . parameters = parameters def needed_y_space ( self ) -> float : \"\"\"Calculate needed vertical space for a Title track. Returns: float: needed vertical space. \"\"\" font_type = self . parameters . arguments [ \"title_font_type\" ] reportlab . pdfbase . pdfmetrics . registerFont ( reportlab . pdfbase . ttfonts . TTFont ( font_type , self . parameters . arguments [ f \"font_ { font_type } \" ])) face = reportlab . pdfbase . pdfmetrics . getFont ( font_type ) . face if self . parameters . arguments [ \"title_font_size\" ] == \"auto\" : text_height = self . parameters . arguments [ \"orf_height\" ] * cm font_size = uorf4u . methods . string_height_to_font_size ( text_height , font_type , self . parameters . arguments ) self . parameters . arguments [ \"title_font_size\" ] = font_size else : text_height = ( self . parameters . arguments [ \"title_font_size\" ] * ( face . ascent - face . descent )) / ( 1000 * 1.38 ) self . visualisation_data [ \"text_height\" ] = text_height self . needed_space = text_height * 1.2 return self . needed_space def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Draw a Title track. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" x_left_border = self . visualisation_data [ \"coordinate_system\" ][ \"x_labels_start\" ] # x_left_border = self.visualisation_data[\"coordinate_system\"][\"x_annotation_start\"] canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFont ( self . parameters . arguments [ \"title_font_type\" ], self . parameters . arguments [ \"title_font_size\" ]) canvas . drawString ( x_left_border , self . visualisation_data [ \"y_top\" ] - self . visualisation_data [ \"text_height\" ], self . visualisation_data [ \"title\" ]) __init__ ( visualisation_data , parameters ) Create TitleVis object. Parameters: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing_annotation.py 186 187 188 189 190 191 192 193 194 195 def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Create TitleVis object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . visualisation_data = visualisation_data self . parameters = parameters draw ( canvas ) Draw a Title track. Parameters: canvas ( reportlab . pdfgen . canvas . Canvas ) \u2013 a pdf object. Returns: None \u2013 None Source code in uorf4u/drawing_annotation.py 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Draw a Title track. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" x_left_border = self . visualisation_data [ \"coordinate_system\" ][ \"x_labels_start\" ] # x_left_border = self.visualisation_data[\"coordinate_system\"][\"x_annotation_start\"] canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFont ( self . parameters . arguments [ \"title_font_type\" ], self . parameters . arguments [ \"title_font_size\" ]) canvas . drawString ( x_left_border , self . visualisation_data [ \"y_top\" ] - self . visualisation_data [ \"text_height\" ], self . visualisation_data [ \"title\" ]) needed_y_space () Calculate needed vertical space for a Title track. Returns: float ( float ) \u2013 needed vertical space. Source code in uorf4u/drawing_annotation.py 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 def needed_y_space ( self ) -> float : \"\"\"Calculate needed vertical space for a Title track. Returns: float: needed vertical space. \"\"\" font_type = self . parameters . arguments [ \"title_font_type\" ] reportlab . pdfbase . pdfmetrics . registerFont ( reportlab . pdfbase . ttfonts . TTFont ( font_type , self . parameters . arguments [ f \"font_ { font_type } \" ])) face = reportlab . pdfbase . pdfmetrics . getFont ( font_type ) . face if self . parameters . arguments [ \"title_font_size\" ] == \"auto\" : text_height = self . parameters . arguments [ \"orf_height\" ] * cm font_size = uorf4u . methods . string_height_to_font_size ( text_height , font_type , self . parameters . arguments ) self . parameters . arguments [ \"title_font_size\" ] = font_size else : text_height = ( self . parameters . arguments [ \"title_font_size\" ] * ( face . ascent - face . descent )) / ( 1000 * 1.38 ) self . visualisation_data [ \"text_height\" ] = text_height self . needed_space = text_height * 1.2 return self . needed_space Track Parent clas for visualisation Tracks. Attributes: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing_annotation.py 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 class Track : \"\"\"Parent clas for visualisation Tracks. Attributes: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Parent's constructor for creating a Track object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . visualisation_data = visualisation_data self . parameters = parameters def needed_y_space ( self ) -> None : \"\"\"Empy parent's method for calculation needed vertical space for a track. Returns: None \"\"\" pass def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Empy parent's method for track visualisation. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" pass __init__ ( visualisation_data , parameters ) Parent's constructor for creating a Track object. Parameters: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing_annotation.py 142 143 144 145 146 147 148 149 150 151 def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Parent's constructor for creating a Track object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . visualisation_data = visualisation_data self . parameters = parameters draw ( canvas ) Empy parent's method for track visualisation. Parameters: canvas ( reportlab . pdfgen . canvas . Canvas ) \u2013 a pdf object. Returns: None \u2013 None Source code in uorf4u/drawing_annotation.py 162 163 164 165 166 167 168 169 170 171 def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Empy parent's method for track visualisation. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" pass needed_y_space () Empy parent's method for calculation needed vertical space for a track. Returns: None \u2013 None Source code in uorf4u/drawing_annotation.py 153 154 155 156 157 158 159 160 def needed_y_space ( self ) -> None : \"\"\"Empy parent's method for calculation needed vertical space for a track. Returns: None \"\"\" pass This module provides visualisation of loci annotation. Image An Image object holds pdf. Attributes: canvas ( reportlab . pdfgen . canvas . Canvas ) \u2013 pdf object of the reportlab library. Source code in uorf4u/drawing_msa.py 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 class Image : \"\"\"An Image object holds pdf. Attributes: canvas (reportlab.pdfgen.canvas.Canvas): pdf object of the reportlab library. \"\"\" def __init__ ( self , filename : str , width : float , height : float ): \"\"\"Create an Image object. Arguments: filename (str): path and name of a pdf. width (float): width of a pdf. height (float): height of a pdf. \"\"\" self . canvas = reportlab . pdfgen . canvas . Canvas ( filename , pagesize = ( width , height )) def save ( self ) -> None : \"\"\"Save a pdf file. Returns: None \"\"\" self . canvas . save () return None __init__ ( filename , width , height ) Create an Image object. Parameters: filename ( str ) \u2013 path and name of a pdf. width ( float ) \u2013 width of a pdf. height ( float ) \u2013 height of a pdf. Source code in uorf4u/drawing_msa.py 335 336 337 338 339 340 341 342 343 344 def __init__ ( self , filename : str , width : float , height : float ): \"\"\"Create an Image object. Arguments: filename (str): path and name of a pdf. width (float): width of a pdf. height (float): height of a pdf. \"\"\" self . canvas = reportlab . pdfgen . canvas . Canvas ( filename , pagesize = ( width , height )) save () Save a pdf file. Returns: None \u2013 None Source code in uorf4u/drawing_msa.py 346 347 348 349 350 351 352 353 354 def save ( self ) -> None : \"\"\"Save a pdf file. Returns: None \"\"\" self . canvas . save () return None Loader Parent class for tracks loaders. Attributes: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. prepared_data ( dict ) \u2013 dict with data needed for visualisation tracks. Source code in uorf4u/drawing_msa.py 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 class Loader : \"\"\"Parent class for tracks loaders. Attributes: parameters (uorf4u.manager.Parameters): Parameters' class object. prepared_data (dict): dict with data needed for visualisation tracks. \"\"\" def __init__ ( self , parameters : uorf4u . manager . Parameters ): \"\"\"Parent's constructor for creating a Loader class object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . parameters = parameters self . prepared_data = None def prepare_data ( self ) -> None : \"\"\"Empty parent's method for data preparation. Returns: None \"\"\" pass def create_track ( self ) -> None : \"\"\"Empty parent's method for initialisation of a track. Returns: None \"\"\" pass __init__ ( parameters ) Parent's constructor for creating a Loader class object. Parameters: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing_msa.py 245 246 247 248 249 250 251 252 def __init__ ( self , parameters : uorf4u . manager . Parameters ): \"\"\"Parent's constructor for creating a Loader class object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . parameters = parameters self . prepared_data = None create_track () Empty parent's method for initialisation of a track. Returns: None \u2013 None Source code in uorf4u/drawing_msa.py 263 264 265 266 267 268 269 270 def create_track ( self ) -> None : \"\"\"Empty parent's method for initialisation of a track. Returns: None \"\"\" pass prepare_data () Empty parent's method for data preparation. Returns: None \u2013 None Source code in uorf4u/drawing_msa.py 254 255 256 257 258 259 260 261 def prepare_data ( self ) -> None : \"\"\"Empty parent's method for data preparation. Returns: None \"\"\" pass MSAPlotManager AnnotationPlotManager object holds needed information for annotation visualisation and controls it. Note: It's supposed that the AnnotationPlotManager' objects will not be used directly by API users since visualisation can be controlled by 'plot_annotation' method. Attributes: msa ( FILL IN ) \u2013 Path class' multiple sequence alignment. upstream_sequences ( list ) \u2013 list of dicts with information about upstream sequences. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. coordinate_system ( dict ) \u2013 coordinate system of figure. additional_data ( dict ) \u2013 dict with data for visualisation tracks. Source code in uorf4u/drawing_msa.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 class MSAPlotManager : \"\"\" AnnotationPlotManager object holds needed information for annotation visualisation and controls it. Note: It's supposed that the AnnotationPlotManager' objects will not be used directly by API users since visualisation can be controlled by 'plot_annotation' method. Attributes: msa (FILL IN): Path class' multiple sequence alignment. upstream_sequences (list): list of dicts with information about upstream sequences. parameters (uorf4u.manager.Parameters): Parameters' class object. coordinate_system (dict): coordinate system of figure. additional_data (dict): dict with data for visualisation tracks. \"\"\" def __init__ ( self , msa , parameters : uorf4u . manager . Parameters , type : str ): \"\"\"Create a AnnotationPlotManager object. Arguments: path (uorf4u.data_processing.Path): Path class' objects that holds list of conserved ORFs. upstream_sequences (list): list of dicts with information about upstream sequences. parameters (uorf4u.manager.Parameters): Parameters' class object. type (str): type of sequences (sd, nt, aa) \"\"\" self . msa = msa self . parameters = parameters self . coordinate_system = dict () self . additional_data = dict () self . type = type def define_x_axis_coordinate_system ( self ) -> None : \"\"\"Define coordinate system. Returns: None \"\"\" label_height = self . parameters . arguments [ \"label_size\" ] * self . parameters . arguments [ \"tile_size\" ] * cm label_font_size = uorf4u . methods . string_height_to_font_size ( label_height , \"regular\" , self . parameters . arguments ) self . additional_data [ \"label_font_size\" ] = label_font_size msa_length = self . msa . get_alignment_length () max_label_width = max ([ reportlab . pdfbase . pdfmetrics . stringWidth ( i . description , \"regular\" , label_font_size ) for i in self . msa ]) char_height = self . parameters . arguments [ \"char_size\" ] * self . parameters . arguments [ \"tile_size\" ] * cm char_font_size = uorf4u . methods . string_height_to_font_size ( char_height , \"mono\" , self . parameters . arguments ) self . additional_data [ \"char_font_size\" ] = char_font_size self . additional_data [ \"number_of_sequences\" ] = len ( self . msa ) self . coordinate_system [ \"x_labels_start\" ] = self . parameters . arguments [ \"margin\" ] * cm self . coordinate_system [ \"x_labels_stop\" ] = self . coordinate_system [ \"x_labels_start\" ] + max_label_width self . coordinate_system [ \"x_msa_start\" ] = self . coordinate_system [ \"x_labels_stop\" ] + \\ self . parameters . arguments [ \"label_gap\" ] * cm msa_width = self . parameters . arguments [ \"tile_size\" ] * msa_length * cm self . coordinate_system [ \"x_msa_stop\" ] = self . coordinate_system [ \"x_msa_start\" ] + msa_width self . coordinate_system [ \"figure_width\" ] = 2 * self . parameters . arguments [ \"margin\" ] * cm + msa_width + \\ max_label_width + self . parameters . arguments [ \"label_gap\" ] * cm self . coordinate_system [ \"figure_height\" ] = self . parameters . arguments [ \"margin\" ] * cm self . additional_data [ \"palette\" ] = self . parameters . arguments [ f \"colors_ { self . type } \" ] self . additional_data [ \"palette\" ] = { k : uorf4u . methods . color_name_to_hex ( v , self . parameters . arguments ) for k , v in self . additional_data [ \"palette\" ] . items ()} return None def create_tracks ( self ) -> None : \"\"\"Create visualisation tracks. Returns: None \"\"\" self . tracks = [] \"\"\" title_loader = TitleLoader(self.parameters) title_loader.prepare_data(self.coordinate_system, self.additional_data) title_track = title_loader.create_track() self.tracks.append(title_track) self.coordinate_system[\"figure_height\"] += title_track.needed_y_space() \"\"\" for record in self . msa : sequence_loader = SequencesLoader ( self . parameters ) sequence_loader . prepare_data ( record , self . coordinate_system , self . additional_data ) track = sequence_loader . create_track () self . tracks . append ( track ) self . coordinate_system [ \"figure_height\" ] += track . needed_y_space () # self.coordinate_system[\"figure_height\"] += self.parameters.arguments[\"gap\"] * cm # if index < self.additional_data[\"number_of_sequences\"] - 1: self . coordinate_system [ \"figure_height\" ] += self . parameters . arguments [ \"margin\" ] * cm def plot ( self , filename ): image = Image ( filename , self . coordinate_system [ \"figure_width\" ], self . coordinate_system [ \"figure_height\" ]) current_y_top = self . coordinate_system [ \"figure_height\" ] - self . parameters . arguments [ \"margin\" ] * cm for track in self . tracks : track . visualisation_data [ \"y_top\" ] = current_y_top track . draw ( image . canvas ) current_y_top -= ( track . needed_space ) image . save () return None __init__ ( msa , parameters , type ) Create a AnnotationPlotManager object. Parameters: path ( uorf4u . data_processing . Path ) \u2013 Path class' objects that holds list of conserved ORFs. upstream_sequences ( list ) \u2013 list of dicts with information about upstream sequences. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. type ( str ) \u2013 type of sequences (sd, nt, aa) Source code in uorf4u/drawing_msa.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def __init__ ( self , msa , parameters : uorf4u . manager . Parameters , type : str ): \"\"\"Create a AnnotationPlotManager object. Arguments: path (uorf4u.data_processing.Path): Path class' objects that holds list of conserved ORFs. upstream_sequences (list): list of dicts with information about upstream sequences. parameters (uorf4u.manager.Parameters): Parameters' class object. type (str): type of sequences (sd, nt, aa) \"\"\" self . msa = msa self . parameters = parameters self . coordinate_system = dict () self . additional_data = dict () self . type = type create_tracks () Create visualisation tracks. Returns: None \u2013 None Source code in uorf4u/drawing_msa.py 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 def create_tracks ( self ) -> None : \"\"\"Create visualisation tracks. Returns: None \"\"\" self . tracks = [] \"\"\" title_loader = TitleLoader(self.parameters) title_loader.prepare_data(self.coordinate_system, self.additional_data) title_track = title_loader.create_track() self.tracks.append(title_track) self.coordinate_system[\"figure_height\"] += title_track.needed_y_space() \"\"\" for record in self . msa : sequence_loader = SequencesLoader ( self . parameters ) sequence_loader . prepare_data ( record , self . coordinate_system , self . additional_data ) track = sequence_loader . create_track () self . tracks . append ( track ) self . coordinate_system [ \"figure_height\" ] += track . needed_y_space () # self.coordinate_system[\"figure_height\"] += self.parameters.arguments[\"gap\"] * cm # if index < self.additional_data[\"number_of_sequences\"] - 1: self . coordinate_system [ \"figure_height\" ] += self . parameters . arguments [ \"margin\" ] * cm define_x_axis_coordinate_system () Define coordinate system. Returns: None \u2013 None Source code in uorf4u/drawing_msa.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 def define_x_axis_coordinate_system ( self ) -> None : \"\"\"Define coordinate system. Returns: None \"\"\" label_height = self . parameters . arguments [ \"label_size\" ] * self . parameters . arguments [ \"tile_size\" ] * cm label_font_size = uorf4u . methods . string_height_to_font_size ( label_height , \"regular\" , self . parameters . arguments ) self . additional_data [ \"label_font_size\" ] = label_font_size msa_length = self . msa . get_alignment_length () max_label_width = max ([ reportlab . pdfbase . pdfmetrics . stringWidth ( i . description , \"regular\" , label_font_size ) for i in self . msa ]) char_height = self . parameters . arguments [ \"char_size\" ] * self . parameters . arguments [ \"tile_size\" ] * cm char_font_size = uorf4u . methods . string_height_to_font_size ( char_height , \"mono\" , self . parameters . arguments ) self . additional_data [ \"char_font_size\" ] = char_font_size self . additional_data [ \"number_of_sequences\" ] = len ( self . msa ) self . coordinate_system [ \"x_labels_start\" ] = self . parameters . arguments [ \"margin\" ] * cm self . coordinate_system [ \"x_labels_stop\" ] = self . coordinate_system [ \"x_labels_start\" ] + max_label_width self . coordinate_system [ \"x_msa_start\" ] = self . coordinate_system [ \"x_labels_stop\" ] + \\ self . parameters . arguments [ \"label_gap\" ] * cm msa_width = self . parameters . arguments [ \"tile_size\" ] * msa_length * cm self . coordinate_system [ \"x_msa_stop\" ] = self . coordinate_system [ \"x_msa_start\" ] + msa_width self . coordinate_system [ \"figure_width\" ] = 2 * self . parameters . arguments [ \"margin\" ] * cm + msa_width + \\ max_label_width + self . parameters . arguments [ \"label_gap\" ] * cm self . coordinate_system [ \"figure_height\" ] = self . parameters . arguments [ \"margin\" ] * cm self . additional_data [ \"palette\" ] = self . parameters . arguments [ f \"colors_ { self . type } \" ] self . additional_data [ \"palette\" ] = { k : uorf4u . methods . color_name_to_hex ( v , self . parameters . arguments ) for k , v in self . additional_data [ \"palette\" ] . items ()} return None SequenceVis Bases: Track SequenceVis track draws sequences and annotation. Attributes: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. needed_space ( float ) \u2013 needed vertical space for a track. Source code in uorf4u/drawing_msa.py 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 class SequenceVis ( Track ): \"\"\"SequenceVis track draws sequences and annotation. Attributes: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. needed_space (float): needed vertical space for a track. \"\"\" def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Create a SequenceVis object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( visualisation_data , parameters ) self . needed_space = None def needed_y_space ( self ) -> float : \"\"\"Calculate needed vertical space for a SequenceVis track. Returns: float: needed vertical space. \"\"\" self . needed_space = self . parameters . arguments [ \"tile_size\" ] * cm return self . needed_space def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Draw a Sequence track. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" tile_size = self . parameters . arguments [ \"tile_size\" ] * cm y_c = self . visualisation_data [ \"y_top\" ] - ( tile_size * 0.5 ) y_l = self . visualisation_data [ \"y_top\" ] - tile_size y_gap_label = tile_size * ( 1 - self . parameters . arguments [ \"label_size\" ]) * 0.5 y_gap_char = tile_size * ( 1 - self . parameters . arguments [ \"char_size\" ]) * 0.5 # Labels canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFont ( \"regular\" , self . visualisation_data [ \"label_font_size\" ]) canvas . drawRightString ( self . visualisation_data [ \"coordinate_system\" ][ \"x_labels_stop\" ], y_l + y_gap_label , self . visualisation_data [ \"label\" ]) canvas . setLineWidth ( 0.05 * tile_size ) canvas . setStrokeColorRGB ( 1 , 1 , 1 ) canvas . setFont ( \"mono\" , self . visualisation_data [ \"char_font_size\" ]) x = self . visualisation_data [ 'msa_left_border' ] for symbol in self . visualisation_data [ \"sequence\" ]: x_c = x + tile_size * 0.5 symbol = symbol . upper () try : color = self . visualisation_data [ \"palette\" ][ symbol ] except : color = \"#FFFFFF\" canvas . setFillColorRGB ( * uorf4u . methods . hex_to_rgb ( color ), self . parameters . arguments [ \"tile_alpha\" ]) canvas . rect ( x , y_l , tile_size , tile_size , fill = 1 ) canvas . setFillColorRGB ( 0 , 0 , 0 , 0.8 ) # to change canvas . drawCentredString ( x_c , y_l + y_gap_char , symbol ) x += tile_size return None __init__ ( visualisation_data , parameters ) Create a SequenceVis object. Parameters: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing_msa.py 173 174 175 176 177 178 179 180 181 182 def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Create a SequenceVis object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( visualisation_data , parameters ) self . needed_space = None draw ( canvas ) Draw a Sequence track. Parameters: canvas ( reportlab . pdfgen . canvas . Canvas ) \u2013 a pdf object. Returns: None \u2013 None Source code in uorf4u/drawing_msa.py 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Draw a Sequence track. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" tile_size = self . parameters . arguments [ \"tile_size\" ] * cm y_c = self . visualisation_data [ \"y_top\" ] - ( tile_size * 0.5 ) y_l = self . visualisation_data [ \"y_top\" ] - tile_size y_gap_label = tile_size * ( 1 - self . parameters . arguments [ \"label_size\" ]) * 0.5 y_gap_char = tile_size * ( 1 - self . parameters . arguments [ \"char_size\" ]) * 0.5 # Labels canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFont ( \"regular\" , self . visualisation_data [ \"label_font_size\" ]) canvas . drawRightString ( self . visualisation_data [ \"coordinate_system\" ][ \"x_labels_stop\" ], y_l + y_gap_label , self . visualisation_data [ \"label\" ]) canvas . setLineWidth ( 0.05 * tile_size ) canvas . setStrokeColorRGB ( 1 , 1 , 1 ) canvas . setFont ( \"mono\" , self . visualisation_data [ \"char_font_size\" ]) x = self . visualisation_data [ 'msa_left_border' ] for symbol in self . visualisation_data [ \"sequence\" ]: x_c = x + tile_size * 0.5 symbol = symbol . upper () try : color = self . visualisation_data [ \"palette\" ][ symbol ] except : color = \"#FFFFFF\" canvas . setFillColorRGB ( * uorf4u . methods . hex_to_rgb ( color ), self . parameters . arguments [ \"tile_alpha\" ]) canvas . rect ( x , y_l , tile_size , tile_size , fill = 1 ) canvas . setFillColorRGB ( 0 , 0 , 0 , 0.8 ) # to change canvas . drawCentredString ( x_c , y_l + y_gap_char , symbol ) x += tile_size return None needed_y_space () Calculate needed vertical space for a SequenceVis track. Returns: float ( float ) \u2013 needed vertical space. Source code in uorf4u/drawing_msa.py 184 185 186 187 188 189 190 191 192 def needed_y_space ( self ) -> float : \"\"\"Calculate needed vertical space for a SequenceVis track. Returns: float: needed vertical space. \"\"\" self . needed_space = self . parameters . arguments [ \"tile_size\" ] * cm return self . needed_space SequencesLoader Bases: Loader A SequencesLoader object prepares data for a Sequence track object. Attributes: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. prepared_data ( dict ) \u2013 dict with data needed for a visualisation track. Source code in uorf4u/drawing_msa.py 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 class SequencesLoader ( Loader ): \"\"\"A SequencesLoader object prepares data for a Sequence track object. Attributes: parameters (uorf4u.manager.Parameters): Parameters' class object. prepared_data (dict): dict with data needed for a visualisation track. \"\"\" def __init__ ( self , parameters ): \"\"\"Create a SequenceLoader object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( parameters ) def prepare_data ( self , record , coordinate_system : dict , additional_data : dict ) -> dict : \"\"\"Prepare data for a Title visualisation track. Attributes: record (FILL in): record of blablabla coordinate_system (dict): coordinate system of a figure page. additional_data (dict): data needed for a track initialisation. Returns: dict: dictionary with prepared data for visualisation. \"\"\" prepared_data = dict () prepared_data [ \"coordinate_system\" ] = coordinate_system prepared_data [ \"label_font_size\" ] = additional_data [ \"label_font_size\" ] prepared_data [ \"char_font_size\" ] = additional_data [ \"char_font_size\" ] prepared_data [ \"label_right_border\" ] = coordinate_system [ \"x_labels_stop\" ] prepared_data [ \"msa_left_border\" ] = coordinate_system [ \"x_msa_start\" ] prepared_data [ \"sequence\" ] = record . seq prepared_data [ \"label\" ] = record . description prepared_data [ \"palette\" ] = additional_data [ \"palette\" ] self . prepared_data = prepared_data return prepared_data def create_track ( self ) -> SequenceVis : \"\"\"Initialise a Sequence track object. Returns: SequenceVis: visualisation track. \"\"\" return SequenceVis ( self . prepared_data , self . parameters ) __init__ ( parameters ) Create a SequenceLoader object. Parameters: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing_msa.py 283 284 285 286 287 288 289 290 def __init__ ( self , parameters ): \"\"\"Create a SequenceLoader object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( parameters ) create_track () Initialise a Sequence track object. Returns: SequenceVis ( SequenceVis ) \u2013 visualisation track. Source code in uorf4u/drawing_msa.py 317 318 319 320 321 322 323 324 def create_track ( self ) -> SequenceVis : \"\"\"Initialise a Sequence track object. Returns: SequenceVis: visualisation track. \"\"\" return SequenceVis ( self . prepared_data , self . parameters ) prepare_data ( record , coordinate_system , additional_data ) Prepare data for a Title visualisation track. Attributes: record ( FILL in ) \u2013 record of blablabla coordinate_system ( dict ) \u2013 coordinate system of a figure page. additional_data ( dict ) \u2013 data needed for a track initialisation. Returns: dict ( dict ) \u2013 dictionary with prepared data for visualisation. Source code in uorf4u/drawing_msa.py 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 def prepare_data ( self , record , coordinate_system : dict , additional_data : dict ) -> dict : \"\"\"Prepare data for a Title visualisation track. Attributes: record (FILL in): record of blablabla coordinate_system (dict): coordinate system of a figure page. additional_data (dict): data needed for a track initialisation. Returns: dict: dictionary with prepared data for visualisation. \"\"\" prepared_data = dict () prepared_data [ \"coordinate_system\" ] = coordinate_system prepared_data [ \"label_font_size\" ] = additional_data [ \"label_font_size\" ] prepared_data [ \"char_font_size\" ] = additional_data [ \"char_font_size\" ] prepared_data [ \"label_right_border\" ] = coordinate_system [ \"x_labels_stop\" ] prepared_data [ \"msa_left_border\" ] = coordinate_system [ \"x_msa_start\" ] prepared_data [ \"sequence\" ] = record . seq prepared_data [ \"label\" ] = record . description prepared_data [ \"palette\" ] = additional_data [ \"palette\" ] self . prepared_data = prepared_data return prepared_data Track Parent clas for visualisation Tracks. Attributes: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing_msa.py 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 class Track : \"\"\"Parent clas for visualisation Tracks. Attributes: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Parent's constructor for creating a Track object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . visualisation_data = visualisation_data self . parameters = parameters def needed_y_space ( self ) -> None : \"\"\"Empy parent's method for calculation needed vertical space for a track. Returns: None \"\"\" pass def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Empy parent's method for track visualisation. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" pass __init__ ( visualisation_data , parameters ) Parent's constructor for creating a Track object. Parameters: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing_msa.py 131 132 133 134 135 136 137 138 139 140 def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Parent's constructor for creating a Track object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . visualisation_data = visualisation_data self . parameters = parameters draw ( canvas ) Empy parent's method for track visualisation. Parameters: canvas ( reportlab . pdfgen . canvas . Canvas ) \u2013 a pdf object. Returns: None \u2013 None Source code in uorf4u/drawing_msa.py 151 152 153 154 155 156 157 158 159 160 def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Empy parent's method for track visualisation. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" pass needed_y_space () Empy parent's method for calculation needed vertical space for a track. Returns: None \u2013 None Source code in uorf4u/drawing_msa.py 142 143 144 145 146 147 148 149 def needed_y_space ( self ) -> None : \"\"\"Empy parent's method for calculation needed vertical space for a track. Returns: None \"\"\" pass","title":"uorf4u.drawing"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.AnnotationPlotManager","text":"AnnotationPlotManager object holds needed information for annotation visualisation and controls it. Note: It's supposed that the AnnotationPlotManager' objects will not be used directly by API users since visualisation can be controlled by 'plot_annotation' method. Attributes: path ( uorf4u . data_processing . Path ) \u2013 Path class' objects that holds list of conserved ORFs. upstream_sequences ( list ) \u2013 list of dicts with information about upstream sequences. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. coordinate_system ( dict ) \u2013 coordinate system of figure. additional_data ( dict ) \u2013 dict with data for visualisation tracks. Source code in uorf4u/drawing_annotation.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 class AnnotationPlotManager : \"\"\" AnnotationPlotManager object holds needed information for annotation visualisation and controls it. Note: It's supposed that the AnnotationPlotManager' objects will not be used directly by API users since visualisation can be controlled by 'plot_annotation' method. Attributes: path (uorf4u.data_processing.Path): Path class' objects that holds list of conserved ORFs. upstream_sequences (list): list of dicts with information about upstream sequences. parameters (uorf4u.manager.Parameters): Parameters' class object. coordinate_system (dict): coordinate system of figure. additional_data (dict): dict with data for visualisation tracks. \"\"\" def __init__ ( self , path , upstream_sequences : list , parameters : uorf4u . manager . Parameters ): \"\"\"Create a AnnotationPlotManager object. Arguments: path (uorf4u.data_processing.Path): Path class' objects that holds list of conserved ORFs. upstream_sequences (list): list of dicts with information about upstream sequences. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . path = path self . upstream_sequences = upstream_sequences self . parameters = parameters self . coordinate_system = dict () self . additional_data = dict () def define_x_axis_coordinate_system ( self ) -> None : \"\"\"Define coordinate system. Returns: None \"\"\" label_height = self . parameters . arguments [ \"label_height_to_orf_height\" ] * self . parameters . arguments [ \"orf_height\" ] * cm label_font_size = uorf4u . methods . string_height_to_font_size ( label_height , \"regular\" , self . parameters . arguments ) self . additional_data [ \"label_font_size\" ] = label_font_size self . additional_data [ \"ordered_upstream_sequences\" ] = [ self . upstream_sequences [ i ] for i in [ orf . useq_index for orf in self . path . path ]] max_label_width = max ([ reportlab . pdfbase . pdfmetrics . stringWidth ( i . annotations [ \"label\" ], \"regular\" , label_font_size ) for i in self . additional_data [ \"ordered_upstream_sequences\" ]]) self . additional_data [ \"number_of_sequences\" ] = len ( self . path ) self . additional_data [ \"max_upstream_sequence_length\" ] = max ( i . annotations [ \"upstream_region_length\" ] for i in self . additional_data [ \"ordered_upstream_sequences\" ]) self . additional_data [ \"max_downstream_sequence_length\" ] = max ( i . annotations [ \"downstream_region_length\" ] for i in self . additional_data [ \"ordered_upstream_sequences\" ]) window_size_nt = self . additional_data [ \"max_upstream_sequence_length\" ] + self . additional_data [ \"max_downstream_sequence_length\" ] if self . parameters . arguments [ \"annotation_width\" ] == \"auto\" : annotation_width = window_size_nt * self . parameters . arguments [ \"mm_per_nt\" ] * mm else : annotation_width = self . parameters . arguments [ \"annotation_width\" ] * cm self . coordinate_system [ \"transformation_coef\" ] = annotation_width / window_size_nt self . coordinate_system [ \"x_labels_start\" ] = self . parameters . arguments [ \"margin\" ] * cm self . coordinate_system [ \"x_labels_stop\" ] = self . coordinate_system [ \"x_labels_start\" ] + max_label_width self . coordinate_system [ \"x_annotation_start\" ] = self . coordinate_system [ \"x_labels_stop\" ] + \\ self . parameters . arguments [ \"label_gap\" ] * cm self . coordinate_system [ \"x_annotation_stop\" ] = self . coordinate_system [ \"x_annotation_start\" ] + annotation_width self . coordinate_system [ \"figure_width\" ] = 2 * self . parameters . arguments [ \"margin\" ] * cm + annotation_width + \\ max_label_width + self . parameters . arguments [ \"label_gap\" ] * cm self . coordinate_system [ \"figure_height\" ] = self . parameters . arguments [ \"margin\" ] * cm return None def create_tracks ( self ) -> None : \"\"\"Create visualisation tracks. Returns: None \"\"\" self . tracks = [] \"\"\" title_loader = TitleLoader(self.parameters) title_loader.prepare_data(self.coordinate_system, self.additional_data) title_track = title_loader.create_track() self.tracks.append(title_track) self.coordinate_system[\"figure_height\"] += title_track.needed_y_space() \"\"\" for index in range ( self . additional_data [ \"number_of_sequences\" ]): upstream_sequence = self . additional_data [ \"ordered_upstream_sequences\" ][ index ] conserved_orf = self . path . path [ index ] sequence_loader = SequencesLoader ( self . parameters ) sequence_loader . prepare_data ( upstream_sequence , conserved_orf , self . coordinate_system , self . additional_data ) track = sequence_loader . create_track () self . tracks . append ( track ) self . coordinate_system [ \"figure_height\" ] += track . needed_y_space () self . coordinate_system [ \"figure_height\" ] += self . parameters . arguments [ \"gap\" ] * cm # if index < self.additional_data[\"number_of_sequences\"] - 1: axis_tics_loader = AxisLoader ( self . parameters ) axis_tics_loader . prepare_data ( self . coordinate_system , self . additional_data ) axis_tics_track = axis_tics_loader . create_track () self . tracks . append ( axis_tics_track ) self . coordinate_system [ \"figure_height\" ] += axis_tics_track . needed_y_space () self . coordinate_system [ \"figure_height\" ] += self . parameters . arguments [ \"margin\" ] * cm def plot ( self , filename ): image = Image ( filename , self . coordinate_system [ \"figure_width\" ], self . coordinate_system [ \"figure_height\" ]) current_y_top = self . coordinate_system [ \"figure_height\" ] - self . parameters . arguments [ \"margin\" ] * cm for track in self . tracks : track . visualisation_data [ \"y_top\" ] = current_y_top track . draw ( image . canvas ) current_y_top -= ( track . needed_space + self . parameters . arguments [ \"gap\" ] * cm ) image . save () return None","title":"AnnotationPlotManager"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.AnnotationPlotManager.__init__","text":"Create a AnnotationPlotManager object. Parameters: path ( uorf4u . data_processing . Path ) \u2013 Path class' objects that holds list of conserved ORFs. upstream_sequences ( list ) \u2013 list of dicts with information about upstream sequences. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing_annotation.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 def __init__ ( self , path , upstream_sequences : list , parameters : uorf4u . manager . Parameters ): \"\"\"Create a AnnotationPlotManager object. Arguments: path (uorf4u.data_processing.Path): Path class' objects that holds list of conserved ORFs. upstream_sequences (list): list of dicts with information about upstream sequences. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . path = path self . upstream_sequences = upstream_sequences self . parameters = parameters self . coordinate_system = dict () self . additional_data = dict ()","title":"__init__()"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.AnnotationPlotManager.create_tracks","text":"Create visualisation tracks. Returns: None \u2013 None Source code in uorf4u/drawing_annotation.py 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 def create_tracks ( self ) -> None : \"\"\"Create visualisation tracks. Returns: None \"\"\" self . tracks = [] \"\"\" title_loader = TitleLoader(self.parameters) title_loader.prepare_data(self.coordinate_system, self.additional_data) title_track = title_loader.create_track() self.tracks.append(title_track) self.coordinate_system[\"figure_height\"] += title_track.needed_y_space() \"\"\" for index in range ( self . additional_data [ \"number_of_sequences\" ]): upstream_sequence = self . additional_data [ \"ordered_upstream_sequences\" ][ index ] conserved_orf = self . path . path [ index ] sequence_loader = SequencesLoader ( self . parameters ) sequence_loader . prepare_data ( upstream_sequence , conserved_orf , self . coordinate_system , self . additional_data ) track = sequence_loader . create_track () self . tracks . append ( track ) self . coordinate_system [ \"figure_height\" ] += track . needed_y_space () self . coordinate_system [ \"figure_height\" ] += self . parameters . arguments [ \"gap\" ] * cm # if index < self.additional_data[\"number_of_sequences\"] - 1: axis_tics_loader = AxisLoader ( self . parameters ) axis_tics_loader . prepare_data ( self . coordinate_system , self . additional_data ) axis_tics_track = axis_tics_loader . create_track () self . tracks . append ( axis_tics_track ) self . coordinate_system [ \"figure_height\" ] += axis_tics_track . needed_y_space () self . coordinate_system [ \"figure_height\" ] += self . parameters . arguments [ \"margin\" ] * cm","title":"create_tracks()"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.AnnotationPlotManager.define_x_axis_coordinate_system","text":"Define coordinate system. Returns: None \u2013 None Source code in uorf4u/drawing_annotation.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 def define_x_axis_coordinate_system ( self ) -> None : \"\"\"Define coordinate system. Returns: None \"\"\" label_height = self . parameters . arguments [ \"label_height_to_orf_height\" ] * self . parameters . arguments [ \"orf_height\" ] * cm label_font_size = uorf4u . methods . string_height_to_font_size ( label_height , \"regular\" , self . parameters . arguments ) self . additional_data [ \"label_font_size\" ] = label_font_size self . additional_data [ \"ordered_upstream_sequences\" ] = [ self . upstream_sequences [ i ] for i in [ orf . useq_index for orf in self . path . path ]] max_label_width = max ([ reportlab . pdfbase . pdfmetrics . stringWidth ( i . annotations [ \"label\" ], \"regular\" , label_font_size ) for i in self . additional_data [ \"ordered_upstream_sequences\" ]]) self . additional_data [ \"number_of_sequences\" ] = len ( self . path ) self . additional_data [ \"max_upstream_sequence_length\" ] = max ( i . annotations [ \"upstream_region_length\" ] for i in self . additional_data [ \"ordered_upstream_sequences\" ]) self . additional_data [ \"max_downstream_sequence_length\" ] = max ( i . annotations [ \"downstream_region_length\" ] for i in self . additional_data [ \"ordered_upstream_sequences\" ]) window_size_nt = self . additional_data [ \"max_upstream_sequence_length\" ] + self . additional_data [ \"max_downstream_sequence_length\" ] if self . parameters . arguments [ \"annotation_width\" ] == \"auto\" : annotation_width = window_size_nt * self . parameters . arguments [ \"mm_per_nt\" ] * mm else : annotation_width = self . parameters . arguments [ \"annotation_width\" ] * cm self . coordinate_system [ \"transformation_coef\" ] = annotation_width / window_size_nt self . coordinate_system [ \"x_labels_start\" ] = self . parameters . arguments [ \"margin\" ] * cm self . coordinate_system [ \"x_labels_stop\" ] = self . coordinate_system [ \"x_labels_start\" ] + max_label_width self . coordinate_system [ \"x_annotation_start\" ] = self . coordinate_system [ \"x_labels_stop\" ] + \\ self . parameters . arguments [ \"label_gap\" ] * cm self . coordinate_system [ \"x_annotation_stop\" ] = self . coordinate_system [ \"x_annotation_start\" ] + annotation_width self . coordinate_system [ \"figure_width\" ] = 2 * self . parameters . arguments [ \"margin\" ] * cm + annotation_width + \\ max_label_width + self . parameters . arguments [ \"label_gap\" ] * cm self . coordinate_system [ \"figure_height\" ] = self . parameters . arguments [ \"margin\" ] * cm return None","title":"define_x_axis_coordinate_system()"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.AxisLoader","text":"Bases: Loader An AxisLoader object prepares data for an Axis track object. Attributes: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. prepared_data ( dict ) \u2013 dict with data needed for a visualisation track. Source code in uorf4u/drawing_annotation.py 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 class AxisLoader ( Loader ): \"\"\"An AxisLoader object prepares data for an Axis track object. Attributes: parameters (uorf4u.manager.Parameters): Parameters' class object. prepared_data (dict): dict with data needed for a visualisation track. \"\"\" def __init__ ( self , parameters ): \"\"\"Create an AxisLoader object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( parameters ) def prepare_data ( self , coordinate_system : dict , additional_data : dict ): \"\"\"Prepare data for an Axis visualisation track. Attributes: coordinate_system (dict): coordinate system of a figure page. additional_data (dict): data needed for a track initialisation. Returns: dict: dictionary with prepared data for visualisation. \"\"\" prepared_data = dict () prepared_data [ \"coordinate_system\" ] = coordinate_system prepared_data [ \"max_upstream_sequence_length\" ] = additional_data [ \"max_upstream_sequence_length\" ] prepared_data [ \"max_downstream_sequence_length\" ] = additional_data [ \"max_downstream_sequence_length\" ] step = int ( round ( additional_data [ \"max_upstream_sequence_length\" ] / 2 , - 2 )) tics = [ - additional_data [ \"max_upstream_sequence_length\" ], 0 , additional_data [ \"max_downstream_sequence_length\" ]] x_tic_centred = int ( round ( - additional_data [ \"max_upstream_sequence_length\" ] / 2 , - 2 )) tics . append ( x_tic_centred ) x_tic_left , x_tic_right = x_tic_centred - step , x_tic_centred + step while x_tic_right < 0 and x_tic_left > - additional_data [ \"max_upstream_sequence_length\" ]: tics . append ( x_tic_left ) tics . append ( x_tic_right ) x_tic_left -= step x_tic_right += step tics . sort () tics_coordinates = [ self . transform_relative_position_to_x_coordinate ( i , coordinate_system , additional_data [ \"max_upstream_sequence_length\" ]) for i in tics ] prepared_data [ \"tics\" ] = { k : v for k , v in zip ( tics , tics_coordinates )} self . prepared_data = prepared_data return prepared_data def transform_relative_position_to_x_coordinate ( self , relative_position : int , coordinate_system : dict , max_upstream_sequence_length : int ) -> float : \"\"\"Transform nucleotide x coordinate to pdf's. Arguments: relative_position (int): nucleotide position coordinate_system (dict): coordinate system of a figure. max_upstream_sequence_length (int): max length of upstream sequences for visualisation. Returns: float: transformed x coordinate. \"\"\" return coordinate_system [ \"x_annotation_start\" ] + ( relative_position + max_upstream_sequence_length ) * \\ coordinate_system [ \"transformation_coef\" ] def create_track ( self ) -> TicsVis : \"\"\"Initialise a Tics track object. Returns: TicsVis: visualisation track. \"\"\" return TicsVis ( self . prepared_data , self . parameters )","title":"AxisLoader"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.AxisLoader.__init__","text":"Create an AxisLoader object. Parameters: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing_annotation.py 706 707 708 709 710 711 712 713 def __init__ ( self , parameters ): \"\"\"Create an AxisLoader object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( parameters )","title":"__init__()"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.AxisLoader.create_track","text":"Initialise a Tics track object. Returns: TicsVis ( TicsVis ) \u2013 visualisation track. Source code in uorf4u/drawing_annotation.py 762 763 764 765 766 767 768 769 def create_track ( self ) -> TicsVis : \"\"\"Initialise a Tics track object. Returns: TicsVis: visualisation track. \"\"\" return TicsVis ( self . prepared_data , self . parameters )","title":"create_track()"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.AxisLoader.prepare_data","text":"Prepare data for an Axis visualisation track. Attributes: coordinate_system ( dict ) \u2013 coordinate system of a figure page. additional_data ( dict ) \u2013 data needed for a track initialisation. Returns: dict \u2013 dictionary with prepared data for visualisation. Source code in uorf4u/drawing_annotation.py 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 def prepare_data ( self , coordinate_system : dict , additional_data : dict ): \"\"\"Prepare data for an Axis visualisation track. Attributes: coordinate_system (dict): coordinate system of a figure page. additional_data (dict): data needed for a track initialisation. Returns: dict: dictionary with prepared data for visualisation. \"\"\" prepared_data = dict () prepared_data [ \"coordinate_system\" ] = coordinate_system prepared_data [ \"max_upstream_sequence_length\" ] = additional_data [ \"max_upstream_sequence_length\" ] prepared_data [ \"max_downstream_sequence_length\" ] = additional_data [ \"max_downstream_sequence_length\" ] step = int ( round ( additional_data [ \"max_upstream_sequence_length\" ] / 2 , - 2 )) tics = [ - additional_data [ \"max_upstream_sequence_length\" ], 0 , additional_data [ \"max_downstream_sequence_length\" ]] x_tic_centred = int ( round ( - additional_data [ \"max_upstream_sequence_length\" ] / 2 , - 2 )) tics . append ( x_tic_centred ) x_tic_left , x_tic_right = x_tic_centred - step , x_tic_centred + step while x_tic_right < 0 and x_tic_left > - additional_data [ \"max_upstream_sequence_length\" ]: tics . append ( x_tic_left ) tics . append ( x_tic_right ) x_tic_left -= step x_tic_right += step tics . sort () tics_coordinates = [ self . transform_relative_position_to_x_coordinate ( i , coordinate_system , additional_data [ \"max_upstream_sequence_length\" ]) for i in tics ] prepared_data [ \"tics\" ] = { k : v for k , v in zip ( tics , tics_coordinates )} self . prepared_data = prepared_data return prepared_data","title":"prepare_data()"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.AxisLoader.transform_relative_position_to_x_coordinate","text":"Transform nucleotide x coordinate to pdf's. Parameters: relative_position ( int ) \u2013 nucleotide position coordinate_system ( dict ) \u2013 coordinate system of a figure. max_upstream_sequence_length ( int ) \u2013 max length of upstream sequences for visualisation. Returns: float ( float ) \u2013 transformed x coordinate. Source code in uorf4u/drawing_annotation.py 747 748 749 750 751 752 753 754 755 756 757 758 759 760 def transform_relative_position_to_x_coordinate ( self , relative_position : int , coordinate_system : dict , max_upstream_sequence_length : int ) -> float : \"\"\"Transform nucleotide x coordinate to pdf's. Arguments: relative_position (int): nucleotide position coordinate_system (dict): coordinate system of a figure. max_upstream_sequence_length (int): max length of upstream sequences for visualisation. Returns: float: transformed x coordinate. \"\"\" return coordinate_system [ \"x_annotation_start\" ] + ( relative_position + max_upstream_sequence_length ) * \\ coordinate_system [ \"transformation_coef\" ]","title":"transform_relative_position_to_x_coordinate()"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.Image","text":"An Image object holds pdf. Attributes: canvas ( reportlab . pdfgen . canvas . Canvas ) \u2013 pdf object of the reportlab library. Source code in uorf4u/drawing_annotation.py 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 class Image : \"\"\"An Image object holds pdf. Attributes: canvas (reportlab.pdfgen.canvas.Canvas): pdf object of the reportlab library. \"\"\" def __init__ ( self , filename : str , width : float , height : float ): \"\"\"Create an Image object. Arguments: filename (str): path and name of a pdf. width (float): width of a pdf. height (float): height of a pdf. \"\"\" self . canvas = reportlab . pdfgen . canvas . Canvas ( filename , pagesize = ( width , height )) def save ( self ) -> None : \"\"\"Save a pdf file. Returns: None \"\"\" self . canvas . save () return None","title":"Image"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.Image.__init__","text":"Create an Image object. Parameters: filename ( str ) \u2013 path and name of a pdf. width ( float ) \u2013 width of a pdf. height ( float ) \u2013 height of a pdf. Source code in uorf4u/drawing_annotation.py 780 781 782 783 784 785 786 787 788 789 def __init__ ( self , filename : str , width : float , height : float ): \"\"\"Create an Image object. Arguments: filename (str): path and name of a pdf. width (float): width of a pdf. height (float): height of a pdf. \"\"\" self . canvas = reportlab . pdfgen . canvas . Canvas ( filename , pagesize = ( width , height ))","title":"__init__()"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.Image.save","text":"Save a pdf file. Returns: None \u2013 None Source code in uorf4u/drawing_annotation.py 791 792 793 794 795 796 797 798 799 def save ( self ) -> None : \"\"\"Save a pdf file. Returns: None \"\"\" self . canvas . save () return None","title":"save()"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.Loader","text":"Parent class for tracks loaders. Attributes: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. prepared_data ( dict ) \u2013 dict with data needed for visualisation tracks. Source code in uorf4u/drawing_annotation.py 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 class Loader : \"\"\"Parent class for tracks loaders. Attributes: parameters (uorf4u.manager.Parameters): Parameters' class object. prepared_data (dict): dict with data needed for visualisation tracks. \"\"\" def __init__ ( self , parameters : uorf4u . manager . Parameters ): \"\"\"Parent's constructor for creating a Loader class object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . parameters = parameters self . prepared_data = None def prepare_data ( self ) -> None : \"\"\"Empty parent's method for data preparation. Returns: None \"\"\" pass def create_track ( self ) -> None : \"\"\"Empty parent's method for initialisation of a track. Returns: None \"\"\" pass","title":"Loader"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.Loader.__init__","text":"Parent's constructor for creating a Loader class object. Parameters: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing_annotation.py 499 500 501 502 503 504 505 506 def __init__ ( self , parameters : uorf4u . manager . Parameters ): \"\"\"Parent's constructor for creating a Loader class object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . parameters = parameters self . prepared_data = None","title":"__init__()"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.Loader.create_track","text":"Empty parent's method for initialisation of a track. Returns: None \u2013 None Source code in uorf4u/drawing_annotation.py 517 518 519 520 521 522 523 524 def create_track ( self ) -> None : \"\"\"Empty parent's method for initialisation of a track. Returns: None \"\"\" pass","title":"create_track()"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.Loader.prepare_data","text":"Empty parent's method for data preparation. Returns: None \u2013 None Source code in uorf4u/drawing_annotation.py 508 509 510 511 512 513 514 515 def prepare_data ( self ) -> None : \"\"\"Empty parent's method for data preparation. Returns: None \"\"\" pass","title":"prepare_data()"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.SequenceVis","text":"Bases: Track SequenceVis track draws sequences and annotation. Attributes: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. needed_space ( float ) \u2013 needed vertical space for a track. Source code in uorf4u/drawing_annotation.py 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 class SequenceVis ( Track ): \"\"\"SequenceVis track draws sequences and annotation. Attributes: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. needed_space (float): needed vertical space for a track. \"\"\" def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Create a SequenceVis object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( visualisation_data , parameters ) self . needed_space = None def needed_y_space ( self ) -> float : \"\"\"Calculate needed vertical space for a SequenceVis track. Returns: float: needed vertical space. \"\"\" self . needed_space = self . parameters . arguments [ \"orf_height\" ] * cm return self . needed_space def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Draw a Sequence track. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" orf_height = self . parameters . arguments [ \"orf_height\" ] * cm y_c = self . visualisation_data [ \"y_top\" ] - 0.5 * orf_height x_offset = 0.5 * self . parameters . arguments [ \"upstream_seq_line_width\" ] canvas . setStrokeColorRGB ( * uorf4u . methods . get_color ( \"upstream_seq_line_color\" , self . parameters . arguments )) canvas . setLineCap ( 0 ) canvas . setLineWidth ( self . parameters . arguments [ \"upstream_seq_line_width\" ]) canvas . line ( self . visualisation_data [ \"upstream_sequence_line_start_x\" ], y_c , self . visualisation_data [ \"upstream_sequence_line_stop_x\" ] - x_offset , y_c ) # Cleaning the space: canvas . setFillColorRGB canvas . setStrokeColorRGB ( 1 , 1 , 1 , 1 ) for orf_dict in self . visualisation_data [ \"orfs_coordinates_dict\" ] . values (): canvas . setLineWidth ( self . parameters . arguments [ \"upstream_seq_line_width\" ] * 1.5 ) canvas . line ( orf_dict [ \"x_start\" ], y_c , orf_dict [ \"x_stop\" ], y_c ) #canvas.rect(orf_dict[\"x_start\"], y_c - orf_height / 2, orf_dict[\"x_stop\"] - orf_dict[\"x_start\"], orf_height, # stroke=0, fill=1) if self . parameters . arguments [ \"check_assembly_annotation\" ] and \\ \"fasta\" not in self . parameters . cmd_arguments . keys (): for protein_id , cds_dict in self . visualisation_data [ \"CDSs_coordinates_dict\" ] . items (): canvas . line ( cds_dict [ \"x_start\" ], y_c , cds_dict [ \"x_stop\" ], y_c ) canvas . setLineWidth ( self . parameters . arguments [ \"upstream_seq_line_width\" ]) # Labels canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFont ( \"regular\" , self . visualisation_data [ \"label_font_size\" ]) y_l = y_c - 0.5 * ( self . parameters . arguments [ \"label_height_to_orf_height\" ] * orf_height ) canvas . drawRightString ( self . visualisation_data [ \"coordinate_system\" ][ \"x_labels_stop\" ], y_l , self . visualisation_data [ \"useq_label\" ]) # main_CDS canvas . setLineWidth ( self . parameters . arguments [ \"orf_line_width\" ]) canvas . setStrokeColorRGB ( * uorf4u . methods . get_color ( \"cds_seq_stroke_color\" , self . parameters . arguments )) canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"cds_seq_fill_color\" , self . parameters . arguments )) p = canvas . beginPath () p . moveTo ( self . visualisation_data [ \"main_CDS_stop_x\" ], y_c - orf_height / 2 ) p . lineTo ( self . visualisation_data [ \"main_CDS_start_x\" ], y_c - orf_height / 2 ) p . lineTo ( self . visualisation_data [ \"main_CDS_start_x\" ], y_c + orf_height / 2 ) p . lineTo ( self . visualisation_data [ \"main_CDS_stop_x\" ], y_c + orf_height / 2 ) canvas . drawPath ( p , stroke = 1 , fill = 1 ) # Other ORFs: for orf in self . visualisation_data [ \"annotated_orfs\" ]: orf_dict = self . visualisation_data [ \"orfs_coordinates_dict\" ][ orf ] if orf != self . visualisation_data [ \"conserved_orf\" ]: fill_color = None stroke_color = uorf4u . methods . get_color ( \"other_uorfs_stroke_color\" , self . parameters . arguments ) else : fill_color = uorf4u . methods . get_color ( \"conserved_uorfs_fill_color\" , self . parameters . arguments ) stroke_color = uorf4u . methods . get_color ( \"conserved_uorfs_stroke_color\" , self . parameters . arguments ) self . orf_object ( canvas , orf_dict [ \"x_start\" ], orf_dict [ \"x_stop\" ], y_c , orf_dict [ \"strand\" ], orf_height , orf_dict [ \"left_out\" ], orf_dict [ \"right_out\" ], fill_color , stroke_color ) # Annotated in RefSeq CDSs if self . parameters . arguments [ \"check_assembly_annotation\" ] and \\ \"fasta\" not in self . parameters . cmd_arguments . keys (): fill_color = None stroke_color = uorf4u . methods . get_color ( \"annotated_orf_stroke_color\" , self . parameters . arguments ) for protein_id , cds_dict in self . visualisation_data [ \"CDSs_coordinates_dict\" ] . items (): self . orf_object ( canvas , cds_dict [ \"x_start\" ], cds_dict [ \"x_stop\" ], y_c , cds_dict [ \"strand\" ], orf_height , cds_dict [ \"left_out\" ], cds_dict [ \"right_out\" ], fill_color , stroke_color ) return None def orf_object ( self , canvas : reportlab . pdfgen . canvas . Canvas , x_start : float , x_stop : float , y_c : float , strand : str , height : float , left_out : bool , right_out : bool , fill_color : str , stroke_color : str ) -> None : \"\"\"Method for drawing an ORF's polygon. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. x_start (float): ORF's start coordinate (already transformed to pdf's) x_stop (float): ORF's stop coordinate (already transformed to pdf's) y_c: (float): centred y coordinate of a current track. strand (str): strand of an ORF. height (float): height of a polygon. left_out (bool): whether an ORF is out of range on the left. right_out (bool): whether an ORF is out of range on the right. fill_color (str): fill color of a polygon. stroke_color (str): stroke color of a polygon. Returns: None \"\"\" fill , stroke = 0 , 0 if stroke_color : canvas . setStrokeColorRGB ( * stroke_color ) stroke = 1 if fill_color : canvas . setFillColorRGB ( * fill_color ) fill = 1 arrow_length = min ( height , ( x_stop - x_start )) p = canvas . beginPath () if strand == \"+\" and not left_out and not right_out : p . moveTo ( x_start , y_c ) p . lineTo ( x_start , y_c + height / 2 ) p . lineTo ( x_stop - arrow_length , y_c + height / 2 ) p . lineTo ( x_stop , y_c ) p . lineTo ( x_stop - arrow_length , y_c - height / 2 ) p . lineTo ( x_start , y_c - height / 2 ) p . lineTo ( x_start , y_c ) elif strand == \"+\" and left_out and not right_out : p . moveTo ( x_start , y_c + height / 2 ) p . lineTo ( x_stop - arrow_length , y_c + height / 2 ) p . lineTo ( x_stop , y_c ) p . lineTo ( x_stop - arrow_length , y_c - height / 2 ) p . lineTo ( x_start , y_c - height / 2 ) elif strand == \"+\" and right_out and not left_out : p . moveTo ( x_stop , y_c + height / 2 ) p . lineTo ( x_start , y_c + height / 2 ) p . lineTo ( x_start , y_c - height / 2 ) p . lineTo ( x_stop , y_c - height / 2 ) elif strand == \"-\" and not left_out and not right_out : p . moveTo ( x_stop , y_c ) p . lineTo ( x_stop , y_c + height / 2 ) p . lineTo ( x_start + arrow_length , y_c + height / 2 ) p . lineTo ( x_start , y_c ) p . lineTo ( x_start + arrow_length , y_c - height / 2 ) p . lineTo ( x_stop , y_c - height / 2 ) p . lineTo ( x_stop , y_c ) elif strand == \"-\" and right_out and not left_out : p . moveTo ( x_stop , y_c + height / 2 ) p . lineTo ( x_start + arrow_length , y_c + height / 2 ) p . lineTo ( x_start , y_c ) p . lineTo ( x_start + arrow_length , y_c - height / 2 ) p . lineTo ( x_stop , y_c - height / 2 ) elif strand == \"-\" and left_out and not right_out : p . moveTo ( x_start , y_c + height / 2 ) p . lineTo ( x_stop , y_c + height / 2 ) p . lineTo ( x_stop , y_c - height / 2 ) p . lineTo ( x_start , y_c - height / 2 ) canvas . drawPath ( p , stroke = stroke , fill = fill )","title":"SequenceVis"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.SequenceVis.__init__","text":"Create a SequenceVis object. Parameters: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing_annotation.py 247 248 249 250 251 252 253 254 255 256 def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Create a SequenceVis object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( visualisation_data , parameters ) self . needed_space = None","title":"__init__()"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.SequenceVis.draw","text":"Draw a Sequence track. Parameters: canvas ( reportlab . pdfgen . canvas . Canvas ) \u2013 a pdf object. Returns: None \u2013 None Source code in uorf4u/drawing_annotation.py 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Draw a Sequence track. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" orf_height = self . parameters . arguments [ \"orf_height\" ] * cm y_c = self . visualisation_data [ \"y_top\" ] - 0.5 * orf_height x_offset = 0.5 * self . parameters . arguments [ \"upstream_seq_line_width\" ] canvas . setStrokeColorRGB ( * uorf4u . methods . get_color ( \"upstream_seq_line_color\" , self . parameters . arguments )) canvas . setLineCap ( 0 ) canvas . setLineWidth ( self . parameters . arguments [ \"upstream_seq_line_width\" ]) canvas . line ( self . visualisation_data [ \"upstream_sequence_line_start_x\" ], y_c , self . visualisation_data [ \"upstream_sequence_line_stop_x\" ] - x_offset , y_c ) # Cleaning the space: canvas . setFillColorRGB canvas . setStrokeColorRGB ( 1 , 1 , 1 , 1 ) for orf_dict in self . visualisation_data [ \"orfs_coordinates_dict\" ] . values (): canvas . setLineWidth ( self . parameters . arguments [ \"upstream_seq_line_width\" ] * 1.5 ) canvas . line ( orf_dict [ \"x_start\" ], y_c , orf_dict [ \"x_stop\" ], y_c ) #canvas.rect(orf_dict[\"x_start\"], y_c - orf_height / 2, orf_dict[\"x_stop\"] - orf_dict[\"x_start\"], orf_height, # stroke=0, fill=1) if self . parameters . arguments [ \"check_assembly_annotation\" ] and \\ \"fasta\" not in self . parameters . cmd_arguments . keys (): for protein_id , cds_dict in self . visualisation_data [ \"CDSs_coordinates_dict\" ] . items (): canvas . line ( cds_dict [ \"x_start\" ], y_c , cds_dict [ \"x_stop\" ], y_c ) canvas . setLineWidth ( self . parameters . arguments [ \"upstream_seq_line_width\" ]) # Labels canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFont ( \"regular\" , self . visualisation_data [ \"label_font_size\" ]) y_l = y_c - 0.5 * ( self . parameters . arguments [ \"label_height_to_orf_height\" ] * orf_height ) canvas . drawRightString ( self . visualisation_data [ \"coordinate_system\" ][ \"x_labels_stop\" ], y_l , self . visualisation_data [ \"useq_label\" ]) # main_CDS canvas . setLineWidth ( self . parameters . arguments [ \"orf_line_width\" ]) canvas . setStrokeColorRGB ( * uorf4u . methods . get_color ( \"cds_seq_stroke_color\" , self . parameters . arguments )) canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"cds_seq_fill_color\" , self . parameters . arguments )) p = canvas . beginPath () p . moveTo ( self . visualisation_data [ \"main_CDS_stop_x\" ], y_c - orf_height / 2 ) p . lineTo ( self . visualisation_data [ \"main_CDS_start_x\" ], y_c - orf_height / 2 ) p . lineTo ( self . visualisation_data [ \"main_CDS_start_x\" ], y_c + orf_height / 2 ) p . lineTo ( self . visualisation_data [ \"main_CDS_stop_x\" ], y_c + orf_height / 2 ) canvas . drawPath ( p , stroke = 1 , fill = 1 ) # Other ORFs: for orf in self . visualisation_data [ \"annotated_orfs\" ]: orf_dict = self . visualisation_data [ \"orfs_coordinates_dict\" ][ orf ] if orf != self . visualisation_data [ \"conserved_orf\" ]: fill_color = None stroke_color = uorf4u . methods . get_color ( \"other_uorfs_stroke_color\" , self . parameters . arguments ) else : fill_color = uorf4u . methods . get_color ( \"conserved_uorfs_fill_color\" , self . parameters . arguments ) stroke_color = uorf4u . methods . get_color ( \"conserved_uorfs_stroke_color\" , self . parameters . arguments ) self . orf_object ( canvas , orf_dict [ \"x_start\" ], orf_dict [ \"x_stop\" ], y_c , orf_dict [ \"strand\" ], orf_height , orf_dict [ \"left_out\" ], orf_dict [ \"right_out\" ], fill_color , stroke_color ) # Annotated in RefSeq CDSs if self . parameters . arguments [ \"check_assembly_annotation\" ] and \\ \"fasta\" not in self . parameters . cmd_arguments . keys (): fill_color = None stroke_color = uorf4u . methods . get_color ( \"annotated_orf_stroke_color\" , self . parameters . arguments ) for protein_id , cds_dict in self . visualisation_data [ \"CDSs_coordinates_dict\" ] . items (): self . orf_object ( canvas , cds_dict [ \"x_start\" ], cds_dict [ \"x_stop\" ], y_c , cds_dict [ \"strand\" ], orf_height , cds_dict [ \"left_out\" ], cds_dict [ \"right_out\" ], fill_color , stroke_color ) return None","title":"draw()"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.SequenceVis.needed_y_space","text":"Calculate needed vertical space for a SequenceVis track. Returns: float ( float ) \u2013 needed vertical space. Source code in uorf4u/drawing_annotation.py 258 259 260 261 262 263 264 265 266 def needed_y_space ( self ) -> float : \"\"\"Calculate needed vertical space for a SequenceVis track. Returns: float: needed vertical space. \"\"\" self . needed_space = self . parameters . arguments [ \"orf_height\" ] * cm return self . needed_space","title":"needed_y_space()"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.SequenceVis.orf_object","text":"Method for drawing an ORF's polygon. Parameters: canvas ( reportlab . pdfgen . canvas . Canvas ) \u2013 a pdf object. x_start ( float ) \u2013 ORF's start coordinate (already transformed to pdf's) x_stop ( float ) \u2013 ORF's stop coordinate (already transformed to pdf's) y_c ( float ) \u2013 (float): centred y coordinate of a current track. strand ( str ) \u2013 strand of an ORF. height ( float ) \u2013 height of a polygon. left_out ( bool ) \u2013 whether an ORF is out of range on the left. right_out ( bool ) \u2013 whether an ORF is out of range on the right. fill_color ( str ) \u2013 fill color of a polygon. stroke_color ( str ) \u2013 stroke color of a polygon. Returns: None \u2013 None Source code in uorf4u/drawing_annotation.py 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 def orf_object ( self , canvas : reportlab . pdfgen . canvas . Canvas , x_start : float , x_stop : float , y_c : float , strand : str , height : float , left_out : bool , right_out : bool , fill_color : str , stroke_color : str ) -> None : \"\"\"Method for drawing an ORF's polygon. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. x_start (float): ORF's start coordinate (already transformed to pdf's) x_stop (float): ORF's stop coordinate (already transformed to pdf's) y_c: (float): centred y coordinate of a current track. strand (str): strand of an ORF. height (float): height of a polygon. left_out (bool): whether an ORF is out of range on the left. right_out (bool): whether an ORF is out of range on the right. fill_color (str): fill color of a polygon. stroke_color (str): stroke color of a polygon. Returns: None \"\"\" fill , stroke = 0 , 0 if stroke_color : canvas . setStrokeColorRGB ( * stroke_color ) stroke = 1 if fill_color : canvas . setFillColorRGB ( * fill_color ) fill = 1 arrow_length = min ( height , ( x_stop - x_start )) p = canvas . beginPath () if strand == \"+\" and not left_out and not right_out : p . moveTo ( x_start , y_c ) p . lineTo ( x_start , y_c + height / 2 ) p . lineTo ( x_stop - arrow_length , y_c + height / 2 ) p . lineTo ( x_stop , y_c ) p . lineTo ( x_stop - arrow_length , y_c - height / 2 ) p . lineTo ( x_start , y_c - height / 2 ) p . lineTo ( x_start , y_c ) elif strand == \"+\" and left_out and not right_out : p . moveTo ( x_start , y_c + height / 2 ) p . lineTo ( x_stop - arrow_length , y_c + height / 2 ) p . lineTo ( x_stop , y_c ) p . lineTo ( x_stop - arrow_length , y_c - height / 2 ) p . lineTo ( x_start , y_c - height / 2 ) elif strand == \"+\" and right_out and not left_out : p . moveTo ( x_stop , y_c + height / 2 ) p . lineTo ( x_start , y_c + height / 2 ) p . lineTo ( x_start , y_c - height / 2 ) p . lineTo ( x_stop , y_c - height / 2 ) elif strand == \"-\" and not left_out and not right_out : p . moveTo ( x_stop , y_c ) p . lineTo ( x_stop , y_c + height / 2 ) p . lineTo ( x_start + arrow_length , y_c + height / 2 ) p . lineTo ( x_start , y_c ) p . lineTo ( x_start + arrow_length , y_c - height / 2 ) p . lineTo ( x_stop , y_c - height / 2 ) p . lineTo ( x_stop , y_c ) elif strand == \"-\" and right_out and not left_out : p . moveTo ( x_stop , y_c + height / 2 ) p . lineTo ( x_start + arrow_length , y_c + height / 2 ) p . lineTo ( x_start , y_c ) p . lineTo ( x_start + arrow_length , y_c - height / 2 ) p . lineTo ( x_stop , y_c - height / 2 ) elif strand == \"-\" and left_out and not right_out : p . moveTo ( x_start , y_c + height / 2 ) p . lineTo ( x_stop , y_c + height / 2 ) p . lineTo ( x_stop , y_c - height / 2 ) p . lineTo ( x_start , y_c - height / 2 ) canvas . drawPath ( p , stroke = stroke , fill = fill )","title":"orf_object()"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.SequencesLoader","text":"Bases: Loader A SequencesLoader object prepares data for a Sequence track object. Attributes: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. prepared_data ( dict ) \u2013 dict with data needed for a visualisation track. Source code in uorf4u/drawing_annotation.py 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 class SequencesLoader ( Loader ): \"\"\"A SequencesLoader object prepares data for a Sequence track object. Attributes: parameters (uorf4u.manager.Parameters): Parameters' class object. prepared_data (dict): dict with data needed for a visualisation track. \"\"\" def __init__ ( self , parameters ): \"\"\"Create a SequenceLoader object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( parameters ) def prepare_data ( self , upstream_sequence : Bio . SeqRecord . SeqRecord , conserved_orf , coordinate_system : dict , additional_data : dict ) -> dict : \"\"\"Prepare data for a Title visualisation track. Attributes: upstream_sequence (dict): upstream sequence' data. conserved_orf (uorf4u.data_processing.ORF): conserved ORF on the upstream sequence. coordinate_system (dict): coordinate system of a figure page. additional_data (dict): data needed for a track initialisation. Returns: dict: dictionary with prepared data for visualisation. \"\"\" prepared_data = dict () max_upstream_sequence_length = additional_data [ \"max_upstream_sequence_length\" ] prepared_data [ \"coordinate_system\" ] = coordinate_system prepared_data [ \"label_font_size\" ] = additional_data [ \"label_font_size\" ] prepared_data [ \"label_right_border\" ] = coordinate_system [ \"x_labels_stop\" ] prepared_data [ \"upstream_sequence_line_start_x\" ] = coordinate_system [ \"x_annotation_start\" ] + \\ (( max_upstream_sequence_length - upstream_sequence . annotations [ \"upstream_region_length\" ]) * \\ coordinate_system [ \"transformation_coef\" ]) prepared_data [ \"upstream_sequence_line_stop_x\" ] = coordinate_system [ \"x_annotation_start\" ] + \\ ( max_upstream_sequence_length * coordinate_system [ \"transformation_coef\" ]) prepared_data [ \"main_CDS_start_x\" ] = coordinate_system [ \"x_annotation_start\" ] + \\ ( max_upstream_sequence_length * coordinate_system [ \"transformation_coef\" ]) prepared_data [ \"main_CDS_stop_x\" ] = coordinate_system [ \"x_annotation_start\" ] + \\ (( max_upstream_sequence_length + upstream_sequence . annotations [ \"downstream_region_length\" ]) * coordinate_system [ \"transformation_coef\" ]) prepared_data [ \"orfs_coordinates_dict\" ] = { k : v for k , v in zip ( upstream_sequence . annotations [ \"ORFs\" ], [ self . calculate_orf_position ( i . start , i . stop , \"+\" , upstream_sequence , max_upstream_sequence_length , coordinate_system ) for i in upstream_sequence . annotations [ \"ORFs\" ]])} prepared_data [ \"useq_label\" ] = upstream_sequence . annotations [ \"label\" ] prepared_data [ \"annotated_orfs\" ] = [ orf for orf in upstream_sequence . annotations [ \"ORFs\" ] if orf != conserved_orf ] prepared_data [ \"annotated_orfs\" ] . append ( conserved_orf ) prepared_data [ \"conserved_orf\" ] = conserved_orf if self . parameters . arguments [ \"check_assembly_annotation\" ] and upstream_sequence . annotations [ \"RefSeq\" ]: prepared_data [ \"CDSs\" ] = [ i for i in upstream_sequence . annotations [ \"locus_annotation\" ] . CDSs if i [ \"relative_start\" ] != upstream_sequence . annotations [ \"upstream_region_length\" ]] prepared_data [ \"CDSs_coordinates_dict\" ] = { k : v for k , v in zip ([ i [ \"protein_id\" ] for i in prepared_data [ \"CDSs\" ]], [ self . calculate_orf_position ( i [ \"relative_start\" ], i [ \"relative_stop\" ], i [ \"relative_strand\" ], upstream_sequence , max_upstream_sequence_length , coordinate_system ) for i in prepared_data [ \"CDSs\" ]])} else : prepared_data [ \"CDSs\" ] = None self . prepared_data = prepared_data return prepared_data def calculate_orf_position ( self , start : int , stop : int , strand : str , useq : Bio . SeqRecord . SeqRecord , max_upstream_sequence_length : int , coordinate_system : dict ) -> dict : \"\"\"Transform an ORF's nucleotide coordinates to pdf's coordinates. Arguments: start (int): start coordinate in nt. stop (int): stop coordinate in nt. strand (str): strand of an ORF. useq (dict): current upstream sequence. max_upstream_sequence_length (int): max length of upstream sequences for visualisation. coordinate_system (dict): coordinate system of a figure. Returns: dict: transformed orf's coordinates. \"\"\" orf_coordinates = dict () orf_coordinates [ \"x_start\" ] = coordinate_system [ \"x_annotation_start\" ] + ( max ( 0 , start ) + ( max_upstream_sequence_length - useq . annotations [ \"upstream_region_length\" ])) * \\ coordinate_system [ \"transformation_coef\" ] orf_coordinates [ \"x_stop\" ] = coordinate_system [ \"x_annotation_start\" ] + ( min ( stop , useq . annotations [ \"length\" ]) + ( max_upstream_sequence_length - useq . annotations [ \"upstream_region_length\" ])) * \\ coordinate_system [ \"transformation_coef\" ] orf_coordinates [ \"strand\" ] = strand orf_coordinates [ \"left_out\" ] = start < 0 orf_coordinates [ \"right_out\" ] = stop > useq . annotations [ \"length\" ] return orf_coordinates def create_track ( self ) -> SequenceVis : \"\"\"Initialise a Sequence track object. Returns: SequenceVis: visualisation track. \"\"\" return SequenceVis ( self . prepared_data , self . parameters )","title":"SequencesLoader"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.SequencesLoader.__init__","text":"Create a SequenceLoader object. Parameters: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing_annotation.py 585 586 587 588 589 590 591 592 def __init__ ( self , parameters ): \"\"\"Create a SequenceLoader object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( parameters )","title":"__init__()"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.SequencesLoader.calculate_orf_position","text":"Transform an ORF's nucleotide coordinates to pdf's coordinates. Parameters: start ( int ) \u2013 start coordinate in nt. stop ( int ) \u2013 stop coordinate in nt. strand ( str ) \u2013 strand of an ORF. useq ( dict ) \u2013 current upstream sequence. max_upstream_sequence_length ( int ) \u2013 max length of upstream sequences for visualisation. coordinate_system ( dict ) \u2013 coordinate system of a figure. Returns: dict ( dict ) \u2013 transformed orf's coordinates. Source code in uorf4u/drawing_annotation.py 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 def calculate_orf_position ( self , start : int , stop : int , strand : str , useq : Bio . SeqRecord . SeqRecord , max_upstream_sequence_length : int , coordinate_system : dict ) -> dict : \"\"\"Transform an ORF's nucleotide coordinates to pdf's coordinates. Arguments: start (int): start coordinate in nt. stop (int): stop coordinate in nt. strand (str): strand of an ORF. useq (dict): current upstream sequence. max_upstream_sequence_length (int): max length of upstream sequences for visualisation. coordinate_system (dict): coordinate system of a figure. Returns: dict: transformed orf's coordinates. \"\"\" orf_coordinates = dict () orf_coordinates [ \"x_start\" ] = coordinate_system [ \"x_annotation_start\" ] + ( max ( 0 , start ) + ( max_upstream_sequence_length - useq . annotations [ \"upstream_region_length\" ])) * \\ coordinate_system [ \"transformation_coef\" ] orf_coordinates [ \"x_stop\" ] = coordinate_system [ \"x_annotation_start\" ] + ( min ( stop , useq . annotations [ \"length\" ]) + ( max_upstream_sequence_length - useq . annotations [ \"upstream_region_length\" ])) * \\ coordinate_system [ \"transformation_coef\" ] orf_coordinates [ \"strand\" ] = strand orf_coordinates [ \"left_out\" ] = start < 0 orf_coordinates [ \"right_out\" ] = stop > useq . annotations [ \"length\" ] return orf_coordinates","title":"calculate_orf_position()"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.SequencesLoader.create_track","text":"Initialise a Sequence track object. Returns: SequenceVis ( SequenceVis ) \u2013 visualisation track. Source code in uorf4u/drawing_annotation.py 686 687 688 689 690 691 692 693 def create_track ( self ) -> SequenceVis : \"\"\"Initialise a Sequence track object. Returns: SequenceVis: visualisation track. \"\"\" return SequenceVis ( self . prepared_data , self . parameters )","title":"create_track()"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.SequencesLoader.prepare_data","text":"Prepare data for a Title visualisation track. Attributes: upstream_sequence ( dict ) \u2013 upstream sequence' data. conserved_orf ( uorf4u . data_processing . ORF ) \u2013 conserved ORF on the upstream sequence. coordinate_system ( dict ) \u2013 coordinate system of a figure page. additional_data ( dict ) \u2013 data needed for a track initialisation. Returns: dict ( dict ) \u2013 dictionary with prepared data for visualisation. Source code in uorf4u/drawing_annotation.py 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 def prepare_data ( self , upstream_sequence : Bio . SeqRecord . SeqRecord , conserved_orf , coordinate_system : dict , additional_data : dict ) -> dict : \"\"\"Prepare data for a Title visualisation track. Attributes: upstream_sequence (dict): upstream sequence' data. conserved_orf (uorf4u.data_processing.ORF): conserved ORF on the upstream sequence. coordinate_system (dict): coordinate system of a figure page. additional_data (dict): data needed for a track initialisation. Returns: dict: dictionary with prepared data for visualisation. \"\"\" prepared_data = dict () max_upstream_sequence_length = additional_data [ \"max_upstream_sequence_length\" ] prepared_data [ \"coordinate_system\" ] = coordinate_system prepared_data [ \"label_font_size\" ] = additional_data [ \"label_font_size\" ] prepared_data [ \"label_right_border\" ] = coordinate_system [ \"x_labels_stop\" ] prepared_data [ \"upstream_sequence_line_start_x\" ] = coordinate_system [ \"x_annotation_start\" ] + \\ (( max_upstream_sequence_length - upstream_sequence . annotations [ \"upstream_region_length\" ]) * \\ coordinate_system [ \"transformation_coef\" ]) prepared_data [ \"upstream_sequence_line_stop_x\" ] = coordinate_system [ \"x_annotation_start\" ] + \\ ( max_upstream_sequence_length * coordinate_system [ \"transformation_coef\" ]) prepared_data [ \"main_CDS_start_x\" ] = coordinate_system [ \"x_annotation_start\" ] + \\ ( max_upstream_sequence_length * coordinate_system [ \"transformation_coef\" ]) prepared_data [ \"main_CDS_stop_x\" ] = coordinate_system [ \"x_annotation_start\" ] + \\ (( max_upstream_sequence_length + upstream_sequence . annotations [ \"downstream_region_length\" ]) * coordinate_system [ \"transformation_coef\" ]) prepared_data [ \"orfs_coordinates_dict\" ] = { k : v for k , v in zip ( upstream_sequence . annotations [ \"ORFs\" ], [ self . calculate_orf_position ( i . start , i . stop , \"+\" , upstream_sequence , max_upstream_sequence_length , coordinate_system ) for i in upstream_sequence . annotations [ \"ORFs\" ]])} prepared_data [ \"useq_label\" ] = upstream_sequence . annotations [ \"label\" ] prepared_data [ \"annotated_orfs\" ] = [ orf for orf in upstream_sequence . annotations [ \"ORFs\" ] if orf != conserved_orf ] prepared_data [ \"annotated_orfs\" ] . append ( conserved_orf ) prepared_data [ \"conserved_orf\" ] = conserved_orf if self . parameters . arguments [ \"check_assembly_annotation\" ] and upstream_sequence . annotations [ \"RefSeq\" ]: prepared_data [ \"CDSs\" ] = [ i for i in upstream_sequence . annotations [ \"locus_annotation\" ] . CDSs if i [ \"relative_start\" ] != upstream_sequence . annotations [ \"upstream_region_length\" ]] prepared_data [ \"CDSs_coordinates_dict\" ] = { k : v for k , v in zip ([ i [ \"protein_id\" ] for i in prepared_data [ \"CDSs\" ]], [ self . calculate_orf_position ( i [ \"relative_start\" ], i [ \"relative_stop\" ], i [ \"relative_strand\" ], upstream_sequence , max_upstream_sequence_length , coordinate_system ) for i in prepared_data [ \"CDSs\" ]])} else : prepared_data [ \"CDSs\" ] = None self . prepared_data = prepared_data return prepared_data","title":"prepare_data()"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.TicsVis","text":"Bases: Track TicsVis track draws axis tics. Attributes: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. needed_space ( float ) \u2013 needed vertical space for a track. Source code in uorf4u/drawing_annotation.py 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 class TicsVis ( Track ): \"\"\"TicsVis track draws axis tics. Attributes: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. needed_space (float): needed vertical space for a track. \"\"\" def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Create a TicsVis object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( visualisation_data , parameters ) self . needed_space = None def needed_y_space ( self ) -> float : \"\"\"Calculate needed vertical space for a SequenceVis track. Returns: float: needed vertical space. \"\"\" font_type = \"regular\" reportlab . pdfbase . pdfmetrics . registerFont ( reportlab . pdfbase . ttfonts . TTFont ( font_type , self . parameters . arguments [ f \"font_ { font_type } \" ])) face = reportlab . pdfbase . pdfmetrics . getFont ( \"regular\" ) . face if self . parameters . arguments [ \"axis_tics_font_size\" ] == \"auto\" : text_height = self . parameters . arguments [ \"label_height_to_orf_height\" ] * self . parameters . arguments [ \"orf_height\" ] * cm font_size = uorf4u . methods . string_height_to_font_size ( text_height , \"regular\" , self . parameters . arguments ) self . parameters . arguments [ \"axis_tics_font_size\" ] = font_size else : text_height = ( self . parameters . arguments [ \"axis_tics_font_size\" ] * ( face . ascent - face . descent )) / ( 1000 * 1.38 ) self . visualisation_data [ \"tics_height\" ] = 0.7 * text_height self . visualisation_data [ \"text_space\" ] = 1.2 * text_height self . needed_space = self . visualisation_data [ \"tics_height\" ] + self . visualisation_data [ \"text_space\" ] return self . needed_space def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Draw an AxisTics track. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" y_top = self . visualisation_data [ \"y_top\" ] canvas . setLineCap ( 2 ) canvas . setLineWidth ( self . parameters . arguments [ \"axis_tics_line_width\" ]) canvas . setStrokeColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFont ( \"regular\" , self . parameters . arguments [ \"axis_tics_font_size\" ]) canvas . line ( self . visualisation_data [ \"coordinate_system\" ][ \"x_annotation_start\" ], y_top , self . visualisation_data [ \"coordinate_system\" ][ \"x_annotation_stop\" ], y_top ) for tic_label , tic_position in self . visualisation_data [ \"tics\" ] . items (): canvas . line ( tic_position , y_top , tic_position , y_top - self . visualisation_data [ \"tics_height\" ]) if tic_label == - self . visualisation_data [ \"max_upstream_sequence_length\" ]: canvas . drawString ( tic_position , y_top - ( self . visualisation_data [ \"tics_height\" ] + self . visualisation_data [ \"text_space\" ]), str ( tic_label )) elif tic_label == self . visualisation_data [ \"max_downstream_sequence_length\" ]: canvas . drawRightString ( tic_position , y_top - ( self . visualisation_data [ \"tics_height\" ] + self . visualisation_data [ \"text_space\" ]), str ( tic_label )) else : canvas . drawCentredString ( tic_position , y_top - ( self . visualisation_data [ \"tics_height\" ] + self . visualisation_data [ \"text_space\" ]), str ( tic_label ))","title":"TicsVis"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.TicsVis.__init__","text":"Create a TicsVis object. Parameters: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing_annotation.py 421 422 423 424 425 426 427 428 429 430 def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Create a TicsVis object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( visualisation_data , parameters ) self . needed_space = None","title":"__init__()"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.TicsVis.draw","text":"Draw an AxisTics track. Parameters: canvas ( reportlab . pdfgen . canvas . Canvas ) \u2013 a pdf object. Returns: None \u2013 None Source code in uorf4u/drawing_annotation.py 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Draw an AxisTics track. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" y_top = self . visualisation_data [ \"y_top\" ] canvas . setLineCap ( 2 ) canvas . setLineWidth ( self . parameters . arguments [ \"axis_tics_line_width\" ]) canvas . setStrokeColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFont ( \"regular\" , self . parameters . arguments [ \"axis_tics_font_size\" ]) canvas . line ( self . visualisation_data [ \"coordinate_system\" ][ \"x_annotation_start\" ], y_top , self . visualisation_data [ \"coordinate_system\" ][ \"x_annotation_stop\" ], y_top ) for tic_label , tic_position in self . visualisation_data [ \"tics\" ] . items (): canvas . line ( tic_position , y_top , tic_position , y_top - self . visualisation_data [ \"tics_height\" ]) if tic_label == - self . visualisation_data [ \"max_upstream_sequence_length\" ]: canvas . drawString ( tic_position , y_top - ( self . visualisation_data [ \"tics_height\" ] + self . visualisation_data [ \"text_space\" ]), str ( tic_label )) elif tic_label == self . visualisation_data [ \"max_downstream_sequence_length\" ]: canvas . drawRightString ( tic_position , y_top - ( self . visualisation_data [ \"tics_height\" ] + self . visualisation_data [ \"text_space\" ]), str ( tic_label )) else : canvas . drawCentredString ( tic_position , y_top - ( self . visualisation_data [ \"tics_height\" ] + self . visualisation_data [ \"text_space\" ]), str ( tic_label ))","title":"draw()"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.TicsVis.needed_y_space","text":"Calculate needed vertical space for a SequenceVis track. Returns: float ( float ) \u2013 needed vertical space. Source code in uorf4u/drawing_annotation.py 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 def needed_y_space ( self ) -> float : \"\"\"Calculate needed vertical space for a SequenceVis track. Returns: float: needed vertical space. \"\"\" font_type = \"regular\" reportlab . pdfbase . pdfmetrics . registerFont ( reportlab . pdfbase . ttfonts . TTFont ( font_type , self . parameters . arguments [ f \"font_ { font_type } \" ])) face = reportlab . pdfbase . pdfmetrics . getFont ( \"regular\" ) . face if self . parameters . arguments [ \"axis_tics_font_size\" ] == \"auto\" : text_height = self . parameters . arguments [ \"label_height_to_orf_height\" ] * self . parameters . arguments [ \"orf_height\" ] * cm font_size = uorf4u . methods . string_height_to_font_size ( text_height , \"regular\" , self . parameters . arguments ) self . parameters . arguments [ \"axis_tics_font_size\" ] = font_size else : text_height = ( self . parameters . arguments [ \"axis_tics_font_size\" ] * ( face . ascent - face . descent )) / ( 1000 * 1.38 ) self . visualisation_data [ \"tics_height\" ] = 0.7 * text_height self . visualisation_data [ \"text_space\" ] = 1.2 * text_height self . needed_space = self . visualisation_data [ \"tics_height\" ] + self . visualisation_data [ \"text_space\" ] return self . needed_space","title":"needed_y_space()"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.TitleLoader","text":"Bases: Loader A TitleLoader object prepares data for a Title track object. Note: Title track currently is not available. Attributes: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. prepared_data ( dict ) \u2013 dict with data needed for a visualisation track. Source code in uorf4u/drawing_annotation.py 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 class TitleLoader ( Loader ): \"\"\"A TitleLoader object prepares data for a Title track object. Note: Title track currently is not available. Attributes: parameters (uorf4u.manager.Parameters): Parameters' class object. prepared_data (dict): dict with data needed for a visualisation track. \"\"\" def __init__ ( self , parameters ): \"\"\"Create a TitleLoader object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( parameters ) def prepare_data ( self , coordinate_system : dict , additional_data : dict ) -> dict : \"\"\"Prepare data for Title visualisation track. Attributes: coordinate_system (dict): coordinate system of a figure page. additional_data (dict): data needed for a track initialisation. Returns: dict: dictionary with prepared data for visualisation. \"\"\" prepared_data = dict () prepared_data [ \"title\" ] = \"Title Testing\" prepared_data [ \"coordinate_system\" ] = coordinate_system self . prepared_data = prepared_data return prepared_data def create_track ( self ) -> TitleVis : \"\"\"Initialise a Title track object. Returns: TitleVis: visualisation track. \"\"\" return TitleVis ( self . prepared_data , self . parameters )","title":"TitleLoader"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.TitleLoader.__init__","text":"Create a TitleLoader object. Parameters: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing_annotation.py 539 540 541 542 543 544 545 546 def __init__ ( self , parameters ): \"\"\"Create a TitleLoader object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( parameters )","title":"__init__()"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.TitleLoader.create_track","text":"Initialise a Title track object. Returns: TitleVis ( TitleVis ) \u2013 visualisation track. Source code in uorf4u/drawing_annotation.py 565 566 567 568 569 570 571 572 def create_track ( self ) -> TitleVis : \"\"\"Initialise a Title track object. Returns: TitleVis: visualisation track. \"\"\" return TitleVis ( self . prepared_data , self . parameters )","title":"create_track()"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.TitleLoader.prepare_data","text":"Prepare data for Title visualisation track. Attributes: coordinate_system ( dict ) \u2013 coordinate system of a figure page. additional_data ( dict ) \u2013 data needed for a track initialisation. Returns: dict ( dict ) \u2013 dictionary with prepared data for visualisation. Source code in uorf4u/drawing_annotation.py 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 def prepare_data ( self , coordinate_system : dict , additional_data : dict ) -> dict : \"\"\"Prepare data for Title visualisation track. Attributes: coordinate_system (dict): coordinate system of a figure page. additional_data (dict): data needed for a track initialisation. Returns: dict: dictionary with prepared data for visualisation. \"\"\" prepared_data = dict () prepared_data [ \"title\" ] = \"Title Testing\" prepared_data [ \"coordinate_system\" ] = coordinate_system self . prepared_data = prepared_data return prepared_data","title":"prepare_data()"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.TitleVis","text":"Bases: Track Title visualisation track object draws figure's title. Note: This track currently is not supported. Attributes: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing_annotation.py 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 class TitleVis ( Track ): \"\"\"Title visualisation track object draws figure's title. Note: This track currently is not supported. Attributes: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Create TitleVis object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . visualisation_data = visualisation_data self . parameters = parameters def needed_y_space ( self ) -> float : \"\"\"Calculate needed vertical space for a Title track. Returns: float: needed vertical space. \"\"\" font_type = self . parameters . arguments [ \"title_font_type\" ] reportlab . pdfbase . pdfmetrics . registerFont ( reportlab . pdfbase . ttfonts . TTFont ( font_type , self . parameters . arguments [ f \"font_ { font_type } \" ])) face = reportlab . pdfbase . pdfmetrics . getFont ( font_type ) . face if self . parameters . arguments [ \"title_font_size\" ] == \"auto\" : text_height = self . parameters . arguments [ \"orf_height\" ] * cm font_size = uorf4u . methods . string_height_to_font_size ( text_height , font_type , self . parameters . arguments ) self . parameters . arguments [ \"title_font_size\" ] = font_size else : text_height = ( self . parameters . arguments [ \"title_font_size\" ] * ( face . ascent - face . descent )) / ( 1000 * 1.38 ) self . visualisation_data [ \"text_height\" ] = text_height self . needed_space = text_height * 1.2 return self . needed_space def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Draw a Title track. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" x_left_border = self . visualisation_data [ \"coordinate_system\" ][ \"x_labels_start\" ] # x_left_border = self.visualisation_data[\"coordinate_system\"][\"x_annotation_start\"] canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFont ( self . parameters . arguments [ \"title_font_type\" ], self . parameters . arguments [ \"title_font_size\" ]) canvas . drawString ( x_left_border , self . visualisation_data [ \"y_top\" ] - self . visualisation_data [ \"text_height\" ], self . visualisation_data [ \"title\" ])","title":"TitleVis"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.TitleVis.__init__","text":"Create TitleVis object. Parameters: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing_annotation.py 186 187 188 189 190 191 192 193 194 195 def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Create TitleVis object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . visualisation_data = visualisation_data self . parameters = parameters","title":"__init__()"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.TitleVis.draw","text":"Draw a Title track. Parameters: canvas ( reportlab . pdfgen . canvas . Canvas ) \u2013 a pdf object. Returns: None \u2013 None Source code in uorf4u/drawing_annotation.py 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Draw a Title track. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" x_left_border = self . visualisation_data [ \"coordinate_system\" ][ \"x_labels_start\" ] # x_left_border = self.visualisation_data[\"coordinate_system\"][\"x_annotation_start\"] canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFont ( self . parameters . arguments [ \"title_font_type\" ], self . parameters . arguments [ \"title_font_size\" ]) canvas . drawString ( x_left_border , self . visualisation_data [ \"y_top\" ] - self . visualisation_data [ \"text_height\" ], self . visualisation_data [ \"title\" ])","title":"draw()"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.TitleVis.needed_y_space","text":"Calculate needed vertical space for a Title track. Returns: float ( float ) \u2013 needed vertical space. Source code in uorf4u/drawing_annotation.py 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 def needed_y_space ( self ) -> float : \"\"\"Calculate needed vertical space for a Title track. Returns: float: needed vertical space. \"\"\" font_type = self . parameters . arguments [ \"title_font_type\" ] reportlab . pdfbase . pdfmetrics . registerFont ( reportlab . pdfbase . ttfonts . TTFont ( font_type , self . parameters . arguments [ f \"font_ { font_type } \" ])) face = reportlab . pdfbase . pdfmetrics . getFont ( font_type ) . face if self . parameters . arguments [ \"title_font_size\" ] == \"auto\" : text_height = self . parameters . arguments [ \"orf_height\" ] * cm font_size = uorf4u . methods . string_height_to_font_size ( text_height , font_type , self . parameters . arguments ) self . parameters . arguments [ \"title_font_size\" ] = font_size else : text_height = ( self . parameters . arguments [ \"title_font_size\" ] * ( face . ascent - face . descent )) / ( 1000 * 1.38 ) self . visualisation_data [ \"text_height\" ] = text_height self . needed_space = text_height * 1.2 return self . needed_space","title":"needed_y_space()"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.Track","text":"Parent clas for visualisation Tracks. Attributes: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing_annotation.py 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 class Track : \"\"\"Parent clas for visualisation Tracks. Attributes: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Parent's constructor for creating a Track object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . visualisation_data = visualisation_data self . parameters = parameters def needed_y_space ( self ) -> None : \"\"\"Empy parent's method for calculation needed vertical space for a track. Returns: None \"\"\" pass def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Empy parent's method for track visualisation. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" pass","title":"Track"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.Track.__init__","text":"Parent's constructor for creating a Track object. Parameters: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing_annotation.py 142 143 144 145 146 147 148 149 150 151 def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Parent's constructor for creating a Track object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . visualisation_data = visualisation_data self . parameters = parameters","title":"__init__()"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.Track.draw","text":"Empy parent's method for track visualisation. Parameters: canvas ( reportlab . pdfgen . canvas . Canvas ) \u2013 a pdf object. Returns: None \u2013 None Source code in uorf4u/drawing_annotation.py 162 163 164 165 166 167 168 169 170 171 def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Empy parent's method for track visualisation. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" pass","title":"draw()"},{"location":"API/package_drawing/#uorf4u.drawing_annotation.Track.needed_y_space","text":"Empy parent's method for calculation needed vertical space for a track. Returns: None \u2013 None Source code in uorf4u/drawing_annotation.py 153 154 155 156 157 158 159 160 def needed_y_space ( self ) -> None : \"\"\"Empy parent's method for calculation needed vertical space for a track. Returns: None \"\"\" pass This module provides visualisation of loci annotation.","title":"needed_y_space()"},{"location":"API/package_drawing/#uorf4u.drawing_msa.Image","text":"An Image object holds pdf. Attributes: canvas ( reportlab . pdfgen . canvas . Canvas ) \u2013 pdf object of the reportlab library. Source code in uorf4u/drawing_msa.py 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 class Image : \"\"\"An Image object holds pdf. Attributes: canvas (reportlab.pdfgen.canvas.Canvas): pdf object of the reportlab library. \"\"\" def __init__ ( self , filename : str , width : float , height : float ): \"\"\"Create an Image object. Arguments: filename (str): path and name of a pdf. width (float): width of a pdf. height (float): height of a pdf. \"\"\" self . canvas = reportlab . pdfgen . canvas . Canvas ( filename , pagesize = ( width , height )) def save ( self ) -> None : \"\"\"Save a pdf file. Returns: None \"\"\" self . canvas . save () return None","title":"Image"},{"location":"API/package_drawing/#uorf4u.drawing_msa.Image.__init__","text":"Create an Image object. Parameters: filename ( str ) \u2013 path and name of a pdf. width ( float ) \u2013 width of a pdf. height ( float ) \u2013 height of a pdf. Source code in uorf4u/drawing_msa.py 335 336 337 338 339 340 341 342 343 344 def __init__ ( self , filename : str , width : float , height : float ): \"\"\"Create an Image object. Arguments: filename (str): path and name of a pdf. width (float): width of a pdf. height (float): height of a pdf. \"\"\" self . canvas = reportlab . pdfgen . canvas . Canvas ( filename , pagesize = ( width , height ))","title":"__init__()"},{"location":"API/package_drawing/#uorf4u.drawing_msa.Image.save","text":"Save a pdf file. Returns: None \u2013 None Source code in uorf4u/drawing_msa.py 346 347 348 349 350 351 352 353 354 def save ( self ) -> None : \"\"\"Save a pdf file. Returns: None \"\"\" self . canvas . save () return None","title":"save()"},{"location":"API/package_drawing/#uorf4u.drawing_msa.Loader","text":"Parent class for tracks loaders. Attributes: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. prepared_data ( dict ) \u2013 dict with data needed for visualisation tracks. Source code in uorf4u/drawing_msa.py 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 class Loader : \"\"\"Parent class for tracks loaders. Attributes: parameters (uorf4u.manager.Parameters): Parameters' class object. prepared_data (dict): dict with data needed for visualisation tracks. \"\"\" def __init__ ( self , parameters : uorf4u . manager . Parameters ): \"\"\"Parent's constructor for creating a Loader class object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . parameters = parameters self . prepared_data = None def prepare_data ( self ) -> None : \"\"\"Empty parent's method for data preparation. Returns: None \"\"\" pass def create_track ( self ) -> None : \"\"\"Empty parent's method for initialisation of a track. Returns: None \"\"\" pass","title":"Loader"},{"location":"API/package_drawing/#uorf4u.drawing_msa.Loader.__init__","text":"Parent's constructor for creating a Loader class object. Parameters: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing_msa.py 245 246 247 248 249 250 251 252 def __init__ ( self , parameters : uorf4u . manager . Parameters ): \"\"\"Parent's constructor for creating a Loader class object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . parameters = parameters self . prepared_data = None","title":"__init__()"},{"location":"API/package_drawing/#uorf4u.drawing_msa.Loader.create_track","text":"Empty parent's method for initialisation of a track. Returns: None \u2013 None Source code in uorf4u/drawing_msa.py 263 264 265 266 267 268 269 270 def create_track ( self ) -> None : \"\"\"Empty parent's method for initialisation of a track. Returns: None \"\"\" pass","title":"create_track()"},{"location":"API/package_drawing/#uorf4u.drawing_msa.Loader.prepare_data","text":"Empty parent's method for data preparation. Returns: None \u2013 None Source code in uorf4u/drawing_msa.py 254 255 256 257 258 259 260 261 def prepare_data ( self ) -> None : \"\"\"Empty parent's method for data preparation. Returns: None \"\"\" pass","title":"prepare_data()"},{"location":"API/package_drawing/#uorf4u.drawing_msa.MSAPlotManager","text":"AnnotationPlotManager object holds needed information for annotation visualisation and controls it. Note: It's supposed that the AnnotationPlotManager' objects will not be used directly by API users since visualisation can be controlled by 'plot_annotation' method. Attributes: msa ( FILL IN ) \u2013 Path class' multiple sequence alignment. upstream_sequences ( list ) \u2013 list of dicts with information about upstream sequences. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. coordinate_system ( dict ) \u2013 coordinate system of figure. additional_data ( dict ) \u2013 dict with data for visualisation tracks. Source code in uorf4u/drawing_msa.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 class MSAPlotManager : \"\"\" AnnotationPlotManager object holds needed information for annotation visualisation and controls it. Note: It's supposed that the AnnotationPlotManager' objects will not be used directly by API users since visualisation can be controlled by 'plot_annotation' method. Attributes: msa (FILL IN): Path class' multiple sequence alignment. upstream_sequences (list): list of dicts with information about upstream sequences. parameters (uorf4u.manager.Parameters): Parameters' class object. coordinate_system (dict): coordinate system of figure. additional_data (dict): dict with data for visualisation tracks. \"\"\" def __init__ ( self , msa , parameters : uorf4u . manager . Parameters , type : str ): \"\"\"Create a AnnotationPlotManager object. Arguments: path (uorf4u.data_processing.Path): Path class' objects that holds list of conserved ORFs. upstream_sequences (list): list of dicts with information about upstream sequences. parameters (uorf4u.manager.Parameters): Parameters' class object. type (str): type of sequences (sd, nt, aa) \"\"\" self . msa = msa self . parameters = parameters self . coordinate_system = dict () self . additional_data = dict () self . type = type def define_x_axis_coordinate_system ( self ) -> None : \"\"\"Define coordinate system. Returns: None \"\"\" label_height = self . parameters . arguments [ \"label_size\" ] * self . parameters . arguments [ \"tile_size\" ] * cm label_font_size = uorf4u . methods . string_height_to_font_size ( label_height , \"regular\" , self . parameters . arguments ) self . additional_data [ \"label_font_size\" ] = label_font_size msa_length = self . msa . get_alignment_length () max_label_width = max ([ reportlab . pdfbase . pdfmetrics . stringWidth ( i . description , \"regular\" , label_font_size ) for i in self . msa ]) char_height = self . parameters . arguments [ \"char_size\" ] * self . parameters . arguments [ \"tile_size\" ] * cm char_font_size = uorf4u . methods . string_height_to_font_size ( char_height , \"mono\" , self . parameters . arguments ) self . additional_data [ \"char_font_size\" ] = char_font_size self . additional_data [ \"number_of_sequences\" ] = len ( self . msa ) self . coordinate_system [ \"x_labels_start\" ] = self . parameters . arguments [ \"margin\" ] * cm self . coordinate_system [ \"x_labels_stop\" ] = self . coordinate_system [ \"x_labels_start\" ] + max_label_width self . coordinate_system [ \"x_msa_start\" ] = self . coordinate_system [ \"x_labels_stop\" ] + \\ self . parameters . arguments [ \"label_gap\" ] * cm msa_width = self . parameters . arguments [ \"tile_size\" ] * msa_length * cm self . coordinate_system [ \"x_msa_stop\" ] = self . coordinate_system [ \"x_msa_start\" ] + msa_width self . coordinate_system [ \"figure_width\" ] = 2 * self . parameters . arguments [ \"margin\" ] * cm + msa_width + \\ max_label_width + self . parameters . arguments [ \"label_gap\" ] * cm self . coordinate_system [ \"figure_height\" ] = self . parameters . arguments [ \"margin\" ] * cm self . additional_data [ \"palette\" ] = self . parameters . arguments [ f \"colors_ { self . type } \" ] self . additional_data [ \"palette\" ] = { k : uorf4u . methods . color_name_to_hex ( v , self . parameters . arguments ) for k , v in self . additional_data [ \"palette\" ] . items ()} return None def create_tracks ( self ) -> None : \"\"\"Create visualisation tracks. Returns: None \"\"\" self . tracks = [] \"\"\" title_loader = TitleLoader(self.parameters) title_loader.prepare_data(self.coordinate_system, self.additional_data) title_track = title_loader.create_track() self.tracks.append(title_track) self.coordinate_system[\"figure_height\"] += title_track.needed_y_space() \"\"\" for record in self . msa : sequence_loader = SequencesLoader ( self . parameters ) sequence_loader . prepare_data ( record , self . coordinate_system , self . additional_data ) track = sequence_loader . create_track () self . tracks . append ( track ) self . coordinate_system [ \"figure_height\" ] += track . needed_y_space () # self.coordinate_system[\"figure_height\"] += self.parameters.arguments[\"gap\"] * cm # if index < self.additional_data[\"number_of_sequences\"] - 1: self . coordinate_system [ \"figure_height\" ] += self . parameters . arguments [ \"margin\" ] * cm def plot ( self , filename ): image = Image ( filename , self . coordinate_system [ \"figure_width\" ], self . coordinate_system [ \"figure_height\" ]) current_y_top = self . coordinate_system [ \"figure_height\" ] - self . parameters . arguments [ \"margin\" ] * cm for track in self . tracks : track . visualisation_data [ \"y_top\" ] = current_y_top track . draw ( image . canvas ) current_y_top -= ( track . needed_space ) image . save () return None","title":"MSAPlotManager"},{"location":"API/package_drawing/#uorf4u.drawing_msa.MSAPlotManager.__init__","text":"Create a AnnotationPlotManager object. Parameters: path ( uorf4u . data_processing . Path ) \u2013 Path class' objects that holds list of conserved ORFs. upstream_sequences ( list ) \u2013 list of dicts with information about upstream sequences. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. type ( str ) \u2013 type of sequences (sd, nt, aa) Source code in uorf4u/drawing_msa.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def __init__ ( self , msa , parameters : uorf4u . manager . Parameters , type : str ): \"\"\"Create a AnnotationPlotManager object. Arguments: path (uorf4u.data_processing.Path): Path class' objects that holds list of conserved ORFs. upstream_sequences (list): list of dicts with information about upstream sequences. parameters (uorf4u.manager.Parameters): Parameters' class object. type (str): type of sequences (sd, nt, aa) \"\"\" self . msa = msa self . parameters = parameters self . coordinate_system = dict () self . additional_data = dict () self . type = type","title":"__init__()"},{"location":"API/package_drawing/#uorf4u.drawing_msa.MSAPlotManager.create_tracks","text":"Create visualisation tracks. Returns: None \u2013 None Source code in uorf4u/drawing_msa.py 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 def create_tracks ( self ) -> None : \"\"\"Create visualisation tracks. Returns: None \"\"\" self . tracks = [] \"\"\" title_loader = TitleLoader(self.parameters) title_loader.prepare_data(self.coordinate_system, self.additional_data) title_track = title_loader.create_track() self.tracks.append(title_track) self.coordinate_system[\"figure_height\"] += title_track.needed_y_space() \"\"\" for record in self . msa : sequence_loader = SequencesLoader ( self . parameters ) sequence_loader . prepare_data ( record , self . coordinate_system , self . additional_data ) track = sequence_loader . create_track () self . tracks . append ( track ) self . coordinate_system [ \"figure_height\" ] += track . needed_y_space () # self.coordinate_system[\"figure_height\"] += self.parameters.arguments[\"gap\"] * cm # if index < self.additional_data[\"number_of_sequences\"] - 1: self . coordinate_system [ \"figure_height\" ] += self . parameters . arguments [ \"margin\" ] * cm","title":"create_tracks()"},{"location":"API/package_drawing/#uorf4u.drawing_msa.MSAPlotManager.define_x_axis_coordinate_system","text":"Define coordinate system. Returns: None \u2013 None Source code in uorf4u/drawing_msa.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 def define_x_axis_coordinate_system ( self ) -> None : \"\"\"Define coordinate system. Returns: None \"\"\" label_height = self . parameters . arguments [ \"label_size\" ] * self . parameters . arguments [ \"tile_size\" ] * cm label_font_size = uorf4u . methods . string_height_to_font_size ( label_height , \"regular\" , self . parameters . arguments ) self . additional_data [ \"label_font_size\" ] = label_font_size msa_length = self . msa . get_alignment_length () max_label_width = max ([ reportlab . pdfbase . pdfmetrics . stringWidth ( i . description , \"regular\" , label_font_size ) for i in self . msa ]) char_height = self . parameters . arguments [ \"char_size\" ] * self . parameters . arguments [ \"tile_size\" ] * cm char_font_size = uorf4u . methods . string_height_to_font_size ( char_height , \"mono\" , self . parameters . arguments ) self . additional_data [ \"char_font_size\" ] = char_font_size self . additional_data [ \"number_of_sequences\" ] = len ( self . msa ) self . coordinate_system [ \"x_labels_start\" ] = self . parameters . arguments [ \"margin\" ] * cm self . coordinate_system [ \"x_labels_stop\" ] = self . coordinate_system [ \"x_labels_start\" ] + max_label_width self . coordinate_system [ \"x_msa_start\" ] = self . coordinate_system [ \"x_labels_stop\" ] + \\ self . parameters . arguments [ \"label_gap\" ] * cm msa_width = self . parameters . arguments [ \"tile_size\" ] * msa_length * cm self . coordinate_system [ \"x_msa_stop\" ] = self . coordinate_system [ \"x_msa_start\" ] + msa_width self . coordinate_system [ \"figure_width\" ] = 2 * self . parameters . arguments [ \"margin\" ] * cm + msa_width + \\ max_label_width + self . parameters . arguments [ \"label_gap\" ] * cm self . coordinate_system [ \"figure_height\" ] = self . parameters . arguments [ \"margin\" ] * cm self . additional_data [ \"palette\" ] = self . parameters . arguments [ f \"colors_ { self . type } \" ] self . additional_data [ \"palette\" ] = { k : uorf4u . methods . color_name_to_hex ( v , self . parameters . arguments ) for k , v in self . additional_data [ \"palette\" ] . items ()} return None","title":"define_x_axis_coordinate_system()"},{"location":"API/package_drawing/#uorf4u.drawing_msa.SequenceVis","text":"Bases: Track SequenceVis track draws sequences and annotation. Attributes: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. needed_space ( float ) \u2013 needed vertical space for a track. Source code in uorf4u/drawing_msa.py 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 class SequenceVis ( Track ): \"\"\"SequenceVis track draws sequences and annotation. Attributes: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. needed_space (float): needed vertical space for a track. \"\"\" def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Create a SequenceVis object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( visualisation_data , parameters ) self . needed_space = None def needed_y_space ( self ) -> float : \"\"\"Calculate needed vertical space for a SequenceVis track. Returns: float: needed vertical space. \"\"\" self . needed_space = self . parameters . arguments [ \"tile_size\" ] * cm return self . needed_space def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Draw a Sequence track. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" tile_size = self . parameters . arguments [ \"tile_size\" ] * cm y_c = self . visualisation_data [ \"y_top\" ] - ( tile_size * 0.5 ) y_l = self . visualisation_data [ \"y_top\" ] - tile_size y_gap_label = tile_size * ( 1 - self . parameters . arguments [ \"label_size\" ]) * 0.5 y_gap_char = tile_size * ( 1 - self . parameters . arguments [ \"char_size\" ]) * 0.5 # Labels canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFont ( \"regular\" , self . visualisation_data [ \"label_font_size\" ]) canvas . drawRightString ( self . visualisation_data [ \"coordinate_system\" ][ \"x_labels_stop\" ], y_l + y_gap_label , self . visualisation_data [ \"label\" ]) canvas . setLineWidth ( 0.05 * tile_size ) canvas . setStrokeColorRGB ( 1 , 1 , 1 ) canvas . setFont ( \"mono\" , self . visualisation_data [ \"char_font_size\" ]) x = self . visualisation_data [ 'msa_left_border' ] for symbol in self . visualisation_data [ \"sequence\" ]: x_c = x + tile_size * 0.5 symbol = symbol . upper () try : color = self . visualisation_data [ \"palette\" ][ symbol ] except : color = \"#FFFFFF\" canvas . setFillColorRGB ( * uorf4u . methods . hex_to_rgb ( color ), self . parameters . arguments [ \"tile_alpha\" ]) canvas . rect ( x , y_l , tile_size , tile_size , fill = 1 ) canvas . setFillColorRGB ( 0 , 0 , 0 , 0.8 ) # to change canvas . drawCentredString ( x_c , y_l + y_gap_char , symbol ) x += tile_size return None","title":"SequenceVis"},{"location":"API/package_drawing/#uorf4u.drawing_msa.SequenceVis.__init__","text":"Create a SequenceVis object. Parameters: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing_msa.py 173 174 175 176 177 178 179 180 181 182 def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Create a SequenceVis object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( visualisation_data , parameters ) self . needed_space = None","title":"__init__()"},{"location":"API/package_drawing/#uorf4u.drawing_msa.SequenceVis.draw","text":"Draw a Sequence track. Parameters: canvas ( reportlab . pdfgen . canvas . Canvas ) \u2013 a pdf object. Returns: None \u2013 None Source code in uorf4u/drawing_msa.py 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Draw a Sequence track. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" tile_size = self . parameters . arguments [ \"tile_size\" ] * cm y_c = self . visualisation_data [ \"y_top\" ] - ( tile_size * 0.5 ) y_l = self . visualisation_data [ \"y_top\" ] - tile_size y_gap_label = tile_size * ( 1 - self . parameters . arguments [ \"label_size\" ]) * 0.5 y_gap_char = tile_size * ( 1 - self . parameters . arguments [ \"char_size\" ]) * 0.5 # Labels canvas . setFillColorRGB ( * uorf4u . methods . get_color ( \"label_color\" , self . parameters . arguments )) canvas . setFont ( \"regular\" , self . visualisation_data [ \"label_font_size\" ]) canvas . drawRightString ( self . visualisation_data [ \"coordinate_system\" ][ \"x_labels_stop\" ], y_l + y_gap_label , self . visualisation_data [ \"label\" ]) canvas . setLineWidth ( 0.05 * tile_size ) canvas . setStrokeColorRGB ( 1 , 1 , 1 ) canvas . setFont ( \"mono\" , self . visualisation_data [ \"char_font_size\" ]) x = self . visualisation_data [ 'msa_left_border' ] for symbol in self . visualisation_data [ \"sequence\" ]: x_c = x + tile_size * 0.5 symbol = symbol . upper () try : color = self . visualisation_data [ \"palette\" ][ symbol ] except : color = \"#FFFFFF\" canvas . setFillColorRGB ( * uorf4u . methods . hex_to_rgb ( color ), self . parameters . arguments [ \"tile_alpha\" ]) canvas . rect ( x , y_l , tile_size , tile_size , fill = 1 ) canvas . setFillColorRGB ( 0 , 0 , 0 , 0.8 ) # to change canvas . drawCentredString ( x_c , y_l + y_gap_char , symbol ) x += tile_size return None","title":"draw()"},{"location":"API/package_drawing/#uorf4u.drawing_msa.SequenceVis.needed_y_space","text":"Calculate needed vertical space for a SequenceVis track. Returns: float ( float ) \u2013 needed vertical space. Source code in uorf4u/drawing_msa.py 184 185 186 187 188 189 190 191 192 def needed_y_space ( self ) -> float : \"\"\"Calculate needed vertical space for a SequenceVis track. Returns: float: needed vertical space. \"\"\" self . needed_space = self . parameters . arguments [ \"tile_size\" ] * cm return self . needed_space","title":"needed_y_space()"},{"location":"API/package_drawing/#uorf4u.drawing_msa.SequencesLoader","text":"Bases: Loader A SequencesLoader object prepares data for a Sequence track object. Attributes: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. prepared_data ( dict ) \u2013 dict with data needed for a visualisation track. Source code in uorf4u/drawing_msa.py 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 class SequencesLoader ( Loader ): \"\"\"A SequencesLoader object prepares data for a Sequence track object. Attributes: parameters (uorf4u.manager.Parameters): Parameters' class object. prepared_data (dict): dict with data needed for a visualisation track. \"\"\" def __init__ ( self , parameters ): \"\"\"Create a SequenceLoader object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( parameters ) def prepare_data ( self , record , coordinate_system : dict , additional_data : dict ) -> dict : \"\"\"Prepare data for a Title visualisation track. Attributes: record (FILL in): record of blablabla coordinate_system (dict): coordinate system of a figure page. additional_data (dict): data needed for a track initialisation. Returns: dict: dictionary with prepared data for visualisation. \"\"\" prepared_data = dict () prepared_data [ \"coordinate_system\" ] = coordinate_system prepared_data [ \"label_font_size\" ] = additional_data [ \"label_font_size\" ] prepared_data [ \"char_font_size\" ] = additional_data [ \"char_font_size\" ] prepared_data [ \"label_right_border\" ] = coordinate_system [ \"x_labels_stop\" ] prepared_data [ \"msa_left_border\" ] = coordinate_system [ \"x_msa_start\" ] prepared_data [ \"sequence\" ] = record . seq prepared_data [ \"label\" ] = record . description prepared_data [ \"palette\" ] = additional_data [ \"palette\" ] self . prepared_data = prepared_data return prepared_data def create_track ( self ) -> SequenceVis : \"\"\"Initialise a Sequence track object. Returns: SequenceVis: visualisation track. \"\"\" return SequenceVis ( self . prepared_data , self . parameters )","title":"SequencesLoader"},{"location":"API/package_drawing/#uorf4u.drawing_msa.SequencesLoader.__init__","text":"Create a SequenceLoader object. Parameters: parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing_msa.py 283 284 285 286 287 288 289 290 def __init__ ( self , parameters ): \"\"\"Create a SequenceLoader object. Arguments: parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" super () . __init__ ( parameters )","title":"__init__()"},{"location":"API/package_drawing/#uorf4u.drawing_msa.SequencesLoader.create_track","text":"Initialise a Sequence track object. Returns: SequenceVis ( SequenceVis ) \u2013 visualisation track. Source code in uorf4u/drawing_msa.py 317 318 319 320 321 322 323 324 def create_track ( self ) -> SequenceVis : \"\"\"Initialise a Sequence track object. Returns: SequenceVis: visualisation track. \"\"\" return SequenceVis ( self . prepared_data , self . parameters )","title":"create_track()"},{"location":"API/package_drawing/#uorf4u.drawing_msa.SequencesLoader.prepare_data","text":"Prepare data for a Title visualisation track. Attributes: record ( FILL in ) \u2013 record of blablabla coordinate_system ( dict ) \u2013 coordinate system of a figure page. additional_data ( dict ) \u2013 data needed for a track initialisation. Returns: dict ( dict ) \u2013 dictionary with prepared data for visualisation. Source code in uorf4u/drawing_msa.py 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 def prepare_data ( self , record , coordinate_system : dict , additional_data : dict ) -> dict : \"\"\"Prepare data for a Title visualisation track. Attributes: record (FILL in): record of blablabla coordinate_system (dict): coordinate system of a figure page. additional_data (dict): data needed for a track initialisation. Returns: dict: dictionary with prepared data for visualisation. \"\"\" prepared_data = dict () prepared_data [ \"coordinate_system\" ] = coordinate_system prepared_data [ \"label_font_size\" ] = additional_data [ \"label_font_size\" ] prepared_data [ \"char_font_size\" ] = additional_data [ \"char_font_size\" ] prepared_data [ \"label_right_border\" ] = coordinate_system [ \"x_labels_stop\" ] prepared_data [ \"msa_left_border\" ] = coordinate_system [ \"x_msa_start\" ] prepared_data [ \"sequence\" ] = record . seq prepared_data [ \"label\" ] = record . description prepared_data [ \"palette\" ] = additional_data [ \"palette\" ] self . prepared_data = prepared_data return prepared_data","title":"prepare_data()"},{"location":"API/package_drawing/#uorf4u.drawing_msa.Track","text":"Parent clas for visualisation Tracks. Attributes: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing_msa.py 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 class Track : \"\"\"Parent clas for visualisation Tracks. Attributes: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Parent's constructor for creating a Track object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . visualisation_data = visualisation_data self . parameters = parameters def needed_y_space ( self ) -> None : \"\"\"Empy parent's method for calculation needed vertical space for a track. Returns: None \"\"\" pass def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Empy parent's method for track visualisation. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" pass","title":"Track"},{"location":"API/package_drawing/#uorf4u.drawing_msa.Track.__init__","text":"Parent's constructor for creating a Track object. Parameters: visualisation_data ( dict ) \u2013 a dictionary with data needed for visualisation. parameters ( uorf4u . manager . Parameters ) \u2013 Parameters' class object. Source code in uorf4u/drawing_msa.py 131 132 133 134 135 136 137 138 139 140 def __init__ ( self , visualisation_data : dict , parameters : uorf4u . manager . Parameters ): \"\"\"Parent's constructor for creating a Track object. Arguments: visualisation_data (dict): a dictionary with data needed for visualisation. parameters (uorf4u.manager.Parameters): Parameters' class object. \"\"\" self . visualisation_data = visualisation_data self . parameters = parameters","title":"__init__()"},{"location":"API/package_drawing/#uorf4u.drawing_msa.Track.draw","text":"Empy parent's method for track visualisation. Parameters: canvas ( reportlab . pdfgen . canvas . Canvas ) \u2013 a pdf object. Returns: None \u2013 None Source code in uorf4u/drawing_msa.py 151 152 153 154 155 156 157 158 159 160 def draw ( self , canvas : reportlab . pdfgen . canvas . Canvas ) -> None : \"\"\"Empy parent's method for track visualisation. Arguments: canvas (reportlab.pdfgen.canvas.Canvas): a pdf object. Returns: None \"\"\" pass","title":"draw()"},{"location":"API/package_drawing/#uorf4u.drawing_msa.Track.needed_y_space","text":"Empy parent's method for calculation needed vertical space for a track. Returns: None \u2013 None Source code in uorf4u/drawing_msa.py 142 143 144 145 146 147 148 149 def needed_y_space ( self ) -> None : \"\"\"Empy parent's method for calculation needed vertical space for a track. Returns: None \"\"\" pass","title":"needed_y_space()"},{"location":"API/package_manager/","text":"This module provides managing classes and methods for the tool. Parameters A Parameters object holds and parse cmd's and config's arguments for the tool. Note: A Parameters object have to be created in each script since it's used by each class of the tool as a mandatory argument. Source code in uorf4u/manager.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 class Parameters : \"\"\"A Parameters object holds and parse cmd's and config's arguments for the tool. Note: A Parameters object have to be created in each script since it's used by each class of the tool as a mandatory argument. \"\"\" def __init__ ( self ): self . arguments = dict ( assemblies_list = \"NA\" , debug = False , verbose = False ) self . cmd_arguments = { \"assemblies_list\" : \"NA\" , \"verbose\" : True } def parse_cmd_arguments ( self ) -> None : parser = argparse . ArgumentParser ( prog = \"uorf4u\" , add_help = False , usage = \"uorf4u [-an accession_number | -hl [ac1, ac2..] | -hlf path | -fa path]\" \"[optional arguments]\" ) mutually_exclusive_group = parser . add_mutually_exclusive_group () mutually_exclusive_group . add_argument ( \"-an\" , dest = \"accession_number\" , type = str , default = None ) mutually_exclusive_group . add_argument ( \"-hl\" , dest = \"homologues_list\" , nargs = \"*\" , default = None ) mutually_exclusive_group . add_argument ( \"-hlf\" , dest = \"homologues_list_file\" , type = str , default = None ) mutually_exclusive_group . add_argument ( \"-fa\" , dest = \"fasta\" , type = str , default = None ) parser . add_argument ( \"-data\" , \"--data\" , dest = \"uorf4u_data\" , action = \"store_true\" ) parser . add_argument ( \"-linux\" , \"--linux\" , dest = \"linux\" , action = \"store_true\" , default = None ) parser . add_argument ( \"-bh\" , dest = \"blastp_hit_list_size\" , type = int , default = None ) parser . add_argument ( \"-bid\" , dest = \"blastp_pident_to_query_length_cutoff\" , type = float , default = None ) parser . add_argument ( \"-mna\" , dest = \"max_number_of_assemblies\" , type = int , default = None ) parser . add_argument ( \"-al\" , dest = \"assemblies_list\" , type = str , default = \"NA\" ) parser . add_argument ( \"-annot\" , dest = \"check_assembly_annotation\" , action = \"store_true\" , default = None ) parser . add_argument ( \"-ul\" , dest = \"upstream_region_length\" , type = int , default = None ) parser . add_argument ( \"-dl\" , dest = \"downstream_region_length\" , type = int , default = None ) parser . add_argument ( \"-asc\" , dest = \"alternative_start_codons\" , action = \"store_true\" , default = None ) parser . add_argument ( \"-nsd\" , dest = \"filter_by_sd\" , action = \"store_false\" , default = None ) parser . add_argument ( \"-at\" , dest = \"alignment_type\" , choices = [ 'nt' , 'aa' , None ], type = str , default = None ) parser . add_argument ( \"-pc\" , dest = \"orfs_presence_cutoff\" , type = float , default = None ) parser . add_argument ( \"-fast\" , dest = \"fast_searching\" , action = \"store_true\" , default = None ) parser . add_argument ( \"-o\" , dest = \"output_dir\" , type = str , default = None ) parser . add_argument ( \"-c\" , dest = \"config_file\" , type = str , default = \"bacteria\" ) parser . add_argument ( \"-v\" , \"--version\" , action = \"version\" , version = \" %(prog)s 0.8.5\" ) parser . add_argument ( \"-q\" , \"--quiet\" , dest = \"verbose\" , default = True , action = \"store_false\" ) parser . add_argument ( \"--debug\" , \"-debug\" , dest = \"debug\" , action = \"store_true\" ) parser . add_argument ( \"-h\" , \"--help\" , dest = \"help\" , action = \"store_true\" ) args = parser . parse_args () args = vars ( args ) if len ( sys . argv [ 1 :]) == 0 : args [ \"help\" ] = True if args [ \"uorf4u_data\" ]: uorf4u . methods . copy_package_data () sys . exit () if args [ \"linux\" ]: uorf4u . methods . adjust_paths_for_linux () sys . exit () if args [ \"help\" ]: help_message_path = os . path . join ( os . path . dirname ( __file__ ), 'uorf4u_data' , \"help.txt\" ) with open ( help_message_path , \"r\" ) as help_message : print ( help_message . read (), file = sys . stdout ) sys . exit () filtered_args = { k : v for k , v in args . items () if v is not None } self . cmd_arguments = filtered_args def load_config ( self , path_c = \"bacteria\" ): try : if path_c == \"bacteria\" or path_c == \"eukaryotes\" : path_c = os . path . join ( os . path . dirname ( __file__ ), \"uorf4u_data\" , f \"uorf4u_ { path_c } .cfg\" ) config = configs . load ( path_c ) config = config . get_config () internal_dir = os . path . dirname ( __file__ ) config [ \"root\" ][ \"output_dir\" ] = config [ \"root\" ][ \"output_dir\" ] . replace ( \" {current_date} \" , time . strftime ( \"%Y_%m_ %d -%H_%M\" )) for key in config [ \"root\" ] . keys (): if type ( config [ \"root\" ][ key ]) is str and \" {config_path} \" in config [ \"root\" ][ key ]: config [ \"root\" ][ key ] = config [ \"root\" ][ key ] . replace ( \" {config_path} \" , os . path . dirname ( path_c )) self . arguments . update ( config [ 'root' ]) self . arguments . update ( self . cmd_arguments ) self . load_palette () self . load_color_config () Bio . Entrez . tool = \"uorf4u\" Bio . Entrez . email = self . arguments [ \"ncbi_entrez_email\" ] if \"ncbi_entrez_api_key\" in self . arguments . keys (): Bio . Entrez . api_key = self . arguments [ \"ncbi_entrez_api_key\" ] # Bio.Entrez.api_key = \"09f9e08fcd7192afdd358d833e565e0f6609\" except Exception as error : raise uORF4uError ( \"Unable to parse the specified config file. Please check your config file or written name.\" ) from error def load_palette ( self ) -> None : palette_path = self . arguments [ f \"palette\" ] self . arguments [ f \"palette\" ] = configs . load ( palette_path ) . get_config ()[ \"root\" ] def load_color_config ( self ) -> None : for seq_type in [ \"nt\" , \"aa\" ]: path = self . arguments [ f \"colors_ { seq_type } \" ] colors_pre_dict = configs . load ( path ) . get_config ()[ \"root\" ] colors_dict = dict () for elements , color in colors_pre_dict . items (): for element in elements : colors_dict [ element ] = color self . arguments [ f \"colors_ { seq_type } \" ] = colors_dict def update ( self , parameters ): self . arguments . update ( parameters ) uORF4uError Bases: Exception A helper for exceptions parsing inherited from the Exception class. Source code in uorf4u/manager.py 14 15 16 17 18 class uORF4uError ( Exception ): \"\"\"A helper for exceptions parsing inherited from the Exception class. \"\"\" pass","title":"uorf4u.manager"},{"location":"API/package_manager/#uorf4u.manager.Parameters","text":"A Parameters object holds and parse cmd's and config's arguments for the tool. Note: A Parameters object have to be created in each script since it's used by each class of the tool as a mandatory argument. Source code in uorf4u/manager.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 class Parameters : \"\"\"A Parameters object holds and parse cmd's and config's arguments for the tool. Note: A Parameters object have to be created in each script since it's used by each class of the tool as a mandatory argument. \"\"\" def __init__ ( self ): self . arguments = dict ( assemblies_list = \"NA\" , debug = False , verbose = False ) self . cmd_arguments = { \"assemblies_list\" : \"NA\" , \"verbose\" : True } def parse_cmd_arguments ( self ) -> None : parser = argparse . ArgumentParser ( prog = \"uorf4u\" , add_help = False , usage = \"uorf4u [-an accession_number | -hl [ac1, ac2..] | -hlf path | -fa path]\" \"[optional arguments]\" ) mutually_exclusive_group = parser . add_mutually_exclusive_group () mutually_exclusive_group . add_argument ( \"-an\" , dest = \"accession_number\" , type = str , default = None ) mutually_exclusive_group . add_argument ( \"-hl\" , dest = \"homologues_list\" , nargs = \"*\" , default = None ) mutually_exclusive_group . add_argument ( \"-hlf\" , dest = \"homologues_list_file\" , type = str , default = None ) mutually_exclusive_group . add_argument ( \"-fa\" , dest = \"fasta\" , type = str , default = None ) parser . add_argument ( \"-data\" , \"--data\" , dest = \"uorf4u_data\" , action = \"store_true\" ) parser . add_argument ( \"-linux\" , \"--linux\" , dest = \"linux\" , action = \"store_true\" , default = None ) parser . add_argument ( \"-bh\" , dest = \"blastp_hit_list_size\" , type = int , default = None ) parser . add_argument ( \"-bid\" , dest = \"blastp_pident_to_query_length_cutoff\" , type = float , default = None ) parser . add_argument ( \"-mna\" , dest = \"max_number_of_assemblies\" , type = int , default = None ) parser . add_argument ( \"-al\" , dest = \"assemblies_list\" , type = str , default = \"NA\" ) parser . add_argument ( \"-annot\" , dest = \"check_assembly_annotation\" , action = \"store_true\" , default = None ) parser . add_argument ( \"-ul\" , dest = \"upstream_region_length\" , type = int , default = None ) parser . add_argument ( \"-dl\" , dest = \"downstream_region_length\" , type = int , default = None ) parser . add_argument ( \"-asc\" , dest = \"alternative_start_codons\" , action = \"store_true\" , default = None ) parser . add_argument ( \"-nsd\" , dest = \"filter_by_sd\" , action = \"store_false\" , default = None ) parser . add_argument ( \"-at\" , dest = \"alignment_type\" , choices = [ 'nt' , 'aa' , None ], type = str , default = None ) parser . add_argument ( \"-pc\" , dest = \"orfs_presence_cutoff\" , type = float , default = None ) parser . add_argument ( \"-fast\" , dest = \"fast_searching\" , action = \"store_true\" , default = None ) parser . add_argument ( \"-o\" , dest = \"output_dir\" , type = str , default = None ) parser . add_argument ( \"-c\" , dest = \"config_file\" , type = str , default = \"bacteria\" ) parser . add_argument ( \"-v\" , \"--version\" , action = \"version\" , version = \" %(prog)s 0.8.5\" ) parser . add_argument ( \"-q\" , \"--quiet\" , dest = \"verbose\" , default = True , action = \"store_false\" ) parser . add_argument ( \"--debug\" , \"-debug\" , dest = \"debug\" , action = \"store_true\" ) parser . add_argument ( \"-h\" , \"--help\" , dest = \"help\" , action = \"store_true\" ) args = parser . parse_args () args = vars ( args ) if len ( sys . argv [ 1 :]) == 0 : args [ \"help\" ] = True if args [ \"uorf4u_data\" ]: uorf4u . methods . copy_package_data () sys . exit () if args [ \"linux\" ]: uorf4u . methods . adjust_paths_for_linux () sys . exit () if args [ \"help\" ]: help_message_path = os . path . join ( os . path . dirname ( __file__ ), 'uorf4u_data' , \"help.txt\" ) with open ( help_message_path , \"r\" ) as help_message : print ( help_message . read (), file = sys . stdout ) sys . exit () filtered_args = { k : v for k , v in args . items () if v is not None } self . cmd_arguments = filtered_args def load_config ( self , path_c = \"bacteria\" ): try : if path_c == \"bacteria\" or path_c == \"eukaryotes\" : path_c = os . path . join ( os . path . dirname ( __file__ ), \"uorf4u_data\" , f \"uorf4u_ { path_c } .cfg\" ) config = configs . load ( path_c ) config = config . get_config () internal_dir = os . path . dirname ( __file__ ) config [ \"root\" ][ \"output_dir\" ] = config [ \"root\" ][ \"output_dir\" ] . replace ( \" {current_date} \" , time . strftime ( \"%Y_%m_ %d -%H_%M\" )) for key in config [ \"root\" ] . keys (): if type ( config [ \"root\" ][ key ]) is str and \" {config_path} \" in config [ \"root\" ][ key ]: config [ \"root\" ][ key ] = config [ \"root\" ][ key ] . replace ( \" {config_path} \" , os . path . dirname ( path_c )) self . arguments . update ( config [ 'root' ]) self . arguments . update ( self . cmd_arguments ) self . load_palette () self . load_color_config () Bio . Entrez . tool = \"uorf4u\" Bio . Entrez . email = self . arguments [ \"ncbi_entrez_email\" ] if \"ncbi_entrez_api_key\" in self . arguments . keys (): Bio . Entrez . api_key = self . arguments [ \"ncbi_entrez_api_key\" ] # Bio.Entrez.api_key = \"09f9e08fcd7192afdd358d833e565e0f6609\" except Exception as error : raise uORF4uError ( \"Unable to parse the specified config file. Please check your config file or written name.\" ) from error def load_palette ( self ) -> None : palette_path = self . arguments [ f \"palette\" ] self . arguments [ f \"palette\" ] = configs . load ( palette_path ) . get_config ()[ \"root\" ] def load_color_config ( self ) -> None : for seq_type in [ \"nt\" , \"aa\" ]: path = self . arguments [ f \"colors_ { seq_type } \" ] colors_pre_dict = configs . load ( path ) . get_config ()[ \"root\" ] colors_dict = dict () for elements , color in colors_pre_dict . items (): for element in elements : colors_dict [ element ] = color self . arguments [ f \"colors_ { seq_type } \" ] = colors_dict def update ( self , parameters ): self . arguments . update ( parameters )","title":"Parameters"},{"location":"API/package_manager/#uorf4u.manager.uORF4uError","text":"Bases: Exception A helper for exceptions parsing inherited from the Exception class. Source code in uorf4u/manager.py 14 15 16 17 18 class uORF4uError ( Exception ): \"\"\"A helper for exceptions parsing inherited from the Exception class. \"\"\" pass","title":"uORF4uError"},{"location":"API/package_methods/","text":"This module provides some methods (e.g. colors tranformation, data copying) used by the tool. adjust_paths_for_linux () Change paths in the internal config files for linux. Returns: None \u2013 None Source code in uorf4u/methods.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def adjust_paths_for_linux () -> None : \"\"\"Change paths in the internal config files for linux. Returns: None \"\"\" internal_dir = os . path . join ( os . path . dirname ( __file__ ), \"uorf4u_data\" ) config_files = [ \"uorf4u_eukaryotes.cfg\" , \"uorf4u_bacteria.cfg\" ] for config_file in config_files : config_file_path = os . path . join ( internal_dir , config_file ) with open ( config_file_path , \"r+\" ) as config : config_txt = re . sub ( r \"/muscle5\\.1\\.macos_arm64\" , \"/muscle5.1.linux_intel64\" , config . read ()) config_txt = re . sub ( r \"/mafft-mac/mafft\\.bat\" , \"/mafft-linux64/mafft.bat\" , config_txt ) config . seek ( 0 ) config . truncate () config . write ( config_txt ) return None copy_package_data () Copy the uorf4u package data folder to your current dir. Returns: None \u2013 None Source code in uorf4u/methods.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 def copy_package_data () -> None : \"\"\"Copy the uorf4u package data folder to your current dir. Returns: None \"\"\" try : users_dir = os . path . join ( os . getcwd (), \"uorf4u_data\" ) internal_dir = os . path . join ( os . path . dirname ( __file__ ), \"uorf4u_data\" ) shutil . copytree ( internal_dir , users_dir , ignore = shutil . ignore_patterns ( \"help*\" , \".*\" , \"msa_plot_dir.R\" )) return None except Exception as error : raise uorf4u . manager . uORF4uError ( f \"Unable to copy uorf4u_data folder in your working dir.\" ) from error get_color ( name , parameters ) Get color code by a name. Parameters: name ( str ) \u2013 name of a color. parameters ( dict ) \u2013 Parameters' object dict. Returns: tuple ( tuple ) \u2013 RGB color. Source code in uorf4u/methods.py 73 74 75 76 77 78 79 80 81 82 83 84 85 def get_color ( name : str , parameters : dict ) -> tuple : \"\"\"Get color code by a name. Arguments: name (str): name of a color. parameters (dict): Parameters' object dict. Returns: tuple: RGB color. \"\"\" rgb_color = * hex_to_rgb ( parameters [ 'palette' ][ parameters [ name ]]), parameters [ f \" { name } _alpha\" ] return rgb_color hex_to_rgb ( value ) Convert HEX color to RGB format. Parameters: value ( str ) \u2013 color in HEX format. Returns: list ( list ) \u2013 RGB color. Source code in uorf4u/methods.py 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 def hex_to_rgb ( value : str ) -> list : \"\"\"Convert HEX color to RGB format. Arguments: value (str): color in HEX format. Returns: list: RGB color. \"\"\" try : value = value . lstrip ( \"#\" ) lv = len ( value ) rgb = [ i / 255 for i in tuple ( int ( value [ i : i + lv // 3 ], 16 ) for i in range ( 0 , lv , lv // 3 ))] return rgb except Exception as error : raise uorf4u . manager . uORF4uError ( f \"Unable to convert color definition from HEX to RGB. Please check the palette config file.\" ) from error parse_fasta_file ( path , parameters ) Parse fasta file with sequences. Arguments path: path to a fasta file. Returns: list ( list ) \u2013 list of processed Bio.SeqRecord.SeqRecord objects. Source code in uorf4u/methods.py 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 def parse_fasta_file ( path : str , parameters ) -> list : \"\"\"Parse fasta file with sequences. Arguments path: path to a fasta file. Returns: list: list of processed Bio.SeqRecord.SeqRecord objects. \"\"\" try : processed_records = [] record_ids = [] with open ( path ) as handle : for record in Bio . SeqIO . parse ( handle , \"fasta\" ): label = record . description record . description = record . description . replace ( record . id , \"\" ) length = len ( record . seq ) record_annotation = dict ( RefSeq = False , length = length , upstream_region_length = length - parameters . arguments [ \"downstream_region_length\" ], downstream_region_length = parameters . arguments [ \"downstream_region_length\" ], label = label ) record . annotations = record_annotation processed_records . append ( record ) return processed_records except Exception as error : raise uorf4u . manager . uORF4uError ( f \"Unable to process the fasta file with sequences.\" ) from error string_height_to_font_size ( height , font_type , parameters ) Transform string height to the font size. Parameters: height ( float ) \u2013 available height of the string. font_type ( str ) \u2013 font type (see config file; at this moment only regular is available). parameters ( dict ) \u2013 Parameters' object dict. Returns: float ( float ) \u2013 font size defined by height. Source code in uorf4u/methods.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 def string_height_to_font_size ( height : float , font_type : str , parameters : dict ) -> float : \"\"\"Transform string height to the font size. Arguments: height (float): available height of the string. font_type (str): font type (see config file; at this moment only regular is available). parameters (dict): Parameters' object dict. Returns: float: font size defined by height. \"\"\" pdfmetrics . registerFont ( TTFont ( font_type , parameters [ f \"font_ { font_type } \" ])) face = pdfmetrics . getFont ( 'regular' ) . face font_size = ( 1000 * 1.38 * height ) / ( face . ascent - face . descent ) return font_size","title":"uorf4u.methods"},{"location":"API/package_methods/#uorf4u.methods.adjust_paths_for_linux","text":"Change paths in the internal config files for linux. Returns: None \u2013 None Source code in uorf4u/methods.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def adjust_paths_for_linux () -> None : \"\"\"Change paths in the internal config files for linux. Returns: None \"\"\" internal_dir = os . path . join ( os . path . dirname ( __file__ ), \"uorf4u_data\" ) config_files = [ \"uorf4u_eukaryotes.cfg\" , \"uorf4u_bacteria.cfg\" ] for config_file in config_files : config_file_path = os . path . join ( internal_dir , config_file ) with open ( config_file_path , \"r+\" ) as config : config_txt = re . sub ( r \"/muscle5\\.1\\.macos_arm64\" , \"/muscle5.1.linux_intel64\" , config . read ()) config_txt = re . sub ( r \"/mafft-mac/mafft\\.bat\" , \"/mafft-linux64/mafft.bat\" , config_txt ) config . seek ( 0 ) config . truncate () config . write ( config_txt ) return None","title":"adjust_paths_for_linux()"},{"location":"API/package_methods/#uorf4u.methods.copy_package_data","text":"Copy the uorf4u package data folder to your current dir. Returns: None \u2013 None Source code in uorf4u/methods.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 def copy_package_data () -> None : \"\"\"Copy the uorf4u package data folder to your current dir. Returns: None \"\"\" try : users_dir = os . path . join ( os . getcwd (), \"uorf4u_data\" ) internal_dir = os . path . join ( os . path . dirname ( __file__ ), \"uorf4u_data\" ) shutil . copytree ( internal_dir , users_dir , ignore = shutil . ignore_patterns ( \"help*\" , \".*\" , \"msa_plot_dir.R\" )) return None except Exception as error : raise uorf4u . manager . uORF4uError ( f \"Unable to copy uorf4u_data folder in your working dir.\" ) from error","title":"copy_package_data()"},{"location":"API/package_methods/#uorf4u.methods.get_color","text":"Get color code by a name. Parameters: name ( str ) \u2013 name of a color. parameters ( dict ) \u2013 Parameters' object dict. Returns: tuple ( tuple ) \u2013 RGB color. Source code in uorf4u/methods.py 73 74 75 76 77 78 79 80 81 82 83 84 85 def get_color ( name : str , parameters : dict ) -> tuple : \"\"\"Get color code by a name. Arguments: name (str): name of a color. parameters (dict): Parameters' object dict. Returns: tuple: RGB color. \"\"\" rgb_color = * hex_to_rgb ( parameters [ 'palette' ][ parameters [ name ]]), parameters [ f \" { name } _alpha\" ] return rgb_color","title":"get_color()"},{"location":"API/package_methods/#uorf4u.methods.hex_to_rgb","text":"Convert HEX color to RGB format. Parameters: value ( str ) \u2013 color in HEX format. Returns: list ( list ) \u2013 RGB color. Source code in uorf4u/methods.py 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 def hex_to_rgb ( value : str ) -> list : \"\"\"Convert HEX color to RGB format. Arguments: value (str): color in HEX format. Returns: list: RGB color. \"\"\" try : value = value . lstrip ( \"#\" ) lv = len ( value ) rgb = [ i / 255 for i in tuple ( int ( value [ i : i + lv // 3 ], 16 ) for i in range ( 0 , lv , lv // 3 ))] return rgb except Exception as error : raise uorf4u . manager . uORF4uError ( f \"Unable to convert color definition from HEX to RGB. Please check the palette config file.\" ) from error","title":"hex_to_rgb()"},{"location":"API/package_methods/#uorf4u.methods.parse_fasta_file","text":"Parse fasta file with sequences. Arguments path: path to a fasta file. Returns: list ( list ) \u2013 list of processed Bio.SeqRecord.SeqRecord objects. Source code in uorf4u/methods.py 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 def parse_fasta_file ( path : str , parameters ) -> list : \"\"\"Parse fasta file with sequences. Arguments path: path to a fasta file. Returns: list: list of processed Bio.SeqRecord.SeqRecord objects. \"\"\" try : processed_records = [] record_ids = [] with open ( path ) as handle : for record in Bio . SeqIO . parse ( handle , \"fasta\" ): label = record . description record . description = record . description . replace ( record . id , \"\" ) length = len ( record . seq ) record_annotation = dict ( RefSeq = False , length = length , upstream_region_length = length - parameters . arguments [ \"downstream_region_length\" ], downstream_region_length = parameters . arguments [ \"downstream_region_length\" ], label = label ) record . annotations = record_annotation processed_records . append ( record ) return processed_records except Exception as error : raise uorf4u . manager . uORF4uError ( f \"Unable to process the fasta file with sequences.\" ) from error","title":"parse_fasta_file()"},{"location":"API/package_methods/#uorf4u.methods.string_height_to_font_size","text":"Transform string height to the font size. Parameters: height ( float ) \u2013 available height of the string. font_type ( str ) \u2013 font type (see config file; at this moment only regular is available). parameters ( dict ) \u2013 Parameters' object dict. Returns: float ( float ) \u2013 font size defined by height. Source code in uorf4u/methods.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 def string_height_to_font_size ( height : float , font_type : str , parameters : dict ) -> float : \"\"\"Transform string height to the font size. Arguments: height (float): available height of the string. font_type (str): font type (see config file; at this moment only regular is available). parameters (dict): Parameters' object dict. Returns: float: font size defined by height. \"\"\" pdfmetrics . registerFont ( TTFont ( font_type , parameters [ f \"font_ { font_type } \" ])) face = pdfmetrics . getFont ( 'regular' ) . face font_size = ( 1000 * 1.38 * height ) / ( face . ascent - face . descent ) return font_size","title":"string_height_to_font_size()"},{"location":"API/usage_examples/","text":"Short example-drived guide to uorf4u API. uorf4u has a simple API allowing it programmatic usage from within a python program. Below we descrive several Python snippets that mimic results of command-line calls. Using a single RefSeq protein accession number as input in bacteria mode import uorf4u parameters = uorf4u . manager . Parameters () parameters . load_config ( \"bacteria\" ) # Load config (bacteria, eukaryotes or path) parameters . arguments [ \"output_dir\" ] = \"ErmCL\" # to change parameters protein = uorf4u . data_processing . RefSeqProtein ( accession_number = \"WP_001003263.1\" , parameters = parameters ) homologues_list = protein . blastp_searching_for_homologues () homologues = uorf4u . data_processing . Homologues ( homologues_list , parameters ) upstream_sequences_records = homologues . get_upstream_sequences () upstream_seqs = uorf4u . data_processing . UpstreamSequences ( upstream_sequences_records , parameters ) upstream_seqs . annotate_orfs () upstream_seqs . filter_orfs_by_sd_annotation () upstream_seqs . save_annotated_orfs () upstream_seqs . conserved_orf_searching () upstream_seqs . filter_out_similar_paths () upstream_seqs . run_msa () upstream_seqs . save_orfs_sequences () upstream_seqs . save_msa () upstream_seqs . save_results_summary_table () upstream_seqs . plot_annotation () upstream_seqs . plot_logo_figs () upstream_seqs . plot_msa_figs () Will be updated with more examples...","title":"Usage examples"},{"location":"API/usage_examples/#short-example-drived-guide-to-uorf4u-api","text":"uorf4u has a simple API allowing it programmatic usage from within a python program. Below we descrive several Python snippets that mimic results of command-line calls. Using a single RefSeq protein accession number as input in bacteria mode import uorf4u parameters = uorf4u . manager . Parameters () parameters . load_config ( \"bacteria\" ) # Load config (bacteria, eukaryotes or path) parameters . arguments [ \"output_dir\" ] = \"ErmCL\" # to change parameters protein = uorf4u . data_processing . RefSeqProtein ( accession_number = \"WP_001003263.1\" , parameters = parameters ) homologues_list = protein . blastp_searching_for_homologues () homologues = uorf4u . data_processing . Homologues ( homologues_list , parameters ) upstream_sequences_records = homologues . get_upstream_sequences () upstream_seqs = uorf4u . data_processing . UpstreamSequences ( upstream_sequences_records , parameters ) upstream_seqs . annotate_orfs () upstream_seqs . filter_orfs_by_sd_annotation () upstream_seqs . save_annotated_orfs () upstream_seqs . conserved_orf_searching () upstream_seqs . filter_out_similar_paths () upstream_seqs . run_msa () upstream_seqs . save_orfs_sequences () upstream_seqs . save_msa () upstream_seqs . save_results_summary_table () upstream_seqs . plot_annotation () upstream_seqs . plot_logo_figs () upstream_seqs . plot_msa_figs () Will be updated with more examples...","title":"Short example-drived guide to uorf4u API."},{"location":"ExampleDrivenGuide/cmd_guide/","text":"Example-driven guide Here we show several usage examples of the uorf4u command-line interface for two well-known uORFs: ermCL (bacteria) and ATF4 (eukaryotes). (See review articles about uORFs in prokaryotes and eukaryotes: Ito et.al. 2013 and Dever et.al. 2020 . Before start: The necessary sample data as well as adjustable tool' configuration files are provided by uorf4u at the post-install step: uorf4u --data If you work on a Linux machine after installation you should run: uorf4u --linux This command replaces the tools paths (maft) in the pre-made config files from the MacOS' version (default) to the Linux'. Bacteria: ermCL Expression of 23S rRNA methyltransferase ermC is regulated by translational attenuation: ribosome stalling on the ermC uORF (named ermCL ) is inducible by erythromycin. The arresst alters the regional mRNA structure, exposing the ermC SD sequence and allowing translation of the ermC ORF. Using a single RefSeq protein accession number as input To test whether uORF4u will find the ermCL we can use only the RefSeq accession number of ermC protein as input which is WP_001003263.1 . uorf4u -an WP_001003263.1 -ul 400 -o ErmC , All arguments, except -an , were optional. -ul was used to overrides the upstream region length to retrieve (default: 500). Output folder name can be set with -o parameter (default: uorf4u_{current_date}). uORF4u finds the expected ermCL and returns one set of conserved uORFs. Output contains MSA plot , annotation plot , and sequence logo: Using a list of homologues as input Alternatively, a list of homologues can be used as input. This is important for allowing a user to decide the breadth and depth of the search. In addition, it can be useful for creating compact output figures that can be used in articles. For such demonstration, we have chosen several ermC proteins from the previous run and used them as input: uorf4u -hl WP_202338192.1 WP_102227852.1 WP_034984371.1 WP_159316313.1 WP_095341278.1 WP_150861853.1 WP_011382144.1 WP_081624258.1 -c bacteria -annot -ul 400 where -annot parameter was used to show on annotation plot known ORFs annotated in the NCBI (shown with blue outlines). We also used bacteria mode by specifying the premade configuration file with -c parameter. Note : List of homologues can be also written in a txt file (one accession per line) and used as input with -hlf parameter. Results with annotation plot, MSA visualisation and sequence logos: Eukaryotes: ATF4 The expression of ATF4 (activating transcription factor) is regulated by two uORFs. After translation of the first uORF1, ribosomes are normally able to reinitiate translation at a downstream uORF2 after rebinding the initiating ternary complex ( eIF2-GTP-Met-tRNA ). Reduced levels of the ternary complex during stress conditions leads to the ribosome scanning through the uORF2 start codon and instead reinitiating at the ATF4 uORF. uORF4u has two modes: bacteria (set as default) and eukaryotes that defined by pre-made configuration files. Archaea mode (no SD sequence annotation + retrieving DNA sequences as well due the absence of mRNAs data) will be presented soon or can be set manually within config files. The main differences between two modes: 1. For eukaryotes there is no SD sequence annotation step and corresponding uORF filtering. 2. While sequences retrieving for found homologues we take only mRNAs (the tool uses regex to perform that which is set by refseq_sequences_regex in the config files. For eukaryotes it's set as '^[NX]M_.*' that means that only sequences with ids that start with NM_ or XM_ (mRNAs) will be taken in the analysis). Using a single RefSeq protein accession number as input Similarly to the bacteria' example, firstly we can use a single protein accession number as input: uorf4u -an NP_877962.1 -c eukaryotes -o ATF4 We used eukaryotes mode by specifying the premade configuration file with -c parameter. uORF4u finds both uORFs and returns (as always) MSA plots ( uORF1 nt , uORF2 nt ), annotation plots ( uORF1 , uORF2 ) and sequence logos. A nucleotide sequence logo for uORF1: Using a list of homologues as input Let's use again a subset of the found homologues to get a compact output. uorf4u -hl NP_001666.2 XP_036720744.1 XP_024434925.1 XP_034632036.1 XP_008703764.1 XP_034983127.1 XP_019400505.1 XP_003989324.2 XP_003419800.1 XP_019302483.1 XP_047407736.1 XP_032062344.1 -c eukaryotes Note : unfortunately, animal's emojis were added manually. Using a fasta file with sequences as input You can use a fasta file with sequences as input as well. Command example with a fasta file obtained from previous run as input: uorf4u -fa ATF4/upstream_sequences.fa -c eukaryotes It is useful to note that when using nucleotide sequences as input, uORF4u can be used as a general conserved ORF search tool, that is, not necessarily upstream of any particular mORF. But be carefull with this mode, recommended range of sequences' length ~100-1000nt and number of sequences: 10-1000. uORF4u was not designed to perform conservation analysis on chromosome' size set of sequences.","title":"Example-driven guide"},{"location":"ExampleDrivenGuide/cmd_guide/#example-driven-guide","text":"Here we show several usage examples of the uorf4u command-line interface for two well-known uORFs: ermCL (bacteria) and ATF4 (eukaryotes). (See review articles about uORFs in prokaryotes and eukaryotes: Ito et.al. 2013 and Dever et.al. 2020 . Before start: The necessary sample data as well as adjustable tool' configuration files are provided by uorf4u at the post-install step: uorf4u --data If you work on a Linux machine after installation you should run: uorf4u --linux This command replaces the tools paths (maft) in the pre-made config files from the MacOS' version (default) to the Linux'.","title":"Example-driven guide"},{"location":"ExampleDrivenGuide/cmd_guide/#bacteria-ermcl","text":"Expression of 23S rRNA methyltransferase ermC is regulated by translational attenuation: ribosome stalling on the ermC uORF (named ermCL ) is inducible by erythromycin. The arresst alters the regional mRNA structure, exposing the ermC SD sequence and allowing translation of the ermC ORF. Using a single RefSeq protein accession number as input To test whether uORF4u will find the ermCL we can use only the RefSeq accession number of ermC protein as input which is WP_001003263.1 . uorf4u -an WP_001003263.1 -ul 400 -o ErmC , All arguments, except -an , were optional. -ul was used to overrides the upstream region length to retrieve (default: 500). Output folder name can be set with -o parameter (default: uorf4u_{current_date}). uORF4u finds the expected ermCL and returns one set of conserved uORFs. Output contains MSA plot , annotation plot , and sequence logo: Using a list of homologues as input Alternatively, a list of homologues can be used as input. This is important for allowing a user to decide the breadth and depth of the search. In addition, it can be useful for creating compact output figures that can be used in articles. For such demonstration, we have chosen several ermC proteins from the previous run and used them as input: uorf4u -hl WP_202338192.1 WP_102227852.1 WP_034984371.1 WP_159316313.1 WP_095341278.1 WP_150861853.1 WP_011382144.1 WP_081624258.1 -c bacteria -annot -ul 400 where -annot parameter was used to show on annotation plot known ORFs annotated in the NCBI (shown with blue outlines). We also used bacteria mode by specifying the premade configuration file with -c parameter. Note : List of homologues can be also written in a txt file (one accession per line) and used as input with -hlf parameter. Results with annotation plot, MSA visualisation and sequence logos:","title":"Bacteria: ermCL"},{"location":"ExampleDrivenGuide/cmd_guide/#eukaryotes-atf4","text":"The expression of ATF4 (activating transcription factor) is regulated by two uORFs. After translation of the first uORF1, ribosomes are normally able to reinitiate translation at a downstream uORF2 after rebinding the initiating ternary complex ( eIF2-GTP-Met-tRNA ). Reduced levels of the ternary complex during stress conditions leads to the ribosome scanning through the uORF2 start codon and instead reinitiating at the ATF4 uORF. uORF4u has two modes: bacteria (set as default) and eukaryotes that defined by pre-made configuration files. Archaea mode (no SD sequence annotation + retrieving DNA sequences as well due the absence of mRNAs data) will be presented soon or can be set manually within config files. The main differences between two modes: 1. For eukaryotes there is no SD sequence annotation step and corresponding uORF filtering. 2. While sequences retrieving for found homologues we take only mRNAs (the tool uses regex to perform that which is set by refseq_sequences_regex in the config files. For eukaryotes it's set as '^[NX]M_.*' that means that only sequences with ids that start with NM_ or XM_ (mRNAs) will be taken in the analysis). Using a single RefSeq protein accession number as input Similarly to the bacteria' example, firstly we can use a single protein accession number as input: uorf4u -an NP_877962.1 -c eukaryotes -o ATF4 We used eukaryotes mode by specifying the premade configuration file with -c parameter. uORF4u finds both uORFs and returns (as always) MSA plots ( uORF1 nt , uORF2 nt ), annotation plots ( uORF1 , uORF2 ) and sequence logos. A nucleotide sequence logo for uORF1: Using a list of homologues as input Let's use again a subset of the found homologues to get a compact output. uorf4u -hl NP_001666.2 XP_036720744.1 XP_024434925.1 XP_034632036.1 XP_008703764.1 XP_034983127.1 XP_019400505.1 XP_003989324.2 XP_003419800.1 XP_019302483.1 XP_047407736.1 XP_032062344.1 -c eukaryotes Note : unfortunately, animal's emojis were added manually. Using a fasta file with sequences as input You can use a fasta file with sequences as input as well. Command example with a fasta file obtained from previous run as input: uorf4u -fa ATF4/upstream_sequences.fa -c eukaryotes It is useful to note that when using nucleotide sequences as input, uORF4u can be used as a general conserved ORF search tool, that is, not necessarily upstream of any particular mORF. But be carefull with this mode, recommended range of sequences' length ~100-1000nt and number of sequences: 10-1000. uORF4u was not designed to perform conservation analysis on chromosome' size set of sequences.","title":"Eukaryotes: ATF4"},{"location":"Parameters/cmd_parameters/","text":"\u0421ommand-line parameters POST-INSTALL DATA AND CONFIGURATION --data Creates the uorf4u_data folder in the current working directory. The folder will contain the adjustable configuration file templates, palettes, tables as well as the necessary sample. --linux All Linux user should run it only once after installation. Replaces the tools paths in the premade config files from the MacOS' version [default] to the Linux'. MANDATORY ARGUMENTS -an accession_number Protein's RefSeq accession number. OR -hl accession_number1 [accession_number2, ...] Space separated list of proteins accession numbers which will be used as list of homologous. OR -hlf file.txt Path to a file with list of accession numbers. File format: one accession number per line, no header. OR -fa file.fa Path to a fasta file with upstream sequences. OPTIONAL ARGUMENTS -bh number_of_hits Max number of blastp hits in homologous searching. -bid identity_cutoff [0-1] BlastP searching cutoff for hit's identity to your query protein. -mna number_f_assemblies Max number of assemblies to take into analysis for each protein. If there are more sequences in the identical protein database then random sampling will be used. -al path_to/assemblies_list.tsv Path to an assemblies list file. During each run of uorf4u, a tsv table with information about assemblies (from identical protein database, ncbi) for each protein is saved to your output folder (output_dir_name/assemblies_list.tsv). There are cases with multiple assemblies for one protein accession numbers (up to thousands). In case to control assemblies included in the analysis this table can be filtered (simply by removing rows) and then used with this parameter as part of input to the next run. In addition, config file (see config parameters section) has max_number_of_assemblies parameter. It can be used to limit max number of assemblies included in the analysis. In case number of assemblies is more than the cutoff, random sampling will be used to take only subset of them. -annot Retrieve sequences annotation (to be sure that annotated uORFs is not overlapped with a known CDS. -ul length Length of upstream sequences to retrieve. -dl length Length of downstream sequences to retrieve. -asc Include alternative start codons in uORF annotation step. List of alternative start codons are taken from the ncbi genetic code. -nsd Deactivate filtering ORFs by SD sequence presence. [default: True for 'prokaryotes' config and False for 'eukaryotes' config]. -at aa|nt Alignment type used by uorf4u for conserved ORFs searching [default: aa]. -pc cutoff [0-1] A cutoff of presence (number of ORFs in a list/number of sequences) for an ORFs set to be called conserved and returned [default: 0.4, set in the config]. -fast Fast searching mode with less accuracy (>~300 sequences or >~2000 ORFs). -o dirname Output dirname. It will be created if it's not exist. All output dirs will be then created in this folder [default: uorf4u_{current_date}; e.g. uorf4u_2022_07_25-20_41]. -c prokaryotes|eukaryotes|file.cfg Path to a configuration file [default: internal]. MISCELLANEOUS ARGUMENTS -h , --help Show help message and exit. -v , --version Show program version. --debug Provide detailed stack trace for debugging purposes. --quiet Don't show progress messages.","title":"Command-line parameters"},{"location":"Parameters/cmd_parameters/#ommand-line-parameters","text":"POST-INSTALL DATA AND CONFIGURATION --data Creates the uorf4u_data folder in the current working directory. The folder will contain the adjustable configuration file templates, palettes, tables as well as the necessary sample. --linux All Linux user should run it only once after installation. Replaces the tools paths in the premade config files from the MacOS' version [default] to the Linux'. MANDATORY ARGUMENTS -an accession_number Protein's RefSeq accession number. OR -hl accession_number1 [accession_number2, ...] Space separated list of proteins accession numbers which will be used as list of homologous. OR -hlf file.txt Path to a file with list of accession numbers. File format: one accession number per line, no header. OR -fa file.fa Path to a fasta file with upstream sequences. OPTIONAL ARGUMENTS -bh number_of_hits Max number of blastp hits in homologous searching. -bid identity_cutoff [0-1] BlastP searching cutoff for hit's identity to your query protein. -mna number_f_assemblies Max number of assemblies to take into analysis for each protein. If there are more sequences in the identical protein database then random sampling will be used. -al path_to/assemblies_list.tsv Path to an assemblies list file. During each run of uorf4u, a tsv table with information about assemblies (from identical protein database, ncbi) for each protein is saved to your output folder (output_dir_name/assemblies_list.tsv). There are cases with multiple assemblies for one protein accession numbers (up to thousands). In case to control assemblies included in the analysis this table can be filtered (simply by removing rows) and then used with this parameter as part of input to the next run. In addition, config file (see config parameters section) has max_number_of_assemblies parameter. It can be used to limit max number of assemblies included in the analysis. In case number of assemblies is more than the cutoff, random sampling will be used to take only subset of them. -annot Retrieve sequences annotation (to be sure that annotated uORFs is not overlapped with a known CDS. -ul length Length of upstream sequences to retrieve. -dl length Length of downstream sequences to retrieve. -asc Include alternative start codons in uORF annotation step. List of alternative start codons are taken from the ncbi genetic code. -nsd Deactivate filtering ORFs by SD sequence presence. [default: True for 'prokaryotes' config and False for 'eukaryotes' config]. -at aa|nt Alignment type used by uorf4u for conserved ORFs searching [default: aa]. -pc cutoff [0-1] A cutoff of presence (number of ORFs in a list/number of sequences) for an ORFs set to be called conserved and returned [default: 0.4, set in the config]. -fast Fast searching mode with less accuracy (>~300 sequences or >~2000 ORFs). -o dirname Output dirname. It will be created if it's not exist. All output dirs will be then created in this folder [default: uorf4u_{current_date}; e.g. uorf4u_2022_07_25-20_41]. -c prokaryotes|eukaryotes|file.cfg Path to a configuration file [default: internal]. MISCELLANEOUS ARGUMENTS -h , --help Show help message and exit. -v , --version Show program version. --debug Provide detailed stack trace for debugging purposes. --quiet Don't show progress messages.","title":"\u0421ommand-line parameters"},{"location":"Parameters/config_parameters/","text":"Configuration file parameters uorf4u configuration file allows detailed customization of the tool's parameters. Note: uorf4u has two pre-made configuration files: uorf4u_eukaryotes.cfg and uorf4u_bacteria located in: ./uorftu/uorf4u_data/ folder (internal). By default, 'bacteria' config file is used if no path or name of premade file is specified by a cmd parameter: -c bacteria|eukaryotes|<file.cfg> . You can copy the uorf4u_data folder that contains the config files to your wiking directory with uorf4u --data command and safely edit and use them without affecting 'internal' set of configs. If you want to use a copied config file, use -c path_to_config . ;[General] ncbi_genetic_code_name = Bacterial ; the ncbi genetic code name ('Standard' for eukaryotes' config) ncbi_entrez_email = uorf4u@gmail.com ; e-mail for the NCBI API. upstream_region_length = 500 ; [int or 'all'] Length of upstream region to retrieve. 'all' value is set for eukaryotes config file since by default it uses only mRNAs sequences. (can be overriden by '-ul' cmd parameter). minimal_upstream_region_length = 300 ; [int] minimal upstream region length for sequences to retrieve. If available sequence length to retrieve is shorter then this record won't be taken in the analysis . downstream_region_length = 100 ; [int] downstream region (overlapped with CDS) length to retrieve. (can be overriden by '-dl' cmd parameter). filter_refseq_sequences_by_regex = True ; [bool] use or not regex parameter (below) for filtering the NCBI RefSeq sequences to retrieve. refseq_sequences_regex = ^ N _. ; [regex] that will be used to filter the NCBI RefSeq sequnces. For eukaryotes set as '^[NX]M_. ' that means that only sequences that start with NM_ or XM_ (mRNAs) will be taken in the analysis. max_number_of_assemblies = 1 ; [int] max number of assemblies to take into analysis for each protein. If there are more sequences in the identical protein database then random sampling will be used. (can be overriden by '-mna' cmd parameter). ;[blastp homologous searching] blastp_evalue_cutoff = 1e-5 ; [float] blastp e-value cutoff during the searching for homologs against the RefSeq database. blastp_hit_list_size = 200 ; [int] max number of blastp hits to take in the analysis. blastp_max_number_of_alignments = 1000 ; [int] max number of alignments during the searching (there could be several alignments for 1 hit, see blastp documentation) blastp_pident_to_query_length_cutoff = 0.5 ; [float: 0-1] cutoff for hit's identity to your query protein. ;[ORF annotation] alternative_start_codons = False ; [bool] use or not set of alternative start codons. main_start_codon = ATG ; [str] min_orf_length = 9 ; [int] cutoff for ORFs length during annotation filter_by_sd = True ; [bool] filter annotated ORFs by Shine-Dalgarno sequence prersence. Filtering based on calculation of binding energy between aSD sequence (UCCUCC) and putative SD sequence in an upstream to uAUG window. Energy calculation performed as described here: Yang et.al, 2016 sd_energy_cutoff = -3 ; [float] cutoff for aSD-SD binding energy. sd_window_length = 20 ; [int] length of a region for SD sequence search. check_assembly_annotation = False ; [bool] retrieve or not the NCBI sequences annotation to be sure that annotated uORFs are not overlapped with known CDSs (can be overriden by '-annot' cmd parameter). ;[conserved ORFs searching] fast_searching = auto ; [bool(true or false) or 'auto'] use or not fast searching mode with less accuracy (needed for >~200 sequences or >~2000 ORFs). Can be also set as auto [default]. (can be overriden by '-fast' cmd parameter). fast_searching_fraction_of_initial_genomes = 0.3 ; [bool] fraction of input sequences that will be used as initial step in algorithm searching. Applied only if the fast_searching parameter is True. orf_length_group_range = 0.25 ; [float or int] orf's lengths window within conserved uORFs set can be annotated. If it's a float value [0-1] then the radius of window is a set percentage of the claster's length, while if it's int then the window radius is fixed. orfs_presence_cutoff = 0.5 ; [float] a set of ORFs will be returned only if they were found in a fraction of input sequences larger than this cutoff. paths_identity_cutoff = 0.5 ; [float] if two sets of found ORFs are ovelapped more than this cutoff, then only a set with a higher. score will be returned. (Helps to remove duplicates). max_num_of_initial_genome_iteration = 100 ; [int] similar to the fast_searching_fraction_of_initial_genomes parametr, but used with a normal mode for optimisation. ;[Pairwise alignment] alignment_type = aa ; [nt or aa] alignment type of uORFs during conservation analysis. ; Below listed global alignments parametersduring conservation analysis. uorf4u uses Bio.Align. package to perfome pairwise alignment of uORFs. global_match_score = 1 ; [float] global_mismatch_score = -1 ; [float] global_open_gap_score = -1 ; [float] global_extend_gap_score = -1 ; [float] global_target_end_gap_score = -1 ; [float] global_query_end_gap_score = -1 ; [float] alignment_score_cutoff = 0 ; [float] if a pairwise alignment score is larger than this cutoff then two uORFs are considered as aligned. ;[Multiple Sequence Alignment] consensus_threshold = 0.7 ; [float] treshold for MSA position to consider a nucleotide/amino acid as conserved in consensus sequence building. ;[Paths] ; Pathes to scripts and files used by the tool. {internal} means a folder uorf4u/uorf4u_data in the tool location. ref_energies = {config_path}/energyRef-CCTCCT.json ; aSD-SD energy table downloaded from: Yang et.al, 2016 maft_binary = {config_path}/bin/mafft-mac/mafft.bat palette = {config_path}/palette.txt colors_nt = {config_path}/colors_nt.txt colors_aa = {config_path}/colors_aa.txt ;[Output] sequences_to_write = nt, aa, sd ; [list] type of sequences results for that (logos, MSAs, fasta files) will writetn. nt - nucleotide seqs of uORFs, aa - amino acid seqs, sd - SD seqs (sd is not available for 'eukaryotes' mode) logo_type = both ; [probability, information or both] type of logo, see logomaker package documentation. output_dir = uorf4u_{current_date} ; [str] default name of the output dir. default: uorf4u_{current_date}; e.g. uorf4u_2022_07_25-20_41. (can be overriden by '-o' cmd parameter). ;------------------------ ;Annotation visualisation ;------------------------ ;[General figure parameters] margin = 0.1 gap = 0.03 label_gap = 0.07 orf_height = 0.15 annotation_width = auto mm_per_nt = 0.04 font_regular = {config_path}/fonts/Lato-Regular.ttf font_bold = {config_path}/fonts/Lato-Bold.ttf font_mono = {config_path}/fonts/RobotoMono-Regular.ttf ;[Sequence labels] label_color = #3D3D3D label_color_alpha = 1 label_height_to_orf_height = 0.65 ;[Axis tics] axis_tics_font_size = auto axis_tics_line_width = 0.3 ;[Loci annotations] upstream_seq_line_color = #CECECE upstream_seq_line_color_alpha = 1 upstream_seq_line_width = 0.5 cds_seq_stroke_color = #489143 cds_seq_stroke_color_alpha = 0.8 cds_seq_fill_color = #9ee19b cds_seq_fill_color_alpha = 0.03 orf_line_width = 0.5 conserved_uorfs_stroke_color = #4e4e4e conserved_uorfs_stroke_color_alpha = 1 conserved_uorfs_fill_color = #ee8fb1 conserved_uorfs_fill_color_alpha = 0.6 other_uorfs_stroke_color = #CECECE other_uorfs_stroke_color_alpha = 1 annotated_orf_stroke_color = #3d6f8e annotated_orf_stroke_color_alpha = 1 ;------------------------ ;MSA plot ;------------------------ tile_size = 0.1 tile_stroke = 0.05 char_size = 0.7 label_size = 0.6 tile_alpha = 0.8 logo_alpha = 0.8","title":"Configuration file parameters"},{"location":"Parameters/config_parameters/#configuration-file-parameters","text":"uorf4u configuration file allows detailed customization of the tool's parameters. Note: uorf4u has two pre-made configuration files: uorf4u_eukaryotes.cfg and uorf4u_bacteria located in: ./uorftu/uorf4u_data/ folder (internal). By default, 'bacteria' config file is used if no path or name of premade file is specified by a cmd parameter: -c bacteria|eukaryotes|<file.cfg> . You can copy the uorf4u_data folder that contains the config files to your wiking directory with uorf4u --data command and safely edit and use them without affecting 'internal' set of configs. If you want to use a copied config file, use -c path_to_config . ;[General] ncbi_genetic_code_name = Bacterial ; the ncbi genetic code name ('Standard' for eukaryotes' config) ncbi_entrez_email = uorf4u@gmail.com ; e-mail for the NCBI API. upstream_region_length = 500 ; [int or 'all'] Length of upstream region to retrieve. 'all' value is set for eukaryotes config file since by default it uses only mRNAs sequences. (can be overriden by '-ul' cmd parameter). minimal_upstream_region_length = 300 ; [int] minimal upstream region length for sequences to retrieve. If available sequence length to retrieve is shorter then this record won't be taken in the analysis . downstream_region_length = 100 ; [int] downstream region (overlapped with CDS) length to retrieve. (can be overriden by '-dl' cmd parameter). filter_refseq_sequences_by_regex = True ; [bool] use or not regex parameter (below) for filtering the NCBI RefSeq sequences to retrieve. refseq_sequences_regex = ^ N _. ; [regex] that will be used to filter the NCBI RefSeq sequnces. For eukaryotes set as '^[NX]M_. ' that means that only sequences that start with NM_ or XM_ (mRNAs) will be taken in the analysis. max_number_of_assemblies = 1 ; [int] max number of assemblies to take into analysis for each protein. If there are more sequences in the identical protein database then random sampling will be used. (can be overriden by '-mna' cmd parameter). ;[blastp homologous searching] blastp_evalue_cutoff = 1e-5 ; [float] blastp e-value cutoff during the searching for homologs against the RefSeq database. blastp_hit_list_size = 200 ; [int] max number of blastp hits to take in the analysis. blastp_max_number_of_alignments = 1000 ; [int] max number of alignments during the searching (there could be several alignments for 1 hit, see blastp documentation) blastp_pident_to_query_length_cutoff = 0.5 ; [float: 0-1] cutoff for hit's identity to your query protein. ;[ORF annotation] alternative_start_codons = False ; [bool] use or not set of alternative start codons. main_start_codon = ATG ; [str] min_orf_length = 9 ; [int] cutoff for ORFs length during annotation filter_by_sd = True ; [bool] filter annotated ORFs by Shine-Dalgarno sequence prersence. Filtering based on calculation of binding energy between aSD sequence (UCCUCC) and putative SD sequence in an upstream to uAUG window. Energy calculation performed as described here: Yang et.al, 2016 sd_energy_cutoff = -3 ; [float] cutoff for aSD-SD binding energy. sd_window_length = 20 ; [int] length of a region for SD sequence search. check_assembly_annotation = False ; [bool] retrieve or not the NCBI sequences annotation to be sure that annotated uORFs are not overlapped with known CDSs (can be overriden by '-annot' cmd parameter). ;[conserved ORFs searching] fast_searching = auto ; [bool(true or false) or 'auto'] use or not fast searching mode with less accuracy (needed for >~200 sequences or >~2000 ORFs). Can be also set as auto [default]. (can be overriden by '-fast' cmd parameter). fast_searching_fraction_of_initial_genomes = 0.3 ; [bool] fraction of input sequences that will be used as initial step in algorithm searching. Applied only if the fast_searching parameter is True. orf_length_group_range = 0.25 ; [float or int] orf's lengths window within conserved uORFs set can be annotated. If it's a float value [0-1] then the radius of window is a set percentage of the claster's length, while if it's int then the window radius is fixed. orfs_presence_cutoff = 0.5 ; [float] a set of ORFs will be returned only if they were found in a fraction of input sequences larger than this cutoff. paths_identity_cutoff = 0.5 ; [float] if two sets of found ORFs are ovelapped more than this cutoff, then only a set with a higher. score will be returned. (Helps to remove duplicates). max_num_of_initial_genome_iteration = 100 ; [int] similar to the fast_searching_fraction_of_initial_genomes parametr, but used with a normal mode for optimisation. ;[Pairwise alignment] alignment_type = aa ; [nt or aa] alignment type of uORFs during conservation analysis. ; Below listed global alignments parametersduring conservation analysis. uorf4u uses Bio.Align. package to perfome pairwise alignment of uORFs. global_match_score = 1 ; [float] global_mismatch_score = -1 ; [float] global_open_gap_score = -1 ; [float] global_extend_gap_score = -1 ; [float] global_target_end_gap_score = -1 ; [float] global_query_end_gap_score = -1 ; [float] alignment_score_cutoff = 0 ; [float] if a pairwise alignment score is larger than this cutoff then two uORFs are considered as aligned. ;[Multiple Sequence Alignment] consensus_threshold = 0.7 ; [float] treshold for MSA position to consider a nucleotide/amino acid as conserved in consensus sequence building. ;[Paths] ; Pathes to scripts and files used by the tool. {internal} means a folder uorf4u/uorf4u_data in the tool location. ref_energies = {config_path}/energyRef-CCTCCT.json ; aSD-SD energy table downloaded from: Yang et.al, 2016 maft_binary = {config_path}/bin/mafft-mac/mafft.bat palette = {config_path}/palette.txt colors_nt = {config_path}/colors_nt.txt colors_aa = {config_path}/colors_aa.txt ;[Output] sequences_to_write = nt, aa, sd ; [list] type of sequences results for that (logos, MSAs, fasta files) will writetn. nt - nucleotide seqs of uORFs, aa - amino acid seqs, sd - SD seqs (sd is not available for 'eukaryotes' mode) logo_type = both ; [probability, information or both] type of logo, see logomaker package documentation. output_dir = uorf4u_{current_date} ; [str] default name of the output dir. default: uorf4u_{current_date}; e.g. uorf4u_2022_07_25-20_41. (can be overriden by '-o' cmd parameter). ;------------------------ ;Annotation visualisation ;------------------------ ;[General figure parameters] margin = 0.1 gap = 0.03 label_gap = 0.07 orf_height = 0.15 annotation_width = auto mm_per_nt = 0.04 font_regular = {config_path}/fonts/Lato-Regular.ttf font_bold = {config_path}/fonts/Lato-Bold.ttf font_mono = {config_path}/fonts/RobotoMono-Regular.ttf ;[Sequence labels] label_color = #3D3D3D label_color_alpha = 1 label_height_to_orf_height = 0.65 ;[Axis tics] axis_tics_font_size = auto axis_tics_line_width = 0.3 ;[Loci annotations] upstream_seq_line_color = #CECECE upstream_seq_line_color_alpha = 1 upstream_seq_line_width = 0.5 cds_seq_stroke_color = #489143 cds_seq_stroke_color_alpha = 0.8 cds_seq_fill_color = #9ee19b cds_seq_fill_color_alpha = 0.03 orf_line_width = 0.5 conserved_uorfs_stroke_color = #4e4e4e conserved_uorfs_stroke_color_alpha = 1 conserved_uorfs_fill_color = #ee8fb1 conserved_uorfs_fill_color_alpha = 0.6 other_uorfs_stroke_color = #CECECE other_uorfs_stroke_color_alpha = 1 annotated_orf_stroke_color = #3d6f8e annotated_orf_stroke_color_alpha = 1 ;------------------------ ;MSA plot ;------------------------ tile_size = 0.1 tile_stroke = 0.05 char_size = 0.7 label_size = 0.6 tile_alpha = 0.8 logo_alpha = 0.8","title":"Configuration file parameters"},{"location":"VersionLog/versions/","text":"Version log Ver 0.8.5 - 17 January 2023 Update for web version Ver 0.8.4 - 30 November 2022 Report files were updated. Ver 0.8.3 - 30 November 2022 Minor bugs were fixed. Warning messages were updated. NCBI database parsing was optimised. Ver 0.8.2 - 7 November 2022 xml files and assemblies annotation bugs were fixed. Annotation parsing was optimised. Ver 0.8.1 - 4 November 2022 Large assemblies annotation bug was fixed. Ver 0.8.0 - 2 November 2022 New exceptions control. New cmd parameter ( -pc ). Ver 0.7.0 - 1 November 2022 NCBI database parsing was optimised and became ~10 times faster. Ver 0.6.4 - 31 October 2022 MAFFT version 7.505 was replaced with v. 7.490 since it's more stable. Ver 0.6.3 - 29 October 2022 Entrez.email for the NCBI requests was set. Ver 0.6.2 - 26 October 2022 A problem with xml file writing was fixed. Ver 0.6.1 - 25 October 2022 ! After the NCBI API update all previous version have a bug with identical protein database parsing. The bug was fixed in this version. Ver 0.6.0 - 23 October 2022 New implementation of MSA visualisation Ver 0.5.4 - 13 October 2022 Annotation visualisation' bug was fixed Ver 0.5.3 - 12 October 2022 Minor bugs with pathes were fixed Ver 0.5.2 - 7 October 2022 MSA tool's path bug was fixed. Fast searching now is set as 'auto'. Ver 0.5.1 - 6 October 2022 Now compatible with python3.7 (previous versions were compatible only with python3.8+). Ver 0.5.0 - 4 October 2022 'Eukaryotes' and 'Prokaryotes' mode were introduced. MSA now perfomed with MAFT. New cmd and configs parameters were added. Minor bugs were fixed. Ver 0.4.0 - 30 August 2022 Visualisation of loci annotation was added. Minor bugs were fixed. Ver 0.3.1 - 17 August 2022 New cmd and configs parameters were added. Annotation of uORFs overlapped with the main CDSs was added. Ver 0.3.0 - 7 August 2022 Algorithm of conserved ORFs searching was updated. New configs parameteres were added. Ver 0.2.1 - 5 August 2022 Annotation parsing bug was fixed. Ver 0.2.0 - 5 August 2022 New cmd and configs parameters were added. New classes and methods were developed. Ver 0.1.5 - 31 July 2022 MSA visualisation functions updated. Bugs were fixed. New cmd and configs parameters were added. Ver 0.1 - 27 July 2022 - Initial release.","title":"Version log"},{"location":"VersionLog/versions/#version-log","text":"Ver 0.8.5 - 17 January 2023 Update for web version Ver 0.8.4 - 30 November 2022 Report files were updated. Ver 0.8.3 - 30 November 2022 Minor bugs were fixed. Warning messages were updated. NCBI database parsing was optimised. Ver 0.8.2 - 7 November 2022 xml files and assemblies annotation bugs were fixed. Annotation parsing was optimised. Ver 0.8.1 - 4 November 2022 Large assemblies annotation bug was fixed. Ver 0.8.0 - 2 November 2022 New exceptions control. New cmd parameter ( -pc ). Ver 0.7.0 - 1 November 2022 NCBI database parsing was optimised and became ~10 times faster. Ver 0.6.4 - 31 October 2022 MAFFT version 7.505 was replaced with v. 7.490 since it's more stable. Ver 0.6.3 - 29 October 2022 Entrez.email for the NCBI requests was set. Ver 0.6.2 - 26 October 2022 A problem with xml file writing was fixed. Ver 0.6.1 - 25 October 2022 ! After the NCBI API update all previous version have a bug with identical protein database parsing. The bug was fixed in this version. Ver 0.6.0 - 23 October 2022 New implementation of MSA visualisation Ver 0.5.4 - 13 October 2022 Annotation visualisation' bug was fixed Ver 0.5.3 - 12 October 2022 Minor bugs with pathes were fixed Ver 0.5.2 - 7 October 2022 MSA tool's path bug was fixed. Fast searching now is set as 'auto'. Ver 0.5.1 - 6 October 2022 Now compatible with python3.7 (previous versions were compatible only with python3.8+). Ver 0.5.0 - 4 October 2022 'Eukaryotes' and 'Prokaryotes' mode were introduced. MSA now perfomed with MAFT. New cmd and configs parameters were added. Minor bugs were fixed. Ver 0.4.0 - 30 August 2022 Visualisation of loci annotation was added. Minor bugs were fixed. Ver 0.3.1 - 17 August 2022 New cmd and configs parameters were added. Annotation of uORFs overlapped with the main CDSs was added. Ver 0.3.0 - 7 August 2022 Algorithm of conserved ORFs searching was updated. New configs parameteres were added. Ver 0.2.1 - 5 August 2022 Annotation parsing bug was fixed. Ver 0.2.0 - 5 August 2022 New cmd and configs parameters were added. New classes and methods were developed. Ver 0.1.5 - 31 July 2022 MSA visualisation functions updated. Bugs were fixed. New cmd and configs parameters were added. Ver 0.1 - 27 July 2022 - Initial release.","title":"Version log"}]}